{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4506bb70-0c47-49f0-bd03-cd33a526b086",
   "metadata": {},
   "source": [
    "### Guidance\n",
    "This script will\n",
    "- constrain MCM and GEOS-Chem mechanism\n",
    "- constrain the customized GEOS-Chem mechanism "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6eb9e-bddf-40e4-8c06-d7555bd9a1f0",
   "metadata": {},
   "source": [
    "Version updates:\n",
    "- We update a function to make the plotting process easier.\n",
    "- In version 11, we correct the chemical age using OH exposure/ambient OH concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42836351-fac4-4bf7-bdfb-3da5406cfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire file is exempt from PEP 8 checks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Changing the CWD\n",
    "os.chdir('/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_helper')\n",
    "from data_processing import *\n",
    "from VOCR_reader_cases import *\n",
    "from Plotting_helper import *\n",
    "from ConstantVal import *\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from data_processing import *\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "#from ltsfit.lts_linefit import lts_linefit\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d557a4c7-f573-4476-9a28-5999c459a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# Import modules\n",
    "# ==============\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Changing the CWD\n",
    "os.chdir('/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_helper')\n",
    "from F0AM_reader_MASTER import *\n",
    "from Flight_transect_csv_reader import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def VOCR_reader_cases(Flight_ID, get_smk_conc, get_smk_dil):\n",
    "    # Read koh\n",
    "    file_prefix  = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/OHR/Koh_obs.csv'\n",
    "    df_koh = pd.read_csv(file_prefix, index_col=0, sep='\\t')\n",
    "    ##################\n",
    "    ## WECAN flights\n",
    "    ##################\n",
    "    if 'RF' in Flight_ID:\n",
    "        # Read VOC conc\n",
    "        file_prefix  = f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_analysis_TS/WE-CAN/Model_inputs_prepared/output_data/{Flight_ID}_smk_conc.csv'\n",
    "        df_conc = pd.read_csv(file_prefix, index_col=0)\n",
    "        file_prefix  = f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_analysis_TS/WE-CAN/Model_inputs_prepared/output_data/{Flight_ID}_bkg_conc.csv'\n",
    "        df_bkg = pd.read_csv(file_prefix, index_col=0)\n",
    "\n",
    "        # clean aerosols and others\n",
    "        df_conc = df_conc.drop(['smk_Methane_PICARRO',\n",
    "                                 'smk_OA_AMS', 'smk_HCN_UWCIMS', 'smk_HCN_TOGA', 'smk_HCN_PTR', \n",
    "                                 'smk_NO', 'smk_PAN', 'smk_PPN', 'smk_SO2_UWCIMS',\n",
    "                                 'smk_HONO_UWCIMS', 'smk_HONO_HNO2_PTR', 'smk_O3', \n",
    "                                 'smk_HCl_UWCIMS', 'smk_HNO3_UWCIMS', 'smk_H_C_AMS', 'smk_NO3_AMS', 'smk_O_C_AMS', 'smk_OM_OC_AMS',\n",
    "                                 'smk_CO2_PICARRO_ppb', 'smk_NO2'], axis=1)\n",
    "\n",
    "        df_bkg = df_bkg.drop(['bkg_Methane_PICARRO',\n",
    "                              'bkg_OA_AMS', 'bkg_HCN_UWCIMS', 'bkg_HCN_TOGA', 'bkg_HCN_PTR', \n",
    "                              'bkg_NO', 'bkg_PAN', 'bkg_PPN', 'bkg_SO2_UWCIMS',\n",
    "                              'bkg_HONO_UWCIMS', 'bkg_HONO_HNO2_PTR', 'bkg_O3', \n",
    "                              'bkg_HCl_UWCIMS', 'bkg_HNO3_UWCIMS', 'bkg_H_C_AMS', 'bkg_NO3_AMS', 'bkg_O_C_AMS', 'bkg_OM_OC_AMS',\n",
    "                              'bkg_CO2_PICARRO_ppb', 'bkg_NO2'], axis=1)\n",
    "\n",
    "\n",
    "        # clean AWAS measurement as it is all 0\n",
    "        columns_AWAS_conc = []\n",
    "        columns_AWAS_bkg = []\n",
    "        for col in df_conc.columns:\n",
    "            if 'AWAS' in col:\n",
    "                columns_AWAS_conc.append(col)\n",
    "        df_conc = df_conc.drop(columns_AWAS_conc, axis=1)\n",
    "\n",
    "        for col in df_bkg.columns:\n",
    "            if 'AWAS' in col:\n",
    "                columns_AWAS_bkg.append(col)\n",
    "        df_bkg = df_bkg.drop(columns_AWAS_bkg, axis=1)\n",
    "\n",
    "        # clean TOGA measurement due to the meaningless sampling method in the short interval\n",
    "        columns_TOGA_conc = []\n",
    "        columns_TOGA_bkg = []\n",
    "        for col in df_conc.columns:\n",
    "            if 'TOGA' in col:\n",
    "                columns_TOGA_conc.append(col)\n",
    "        df_conc = df_conc.drop(columns_TOGA_conc, axis=1)\n",
    "        for col in df_bkg.columns:\n",
    "            if 'TOGA' in col:\n",
    "                columns_TOGA_bkg.append(col)\n",
    "        df_bkg = df_bkg.drop(columns_TOGA_bkg, axis=1)\n",
    "\n",
    "        # fix C2H4 in PTR\n",
    "        df_conc['smk_ethene_C2H4_PTR'] = df_conc['smk_CO_QCL']*15.83*0.001 \n",
    "\n",
    "        # get VOCR\n",
    "        time = df_conc.index\n",
    "        VOCR_conc = []\n",
    "        VOCR_bkg = []\n",
    "        names = []\n",
    "        for col in df_conc.columns:\n",
    "            col_rem = col.replace('smk_', '')\n",
    "            if col_rem in df_koh.index:\n",
    "                VOCR_conc.append((df_koh.loc[col_rem].values * df_conc[col]).values*2.46e10)\n",
    "                names.append(col_rem)\n",
    "\n",
    "        for col in df_bkg.columns:\n",
    "            col_rem = col.replace('bkg_', '')\n",
    "            if col_rem in df_koh.index:\n",
    "                VOCR_bkg.append((df_koh.loc[col_rem].values * df_bkg[col]).values*2.46e10)\n",
    "        VOCR_conc_sum = sum(VOCR_conc)\n",
    "        VOCR_bkg_sum  = sum(VOCR_bkg)\n",
    "        # Make VOCR_conc_sum as panda series...\n",
    "        VOCR_conc_sum = pd.Series(VOCR_conc_sum, index=time)\n",
    "\n",
    "        # create the dataframe for VOCR\n",
    "        df_VOCR = pd.DataFrame(VOCR_conc, index=names, columns=time).T\n",
    "        df_VOCR = df_VOCR.reindex(df_VOCR.mean().sort_values(ascending=False).index, axis=1)\n",
    "\n",
    "        # calcualte dilution normalized mixing ratio for observations\n",
    "        delta_CO = df_conc['smk_CO_QCL'] - df_bkg['bkg_CO_QCL'].values[0]\n",
    "        fCO = delta_CO.iloc[0] / delta_CO\n",
    "        b = VOCR_bkg_sum[0]\n",
    "        delta_X = VOCR_conc_sum - b\n",
    "        VOCR_smk_dil = delta_X*fCO\n",
    "\n",
    "\n",
    "    ##################\n",
    "    ## FIREX-AQ\n",
    "    ##################\n",
    "    # FIREX-AQ fires: this might be slighly more complex than reading csv files\n",
    "    if 'FN' in Flight_ID:\n",
    "        file =  f'/glade/u/home/lixujin/matlab/F0AM-4.2.1/Setups/Examples/Lixu/FIREX-AQ/output_data/FIREXAQ_dilution_correctedMCMv331_base{Flight_ID}.mat'\n",
    "\n",
    "        df_obs_bkg = get_df_specs(file_name=file, spec_list = ['CO'], \n",
    "                            GC_setting=False, MCM_setting=True, get_conc=False) \n",
    "\n",
    "        # reading in chem input data\n",
    "        if Flight_ID == 'FN19': F0AM_model_file_chem =  '/glade/u/home/lixujin/matlab/F0AM-4.2.1/Setups/Examples/Lixu/FIREX-AQ/FN19_Blackwater_20190830/ChemInput_avg_FN19Blackwater_20200513.mat' \n",
    "        if Flight_ID == 'FN06': F0AM_model_file_chem =  '/glade/u/home/lixujin/matlab/F0AM-4.2.1/Setups/Examples/Lixu/FIREX-AQ/FN6_WilliamsFlat_20190803/ChemInput_avg_FN06WF_20200515.mat' \n",
    "        mod_struc_chem = scipy.io.loadmat(F0AM_model_file_chem)\n",
    "        data_dummy = []\n",
    "        names = []\n",
    "        for key in list(mod_struc_chem.keys()):\n",
    "            if len(mod_struc_chem[key])==4 or len(mod_struc_chem[key])==14: \n",
    "                data_dummy.append(mod_struc_chem[key])\n",
    "                names.append(key)\n",
    "\n",
    "        # mapping names in to the standard form   \n",
    "        names_FIREXAQ2std = {'AceticAcid': 'Acetic acid',\n",
    "                             'Acrylicacid': 'Acrylic acid',\n",
    "                             'BenzeneDiol': 'Benzene Diol',\n",
    "                             'FormicAcid': 'Formic acid', \n",
    "                             'MaleicAnhydride': 'Maleic Anhydride',\n",
    "                             'acetylene': 'Acetylene',\n",
    "                             'butenes': 'Butenes',\n",
    "                             'ethene': 'C2H4',\n",
    "                             'hydroxyacetone': 'Hydroxyacetone',\n",
    "                             'methylacetate': 'Methylacetate',\n",
    "                             'MethylFuran': 'Methylfuran',\n",
    "                             'MethylFurfural': 'Methylfurfural'}\n",
    "        names = [names_FIREXAQ2std.get(key, key) for key in names]\n",
    "\n",
    "        df_obs_smk = pd.DataFrame(np.hstack(data_dummy), columns = names)\n",
    "\n",
    "        # set up index for the dataframe\n",
    "        time = df_obs_smk['TimeDownwind_s']\n",
    "        df_obs_smk = df_obs_smk.drop('TimeDownwind_s', axis = 1)\n",
    "        df_obs_smk.index = (time+580)/60 # convert second to min\n",
    "        \n",
    "        # adding values for lumping compounds\n",
    "        df_obs_smk.loc[:, 'NOx'] = df_obs_smk.loc[:, 'NO'] +  df_obs_smk.loc[:, 'NO2']    \n",
    "        df_obs_smk.loc[:, 'Lumped C>=3 alkenes'] = df_obs_smk.loc[:, 'Propene'] +  df_obs_smk.loc[:, 'Butenes'] +  df_obs_smk.loc[:, 'Pentene_methylbutene']\n",
    "\n",
    "        # Create dataframe based on what Permar had\n",
    "        file_prefix  = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/OHR/ER_Permar.csv'\n",
    "        df_ER_permar = pd.read_csv(file_prefix, index_col=0, sep='\\t').T\n",
    "        names = df_ER_permar.columns\n",
    "        df_dummy = pd.DataFrame(columns=names) # Note that there is no row data inserted.\n",
    "        for col in names:\n",
    "            df_dummy[col] = df_obs_smk['CO']*df_ER_permar[col].values/1000.0\n",
    "\n",
    "        # delete old and update new data\n",
    "        df_dummy['ACETALDEHYDE_C2H4O_PTR'] = df_obs_smk['Acetaldehyde']\n",
    "        df_dummy['acetic_acid_C2H4O2_PTR'] = df_obs_smk['Acetic acid']\n",
    "        df_dummy['ACETONE_C3H6O_PTR'] = df_obs_smk['Acetone']\n",
    "        df_dummy['ACETONITRILE_C2H3N_PTR'] = df_obs_smk['Acetonitrile']\n",
    "        df_dummy['acrolein_C3H4O_PTR'] = df_obs_smk['Acrolein']\n",
    "        df_dummy['benzaldehyde_C7H6O_PTR'] = df_obs_smk['Benzaldehyde']\n",
    "        df_dummy['2_3_butanedione_C4H6O2_PTR'] = df_obs_smk['Butanedione']\n",
    "        df_dummy['o_cresol_C7H8O_PTR'] = df_obs_smk['Cresol']\n",
    "        df_dummy['2_5_dimethyl_furan_C6H8O'] = df_obs_smk['Dimethylfuran']\n",
    "        df_dummy['ETHANOL_C2H6O_PTR'] = df_obs_smk['Ethanol']\n",
    "        df_dummy['o_cresol_C7H8O_PTR'] = df_obs_smk['Cresol']\n",
    "        df_dummy['formaldehyde_CH2O_PTR'] = df_obs_smk['Formaldehyde']\n",
    "        df_dummy['formic_acid_CH2O2_PTR'] = df_obs_smk['Formic acid']\n",
    "        df_dummy['FURAN_C4H4O_PTR'] = df_obs_smk['Furan']\n",
    "        df_dummy['2_3H_furanone_C4H4O2_PTR'] = df_obs_smk['Furanone']\n",
    "        df_dummy['2_FURALDEHYDE_C5H4O2_PTR'] = df_obs_smk['Furfural']\n",
    "        df_dummy['glyoxal_C2H2O2_PTR'] = df_obs_smk['Glyoxal']\n",
    "        df_dummy['guaiacol_C7H8O2_PTR'] = df_obs_smk['Guaiacol']\n",
    "        df_dummy['ISOPRENE_C5H8_PTR'] = df_obs_smk['Isoprene']\n",
    "        df_dummy['MACR_MVK_C4H6O_PTR'] = df_obs_smk['MVK'] + df_obs_smk['MACR']\n",
    "        df_dummy['MEK_C4H8O_PTR'] = df_obs_smk['MEK']\n",
    "        df_dummy['maleic_anhydride_C4H2O3_PTR'] = df_obs_smk['Maleic Anhydride']\n",
    "        df_dummy['METHANOL_CH3OH_PTR'] = df_obs_smk['Methanol']\n",
    "        df_dummy['2_METHYLFURAN_C5H6O_PTR'] = df_obs_smk['Methylfuran']\n",
    "        df_dummy['5_METHYLFURFURAL_C6H6O2_PTR'] = df_obs_smk['Methylfurfural']\n",
    "        df_dummy['methyl_glyoxal_C3H4O2_PTR'] = df_obs_smk['Methylglyoxal']\n",
    "        df_dummy['MONOTERPENES_C10H16_PTR'] = df_obs_smk['Monoterpenes']\n",
    "        df_dummy['pentene_C5H10_PTR'] = df_obs_smk['Pentene_methylbutene']\n",
    "        df_dummy['phenol_C6H6O_PTR'] = df_obs_smk['Phenol']\n",
    "        df_dummy['propene_C3H6_PTR'] = df_obs_smk['Propene']\n",
    "        df_dummy['styrene_C8H8_PTR'] = df_obs_smk['Styrene']\n",
    "        df_dummy['TOLUENE_C7H8_PTR'] = df_obs_smk['Toluene']\n",
    "        df_dummy['1_BUTENE_PTR'] = df_obs_smk['Butenes']\n",
    "        df_dummy['ethene_C2H4_PTR'] = df_obs_smk['C2H4']\n",
    "        df_dummy['hydroxyacetone_C3H6O2_PTR'] = df_obs_smk['Hydroxyacetone']\n",
    "\n",
    "        # calcluate VOCR\n",
    "        # get VOCR\n",
    "        time = df_dummy.index\n",
    "        VOCR_conc = []\n",
    "        names = []\n",
    "        for col in df_dummy.columns:\n",
    "            VOCR_conc.append((df_koh.loc[col].values * df_dummy[col]).values*2.46e10)\n",
    "            names.append(col)\n",
    "\n",
    "        # create the dataframe for VOCR\n",
    "        df_VOCR = pd.DataFrame(VOCR_conc, index=names, columns=time).T\n",
    "        df_VOCR = df_VOCR.reindex(df_VOCR.mean().sort_values(ascending=False).index, axis=1)\n",
    "        df_VOCR.replace(np.nan,0)\n",
    "\n",
    "        # sum the dataframe\n",
    "        VOCR_conc_sum = df_VOCR.sum(axis = 1)\n",
    "\n",
    "        # ============================================================\n",
    "        # calcualte dilution normalized mixing ratio for observations\n",
    "        # ============================================================\n",
    "        delta_CO = df_obs_smk['CO'] - df_obs_bkg['CO'].values[0]\n",
    "        fCO = delta_CO.iloc[0] / delta_CO\n",
    "        b = 0\n",
    "        delta_X = VOCR_conc_sum - b\n",
    "        VOCR_smk_dil = delta_X*fCO\n",
    "\n",
    "    ##################\n",
    "    ## DISCOVER-AQ\n",
    "    ##################\n",
    "    if Flight_ID == 'P-3B':\n",
    "        F0AM_model_file = '/glade/u/home/lixujin/matlab/F0AM-4.2.1/Setups/Examples/Lixu/P-3B/LagrangianPlumeData_Extrapolated.mat'\n",
    "        mod_struc = scipy.io.loadmat(F0AM_model_file)\n",
    "        # ==============\n",
    "        # Variable names\n",
    "        # ==============\n",
    "        var_names = []\n",
    "        # varaible in the data\n",
    "        dtype_names = [('P', 'O'), ('T', 'O'), ('TIME', 'O'), ('RH', 'O'), ('SZA', 'O'), ('CH4', 'O'), ('NO', 'O'), ('NO2', 'O'), ('O3', 'O'), ('CO2', 'O'), ('CO', 'O'), ('HCHO', 'O'), ('HONO', 'O'), ('CH3CHO', 'O'), ('C3H6', 'O'), ('BENZENE', 'O'), ('FURAN', 'O'), ('C5H8', 'O'), ('CH3COCH3', 'O'), ('HCOOH', 'O'), ('CH3CO2H', 'O'), ('BIACET', 'O'), ('MVK', 'O'), ('MGLYOX', 'O'), ('FURFURAL', 'O'), ('ACETOL', 'O'), ('JNO2', 'O'), ('CH3OH', 'O'), ('DIL1', 'O'), ('jcorr', 'O'), ('Sol', 'O'), ('MEFURAN', 'O'), ('MALANHY', 'O'), ('C4H4O3', 'O'), ('FURANONE', 'O'), ('PHENOL', 'O'), ('CATECHOL', 'O'), ('STYRENE', 'O'), ('CRESOL', 'O'), ('TIME_EXT', 'O'), ('CO_EXT', 'O'), ('H2O', 'O')]\n",
    "        for dname, tmp in dtype_names:\n",
    "            var_names.append(dname)\n",
    "        # remove the inconsistent data\n",
    "        var_names.remove(var_names[30])\n",
    "\n",
    "        # ==============\n",
    "        # Variable data\n",
    "        # ==============\n",
    "        # retrieve the irregular information first\n",
    "        loc_date = mod_struc['DAQ'].item()[30]\n",
    "        lat, lon, alt = loc_date.item()[0][0][0], loc_date.item()[1][0][0], loc_date.item()[2][0][0]\n",
    "        startTime, updateTime =  loc_date.item()[3][0][0], loc_date.item()[4][0][0]\n",
    "        # other data\n",
    "        var_data = []\n",
    "        ct = 0\n",
    "        for ele in mod_struc['DAQ'].item():\n",
    "            if ct != 30: \n",
    "                ele = [item for sublist in ele for item in sublist]\n",
    "                var_data.append(ele)\n",
    "            # increment the pointer\n",
    "            ct += 1 \n",
    "        # ================================================\n",
    "        # Prepare  data\n",
    "        # Only for model input but not for data analysis \n",
    "        # ================================================\n",
    "        # Met data: get ind where len of element is 65\n",
    "        met_indices     = [i for i, seq in enumerate(var_data) if len(seq) == 65]\n",
    "        met_data_list   = [var_data[i]             for i in met_indices]\n",
    "        met_names       = [var_names[i]             for i in met_indices]\n",
    "    \n",
    "        # build DataFrame (variables → columns, time → index)\n",
    "        df_met = pd.DataFrame(met_data_list, index=met_names).T\n",
    "        # set time index (seconds → minutes)\n",
    "        df_met.index = df_met['TIME_EXT'] / 60\n",
    "        df_met      = df_met.drop('TIME_EXT', axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "        # smk data: get ind where len of element is 15\n",
    "        smk_indices     = [i for i, seq in enumerate(var_data) if len(seq) == 15]\n",
    "        smk_data_list   = [var_data[i]               for i in smk_indices]\n",
    "        smk_names       = [var_names[i]               for i in smk_indices]\n",
    "    \n",
    "        df_obs_smk = pd.DataFrame(smk_data_list, index=smk_names).T\n",
    "        df_obs_smk.index = df_obs_smk['TIME'] / 60\n",
    "        df_obs_smk      = df_obs_smk.drop('TIME', axis=1)\n",
    "\n",
    "\n",
    "        # rename the column names\n",
    "        df_obs_smk = df_obs_smk.rename(columns={\"HCHO\":\"Formaldehyde\", \"CH3CHO\": \"Acetaldehyde\", \"BENZENE\":\"Benzene\", \n",
    "                                                \"FURAN\":\"Furan\", \"C5H8\": \"Isoprene\", \n",
    "                                                \"HCOOH\": \"Formic acid\", \"CH3CO2H\": \"Acetic acid\", \"BIACET\": \"2,3-butanedione\",\n",
    "                                                \"MGLYOX\": \"Methylglyoxal\", \"FURFURAL\": \"Furfural\", \"ACETOL\": \"Hydroxyacetone\", \n",
    "                                                \"CH3OH\": \"Methanol\", \"MEFURAN\": \"Methylfuran\", \"MALANHY\": \"Maleic Anhydride\", \n",
    "                                                \"C4H4O3\": \"5-hydroxy-2(5H)-furanone\", \"FURANONE\": \"Furanone\", \"PHENOL\": \"Phenol\", \n",
    "                                                \"CATECHOL\": \"Catechol\", \"STYRENE\": \"Styrene\", \"CRESOL\": \"Cresol\"})\n",
    "\n",
    "        # Using the ratio to scale up ethene, propanal, MACR, MVK, acetone, dimethylfuran, methylfurfural, Phenol, Catechol, Cresol\n",
    "        df_obs_smk['Ethene']                = df_obs_smk['C3H6']\n",
    "        df_obs_smk['propanal'] = df_obs_smk['CH3COCH3'] * 0.22\n",
    "        df_obs_smk['Methacrolein']          = df_obs_smk['MVK'] * 0.5\n",
    "        df_obs_smk['MVK']   = df_obs_smk['MVK'] * 0.5\n",
    "        df_obs_smk['Acetone']               = df_obs_smk['CH3COCH3'] * 0.78\n",
    "        #df_obs_smk['Dimethylfuran']         = df_obs_smk['Methylfuran'] * 0.5\n",
    "        df_obs_smk['Methylfurfural']        = df_obs_smk['Catechol'] * 0.5\n",
    "        df_obs_smk['Phenol']                = df_obs_smk['Phenol'] * 1.05\n",
    "        df_obs_smk['Catechol']              = df_obs_smk['Catechol'] * 0.5\n",
    "        df_obs_smk['Cresol']                = df_obs_smk['Cresol'] * 1.5\n",
    "        df_obs_smk['NOx'] = df_obs_smk['NO'] + df_obs_smk['NO2']\n",
    "\n",
    "        # drop some columns that are no needed.\n",
    "        #df_obs_smk = df_obs_smk.drop(['TIME', 'DIL1'], axis = 1)\n",
    "        df_obs_smk = df_obs_smk.drop(['CH4', 'CO2', 'C3H6', 'Benzene', 'Methanol', 'Ethene', 'CH3COCH3',\n",
    "                                      '5-hydroxy-2(5H)-furanone'], axis = 1)\n",
    "        df_obs_smk = df_obs_smk.drop(['NO', 'NO2', 'O3', 'NOx', 'HONO'], axis=1)\n",
    "\n",
    "        # Create dataframe based on what Permar had\n",
    "        file_prefix  = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/OHR/ER_Permar.csv'\n",
    "        df_ER_permar = pd.read_csv(file_prefix, index_col=0, sep='\\t').T\n",
    "        names = df_ER_permar.columns\n",
    "        df_dummy = pd.DataFrame(columns=names) # Note that there is no row data inserted.\n",
    "        for col in names:\n",
    "            df_dummy[col] = df_obs_smk['CO']*df_ER_permar[col].values/1000.0\n",
    "        # delete old and update new data\n",
    "        df_dummy['formaldehyde_CH2O_PTR'] = df_obs_smk['Formaldehyde']\n",
    "        df_dummy['ACETALDEHYDE_C2H4O_PTR'] = df_obs_smk['Acetaldehyde']\n",
    "        df_dummy['FURAN_C4H4O_PTR'] = df_obs_smk['Furan']\n",
    "        df_dummy['ISOPRENE_C5H8_PTR'] = df_obs_smk['Isoprene']\n",
    "        df_dummy['CH2O2_UWCIMS'] = df_obs_smk['Formic acid']\n",
    "        df_dummy['acetic_acid_C2H4O2_PTR'] = df_obs_smk['Acetic acid']\n",
    "        df_dummy['2_3_butanedione_C4H6O2_PTR'] = df_obs_smk['2,3-butanedione']\n",
    "        df_dummy['MACR_MVK_C4H6O_PTR'] = df_obs_smk['MVK'] + df_obs_smk['Methacrolein']\n",
    "        df_dummy['methyl_glyoxal_C3H4O2_PTR'] = df_obs_smk['Methylglyoxal']\n",
    "        df_dummy['2_FURALDEHYDE_C5H4O2_PTR'] = df_obs_smk['Furfural']\n",
    "        df_dummy['hydroxyacetone_C3H6O2_PTR'] = df_obs_smk['Hydroxyacetone']\n",
    "        df_dummy['2_METHYLFURAN_C5H6O_PTR'] = df_obs_smk['Methylfuran']\n",
    "        df_dummy['maleic_anhydride_C4H2O3_PTR'] = df_obs_smk['Maleic Anhydride']\n",
    "        df_dummy['2_3H_furanone_C4H4O2_PTR'] = df_obs_smk['Furanone']\n",
    "        df_dummy['phenol_C6H6O_PTR'] = df_obs_smk['Phenol']\n",
    "        df_dummy['5_METHYLFURFURAL_C6H6O2_PTR'] = df_obs_smk['Catechol'] + df_obs_smk['Methylfurfural']\n",
    "        df_dummy['styrene_C8H8_PTR'] = df_obs_smk['Styrene']\n",
    "        df_dummy['o_cresol_C7H8O_PTR'] = df_obs_smk['Cresol']\n",
    "        df_dummy['ACETONE_C3H6O_PTR'] = df_obs_smk['Acetone']\n",
    "\n",
    "        # get background value\n",
    "        file =  '/glade/u/home/lixujin/matlab/F0AM-4.2.1/Setups/Examples/Lixu/FIREX-AQ/output_data/FIREXAQ_dilution_correctedMCMv331_noFURFN19.mat' \n",
    "        spec_total = df_obs_smk.columns\n",
    "        df_obs_bkg = get_df_specs(file_name=file, spec_list = spec_total, \n",
    "                            GC_setting=False, MCM_setting=True, get_conc=False) \n",
    "        df_dummy_bkg = pd.DataFrame(columns=names) # Note that there is no row data inserted.\n",
    "        # delete old and update new data\n",
    "        df_dummy_bkg['formaldehyde_CH2O_PTR'] = df_obs_bkg['Formaldehyde'].iloc[0:1]\n",
    "        df_dummy_bkg['ACETALDEHYDE_C2H4O_PTR'] = df_obs_bkg['Acetaldehyde'].iloc[0:1]\n",
    "        df_dummy_bkg['FURAN_C4H4O_PTR'] = df_obs_bkg['Furan'].iloc[0:1]\n",
    "        df_dummy_bkg['ISOPRENE_C5H8_PTR'] = df_obs_bkg['Isoprene'].iloc[0:1]\n",
    "        df_dummy_bkg['CH2O2_UWCIMS'] = df_obs_bkg['Formic acid'].iloc[0:1]\n",
    "        df_dummy_bkg['acetic_acid_C2H4O2_PTR'] = df_obs_bkg['Acetic acid'].iloc[0:1]\n",
    "        df_dummy_bkg['2_3_butanedione_C4H6O2_PTR'] = df_obs_bkg['2,3-butanedione'].iloc[0:1]\n",
    "        df_dummy_bkg['MACR_MVK_C4H6O_PTR'] = df_obs_bkg['MVK'][0:1]+ df_obs_bkg['Methacrolein'].iloc[0:1]\n",
    "        df_dummy_bkg['methyl_glyoxal_C3H4O2_PTR'] = df_obs_bkg['Methylglyoxal'].iloc[0:1]\n",
    "        df_dummy_bkg['2_FURALDEHYDE_C5H4O2_PTR'] = df_obs_bkg['Furfural'].iloc[0:1]\n",
    "        df_dummy_bkg['hydroxyacetone_C3H6O2_PTR'] = df_obs_bkg['Hydroxyacetone'].iloc[0:1]\n",
    "        df_dummy_bkg['2_METHYLFURAN_C5H6O_PTR'] = df_obs_bkg['Methylfuran'].iloc[0:1]\n",
    "        df_dummy_bkg['maleic_anhydride_C4H2O3_PTR'] = df_obs_bkg['Maleic Anhydride'].iloc[0:1]\n",
    "        df_dummy_bkg['2_3H_furanone_C4H4O2_PTR'] = df_obs_bkg['Furanone'].iloc[0:1]\n",
    "        df_dummy_bkg['phenol_C6H6O_PTR'] = df_obs_bkg['Phenol'].iloc[0:1]\n",
    "        df_dummy_bkg['5_METHYLFURFURAL_C6H6O2_PTR'] = df_obs_bkg['Catechol'].iloc[0:1]\n",
    "        df_dummy_bkg['styrene_C8H8_PTR'] = df_obs_bkg['Styrene'].iloc[0:1]\n",
    "        df_dummy_bkg['o_cresol_C7H8O_PTR'] = df_obs_bkg['Cresol'].iloc[0:1]\n",
    "        df_dummy_bkg['ACETONE_C3H6O_PTR'] = df_obs_bkg['Acetone'].iloc[0:1]\n",
    "\n",
    "        # calcluate VOCR\n",
    "        # get VOCR\n",
    "        time = df_dummy.index\n",
    "        VOCR_conc = []\n",
    "        VOCR_bkg  = []\n",
    "        names = []\n",
    "        for col in df_dummy.columns:\n",
    "            VOCR_conc.append((df_koh.loc[col].values * df_dummy[col]).values*2.46e10)\n",
    "            VOCR_bkg.append((df_koh.loc[col].values * df_dummy_bkg[col]).values*2.46e10)\n",
    "            names.append(col)\n",
    "\n",
    "        # create the dataframe for VOCR\n",
    "        df_VOCR = pd.DataFrame(VOCR_conc, index=names, columns=time).T\n",
    "        df_VOCR = df_VOCR.reindex(df_VOCR.mean().sort_values(ascending=False).index, axis=1)\n",
    "        df_VOCR.replace(np.nan,0)\n",
    "\n",
    "\n",
    "        df_VOCR_bkg = pd.DataFrame(VOCR_bkg, index=names).T\n",
    "        df_VOCR_bkg = df_VOCR_bkg.reindex(df_VOCR_bkg.mean().sort_values(ascending=False).index, axis=1)\n",
    "        df_VOCR_bkg.replace(np.nan,0)\n",
    "\n",
    "\n",
    "        # sum the dataframe\n",
    "        VOCR_conc_sum = df_VOCR.sum(axis = 1)\n",
    "        VOCR_bkg_sum = df_VOCR_bkg.sum(axis = 1)\n",
    "        # ============================================================\n",
    "        # calcualte dilution normalized mixing ratio for observations\n",
    "        # ============================================================\n",
    "        delta_CO = df_obs_smk['CO'] - df_obs_bkg['CO'].values[0]\n",
    "        fCO = delta_CO.iloc[0] / delta_CO\n",
    "        b = VOCR_bkg_sum[0]\n",
    "        delta_X = VOCR_conc_sum - b\n",
    "        VOCR_smk_dil = delta_X*fCO\n",
    "    # compile data\n",
    "    df_VOCR_smk_conc = pd.DataFrame(VOCR_conc_sum).rename(columns={0: 'Observation'})\n",
    "    df_VOCR_smk_dil = pd.DataFrame(VOCR_smk_dil).rename(columns={0: 'Observation'})\n",
    "    \n",
    "    # standardrize the observation index\n",
    "    df_VOCR_smk_conc.index = pd.Series(df_VOCR_smk_conc.index).round(2)\n",
    "    df_VOCR_smk_dil.index = pd.Series(df_VOCR_smk_dil.index).round(2)\n",
    "\n",
    "    if get_smk_conc: return df_VOCR_smk_conc\n",
    "    if get_smk_dil:  return df_VOCR_smk_dil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "601d3254-5b00-4d37-881a-6429e68202ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify each row\n",
    "def group_above_threshold(df, threshold, group_by_column):\n",
    "    \"\"\"\n",
    "    Groups and aggregates DataFrame entries above a specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to be processed.\n",
    "    threshold (float): Threshold above which the DataFrame will be grouped.\n",
    "    group_by_column (str): Column name to use for grouping.\n",
    "    aggregation (str): Aggregation function (e.g., 'mean', 'sum').\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Processed DataFrame with entries above the threshold grouped.\n",
    "    \"\"\"\n",
    "    # Split the DataFrame\n",
    "    df_below_or_equal_threshold = df[df.index <= threshold]\n",
    "    df_above_threshold = df[df.index > threshold]\n",
    "    \n",
    "    # Group and aggregate the portion of the DataFrame with index > threshold\n",
    "    data_above_threshold = df_above_threshold.mean()\n",
    "    df_above_threshold   = (pd.DataFrame(data_above_threshold)).transpose()\n",
    "\n",
    "    # Rename the index\n",
    "    df_above_threshold = df_above_threshold.rename(index={0: f'> {threshold} hour'})\n",
    "    # Concatenate the ungrouped and grouped parts\n",
    "    final_df = pd.concat([df_below_or_equal_threshold, df_above_threshold])\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def reorder_legend(ax, desired_order, label_mapping, fontsize, legend_title=None, title_fontsize=None, legend_loc='upper right', markerscale=1):\n",
    "    \"\"\"\n",
    "    Reorders the legend of a plot based on a specified order and allows adjusting the marker scale in the legend.\n",
    "\n",
    "    Parameters:\n",
    "    ax (matplotlib.axes.Axes): The axes object of the plot.\n",
    "    desired_order (list): The desired order of legend labels.\n",
    "    label_mapping (dict): A dictionary mapping original labels to desired labels.\n",
    "    fontsize (int): Font size for the legend labels.\n",
    "    legend_title (str, optional): Title for the legend.\n",
    "    title_fontsize (int, optional): Font size for the legend title.\n",
    "    legend_loc (str, optional): Location for the legend.\n",
    "    markerscale (float, optional): The relative size of legend markers compared with the originally drawn ones. Default is 1.\n",
    "    \"\"\"\n",
    "    # Use the dictionary to get the corresponding labels, defaulting to the key itself\n",
    "    desired_order_labels = [label_mapping.get(key, key) for key in desired_order]\n",
    "\n",
    "    # Capture the existing handles and labels from the current legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    # Create a dictionary from labels to handles\n",
    "    label_handle_dict = dict(zip(labels, handles))\n",
    "\n",
    "    # Reorder the handles based on the desired order of labels\n",
    "    handles_ordered = [label_handle_dict[label] for label in desired_order_labels if label in label_handle_dict]\n",
    "\n",
    "    # Only include the labels that are actually present in the labels list\n",
    "    labels_ordered = [label for label in desired_order_labels if label in label_handle_dict]\n",
    "\n",
    "    # Create a new legend with the ordered handles and labels\n",
    "    ax.legend(handles_ordered, labels_ordered, fontsize=fontsize, title=legend_title, title_fontsize=title_fontsize, loc=legend_loc, markerscale=markerscale)\n",
    "\n",
    "    \n",
    "def photolysis_retriver(all_data, var_compound, var_jvalue, aggregation):\n",
    "\n",
    "    # Drop rows where either the compound or J-value is missing\n",
    "    temp_obs = all_data.dropna(subset=[var_compound, var_jvalue])\n",
    "    '''\n",
    "    # test\n",
    "    test_obs = temp_obs[temp_obs['time_bin']==150.0]\n",
    "    total_rows = len(temp_obs)\n",
    "    total_columns = len(temp_obs.columns)\n",
    "\n",
    "    pd.set_option('display.max_rows', total_rows)\n",
    "    pd.set_option('display.max_columns', total_columns)\n",
    "\n",
    "    print(temp_obs[['Flight_ID','Plume_Age', var_compound, var_jvalue, 'time_bin']])\n",
    "\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    '''\n",
    "    # Group by time bins and calculate statistical aggregations\n",
    "    binned_obs_stat = temp_obs.groupby('time_bin').agg(['mean', 'std', 'median', iqr])\n",
    "    \n",
    "    # Calculate the photolysis rate\n",
    "    data_obs = binned_obs_stat[var_compound, aggregation].mul(binned_obs_stat[var_jvalue, aggregation].values, axis=0)\n",
    "\n",
    "    return data_obs, binned_obs_stat[var_jvalue, aggregation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31545f95-83b4-4c4a-b776-a5aeecb493b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc01fa0-73de-4c2b-9f1d-07578704a834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89661e2-5dac-4aaa-96aa-bcc28ebae23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_df(df, interval_X):\n",
    "    \"\"\"\n",
    "    Bins a DataFrame based on a specified time interval and computes statistical measures for each bin.\n",
    "\n",
    "    This function takes a DataFrame where the index represents time and groups the data into bins of a specified interval. \n",
    "    It computes the median, interquartile range (IQR), mean, and standard deviation for each bin.\n",
    "\n",
    "    Parameters:\n",
    "    df_compound_mod (DataFrame): A DataFrame with a time-based index.\n",
    "    interval_X (int): The time interval for binning data, specified in the same units as the DataFrame index.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A new DataFrame where each row represents a time bin, and columns include the median, IQR, mean, \n",
    "               and standard deviation of the original DataFrame's columns for that bin.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bin edges for every X minutes, doulbe check if we want it to start with 0 or not...\n",
    "    max_age = df.index.max()\n",
    "    bin_edges = np.arange(0, max_age + interval_X, interval_X)\n",
    "\n",
    "    # Use the `cut` function to bin the data\n",
    "    df['time_bin'] = pd.cut(df.index, bins=bin_edges, labels=bin_edges[:-1] + interval_X, right=False)\n",
    "    \n",
    "    # Group by the time bin and compute median, IQR, mean, and standard deviation for each bin\n",
    "    #binned_mod_stats = df.groupby('time_bin').agg(['median', iqr, 'mean', 'std'])\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    binned_mod_stats = (\n",
    "        df[numeric_cols]\n",
    "        .groupby(df['time_bin'])\n",
    "        .agg(['median', iqr, 'mean', 'std'])\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Drop rows where all elements are NaN\n",
    "    binned_mod_stats = binned_mod_stats.dropna(how='all')    \n",
    "    \n",
    "    # Convert the index to numeric (if it's not already numeric)\n",
    "    numeric_index = pd.to_numeric(binned_mod_stats.index, errors='coerce')\n",
    "\n",
    "    # Check if the conversion was successful\n",
    "    if numeric_index.isnull().any():\n",
    "        print(\"Warning: Some index values could not be converted to numeric.\")\n",
    "\n",
    "    # Round the numeric index by converting to a Series first\n",
    "    rounded_index = pd.Series(numeric_index).round(2)\n",
    "\n",
    "    # Assign the rounded index back to the DataFrame\n",
    "    binned_mod_stats.index = rounded_index\n",
    "\n",
    "    # Return the binned statistics\n",
    "    return binned_mod_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3098633-8d3a-41df-8919-31a4a01e496c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data processing for smk concentration\n",
    "This script reads all observed flights and put them in one dataset.\n",
    "- Evaluting O3 and OH turnover rate\n",
    "- Evaluting OH concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13e3597-8da3-4cfd-95c0-f8283d04e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store OH exposure data for each flight\n",
    "# Observation\n",
    "nemr_ox_per_flight_obs           = {}\n",
    "nemr_o3_per_flight_obs           = {}\n",
    "nemr_o3_nox_per_flight_obs       = {}\n",
    "co_per_flight_obs                = {}\n",
    "no_per_flight_obs                = {}\n",
    "no2_per_flight_obs               = {}\n",
    "nox_per_flight_obs               = {}\n",
    "no_no2_per_flight_obs            = {}\n",
    "\n",
    "o3_per_flight_obs                = {}\n",
    "ox_per_flight_obs                = {}\n",
    "\n",
    "pan_per_flight_obs               = {}\n",
    "ppan_per_flight_obs              = {}\n",
    "pmco3_per_flight_obs             = {}\n",
    "lpan_per_flight_obs              = {}\n",
    "lmco3_per_flight_obs             = {}\n",
    "\n",
    "ch2o_per_flight_obs              = {}\n",
    "ch2o_no2_per_flight_obs          = {}\n",
    "\n",
    "calOH_conc_stat_per_flight_obs   = {}\n",
    "calOH_conc_vocs_per_flight_obs   = {}\n",
    "\n",
    "calOH_conc_stat_per_flight_obs_wide = {}\n",
    "calOH_conc_vocs_per_flight_obs_wide = {}\n",
    "\n",
    "outputOH_conc_per_flight_obs     = {}\n",
    "calOH_expo_stat_per_flight_obs   = {}\n",
    "calOH_expo_vocs_per_flight_obs   = {}\n",
    "outputOH_expo_per_flight_obs     = {}\n",
    "\n",
    "cal_chem_age_stat_per_flight_obs = {}\n",
    "cal_chem_age_vocs_per_flight_obs = {}\n",
    "output_chem_age_per_flight_obs   = {}\n",
    "\n",
    "vocr_per_flight_obs              = {}\n",
    "noxr_per_flight_obs              = {}\n",
    "OHRvoc_OHRnox_per_flight_obs     = {}\n",
    "OHRnox_OHRvoc_per_flight_obs     = {}\n",
    "\n",
    "Ln_per_flight_obs                = {}\n",
    "Q_per_flight_obs                 = {}\n",
    "\n",
    "hno2_per_flight_obs              = {}\n",
    "nemr_hno2_per_flight_obs         = {}\n",
    "\n",
    "ald2_per_flight_obs              = {}\n",
    "glyx_per_flight_obs              = {}\n",
    "mgly_per_flight_obs              = {}\n",
    "biacet_per_flight_obs            = {}\n",
    "\n",
    "propanal_per_flight_obs          = {}\n",
    "butanal_per_flight_obs           = {}\n",
    "\n",
    "acet_per_flight_obs              = {}\n",
    "mek_per_flight_obs               = {}\n",
    "acr_per_flight_obs               = {}\n",
    "macr_per_flight_obs              = {}\n",
    "mvk_per_flight_obs               = {}\n",
    "glyc_per_flight_obs              = {}\n",
    "hac_per_flight_obs               = {}\n",
    "furfural_per_flight_obs          = {}\n",
    "\n",
    "met_per_flight_obs               = {}\n",
    "\n",
    "sesq_per_flight_obs              = {}\n",
    "dmf_per_flight_obs               = {}\n",
    "\n",
    "# CH2O, ALD2, MA\n",
    "ch2o_per_flight_dil_obs          = {}\n",
    "ald2_per_flight_dil_obs          = {}\n",
    "ma_per_flight_dil_obs            = {}\n",
    "# furanoids (excluding M3F and DMF), acrolein, 1,3-butdiene\n",
    "furanoids_excl_per_flight_dil_obs= {}\n",
    "furanoids_excl_per_flight_obs    = {}\n",
    "\n",
    "methylfuran_per_flight_dil_obs   = {}\n",
    "acr_per_flight_dil_obs           = {}\n",
    "butd_per_flight_dil_obs          = {}\n",
    "\n",
    "\n",
    "# Other primary VOCs\n",
    "# This includes isoprene, monoterpenes, xylenes, 2-butenal, and cresol\n",
    "# creosol, 2,5-dimethylfuran, guaiacol, syringol, and sesquiterpene\n",
    "isop_per_flight_dil_obs          = {}\n",
    "mtpa_per_flight_dil_obs          = {}\n",
    "xyle_per_flight_dil_obs          = {}\n",
    "butenal_per_flight_dil_obs       = {}\n",
    "cresol_per_flight_dil_obs        = {}\n",
    "dmf_per_flight_dil_obs           = {}\n",
    "guaiacol_per_flight_dil_obs      = {}\n",
    "syringol_per_flight_dil_obs      = {}\n",
    "sesq_per_flight_dil_obs          = {}\n",
    "\n",
    "# Other secondary VOCs\n",
    "rcho_per_flight_dil_obs          = {}\n",
    "glyx_per_flight_dil_obs          = {}\n",
    "hcooh_per_flight_dil_obs         = {}\n",
    "acta_per_flight_dil_obs          = {}\n",
    "macr_mvk_per_flight_dil_obs      = {}\n",
    "mek_per_flight_dil_obs           = {}\n",
    "glyc_per_flight_dil_obs          = {}\n",
    "mgly_per_flight_dil_obs          = {}\n",
    "hac_per_flight_dil_obs           = {}\n",
    "phen_per_flight_dil_obs          = {}\n",
    "bald_per_flight_dil_obs          = {}\n",
    "furanone_per_flight_dil_obs      = {}\n",
    "acr_per_flight_dil_obs           = {}\n",
    "ma_per_flight_dil_obs            = {}\n",
    "butanedione_per_flight_dil_obs   = {}\n",
    "butanedione_per_flight_obs       = {}\n",
    "TM123B_per_flight_dil_obs        = {}\n",
    "TM135B_per_flight_dil_obs        = {}\n",
    "C9arom_per_flight_dil_obs        = {}\n",
    "\n",
    "o3_per_flight_dil_obs            = {}\n",
    "pan_per_flight_dil_obs           = {}\n",
    "\n",
    "furan_per_flight_obs             = {}\n",
    "mefuran_per_flight_obs           = {} \n",
    "dmf_per_flight_obs               = {}\n",
    "furfural_per_flight_obs          = {}\n",
    "mefurfural_per_flight_obs        = {}\n",
    "furanone_per_flight_obs          = {}\n",
    "\n",
    "ch2o_co_per_flight_obs           = {}\n",
    "vocr_co_per_flight_obs           = {}\n",
    "noxr_co_per_flight_obs           = {}\n",
    "no_co_per_flight_obs             = {}\n",
    "no2_co_per_flight_obs            = {}\n",
    "nox_co_per_flight_obs            = {}\n",
    "pan_co_per_flight_obs            = {}\n",
    "hno2_co_per_flight_obs           = {}\n",
    "noz_co_per_flight_obs            = {}\n",
    "\n",
    "furan_co_per_flight_obs          = {}\n",
    "mefuran_co_per_flight_obs        = {} \n",
    "dmf_co_per_flight_obs            = {}\n",
    "furfural_co_per_flight_obs       = {}\n",
    "mefurfural_co_per_flight_obs     = {}\n",
    "furanone_co_per_flight_obs       = {}\n",
    "butd_co_per_flight_obs           = {}\n",
    "acr_co_per_flight_obs            = {}\n",
    "\n",
    "ho2_per_flight_obs            = {}\n",
    "ro2_per_flight_obs            = {}\n",
    "\n",
    "pox_per_flight_obs               = {}\n",
    "po3_per_flight_obs               = {}\n",
    "\n",
    "lox_per_flight_obs               = {}\n",
    "lo3_per_flight_obs               = {}\n",
    "# Other photochemical indicators \n",
    "lrox_lnox_per_flight_obs         = {}\n",
    "ln_q_per_flight_obs              = {}\n",
    "h2o2_hno3_per_flight_obs         = {}\n",
    "\n",
    "# Nitrate\n",
    "no_per_flight_obs                = {}\n",
    "no2_per_flight_obs               = {}\n",
    "hno2_per_flight_obs              = {}\n",
    "pno3_per_flight_obs              = {}\n",
    "hno3_per_flight_obs              = {}\n",
    "hno4_per_flight_obs              = {}\n",
    "ppn_per_flight_obs               = {}\n",
    "pns_per_flight_obs               = {}\n",
    "ans_per_flight_obs               = {}\n",
    "\n",
    "no_per_flight_dil_obs            = {}\n",
    "no2_per_flight_dil_obs            = {}\n",
    "hno2_per_flight_dil_obs            = {}\n",
    "pno3_per_flight_dil_obs           = {}\n",
    "hno3_per_flight_dil_obs           = {}\n",
    "hno4_per_flight_dil_obs           = {}\n",
    "ppn_per_flight_dil_obs            = {}\n",
    "pns_per_flight_dil_obs            = {}\n",
    "ans_per_flight_dil_obs            = {}\n",
    "pns_excl_per_flight_dil_obs   = {}\n",
    "pan_per_flight_dil_obs            = {}\n",
    "\n",
    "nemr_no_per_flight_obs            = {}\n",
    "nemr_no2_per_flight_obs           = {}\n",
    "nemr_hno2_per_flight_obs          = {}\n",
    "nemr_pno3_per_flight_obs          = {}\n",
    "nemr_hno3_per_flight_obs          = {}\n",
    "nemr_hno4_per_flight_obs          = {}\n",
    "nemr_ppn_per_flight_obs           = {}\n",
    "nemr_pns_per_flight_obs           = {}\n",
    "nemr_ans_per_flight_obs           = {}\n",
    "nemr_pns_excl_per_flight_obs      = {}\n",
    "nemr_pan_per_flight_obs           = {}\n",
    "\n",
    "\n",
    "# Response to reviewer\n",
    "furan_per_flight_obs          = {}\n",
    "mefuran_per_flight_obs        = {} \n",
    "dmf_per_flight_obs            = {}\n",
    "furfural_per_flight_obs       = {}\n",
    "mefurfural_per_flight_obs     = {}\n",
    "furanone_per_flight_obs       = {}\n",
    "benzene_per_flight_obs        = {}\n",
    "nemr_benzene_per_flight_obs   = {}\n",
    "\n",
    "\n",
    "# Model\n",
    "nemr_ox_per_flight_mod           = {}\n",
    "nemr_o3_per_flight_mod           = {}\n",
    "nemr_o3_nox_per_flight_mod       = {}\n",
    "co_per_flight_mod                = {}\n",
    "no_per_flight_mod                = {}\n",
    "no2_per_flight_mod               = {}\n",
    "nox_per_flight_mod               = {}\n",
    "o3_per_flight_mod                = {}\n",
    "ox_per_flight_mod                = {}\n",
    "\n",
    "pan_per_flight_mod               = {}\n",
    "\n",
    "ppan_per_flight_mod              = {}\n",
    "pmco3_per_flight_mod             = {}\n",
    "lpan_per_flight_mod              = {}\n",
    "lmco3_per_flight_mod             = {}\n",
    "\n",
    "ch2o_per_flight_mod              = {}\n",
    "ch2o_no2_per_flight_mod          = {}\n",
    "\n",
    "calOH_conc_stat_per_flight_mod      = {}\n",
    "calOH_conc_vocs_per_flight_mod      = {}\n",
    "calOH_conc_stat_per_flight_mod_wide = {}\n",
    "calOH_conc_vocs_per_flight_mod_wide = {}\n",
    "outputOH_conc_per_flight_mod        = {}\n",
    "calOH_expo_stat_per_flight_mod      = {}\n",
    "calOH_expo_vocs_per_flight_mod      = {}\n",
    "outputOH_expo_per_flight_mod        = {}\n",
    "\n",
    "cal_chem_age_stat_per_flight_mod = {}\n",
    "cal_chem_age_vocs_per_flight_mod = {}\n",
    "output_chem_age_per_flight_mod   = {}\n",
    "\n",
    "vocr_per_flight_mod              = {}\n",
    "noxr_per_flight_mod              = {}\n",
    "OHRvoc_OHRnox_per_flight_mod     = {}\n",
    "OHRnox_OHRvoc_per_flight_mod     = {}\n",
    "\n",
    "Ln_per_flight_mod                = {}\n",
    "Q_per_flight_mod                 = {}\n",
    "\n",
    "hno2_per_flight_mod              = {}\n",
    "nemr_hno2_per_flight_mod         = {} \n",
    "\n",
    "ald2_per_flight_mod              = {}\n",
    "glyx_per_flight_mod              = {}\n",
    "mgly_per_flight_mod              = {}\n",
    "biacet_per_flight_mod            = {}\n",
    "\n",
    "propanal_per_flight_mod          = {}\n",
    "butanal_per_flight_mod           = {}\n",
    "\n",
    "acet_per_flight_mod              = {}\n",
    "mek_per_flight_mod               = {}\n",
    "acr_per_flight_mod               = {}\n",
    "macr_per_flight_mod              = {}\n",
    "mvk_per_flight_mod               = {}\n",
    "glyc_per_flight_mod              = {}\n",
    "hac_per_flight_mod               = {}\n",
    "furfural_per_flight_mod          = {}\n",
    "\n",
    "sesq_per_flight_mod              = {}\n",
    "dmf_per_flight_mod               = {}\n",
    "\n",
    "# model evualtion VOCs\n",
    "ch2o_per_flight_dil_mod          = {}\n",
    "ald2_per_flight_dil_mod          = {}\n",
    "ma_per_flight_dil_mod            = {}\n",
    "# furanoids (excluding DMF and M3F), acrolein, 1,3-butdien\n",
    "furanoids_excl_per_flight_dil_mod = {}\n",
    "furanoids_excl_per_flight_mod     = {}\n",
    "methylfuran_per_flight_dil_mod    = {}\n",
    "\n",
    "acr_per_flight_dil_mod           = {}\n",
    "butd_per_flight_dil_mod          = {}\n",
    "\n",
    "# Other primary VOCs\n",
    "# This includes isoprene, monoterpenes, xylenes, 2-butenal, and cresol\n",
    "# creosol, 2,5-dimethylfuran, guaiacol, syringol, and sesquiterpene\n",
    "isop_per_flight_dil_mod          = {}\n",
    "mtpa_per_flight_dil_mod          = {}\n",
    "xyle_per_flight_dil_mod          = {}\n",
    "butenal_per_flight_dil_mod       = {}\n",
    "cresol_per_flight_dil_mod        = {}\n",
    "dmf_per_flight_dil_mod           = {}\n",
    "guaiacol_per_flight_dil_mod       = {}\n",
    "syringol_per_flight_dil_mod      = {}\n",
    "sesq_per_flight_dil_mod          = {}\n",
    "\n",
    "# Other secondary VOCs\n",
    "rcho_per_flight_dil_mod          = {}\n",
    "glyx_per_flight_dil_mod          = {}\n",
    "hcooh_per_flight_dil_mod         = {}\n",
    "acta_per_flight_dil_mod          = {}\n",
    "macr_mvk_per_flight_dil_mod      = {}\n",
    "mek_per_flight_dil_mod           = {}\n",
    "glyc_per_flight_dil_mod          = {}\n",
    "mgly_per_flight_dil_mod          = {}\n",
    "hac_per_flight_dil_mod           = {}\n",
    "phen_per_flight_dil_mod          = {}\n",
    "bald_per_flight_dil_mod          = {}\n",
    "furanone_per_flight_dil_mod      = {}\n",
    "acr_per_flight_dil_mod           = {}\n",
    "ma_per_flight_dil_mod            = {}\n",
    "butanedione_per_flight_dil_mod   = {}\n",
    "butanedione_per_flight_mod       = {}\n",
    "\n",
    "TM123B_per_flight_dil_mod        = {}\n",
    "TM135B_per_flight_dil_mod        = {}\n",
    "C9arom_per_flight_dil_mod        = {}\n",
    "\n",
    "o3_per_flight_dil_mod            = {}\n",
    "pan_per_flight_dil_mod           = {}\n",
    "\n",
    "ch2o_co_per_flight_mod           = {}\n",
    "vocr_co_per_flight_mod           = {}\n",
    "noxr_co_per_flight_mod           = {}\n",
    "no_co_per_flight_mod             = {}\n",
    "no2_co_per_flight_mod            = {}\n",
    "\n",
    "nox_co_per_flight_mod            = {}\n",
    "pan_co_per_flight_mod            = {}\n",
    "hno2_co_per_flight_mod           = {}\n",
    "noz_co_per_flight_mod            = {}\n",
    "\n",
    "furan_co_per_flight_mod          = {}\n",
    "mefuran_co_per_flight_mod        = {} \n",
    "dmf_co_per_flight_mod            = {}\n",
    "furfural_co_per_flight_mod       = {}\n",
    "mefurfural_co_per_flight_mod     = {}\n",
    "furanone_co_per_flight_mod       = {}\n",
    "butd_co_per_flight_mod           = {}\n",
    "acr_co_per_flight_mod            = {}\n",
    "\n",
    "ho2_per_flight_mod               = {}\n",
    "ro2_per_flight_mod               = {}\n",
    "pox_per_flight_mod               = {}\n",
    "po3_per_flight_mod               = {}\n",
    "lox_per_flight_mod               = {}\n",
    "lo3_per_flight_mod               = {}\n",
    "# Other photochemical indicators \n",
    "lrox_lnox_per_flight_mod         = {}\n",
    "ln_q_per_flight_mod              = {}\n",
    "h2o2_hno3_per_flight_mod         = {}\n",
    "\n",
    "# Nitrates\n",
    "no_per_flight_mod                = {}\n",
    "no2_per_flight_mod               = {}\n",
    "hno2_per_flight_mod              = {}\n",
    "no_no2_per_flight_mod            = {}\n",
    "\n",
    "\n",
    "\n",
    "pno3_per_flight_mod              = {}\n",
    "hno3_per_flight_mod              = {}\n",
    "hno4_per_flight_mod              = {}\n",
    "ppn_per_flight_mod               = {}\n",
    "pns_per_flight_mod               = {}\n",
    "ans_per_flight_mod               = {}\n",
    "\n",
    "\n",
    "no_per_flight_dil_mod            = {}\n",
    "no2_per_flight_dil_mod           = {}\n",
    "hno2_per_flight_dil_mod          = {}\n",
    "pno3_per_flight_dil_mod          = {}\n",
    "hno3_per_flight_dil_mod          = {}\n",
    "hno4_per_flight_dil_mod          = {}\n",
    "ppn_per_flight_dil_mod           = {}\n",
    "pns_per_flight_dil_mod           = {}\n",
    "ans_per_flight_dil_mod           = {}\n",
    "pns_excl_per_flight_dil_mod      = {}\n",
    "\n",
    "pan_per_flight_dil_mod           = {}\n",
    "\n",
    "nemr_no_per_flight_mod            = {}\n",
    "nemr_no2_per_flight_mod           = {}\n",
    "nemr_hno2_per_flight_mod          = {}\n",
    "nemr_pno3_per_flight_mod          = {}\n",
    "nemr_hno3_per_flight_mod          = {}\n",
    "nemr_hno4_per_flight_mod          = {}\n",
    "nemr_ppn_per_flight_mod           = {}\n",
    "nemr_pns_per_flight_mod           = {}\n",
    "nemr_ans_per_flight_mod           = {}\n",
    "nemr_pns_excl_per_flight_mod      = {}\n",
    "nemr_pan_per_flight_mod           = {}\n",
    "\n",
    "# Response to reviewer\n",
    "furan_per_flight_mod          = {}\n",
    "mefuran_per_flight_mod        = {} \n",
    "dmf_per_flight_mod            = {}\n",
    "furfural_per_flight_mod       = {}\n",
    "mefurfural_per_flight_mod     = {}\n",
    "furanone_per_flight_mod       = {}\n",
    "benzene_per_flight_mod        = {}\n",
    "nemr_benzene_per_flight_mod   = {}\n",
    "\n",
    "# Plotting for the figure\n",
    "linewidth = 3\n",
    "error_infor = False\n",
    "fontsize_flight = 20\n",
    "fontsize_tick   = 20\n",
    "fontsize_label  = 12\n",
    "fontsize_comp   = 18\n",
    "\n",
    "# Colors for model\n",
    "#colors = ['green', 'purple', 'orange', \\\n",
    "#         'red', 'blue']\n",
    "colors = [\n",
    "    \"darkred\",  \n",
    "    \"royalblue\",  \n",
    "    \"darkgreen\",  \n",
    "    \"darkorange\", \n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\", \n",
    "    \"darkgray\", \n",
    "    \"gold\",      # yellow\n",
    "    \"indigo\",  # purple\n",
    "    \"black\", \n",
    "    \"lawngreen\", \n",
    "]\n",
    "# VOCs used to calculated OH concentration\n",
    "voc_names = ['Furan', 'Furfural', 'Furanone', 'Butadiene', \n",
    "             'Phenol', 'Tolualdehyde', 'Guaiacol', \n",
    "             'Isoprene', 'Ethanol', 'Styrene']\n",
    "\n",
    "#'Isoprene', 'Ethanol', 'Styrene'# NA\n",
    "voc_names = ['Furan', 'Furfural', 'Furanone',\n",
    "             'Butadiene', 'Guaiacol',\n",
    "             'Methylfuran', '2,5-Dimethylfuran', 'Methylfurfural',\n",
    "             'Monoterpenes', 'Butenal', 'Xylenes', \n",
    "             'Phenol', 'Tolualdehyde', \n",
    "             'Bezene', 'Toluene']\n",
    "\n",
    "\n",
    "# Last decision. Some are filtered out due to other path and secondary productions.\n",
    "voc_names = ['Furan', 'Furfural', 'Xylenes',\n",
    "             'Furanone', 'Butadiene',\n",
    "             'Butenal']\n",
    "\n",
    "# Testing\n",
    "voc_names = ['Furan', 'Furfural','Furanone']\n",
    "\n",
    "# Setting of if having chem age and model results\n",
    "chem_age = 0\n",
    "\n",
    "# Setting for smk or bkg\n",
    "get_smk, get_smk_dil, get_smk_conorm = True, False, False\n",
    "#get_smk, get_smk_dil, get_smk_conorm = False, True, False\n",
    "#get_smk, get_smk_dil, get_smk_conorm = False, False, True\n",
    "\n",
    "if get_smk:         postfix = 'smk'\n",
    "if get_smk_dil:     postfix = 'smk_dil'\n",
    "if get_smk_conorm:  postfix = 'smk_conorm'\n",
    "\n",
    "\n",
    "# Read compounds and each flight dataframe\n",
    "Flight_IDs   = ['RF03', 'RF07', 'RF09']\n",
    "Flight_IDs   = ['FN19', 'P-3B']\n",
    "\n",
    "Flight_IDs = ['RF01', 'RF02', 'RF03', 'RF04', 'RF05', \n",
    "              'RF06', 'RF07', 'RF09', 'RF10',\n",
    "              'RF11', 'RF13', 'FN19', 'P-3B']\n",
    "Flight_IDs = ['FN19', 'P-3B', 'RF01', 'RF02', 'RF03', 'RF04', 'RF05', \n",
    "              'RF06', 'RF07', 'RF09', 'RF10',\n",
    "              'RF13']\n",
    "Lagrangian_flights  = ['RF03', 'RF07', 'RF09', 'FN19', 'P-3B']\n",
    "\n",
    "desired_order_flights  = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19', 'Other WE-CAN flights']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cb36a-0515-4649-b9de-c09d30733f94",
   "metadata": {},
   "source": [
    "#### Step 1: Save out all flights data.\n",
    "- Save out key parameters such as plume_Age, OH_Exposure, VOCR, O3, NO2, OHRvoc: OHRnox, and OH turnover rate.\n",
    "\n",
    "- The post-group is also processed, including VOCR_NOxR_group, VOCR_group, and K-means Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2579f765-7438-49af-9aaa-7ccd47b4c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OH_conc_avg(time, A, B, k_OH_A, k_OH_B, ER_a_over_b):\n",
    "    # Calculate the logarithm of the VOC/CO ratio for each point in the series\n",
    "    ln_ratio = np.log(A / B)\n",
    "    \n",
    "    # Initialize the modified ln_ratio array with the initial lab ratio log value\n",
    "    modified_ln_ratio = np.insert(ln_ratio, 0, np.log(ER_a_over_b))\n",
    "    \n",
    "    # Add an initial time point at time 0\n",
    "    # The unit of time should be second in this case to cancel out the unit\n",
    "    time = np.insert(time, 0, 0)  # Insert time zero at the beginning\n",
    "    \n",
    "    # Calculate the difference in logarithmic ratios between consecutive points\n",
    "    diff_ln_ratio = np.diff(modified_ln_ratio)\n",
    "    \n",
    "    # Calculate the delta time (time difference between consecutive measurements)\n",
    "    delta_t = np.diff(time)\n",
    "    \n",
    "    # Calculate [OH]cal using the given formula\n",
    "    OH_concentration = (1 / (delta_t * (k_OH_A - k_OH_B))) * (-diff_ln_ratio)\n",
    "    \n",
    "    # Check for non-physical negative values in OH concentration and adjust\n",
    "    for i in range(1, len(OH_concentration)):\n",
    "        if OH_concentration[i] < 0:\n",
    "            # Check previous values until the initial condition\n",
    "            for j in range(i, 0, -1):\n",
    "                diff_ln_ratio[j] = modified_ln_ratio[j] - modified_ln_ratio[j - 1]\n",
    "                OH_concentration[j] = (1 / (delta_t[j - 1] * (k_OH_A - k_OH_B))) * (-diff_ln_ratio[j])\n",
    "                if OH_concentration[j] >= 0:\n",
    "                    break\n",
    "            else:\n",
    "                # If all previous steps still negative, keep the initial negative value\n",
    "                OH_concentration[i] = (1 / (delta_t[i] * (k_OH_A - k_OH_B))) * (-diff_ln_ratio[i])\n",
    "    return OH_concentration\n",
    "\n",
    "\n",
    "'''\n",
    "def calculate_OH_conc_avg(time, A, B, k_OH_A, k_OH_B, ER_a_over_b):\n",
    "    \"\"\"\n",
    "    Estimates average OH concentrations between measurement points by using \n",
    "    the log-ratio (hydrocarbon clock) method on two species, A and B.\n",
    "    \n",
    "    This revised version:\n",
    "      1) Calculates OH via the log-ratio method,\n",
    "      2) Flags negative OH as NaN (physically invalid),\n",
    "      3) Linearly interpolates over NaN values.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Compute ln(A/B)\n",
    "    ln_ratio = np.log(A / B)\n",
    "\n",
    "    # 2) Insert the initial ratio at time = 0\n",
    "    modified_ln_ratio = np.insert(ln_ratio, 0, np.log(ER_a_over_b))\n",
    "    time = np.insert(time, 0, 0)  # Add time zero\n",
    "\n",
    "    # 3) Compute the difference in ln-ratios and in time\n",
    "    diff_ln_ratio = np.diff(modified_ln_ratio)\n",
    "    delta_t = np.diff(time)\n",
    "\n",
    "    # 4) Calculate OH from the log-ratio approach\n",
    "    #    (Assuming the sum of rate constants: k_OH_A - k_OH_B)\n",
    "    OH_concentration = (1 / (delta_t * (k_OH_A - k_OH_B))) * (-diff_ln_ratio)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5) Flag negative values as NaN\n",
    "    # ----------------------------\n",
    "    OH_concentration[OH_concentration < 0] = np.nan\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6) Interpolate over NaN values (linear interpolation)\n",
    "    # ------------------------------------------------------------\n",
    "    # Place each OH value at the midpoint of the corresponding time interval.\n",
    "    oh_time = (time[:-1] + time[1:]) / 2.0\n",
    "    valid_mask = ~np.isnan(OH_concentration)\n",
    "\n",
    "    # If everything is NaN, just return\n",
    "    if not np.any(valid_mask):\n",
    "        return OH_concentration\n",
    "\n",
    "    # Make a copy for interpolation\n",
    "    oh_concentration_interpolated = np.copy(OH_concentration)\n",
    "    # Use np.interp to fill missing (NaN) points\n",
    "    oh_concentration_interpolated[~valid_mask] = np.interp(\n",
    "        oh_time[~valid_mask],     # where to interpolate\n",
    "        oh_time[valid_mask],      # known x-values\n",
    "        OH_concentration[valid_mask]  # known y-values\n",
    "    )\n",
    "\n",
    "    return oh_concentration_interpolated\n",
    "'''\n",
    "\n",
    "def calculate_OH_expo_avg(time, OH_conc):\n",
    "    \"\"\"\n",
    "    Calculate the cumulative OH exposure over time given OH concentrations and corresponding time points.\n",
    "    \n",
    "    Parameters:\n",
    "        time (array-like): The time points at which OH concentrations are measured.\n",
    "                           Should be in consistent units (e.g., seconds).\n",
    "        OH_conc (array-like): OH concentrations at the corresponding time points in molecules/cm³.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Cumulative OH exposure in molecule-time units/cm³ (e.g., molecule-seconds/cm³).\n",
    "    \"\"\"\n",
    "    # Ensure the inputs are numpy arrays for numerical operations\n",
    "    time = np.array(time)\n",
    "    OH_conc = np.array(OH_conc)\n",
    "    \n",
    "    # Initialize an array to store cumulative OH exposure at each time point\n",
    "    OH_expo = np.zeros(len(time))\n",
    "    \n",
    "    # Calculate incremental OH exposure for each interval and accumulate\n",
    "    for i in range(1, len(time)):\n",
    "        # Calculate the area under the curve from the current point to the next\n",
    "        interval_expo = np.trapz(OH_conc[i-1:i+1], time[i-1:i+1])\n",
    "        # Accumulate the exposure\n",
    "        OH_expo[i] = OH_expo[i-1] + interval_expo\n",
    "    \n",
    "    return OH_expo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df5860f-2423-41b5-a62f-a6c2d4d9f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OH_conc_avg_wide(time, A, B, k_OH_A, k_OH_B, ER_a_over_b):\n",
    "    \"\"\"\n",
    "    Calculate the hydroxyl radical concentration [OH] using a photochemical clock method\n",
    "    based on the initial time point (t0 = 0) and each subsequent plume age (ti).\n",
    "\n",
    "    Parameters:\n",
    "    - time (array-like): Array of plume ages (in seconds), starting from 0.\n",
    "    - A (array-like): Concentration of species A at each time point.\n",
    "    - B (array-like): Concentration of species B at each time point.\n",
    "    - k_OH_A (float): Rate constant for the reaction of OH with species A (cm³/molecule/s).\n",
    "    - k_OH_B (float): Rate constant for the reaction of OH with species B (cm³/molecule/s).\n",
    "    - ER_a_over_b (float): Initial ratio of A to B (A/B) before any reaction occurs.\n",
    "\n",
    "    Returns:\n",
    "    - OH_concentration (np.ndarray): Array of calculated [OH] concentrations at each plume age.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the logarithm of the VOC/CO ratio for each point in the series\n",
    "    ln_ratio = np.log(A / B)\n",
    "    \n",
    "    # Initialize the modified ln_ratio array with the initial lab ratio log value\n",
    "    modified_ln_ratio = np.insert(ln_ratio, 0, np.log(ER_a_over_b))\n",
    "\n",
    "    # Calculate the difference in logarithmic ratios between consecutive points\n",
    "    diff_ln_ratio = np.diff(modified_ln_ratio)\n",
    "\n",
    "    # Calculate the delta time (time difference between consecutive measurements)\n",
    "    delta_t = time\n",
    "\n",
    "    # Calculate [OH]cal using the given formula\n",
    "    OH_concentration = (1 / (delta_t * (k_OH_A - k_OH_B))) * (-diff_ln_ratio)\n",
    "\n",
    "    # Check for non-physical negative values in OH concentration and adjust\n",
    "    for i in range(1, len(OH_concentration)):\n",
    "        if OH_concentration[i] < 0:\n",
    "            # Check previous values until the initial condition\n",
    "            for j in range(i, 0, -1):\n",
    "                diff_ln_ratio[j] = modified_ln_ratio[j] - modified_ln_ratio[j - 1]\n",
    "                OH_concentration[j] = (1 / (delta_t[j - 1] * (k_OH_A - k_OH_B))) * (-diff_ln_ratio[j])\n",
    "                if OH_concentration[j] >= 0:\n",
    "                    break\n",
    "            else:\n",
    "                # If all previous steps still negative, keep the initial negative value\n",
    "                OH_concentration[i] = (1 / (delta_t[i] * (k_OH_A - k_OH_B))) * (-diff_ln_ratio[i])\n",
    "    return OH_concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9adc6-02b9-4549-80b5-398ae8898ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fbe1183-9df8-483e-977d-a628dc424adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN19\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "NO 2,3-butanedione EXIST!\n",
      "NO DIL1 EXIST!\n",
      "NO Maleic Anhydride EXIST!\n",
      "NO propanal EXIST!\n",
      "P-3B\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "RF03\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "RF07\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "RF09\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "All lengths match.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Save out emission pass 1 and pass 2 in RF07 and RF09\n",
    "OH_series_dict = {}\n",
    "\n",
    "for col, Flight_ID in enumerate(Flight_IDs):\n",
    "    if 'RF' in Flight_ID:     file_prefix = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_analysis_TS/WE-CAN/Dataprocess/analysis_bycompound/'\n",
    "    if Flight_ID in ['FN19']: file_prefix = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_analysis_TS/FIREX-AQ/Dataprocess/analysis_bycompound/'\n",
    "    if Flight_ID in ['P-3B']: file_prefix = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_analysis_TS/P-3B/Dataprocess/analysis_bycompound/'\n",
    "    file_prefix_PL  = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/PL_budget/output/'\n",
    "\n",
    "    # -------------------------------\n",
    "    # Read observation and model data\n",
    "    # -------------------------------\n",
    "    # ! Initial CO\n",
    "    # Read CO smk data\n",
    "    data_CO_smk_init = pd.read_csv(f'{file_prefix}CO/{Flight_ID}_obs_smk.csv', index_col=0)['Observation'].iloc[0]\n",
    "    # !! Observation\n",
    "    df_obs_nemr_o3      = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    df_obs_nemr_ox      = (pd.read_csv(f'{file_prefix}O3/{Flight_ID}_obs_smk_dil.csv', index_col=0)+pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_obs_smk_dil.csv', index_col=0)) / data_CO_smk_init\n",
    "    df_obs_co           = pd.read_csv(f'{file_prefix}CO/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_no           = pd.read_csv(f'{file_prefix}NO/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_no2          = pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_nox          = pd.read_csv(f'{file_prefix}NOx/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_no_no2       = df_obs_no.div(df_obs_no2)\n",
    "    \n",
    "    df_obs_o3           = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_ox           = df_obs_o3 + df_obs_no2\n",
    "    \n",
    "    df_obs_pan          = pd.read_csv(f'{file_prefix}PAN/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "\n",
    "    df_obs_ch2o         = pd.read_csv(f'{file_prefix}Formaldehyde/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_ch2o_no2     = df_obs_ch2o.div(df_obs_no2)\n",
    "    \n",
    "    df_obs_vocr         = VOCR_reader_cases(Flight_ID=Flight_ID, get_smk_dil=(postfix == 'smk_dil'), get_smk_conc=(postfix == 'smk'))    \n",
    "\n",
    "    df_obs_OHRnox       = (df_obs_no*9.7605E-12 + df_obs_no2*9.8258E-12)*2.46e10\n",
    "    # Workaround, need to be updated after\n",
    "    df_obs_vocr.index   = df_obs_OHRnox.index\n",
    "\n",
    "    df_obs_OHRvoc_OHRnox= df_obs_vocr.div(df_obs_OHRnox)\n",
    "    df_obs_OHRnox_OHRvoc= df_obs_OHRnox.div(df_obs_vocr)\n",
    "    \n",
    "    df_obs_nemr_hno2    = pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    df_obs_hno2         = pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_ald2         = pd.read_csv(f'{file_prefix}Acetaldehyde/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_glyx         = pd.read_csv(f'{file_prefix}Glyoxal/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_mgly         = pd.read_csv(f'{file_prefix}Methylglyoxal/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_biacet       = pd.read_csv(f'{file_prefix}Butanedione/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    # Propanal, important, TBD, for photolysis\n",
    "    df_obs_propanal     = df_obs_co*0.81/1000\n",
    "    # Butanal, important, TBD, for photolysis  \n",
    "    df_obs_butanal      = df_obs_co*0.20/1000\n",
    "    \n",
    "    df_obs_acet         = pd.read_csv(f'{file_prefix}Acetone/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_mek          = pd.read_csv(f'{file_prefix}MEK/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_acr          = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_macr         = pd.read_csv(f'{file_prefix}Methacrolein/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_mvk          = pd.read_csv(f'{file_prefix}Methacrolein/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_glyc         = pd.read_csv(f'{file_prefix}Glycoaldehyde/{Flight_ID}_obs_{postfix}.csv', index_col=0) # important\n",
    "    df_obs_hac          = pd.read_csv(f'{file_prefix}Hydroxyacetone/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_furfural     = pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_obs_{postfix}.csv', index_col=0) # important\n",
    "\n",
    "    df_obs_sesq         = pd.read_csv(f'{file_prefix}Sesquiterpenes/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_dmf          = pd.read_csv(f'{file_prefix}Dimethylfuran/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "\n",
    "    df_obs_ch2o_dil     = pd.read_csv(f'{file_prefix}Formaldehyde/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_ald2_dil     = pd.read_csv(f'{file_prefix}Acetaldehyde/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_ma_dil       = pd.read_csv(f'{file_prefix}Maleic_anhydride/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_furanoids_excl_dil= pd.read_csv(f'{file_prefix}Furan/{Flight_ID}_obs_smk_dil.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_obs_smk_dil.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_obs_smk_dil.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Methylfurfural/{Flight_ID}_obs_smk_dil.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_furanoids_excl    = pd.read_csv(f'{file_prefix}Furan/{Flight_ID}_obs_smk.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_obs_smk.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_obs_smk.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Methylfurfural/{Flight_ID}_obs_smk.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_obs_smk.csv', index_col=0)\n",
    "    \n",
    "    df_obs_methylfuran_dil   = pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "\n",
    "    df_obs_acr_dil      = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_butd_dil     = pd.read_csv(f'{file_prefix}Butadiene/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_o3_dil       = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_pan_dil       = pd.read_csv(f'{file_prefix}PAN/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "\n",
    "    # other primary vocs\n",
    "    df_obs_isop_dil     = pd.read_csv(f'{file_prefix}Isoprene/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_mtpa_dil     = pd.read_csv(f'{file_prefix}Monoterpenes/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_xyle_dil     = pd.read_csv(f'{file_prefix}Xylenes/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_butenal_dil  = pd.read_csv(f'{file_prefix}Butenal/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_cresol_dil   = pd.read_csv(f'{file_prefix}Cresol/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_dmf_dil      = pd.read_csv(f'{file_prefix}Dimethylfuran/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_guaiacol_dil = pd.read_csv(f'{file_prefix}Guaiacol/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_syringol_dil = pd.read_csv(f'{file_prefix}Syringol/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_sesq_dil     = pd.read_csv(f'{file_prefix}Sesquiterpenes/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "\n",
    "    # other secondary vocs\n",
    "    df_obs_rcho_dil     = pd.read_csv(f'{file_prefix}Lumped_C>=3_aldehydes/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_glyx_dil     = pd.read_csv(f'{file_prefix}Glyoxal/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_hcooh_dil    = pd.read_csv(f'{file_prefix}Formic_acid/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_acta_dil     = pd.read_csv(f'{file_prefix}Acetic_acid/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_macr_mvk_dil = pd.read_csv(f'{file_prefix}Methacrolein/{Flight_ID}_obs_smk_dil.csv', index_col=0) + \\\n",
    "                            pd.read_csv(f'{file_prefix}MVK/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_mek_dil      = pd.read_csv(f'{file_prefix}MEK/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_glyc_dil     = pd.read_csv(f'{file_prefix}Glycoaldehyde/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_mgly_dil     = pd.read_csv(f'{file_prefix}Methylglyoxal/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_hac_dil      = pd.read_csv(f'{file_prefix}Hydroxyacetone/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_phen_dil     = pd.read_csv(f'{file_prefix}Phenol/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_bald_dil     = pd.read_csv(f'{file_prefix}Benzaldehyde/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_furanone_dil = pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_acr_dil      = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_ma_dil       = pd.read_csv(f'{file_prefix}Maleic_anhydride/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_butanedione_dil= pd.read_csv(f'{file_prefix}Butanedione/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    \n",
    "    df_obs_TM123B_dil= pd.read_csv(f'{file_prefix}Trimethyl123benzene/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_TM135B_dil= pd.read_csv(f'{file_prefix}Trimethyl135benzene/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_C9arom_dil= df_obs_TM123B_dil + df_obs_TM135B_dil\n",
    "    \n",
    "    \n",
    "    # L(ROx)/L(NOx_broad)\n",
    "    df_obs_lrox_lnox_broad               = df_obs_co.copy()\n",
    "    df_obs_lrox_lnox_broad['Observation']= [np.nan]*len(df_obs_co)\n",
    "    # Ln/Q\n",
    "    df_obs_ln_q                          = df_obs_co.copy()\n",
    "    df_obs_ln_q['Observation']           = [np.nan]*len(df_obs_co)\n",
    "\n",
    "    # H2O2: HNO3\n",
    "    df_obs_h2o2_hno3                     = df_obs_co.copy()\n",
    "    df_obs_h2o2_hno3['Observation']      = [np.nan]*len(df_obs_co)\n",
    "    \n",
    "    df_obs_ch2o_co                       = df_obs_ch2o.div(df_obs_co)\n",
    "    df_obs_vocr_co                       = df_obs_vocr.div(df_obs_co)\n",
    "    df_obs_noxr_co                       = df_obs_OHRnox.div(df_obs_co)\n",
    "    df_obs_no_co                         = df_obs_no.div(df_obs_co)\n",
    "    df_obs_no2_co                        = df_obs_no2.div(df_obs_co)\n",
    "    df_obs_nox_co                        = df_obs_nox.div(df_obs_co)\n",
    "    df_obs_pan_co                        = df_obs_pan.div(df_obs_co)\n",
    "    df_obs_hno2_co                       = df_obs_hno2.div(df_obs_co)\n",
    "    df_obs_noz_co                        = df_obs_pan_co + df_obs_hno2_co\n",
    "\n",
    "\n",
    "    df_obs_furan                         = pd.read_csv(f'{file_prefix}Furan/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_mefuran                       = pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_dmf                           = pd.read_csv(f'{file_prefix}Dimethylfuran/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_furfural                      = pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_mefurfural                    = pd.read_csv(f'{file_prefix}Methylfurfural/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_furanone                      = pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_butd                          = pd.read_csv(f'{file_prefix}Butadiene/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_acr                           = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "\n",
    "    df_obs_furan_co                      = df_obs_furan.div(df_obs_co)\n",
    "    df_obs_mefuran_co                    = df_obs_mefuran.div(df_obs_co)\n",
    "    df_obs_dmf_co                        = df_obs_dmf.div(df_obs_co)\n",
    "    df_obs_furfural_co                   = df_obs_furfural.div(df_obs_co)\n",
    "    df_obs_mefurfural_co                 = df_obs_mefurfural.div(df_obs_co)\n",
    "    df_obs_furanone_co                   = df_obs_furanone.div(df_obs_co)\n",
    "    df_obs_butd_co                       = df_obs_butd.div(df_obs_co)\n",
    "    df_obs_acr_co                        = df_obs_acr.div(df_obs_co)\n",
    "\n",
    "    # Radicals\n",
    "    df_obs_ho2                           = df_obs_co.copy()\n",
    "    df_obs_ho2['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    df_obs_ro2                           = df_obs_co.copy()\n",
    "    df_obs_ro2['Observation']            = [np.nan]*len(df_obs_co)\n",
    "\n",
    "    # Produciton\n",
    "    df_obs_po3                           = df_obs_co.copy()\n",
    "    df_obs_po3['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    df_obs_pox                           = df_obs_co.copy()\n",
    "    df_obs_pox['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    df_obs_lo3                           = df_obs_co.copy()\n",
    "    df_obs_lo3['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    df_obs_lox                           = df_obs_co.copy()\n",
    "    df_obs_lox['Observation']            = [np.nan]*len(df_obs_co)\n",
    "\n",
    "    # Nitrate\n",
    "    #df_obs_pno3                          = pd.read_csv(f'{file_prefix}pNO3/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_hno3                          = pd.read_csv(f'{file_prefix}HNO3/{Flight_ID}_obs_{postfix}.csv', index_col=0)\n",
    "    df_obs_hno4                           = df_obs_co.copy()\n",
    "    df_obs_hno4['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    df_obs_ppn                           = df_obs_co.copy()\n",
    "    df_obs_ppn['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    df_obs_pns                           = df_obs_co.copy()\n",
    "    df_obs_pns['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    df_obs_ans                           = df_obs_co.copy()\n",
    "    df_obs_ans['Observation']            = [np.nan]*len(df_obs_co)\n",
    "\n",
    "    df_obs_no_dil                       = pd.read_csv(f'{file_prefix}NO/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_no2_dil                      = pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_hno2_dil                     = pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    #df_obs_pno3_dil                    = pd.read_csv(f'{file_prefix}pNO3/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_hno3_dil                     = pd.read_csv(f'{file_prefix}HNO3/{Flight_ID}_obs_smk_dil.csv', index_col=0)\n",
    "    df_obs_hno4_dil                     = df_obs_co.copy()\n",
    "    df_obs_hno4_dil['Observation']      = [np.nan]*len(df_obs_co)\n",
    "    df_obs_ppn_dil                      = df_obs_co.copy()\n",
    "    df_obs_ppn_dil['Observation']       = [np.nan]*len(df_obs_co)\n",
    "    df_obs_pns_dil                      = df_obs_co.copy()\n",
    "    df_obs_pns_dil['Observation']       = [np.nan]*len(df_obs_co)\n",
    "    df_obs_ans_dil                      = df_obs_co.copy()\n",
    "    df_obs_ans_dil['Observation']       = [np.nan]*len(df_obs_co)\n",
    "    df_obs_pns_excl_dil                 = df_obs_co.copy()\n",
    "    df_obs_pns_excl_dil['Observation']  = [np.nan]*len(df_obs_co)\n",
    "    df_obs_pan_dil                      = df_obs_co.copy()\n",
    "    df_obs_pan_dil['Observation']       = [np.nan]*len(df_obs_co)\n",
    "\n",
    "    df_obs_nemr_no                      = pd.read_csv(f'{file_prefix}NO/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    df_obs_nemr_no2                     = pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    df_obs_nemr_o3_nox                  = df_obs_nemr_o3.div(df_obs_nemr_no + df_obs_nemr_no2)\n",
    "    df_obs_nemr_hno2                    = pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    #df_obs_nemr_pno3                   = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    df_obs_nemr_hno3                    = pd.read_csv(f'{file_prefix}HNO3/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    df_obs_nemr_hno4                    = df_obs_co.copy()\n",
    "    df_obs_nemr_hno4['Observation']     = [np.nan]*len(df_obs_co)\n",
    "    df_obs_nemr_ppn                     = df_obs_co.copy()\n",
    "    df_obs_nemr_ppn['Observation']      = [np.nan]*len(df_obs_co)\n",
    "    df_obs_nemr_pns                     = df_obs_co.copy()\n",
    "    df_obs_nemr_pns['Observation']      = [np.nan]*len(df_obs_co)\n",
    "    df_obs_nemr_ans                     = df_obs_co.copy()\n",
    "    df_obs_nemr_ans['Observation']      = [np.nan]*len(df_obs_co)\n",
    "    df_obs_nemr_pns_excl                = df_obs_co.copy()\n",
    "    df_obs_nemr_pns_excl['Observation'] = [np.nan]*len(df_obs_co)\n",
    "    df_obs_nemr_pan                     = pd.read_csv(f'{file_prefix}PAN/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "\n",
    "    #df_obs_ppan                           = df_obs_co.copy()\n",
    "    #df_obs_ppan['Observation']            = [np.nan]*len(df_obs_co)\n",
    "    #df_obs_pmco3                          = df_obs_co.copy()\n",
    "    #df_obs_pmco3['Observation']           = [np.nan]*len(df_obs_co)\n",
    "    #df_obs_lpan                          = df_obs_co.copy()\n",
    "    #df_obs_lpan['Observation']           = [np.nan]*len(df_obs_co)\n",
    "    #df_obs_lmco3                          = df_obs_co.copy()\n",
    "    #df_obs_lmco3['Observation']           = [np.nan]*len(df_obs_co)\n",
    "\n",
    "    # response to reviewer\n",
    "    df_obs_nemr_benzene               = pd.read_csv(f'{file_prefix}Benzene/{Flight_ID}_obs_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "    df_obs_benzene                    = pd.read_csv(f'{file_prefix}Benzene/{Flight_ID}_obs_smk.csv', index_col=0)\n",
    "\n",
    "    if 'RF' in Flight_ID: \n",
    "        file_prefix_met = f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/F0AM_analysis_TS/WE-CAN/Model_inputs_prepared/output_data/{Flight_ID}_met_data.csv'\n",
    "        df_obs_met = pd.read_csv(file_prefix_met, index_col=0)\n",
    "    else:\n",
    "        df_obs_met = pd.DataFrame(index=df_obs_co.index)\n",
    "        dummy_columns = ['PRESSURE', 'TEMPERATURE', 'RHUM', 'SZA', 'JNO2_NO_O3P', 'JHNO2_OH_NO',\n",
    "                           'JH2O2_2OH', 'JHNO3_OH_NO2', 'JO3_O2_O1D', 'JCH2O_H_HCO', 'JCH2O_H2_CO',\n",
    "                           'JNO3_NO_O2', 'JNO3_NO2_O3P', 'JN2O5_NO3_NO2',\n",
    "                           'JHNO4_HO2_NO2_UV_VISonly', 'JCH3CHO_CH3_HCO', 'JPropanal_C2H5_HCO',\n",
    "                           'JCH3OOH_CH3O_OH', 'JMeONO2_CH3O_NO2', 'JEthONO2_CH3CH2O_NO2',\n",
    "                           'JCH3COOONO2_CH3COOO_NO2', 'JCH3COOONO2_CH3COO_NO3', 'JMAC_Products',\n",
    "                           'JMVK_Products', 'JAcetone_CH3CO_CH3', 'JMEK_CH3CO_CH2CH3',\n",
    "                           'JHydroxyacetone_CH3COO_CH3', 'JHydroxyacetone_CH3CO_CH3O',\n",
    "                           'JCHOCHO_HCO_HCO', 'JCHOCHO_H2_2CO', 'JCHOCHO_CH2O_CO',\n",
    "                           'JCH3COCHO_CH3CO_HCO', 'J23Butanedione_Products', 'JCl2_Cl_Cl',\n",
    "                           'JClO_Cl_O3P', 'JClNO2_Cl_NO2', 'JClONO_Cl_NO2', 'JClONO2_Cl_NO3',\n",
    "                           'JClONO2_ClO_NO2', 'JBr2_Br_Br', 'JBrO_Br_O', 'JHOBr_OH_Br',\n",
    "                           'JBrNO_Br_NO', 'JBrONO_Br_NO2', 'JBrONO_BrO_NO', 'JBrNO2_Br_NO2',\n",
    "                           'JBrONO2_BrO_NO2', 'JBrONO2_Br_NO3', 'JBrCl_Br_Cl', 'JCHBr3_Products']\n",
    "        for column in dummy_columns: df_obs_met[column] = [np.nan]*len(df_obs_co)\n",
    "\n",
    "    if Flight_ID in Lagrangian_flights:\n",
    "        print(Flight_ID)\n",
    "        #print(df_obs_met['TEMPERATURE'])\n",
    "\n",
    "    # !! Model\n",
    "    # Read model data if only focusing on observations, Lagrangian flights, and the model simulation exists\n",
    "    if (Path(f'{file_prefix}CO/{Flight_ID}_mod_{postfix}.csv').is_file()) and Flight_ID in Lagrangian_flights:\n",
    "        df_mod_nemr_o3 = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_ox = (pd.read_csv(f'{file_prefix}O3/{Flight_ID}_mod_smk_dil.csv', index_col=0) +  pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_mod_smk_dil.csv', index_col=0))/ data_CO_smk_init\n",
    "        df_mod_co      = pd.read_csv(f'{file_prefix}CO/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_no      = pd.read_csv(f'{file_prefix}NO/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_no2     = pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_nox     = pd.read_csv(f'{file_prefix}NOx/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "\n",
    "        df_mod_no_no2  = df_mod_no.div(df_mod_no2)\n",
    "        \n",
    "        df_mod_o3      = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_ox      = df_mod_o3 + df_mod_no2\n",
    "        \n",
    "        df_mod_pan     = pd.read_csv(f'{file_prefix}PAN/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "\n",
    "        df_mod_ch2o    = pd.read_csv(f'{file_prefix}Formaldehyde/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_ch2o_no2= df_mod_ch2o.div(df_mod_no2)\n",
    "        \n",
    "        df_mod_vocr    = pd.read_csv(f'{file_prefix}TVOCR/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        if len(df_mod_vocr) == len(df_mod_co): \n",
    "            df_mod_vocr.index = df_mod_co.index\n",
    "        else:\n",
    "            print('smt is wrong...')\n",
    "        df_mod_OHRnox  = (df_mod_no*9.7605E-12 + df_mod_no2*9.8258E-12)*2.46e10\n",
    "        df_mod_OHRvoc_OHRnox = df_mod_vocr.div(df_mod_OHRnox) \n",
    "        df_mod_OHRnox_OHRvoc = df_mod_OHRnox.div(df_mod_vocr)\n",
    "\n",
    "        df_mod_nemr_hno2= pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_hno2     = pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_ald2     = pd.read_csv(f'{file_prefix}Acetaldehyde/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_glyx     = pd.read_csv(f'{file_prefix}Glyoxal/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_mgly     = pd.read_csv(f'{file_prefix}Methylglyoxal/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_biacet   = pd.read_csv(f'{file_prefix}Butanedione/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        # Propanal, important, TBD\n",
    "        df_mod_propanal = df_mod_co*0.81/1000\n",
    "        # Butanal, important, TBD    \n",
    "        df_mod_butanal  = df_mod_co*0.20/1000\n",
    "\n",
    "        df_mod_acet     = pd.read_csv(f'{file_prefix}Acetone/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_mek      = pd.read_csv(f'{file_prefix}MEK/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_acr      = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_macr     = pd.read_csv(f'{file_prefix}Methacrolein/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_mvk      = pd.read_csv(f'{file_prefix}Methacrolein/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_glyc     = pd.read_csv(f'{file_prefix}Glycoaldehyde/{Flight_ID}_mod_{postfix}.csv', index_col=0) # important\n",
    "        df_mod_hac      = pd.read_csv(f'{file_prefix}Hydroxyacetone/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_furfural = pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_mod_{postfix}.csv', index_col=0) # important\n",
    "    \n",
    "        df_mod_sesq     = pd.read_csv(f'{file_prefix}Sesquiterpenes/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_dmf      = pd.read_csv(f'{file_prefix}Dimethylfuran/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "            \n",
    "        df_mod_ch2o_dil     = pd.read_csv(f'{file_prefix}Formaldehyde/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_ald2_dil     = pd.read_csv(f'{file_prefix}Acetaldehyde/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_ma_dil       = pd.read_csv(f'{file_prefix}Maleic_anhydride/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_furanoids_excl_dil= pd.read_csv(f'{file_prefix}Furan/{Flight_ID}_mod_smk_dil.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_mod_smk_dil.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_mod_smk_dil.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Methylfurfural/{Flight_ID}_mod_smk_dil.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_furanoids_excl    = pd.read_csv(f'{file_prefix}Furan/{Flight_ID}_mod_smk.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_mod_smk.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_mod_smk.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Methylfurfural/{Flight_ID}_mod_smk.csv', index_col=0) + \\\n",
    "                                    pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_mod_smk.csv', index_col=0)\n",
    "\n",
    "        \n",
    "        df_mod_methylfuran_dil   = pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "\n",
    "        df_mod_acr_dil      = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_butd_dil     = pd.read_csv(f'{file_prefix}Butadiene/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_o3_dil       = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_pan_dil      = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "\n",
    "        # other primary VOCs\n",
    "        df_mod_isop_dil     = pd.read_csv(f'{file_prefix}Isoprene/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_mtpa_dil     = pd.read_csv(f'{file_prefix}Monoterpenes/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_xyle_dil     = pd.read_csv(f'{file_prefix}Xylenes/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_butenal_dil  = pd.read_csv(f'{file_prefix}Butenal/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_cresol_dil   = pd.read_csv(f'{file_prefix}Cresol/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_dmf_dil      = pd.read_csv(f'{file_prefix}Dimethylfuran/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_guaiacol_dil  = pd.read_csv(f'{file_prefix}Guaiacol/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_syringol_dil = pd.read_csv(f'{file_prefix}Syringol/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_sesq_dil     = pd.read_csv(f'{file_prefix}Sesquiterpenes/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "    \n",
    "        # other secondary vocs\n",
    "        df_mod_rcho_dil     = pd.read_csv(f'{file_prefix}Lumped_C>=3_aldehydes/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_glyx_dil     = pd.read_csv(f'{file_prefix}Glyoxal/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_hcooh_dil    = pd.read_csv(f'{file_prefix}Formic_acid/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_acta_dil     = pd.read_csv(f'{file_prefix}Acetic_acid/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_macr_mvk_dil = pd.read_csv(f'{file_prefix}Methacrolein/{Flight_ID}_mod_smk_dil.csv', index_col=0) + \\\n",
    "                                pd.read_csv(f'{file_prefix}MVK/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_mek_dil      = pd.read_csv(f'{file_prefix}MEK/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_glyc_dil     = pd.read_csv(f'{file_prefix}Glycoaldehyde/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_mgly_dil     = pd.read_csv(f'{file_prefix}Methylglyoxal/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_hac_dil      = pd.read_csv(f'{file_prefix}Hydroxyacetone/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_phen_dil     = pd.read_csv(f'{file_prefix}Phenol/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_bald_dil     = pd.read_csv(f'{file_prefix}Benzaldehyde/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_furanone_dil = pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_acr_dil      = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_ma_dil       = pd.read_csv(f'{file_prefix}Maleic_anhydride/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_butanedione_dil= pd.read_csv(f'{file_prefix}Butanedione/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        \n",
    "        df_mod_TM123B_dil= pd.read_csv(f'{file_prefix}Trimethyl123benzene/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_TM135B_dil= pd.read_csv(f'{file_prefix}Trimethyl135benzene/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_C9arom_dil= df_mod_TM123B_dil + df_mod_TM135B_dil\n",
    "        # L(ROx)/L(NOx_broad)\n",
    "        df_mod_nox_broad_loss        = pd.read_csv(f'{file_prefix_PL}NOx_broad/{Flight_ID}_Loss_rates_evolution.csv', index_col=0)\n",
    "        df_mod_rox_loss              = pd.read_csv(f'{file_prefix_PL}ROx/{Flight_ID}_Loss_rates_evolution.csv', index_col=0)   \n",
    "        df_mod_lrox_lnox_broad_dummy = df_mod_rox_loss.div(df_mod_nox_broad_loss)\n",
    "    \n",
    "        # Ln/Q\n",
    "        df_mod_ln                    = (pd.read_csv(f'{file_prefix_PL}HNO3/{Flight_ID}_Production_rates_evolution.csv', index_col=0) + \\\n",
    "                                        pd.read_csv(f'{file_prefix_PL}HNO4/{Flight_ID}_Production_rates_evolution.csv', index_col=0) + \\\n",
    "                                        pd.read_csv(f'{file_prefix_PL}PNs/{Flight_ID}_Production_rates_evolution.csv', index_col=0) + \\\n",
    "                                        pd.read_csv(f'{file_prefix_PL}ANs/{Flight_ID}_Production_rates_evolution.csv', index_col=0))*(-1)\n",
    "        df_mod_rox_loss              = pd.read_csv(f'{file_prefix_PL}ROx/{Flight_ID}_Loss_rates_evolution.csv', index_col=0)   \n",
    "        df_mod_q                     = df_mod_ln + df_mod_rox_loss\n",
    "        df_mod_ln_q_dummy            = df_mod_ln.div(df_mod_q)\n",
    "\n",
    "        # H2O2/HNO3\n",
    "        df_mod_h2o2                  = pd.read_csv(f'{file_prefix}H2O2/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_hno3                  = pd.read_csv(f'{file_prefix}HNO3/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_hno3.index            = df_mod_h2o2.index\n",
    "        df_mod_h2o2_hno3_dummy       = df_mod_h2o2.div(df_mod_hno3)\n",
    "\n",
    "        # Standardize the model simulations of produciton/rate related\n",
    "        df_mod_ln_q                  = interp(df_mod_ln_q_dummy, df_mod_co.index.values)\n",
    "        df_mod_lrox_lnox_broad       = interp(df_mod_lrox_lnox_broad_dummy, df_mod_co.index.values)\n",
    "        df_mod_h2o2_hno3             = interp(df_mod_h2o2_hno3_dummy, df_mod_co.index.values)\n",
    "        \n",
    "        df_mod_ch2o_co               = df_mod_ch2o.div(df_mod_co)\n",
    "        df_mod_vocr_co               = df_mod_vocr.div(df_mod_co)\n",
    "        df_mod_noxr_co               = df_mod_OHRnox.div(df_mod_co)\n",
    "        df_mod_no_co                 = df_mod_no.div(df_mod_co)\n",
    "        df_mod_no2_co                = df_mod_no2.div(df_mod_co)\n",
    "        df_mod_nox_co                = df_mod_nox.div(df_mod_co)\n",
    "        df_mod_pan_co                = df_mod_pan.div(df_mod_co)\n",
    "        df_mod_hno2_co               = df_mod_hno2.div(df_mod_co)\n",
    "        df_mod_noz_co                = df_mod_pan_co + df_mod_hno2_co\n",
    "\n",
    "        df_mod_furan                         = pd.read_csv(f'{file_prefix}Furan/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_mefuran                       = pd.read_csv(f'{file_prefix}Methylfuran/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_dmf                           = pd.read_csv(f'{file_prefix}Dimethylfuran/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_furfural                      = pd.read_csv(f'{file_prefix}Furfural/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_mefurfural                    = pd.read_csv(f'{file_prefix}Methylfurfural/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_furanone                      = pd.read_csv(f'{file_prefix}Furanone/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_butd                          = pd.read_csv(f'{file_prefix}Butadiene/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_acr                           = pd.read_csv(f'{file_prefix}Acrolein/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "    \n",
    "        df_mod_furan_co                      = df_mod_furan.div(df_mod_co)\n",
    "        df_mod_mefuran_co                    = df_mod_mefuran.div(df_mod_co)\n",
    "        df_mod_dmf_co                        = df_mod_dmf.div(df_mod_co)\n",
    "        df_mod_furfural_co                   = df_mod_furfural.div(df_mod_co)\n",
    "        df_mod_mefurfural_co                 = df_mod_mefurfural.div(df_mod_co)\n",
    "        df_mod_furanone_co                   = df_mod_furanone.div(df_mod_co)\n",
    "        df_mod_butd_co                       = df_mod_butd.div(df_mod_co)\n",
    "        df_mod_acr_co                        = df_mod_acr.div(df_mod_co)\n",
    "    \n",
    "        df_mod_ho2_dummy                     = pd.read_csv(f'{file_prefix}HO2/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_ro2_dummy                     = pd.read_csv(f'{file_prefix}TRO2/{Flight_ID}_mod_{postfix}.csv', index_col=0)   \n",
    "\n",
    "        df_mod_po3_dummy                     = pd.read_csv(f'{file_prefix_PL}O3/{Flight_ID}_Production_rates_evolution.csv', index_col=0)        \n",
    "        df_mod_pox_dummy                     = pd.read_csv(f'{file_prefix_PL}Ox/{Flight_ID}_Production_rates_evolution.csv', index_col=0)\n",
    "        df_mod_lo3_dummy                     = pd.read_csv(f'{file_prefix_PL}O3/{Flight_ID}_Loss_rates_evolution.csv', index_col=0)        \n",
    "        df_mod_lox_dummy                     = pd.read_csv(f'{file_prefix_PL}Ox/{Flight_ID}_Loss_rates_evolution.csv', index_col=0)\n",
    "        #df_mod_ppan                 = pd.read_csv(f'{file_prefix_PL}PAN/{Flight_ID}_Production_rates_full_MCMBBVOC.csv', index_col=0)\n",
    "        #df_mod_pmco3                = pd.read_csv(f'{file_prefix_PL}CH3CO3/{Flight_ID}_Production_rates_full_MCMBBVOC.csv', index_col=0)\n",
    "        #df_mod_lpan                 = pd.read_csv(f'{file_prefix_PL}PAN/{Flight_ID}_Loss_rates_full_MCMBBVOC.csv', index_col=0)\n",
    "        #df_mod_lmco3                = pd.read_csv(f'{file_prefix_PL}CH3CO3/{Flight_ID}_Loss_rates_full_MCMBBVOC.csv', index_col=0)\n",
    "\n",
    "        # Regrid production/loss rate to concentration index\n",
    "        # Observation indices to which the model data needs to be regridded\n",
    "        conc_index = df_mod_co.index\n",
    "        # Interpolating model values at the observation indices\n",
    "        df_mod_ho2= interp(df_mod_ho2_dummy, conc_index)\n",
    "        df_mod_ro2= interp(df_mod_ro2_dummy, conc_index)\n",
    "        df_mod_po3= interp(df_mod_po3_dummy, conc_index)\n",
    "        df_mod_pox= interp(df_mod_pox_dummy, conc_index)\n",
    "        df_mod_lo3= interp(df_mod_lo3_dummy, conc_index)\n",
    "        df_mod_lox= interp(df_mod_lox_dummy, conc_index)\n",
    "\n",
    "        # Nitrate\n",
    "        #df_mod_pno3                          = pd.read_csv(f'{file_prefix}pNO3/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_hno3                         = pd.read_csv(f'{file_prefix}HNO3/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_hno4                         = pd.read_csv(f'{file_prefix}HNO4/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_ppn                          = pd.read_csv(f'{file_prefix}PPN/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_pns                          = pd.read_csv(f'{file_prefix}TPNs/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        df_mod_ans                          = pd.read_csv(f'{file_prefix}TANs/{Flight_ID}_mod_{postfix}.csv', index_col=0)\n",
    "        \n",
    "        df_mod_no_dil                       = pd.read_csv(f'{file_prefix}NO/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_no2_dil                      = pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_hno2_dil                     = pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        #df_mod_pno3_dil                     = pd.read_csv(f'{file_prefix}pNO3/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_hno3_dil                     = pd.read_csv(f'{file_prefix}HNO3/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_hno4_dil                     = pd.read_csv(f'{file_prefix}HNO4/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_ppn_dil                      = pd.read_csv(f'{file_prefix}PPN/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_pns_dil                      = pd.read_csv(f'{file_prefix}TPNs/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_ans_dil                      = pd.read_csv(f'{file_prefix}TANs/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_pan_dil                      = pd.read_csv(f'{file_prefix}PAN/{Flight_ID}_mod_smk_dil.csv', index_col=0)\n",
    "        df_mod_no_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_no2_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_hno2_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_hno3_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_hno4_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_ppn_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_pns_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_ans_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_pan_dil.index = df_mod_o3_dil.index\n",
    "        df_mod_pns_excl_dil  = df_mod_pns_dil - df_mod_pan_dil - df_mod_ppn_dil\n",
    "\n",
    "        df_mod_nemr_no                      = pd.read_csv(f'{file_prefix}NO/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_no2                     = pd.read_csv(f'{file_prefix}NO2/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_hno2                    = pd.read_csv(f'{file_prefix}HONO/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        #df_mod_nemr_pno3                   = pd.read_csv(f'{file_prefix}O3/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_hno3                    = pd.read_csv(f'{file_prefix}HNO3/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_hno4                    = pd.read_csv(f'{file_prefix}HNO4/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_ppn                     = pd.read_csv(f'{file_prefix}PPN/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_pns                     = pd.read_csv(f'{file_prefix}TPNs/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_ans                     = pd.read_csv(f'{file_prefix}TANs/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_pan                     = pd.read_csv(f'{file_prefix}PAN/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_nemr_no.index   = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_no2.index  = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_hno2.index = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_hno3.index = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_hno4.index = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_ppn.index  = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_pns.index  = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_ans.index  = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_pan.index  = df_mod_nemr_o3.index\n",
    "        df_mod_nemr_pns_excl   = df_mod_nemr_pns-df_mod_nemr_pan-df_mod_nemr_ppn\n",
    "\n",
    "        df_mod_nemr_o3_nox     = df_mod_nemr_o3.div(df_mod_nemr_no + df_mod_nemr_no2)\n",
    "\n",
    "        # Response to reviewer\n",
    "        df_mod_nemr_benzene               = pd.read_csv(f'{file_prefix}Benzene/{Flight_ID}_mod_smk_dil.csv', index_col=0) / data_CO_smk_init\n",
    "        df_mod_benzene                    = pd.read_csv(f'{file_prefix}Benzene/{Flight_ID}_mod_smk.csv', index_col=0)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Calulated OH values and chemical ages\n",
    "    # for both model and observations\n",
    "    # ---------------------------------------------------\n",
    "    # Initialize an empty DataFrame to store OH values\n",
    "    Cal_OH_conc_df_obs = pd.DataFrame()\n",
    "    Cal_OH_conc_df_mod = pd.DataFrame()\n",
    "    \n",
    "    Cal_OH_conc_df_obs_wide = pd.DataFrame()\n",
    "    Cal_OH_conc_df_mod_wide = pd.DataFrame()\n",
    "\n",
    "    Cal_OH_expo_df_obs = pd.DataFrame()\n",
    "    Cal_OH_expo_df_mod = pd.DataFrame()\n",
    "    \n",
    "    # Get the OH data\n",
    "    for voc_name in voc_names:\n",
    "        # Differnt VOC sets\n",
    "        file_obs_voc, file_mod_voc  = f'{file_prefix}{voc_name.replace(\" \", \"_\")}/{Flight_ID}_obs_{postfix}.csv', f'{file_prefix}{voc_name.replace(\" \", \"_\")}/{Flight_ID}_mod_{postfix}.csv'\n",
    "        file_obs_co, file_mod_co    = f'{file_prefix}CO/{Flight_ID}_obs_{postfix}.csv', f'{file_prefix}CO/{Flight_ID}_mod_{postfix}.csv'\n",
    "        file_obs_benz, file_mod_benz= f'{file_prefix}Benzene/{Flight_ID}_obs_{postfix}.csv', f'{file_prefix}Benzene/{Flight_ID}_mod_{postfix}.csv'\n",
    "        # Read in data when observation values exist\n",
    "        if Path(file_obs_voc).is_file(): \n",
    "            # Observation\n",
    "            df_obs_voc            = pd.read_csv(file_obs_voc, index_col=0)\n",
    "            df_obs_co             = pd.read_csv(file_obs_co, index_col=0)\n",
    "            df_obs_voc.index.name = 'Avg_physical_age_min'\n",
    "            df_obs_co.index.name  = 'Avg_physical_age_min'\n",
    "            # Further play with observations for selected cases\n",
    "            if (Flight_ID in Lagrangian_flights):    \n",
    "                df_mod_voc            = pd.read_csv(file_mod_voc, index_col=0)\n",
    "                df_mod_co             = pd.read_csv(file_mod_co, index_col=0)\n",
    "                df_mod_voc.index.name = 'Avg_physical_age_min'                \n",
    "                df_mod_co.index.name  = 'Avg_physical_age_min'                \n",
    "        else:\n",
    "            # Observation\n",
    "            df_dummy = pd.read_csv(file_prefix + 'O3' + '/'+ Flight_ID + '_obs_' + postfix +'.csv', index_col=0)\n",
    "            df_obs_voc = pd.DataFrame(0, index=df_dummy.index, columns = ['Observation'])\n",
    "            df_obs_co  = pd.DataFrame(0, index=df_dummy.index, columns = ['Observation'])\n",
    "            # Model\n",
    "            dummy_columns =  ['GEOS-Chem (base)', 'GEOS-Chem + FUR', 'MCM + FUR', 'MCM + GEOS-Chem VOCs']\n",
    "            df_mod_voc = pd.DataFrame(index=df_obs_voc.index)\n",
    "            df_mod_co  = pd.DataFrame(index=df_obs_voc.index)\n",
    "            #df_mod_benz= pd.DataFrame(index=df_obs_voc.index)\n",
    "            for column in dummy_columns:\n",
    "                df_mod_voc[column] = df_obs_voc['Observation']\n",
    "                df_mod_co[column]  = df_obs_voc['Observation']    \n",
    "\n",
    "        # Calculate OH level\n",
    "        time_obs                    = df_obs_voc.index.values\n",
    "        # Select A and B here\n",
    "        k_OH_A, k_OH_B, ER_a_over_b = k_OH_dic[voc_name], k_OH_dic['CO'], ER_dic[voc_name]/ER_dic['CO']\n",
    "        A_obs, B_obs                = df_obs_voc.values.T[0], df_obs_co.values.T[0]\n",
    "        if Flight_ID in  ['RF07', 'RF09']:\n",
    "            # Define the time values (in the same units as your index) for each emission pass\n",
    "            if Flight_ID == 'RF07':\n",
    "                times_pass1 = np.array([134.1, 165.99, 189.73, 195.37, 212.49])\n",
    "                #times_pass1 = np.array([25, 28, 29]) # dummy data\n",
    "\n",
    "                times_pass2 = np.array([121.49, 181.23, 188.55, 243.56, 276.89, 295.82])\n",
    "                #times_pass2 = np.array([25, 28, 29]) # dummy data\n",
    "\n",
    "            if Flight_ID == 'RF09':\n",
    "                times_pass1 = np.array([24.57, 47.14, 66.95, 89.56, 113.69, 123.45, 158.0, 178.75, 202.59, 224.64])\n",
    "                #times_pass1 = np.array([25, 28, 29]) # dummy data\n",
    "                times_pass2 = np.array([64.43, 106.83, 154.96, 240.51, 245.62, 263.51, 277.23])\n",
    "                #times_pass2 = np.array([25, 28, 29]) # dummy data\n",
    "            # Create masks for each emission pass\n",
    "            mask_pass1 = np.isin(df_obs_voc.index.values, times_pass1)\n",
    "            mask_pass2 = np.isin(df_obs_voc.index.values, times_pass2)\n",
    "            \n",
    "            # Subset the DataFrames for each pass\n",
    "            df_voc_pass1 = df_obs_voc[mask_pass1]\n",
    "            df_co_pass1  = df_obs_co[mask_pass1]\n",
    "            \n",
    "            df_voc_pass2 = df_obs_voc[mask_pass2]\n",
    "            df_co_pass2  = df_obs_co[mask_pass2]\n",
    "            \n",
    "            # Set up the parameters for calculating OH\n",
    "            k_OH_A = k_OH_dic[voc_name]\n",
    "            k_OH_B = k_OH_dic['CO']\n",
    "            ER_a_over_b = ER_dic[voc_name] / ER_dic['CO']\n",
    "            \n",
    "            # Calculate OH for emission pass 1:\n",
    "            time_obs_pass1 = df_voc_pass1.index.values\n",
    "            A_obs_pass1    = df_voc_pass1.values.T[0]  # VOC observations\n",
    "            B_obs_pass1    = df_co_pass1.values.T[0]   # CO observations\n",
    "            \n",
    "            OH_pass1 = calculate_OH_conc_avg(time_obs_pass1 * 60, A_obs_pass1, B_obs_pass1,\n",
    "                                             k_OH_A, k_OH_B, ER_a_over_b)\n",
    "            \n",
    "            # Calculate OH for emission pass 2:\n",
    "            time_obs_pass2 = df_voc_pass2.index.values\n",
    "            A_obs_pass2    = df_voc_pass2.values.T[0]\n",
    "            B_obs_pass2    = df_co_pass2.values.T[0]\n",
    "            \n",
    "            OH_pass2 = calculate_OH_conc_avg(time_obs_pass2 * 60, A_obs_pass2, B_obs_pass2,\n",
    "                                             k_OH_A, k_OH_B, ER_a_over_b)\n",
    "            \n",
    "            # Convert the results into Series with the original time index\n",
    "            OH_series_pass1 = pd.Series(OH_pass1, index=df_voc_pass1.index)\n",
    "            OH_series_pass2 = pd.Series(OH_pass2, index=df_voc_pass2.index)\n",
    "\n",
    "            # Save out the data\n",
    "            OH_series_dict[Flight_ID] = {\n",
    "                'pass1': OH_series_pass1,\n",
    "                'pass2': OH_series_pass2\n",
    "            }\n",
    "\n",
    "            # Merge the two Series back together and sort by time index\n",
    "            Cal_OH_conc_obs = pd.concat([OH_series_pass1, OH_series_pass2]).sort_index()\n",
    "        else:\n",
    "            Cal_OH_conc_obs                  = calculate_OH_conc_avg(time_obs*60, A_obs, B_obs, k_OH_A, k_OH_B, ER_a_over_b)\n",
    "\n",
    "        # Reindex Cal_OH_conc_df_obs to match df_obs_voc's index\n",
    "        Cal_OH_conc_df_obs = Cal_OH_conc_df_obs.reindex(df_obs_voc.index)\n",
    "        \n",
    "        # Calculate others\n",
    "        Cal_OH_conc_obs_wide             = calculate_OH_conc_avg_wide(time_obs*60, A_obs, B_obs, k_OH_A, k_OH_B, ER_a_over_b)\n",
    "        Cal_OH_expo_obs                  = calculate_OH_expo_avg(time_obs*60, Cal_OH_conc_obs)\n",
    "\n",
    "        # Making the first data point None (np.nan), make Lu happy...\n",
    "        Cal_OH_conc_obs[0]               = np.nan        \n",
    "        Cal_OH_conc_obs_wide[0]          = np.nan        \n",
    "        Cal_OH_conc_df_obs[voc_name]     = Cal_OH_conc_obs \n",
    "        Cal_OH_conc_df_obs_wide[voc_name]= Cal_OH_conc_obs_wide\n",
    "        \n",
    "        Cal_OH_conc_df_obs.index         = df_obs_voc.index\n",
    "        Cal_OH_conc_df_obs_wide.index    = df_obs_voc.index\n",
    "        \n",
    "        Cal_OH_expo_obs[0]               = np.nan        \n",
    "        Cal_OH_expo_df_obs[voc_name]     = Cal_OH_expo_obs \n",
    "        Cal_OH_expo_df_obs.index         = df_obs_voc.index\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        if (Flight_ID in Lagrangian_flights): \n",
    "            time_mod                     = df_mod_voc.index.values\n",
    "            A_mod, B_mod                 = df_mod_voc['MCM + FUR'].values, df_mod_co['MCM + FUR'].values\n",
    "            Cal_OH_conc_mod              = calculate_OH_conc_avg(time_mod*60, A_mod, B_mod, k_OH_A, k_OH_B, ER_a_over_b)\n",
    "            Cal_OH_conc_mod_wide         = calculate_OH_conc_avg_wide(time_mod*60, A_mod, B_mod, k_OH_A, k_OH_B, ER_a_over_b)\n",
    "            Cal_OH_conc_df_mod[voc_name]      = Cal_OH_conc_mod\n",
    "            Cal_OH_conc_df_mod_wide[voc_name] = Cal_OH_conc_mod_wide\n",
    "            Cal_OH_conc_df_mod.index     = df_mod_voc.index\n",
    "            Cal_OH_conc_df_mod_wide.index= df_mod_voc.index\n",
    "            Cal_OH_expo_mod              = calculate_OH_expo_avg(time_mod*60, Cal_OH_conc_mod)\n",
    "            Cal_OH_expo_df_mod[voc_name] = Cal_OH_expo_mod\n",
    "            Cal_OH_expo_df_mod.index     = df_mod_voc.index\n",
    "\n",
    "    \n",
    "    # Replace np.inf and negative value with NaN\n",
    "    Cal_OH_conc_df_obs = Cal_OH_conc_df_obs.replace([np.inf, -np.inf], np.nan)\n",
    "    Cal_OH_conc_df_mod = Cal_OH_conc_df_mod.replace([np.inf, -np.inf], np.nan)\n",
    "    Cal_OH_conc_df_obs = Cal_OH_conc_df_obs.mask(Cal_OH_conc_df_obs < 0)\n",
    "    Cal_OH_conc_df_mod = Cal_OH_conc_df_mod.mask(Cal_OH_conc_df_mod < 0)\n",
    "\n",
    "    Cal_OH_conc_df_obs_wide = Cal_OH_conc_df_obs_wide.replace([np.inf, -np.inf], np.nan)\n",
    "    Cal_OH_conc_df_mod_wide = Cal_OH_conc_df_mod_wide.replace([np.inf, -np.inf], np.nan)\n",
    "    Cal_OH_conc_df_obs_wide = Cal_OH_conc_df_obs_wide.mask(Cal_OH_conc_df_obs_wide < 0)\n",
    "    Cal_OH_conc_df_mod_wide = Cal_OH_conc_df_mod_wide.mask(Cal_OH_conc_df_mod_wide < 0)\n",
    "\n",
    "    \n",
    "    Cal_OH_expo_df_obs = Cal_OH_expo_df_obs.replace([np.inf, -np.inf], np.nan)\n",
    "    Cal_OH_expo_df_mod = Cal_OH_expo_df_mod.replace([np.inf, -np.inf], np.nan)\n",
    "    Cal_OH_expo_df_obs = Cal_OH_expo_df_obs.mask(Cal_OH_expo_df_obs < 0)\n",
    "    Cal_OH_expo_df_mod = Cal_OH_expo_df_mod.mask(Cal_OH_expo_df_mod < 0)\n",
    "\n",
    "    # Clean up the data when the whole column is missing data.\n",
    "    Cal_OH_conc_df_obs      = Cal_OH_conc_df_obs.dropna(axis='columns', how='all')\n",
    "    Cal_OH_conc_df_mod      = Cal_OH_conc_df_mod.dropna(axis='columns', how='all')\n",
    "\n",
    "    Cal_OH_conc_df_obs_wide = Cal_OH_conc_df_obs_wide.dropna(axis='columns', how='all')\n",
    "    Cal_OH_conc_df_mod_wide = Cal_OH_conc_df_mod_wide.dropna(axis='columns', how='all')\n",
    "    \n",
    "    Cal_OH_expo_df_obs = Cal_OH_expo_df_obs.dropna(axis='columns', how='all')\n",
    "    Cal_OH_expo_df_mod = Cal_OH_expo_df_mod.dropna(axis='columns', how='all')\n",
    "\n",
    "    \n",
    "    # Clean up the column when the column is five times larger or smaller than the median value \n",
    "    df_thresh, data_thresh = Cal_OH_conc_df_obs.median(), Cal_OH_conc_df_obs.median().median()\n",
    "    col_filtered = [column for column in df_thresh.index if data_thresh/5 < df_thresh.loc[column] < 5*data_thresh]        \n",
    "    Cal_OH_conc_df_obs = Cal_OH_conc_df_obs[col_filtered]\n",
    "    df_thresh, data_thresh = Cal_OH_expo_df_obs.median(), Cal_OH_expo_df_obs.median().median()\n",
    "    col_filtered = [column for column in df_thresh.index if data_thresh/5 < df_thresh.loc[column] < 5*data_thresh]        \n",
    "    Cal_OH_expo_df_obs = Cal_OH_expo_df_obs[col_filtered]\n",
    "\n",
    "    # Clean column when all values in the column is negative\n",
    "    Cal_OH_conc_df_obs      = Cal_OH_conc_df_obs.loc[:, ~(Cal_OH_conc_df_obs < 0).all()]\n",
    "    Cal_OH_conc_df_obs_wide = Cal_OH_conc_df_obs_wide.loc[:, ~(Cal_OH_conc_df_obs_wide < 0).all()]\n",
    "    Cal_OH_expo_df_obs      = Cal_OH_expo_df_obs.loc[:, ~(Cal_OH_expo_df_obs < 0).all()]\n",
    "    \n",
    "    # Clean row when all values in the row is negative\n",
    "    #Cal_OH_conc_df_obs= Cal_OH_conc_df_obs[~(Cal_OH_conc_df_obs < 0).all(axis=1)]\n",
    "    #Cal_OH_expo_df_obs= Cal_OH_expo_df_obs[~(Cal_OH_expo_df_obs < 0).all(axis=1)]\n",
    "\n",
    "    # Chemical age (calcualted OH/1.5E6)\n",
    "    Cal_chem_age_df_obs = pd.DataFrame(index=Cal_OH_expo_df_obs.index, columns=Cal_OH_expo_df_obs.columns)\n",
    "    Cal_chem_age_df_mod = pd.DataFrame(index=Cal_OH_expo_df_mod.index, columns=Cal_OH_expo_df_mod.columns)\n",
    "    for column in Cal_chem_age_df_obs.columns: \n",
    "        Cal_chem_age_df_obs[column] =  Cal_OH_expo_df_obs[column]/1.5E6/3600\n",
    "        if (Flight_ID in Lagrangian_flights): Cal_chem_age_df_mod[column] =  Cal_OH_expo_df_mod[column]/1.5E6/3600\n",
    "\n",
    "    # Calculate mean and standard deviation for each calculated OH and calculated chemical age\n",
    "    # Calcualted OH\n",
    "    mean_values_obs, median_values_obs, std_values_obs= Cal_OH_conc_df_obs.mean(axis=1), Cal_OH_conc_df_obs.median(axis=1), Cal_OH_conc_df_obs.std(axis=1)\n",
    "    q1_values_obs, q3_values_obs                      = Cal_OH_conc_df_obs.quantile(0.25, axis=1), Cal_OH_conc_df_obs.quantile(0.75, axis=1)\n",
    "    iqr_values_obs                                    = q3_values_obs - q1_values_obs\n",
    "    calOH_conc_obs_stat                               = pd.DataFrame({'Mean': mean_values_obs, 'Std Dev': std_values_obs, 'Median': median_values_obs, 'IQR': iqr_values_obs})\n",
    "    if (Flight_ID in Lagrangian_flights):\n",
    "        mean_values_mod, median_values_mod, std_values_mod= Cal_OH_conc_df_mod.mean(axis=1), Cal_OH_conc_df_mod.median(axis=1), Cal_OH_conc_df_mod.std(axis=1)\n",
    "        q1_values_mod, q3_values_mod = Cal_OH_conc_df_mod.quantile(0.25, axis=1), Cal_OH_conc_df_mod.quantile(0.75, axis=1)\n",
    "        iqr_values_mod               = q3_values_mod - q1_values_mod\n",
    "        calOH_conc_mod_stat          = pd.DataFrame({'Mean': mean_values_mod, 'Std Dev': std_values_mod, 'Median': median_values_mod, 'IQR': iqr_values_mod})  \n",
    "        \n",
    "    # Calcualted OH (wider avg)\n",
    "    mean_values_obs_wide, median_values_obs_wide, std_values_obs_wide= Cal_OH_conc_df_obs_wide.mean(axis=1), Cal_OH_conc_df_obs_wide.median(axis=1), Cal_OH_conc_df_obs_wide.std(axis=1)\n",
    "    q1_values_obs_wide, q3_values_obs_wide  = Cal_OH_conc_df_obs_wide.quantile(0.25, axis=1), Cal_OH_conc_df_obs_wide.quantile(0.75, axis=1)\n",
    "    iqr_values_obs_wide                     = q3_values_obs_wide - q1_values_obs_wide\n",
    "    calOH_conc_obs_stat_wide                = pd.DataFrame({'Mean': mean_values_obs_wide, 'Std Dev': std_values_obs_wide, 'Median': median_values_obs_wide, 'IQR': iqr_values_obs_wide})\n",
    "    if (Flight_ID in Lagrangian_flights):\n",
    "        mean_values_mod_wide, median_values_mod_wide, std_values_mod_wide= Cal_OH_conc_df_mod_wide.mean(axis=1), Cal_OH_conc_df_mod_wide.median(axis=1), Cal_OH_conc_df_mod_wide.std(axis=1)\n",
    "        q1_values_mod_wide, q3_values_mod_wide = Cal_OH_conc_df_mod_wide.quantile(0.25, axis=1), Cal_OH_conc_df_mod_wide.quantile(0.75, axis=1)\n",
    "        iqr_values_mod_wide                    = q3_values_mod_wide - q1_values_mod_wide\n",
    "        calOH_conc_mod_stat_wide               = pd.DataFrame({'Mean': mean_values_mod_wide, 'Std Dev': std_values_mod_wide, 'Median': median_values_mod_wide, 'IQR': iqr_values_mod_wide})  \n",
    "    \n",
    "    # Calculated chemical age\n",
    "    mean_values_obs, median_values_obs, std_values_obs= Cal_chem_age_df_obs.mean(axis=1), Cal_chem_age_df_obs.median(axis=1), Cal_chem_age_df_obs.std(axis=1)\n",
    "    q1_values_obs, q3_values_obs  = Cal_chem_age_df_obs.quantile(0.25, axis=1), Cal_chem_age_df_obs.quantile(0.75, axis=1)\n",
    "    iqr_values_obs = q3_values_obs - q1_values_obs\n",
    "    cal_chem_age_obs_stat = pd.DataFrame({'Mean': mean_values_obs, 'Std Dev': std_values_obs, 'Median': median_values_obs, 'IQR': iqr_values_obs})\n",
    "    if (Flight_ID in Lagrangian_flights):\n",
    "        mean_values_mod, median_values_mod, std_values_mod= Cal_chem_age_df_mod.mean(axis=1), Cal_chem_age_df_mod.median(axis=1), Cal_chem_age_df_mod.std(axis=1)\n",
    "        q1_values_mod, q3_values_mod = Cal_chem_age_df_mod.quantile(0.25, axis=1), Cal_chem_age_df_mod.quantile(0.75, axis=1)\n",
    "        iqr_values_mod = q3_values_mod - q1_values_mod\n",
    "        cal_chem_age_mod_stat = pd.DataFrame({'Mean': mean_values_mod, 'Std Dev': std_values_mod, 'Median': median_values_mod, 'IQR': iqr_values_mod})  \n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # Direct OH model output and chemical ages\n",
    "    # --------------------------------------------\n",
    "    df_obs_OH_conc_output                  = df_obs_co.copy()*2.46E10\n",
    "    df_obs_OH_conc_output['Observation']   = np.nan\n",
    "    df_obs_chem_age_output                 = df_obs_OH_conc_output.copy()\n",
    "    if (Path(f'{file_prefix}CO/{Flight_ID}_mod_{postfix}.csv').is_file()) and Flight_ID in Lagrangian_flights:\n",
    "        df_mod_OH_conc_output              = pd.read_csv(f'{file_prefix}OH/{Flight_ID}_mod_{postfix}.csv', index_col=0)*2.46E10\n",
    "        df_mod_OH_expo_output              = pd.DataFrame(index=df_mod_OH_conc_output.index, columns=df_mod_OH_conc_output.columns)\n",
    "        df_mod_OH_expo_output[:]           = np.nan  # Explicitly fill with NaN if needed\n",
    "        df_mod_chem_age_output             = df_mod_OH_expo_output.copy()\n",
    "        for column in df_mod_OH_expo_output.columns: \n",
    "            df_mod_OH_expo_output[column]  = calculate_OH_expo_avg(60*df_mod_OH_conc_output.index, df_mod_OH_conc_output[column])\n",
    "            df_mod_chem_age_output[column] = df_mod_OH_expo_output[column]/1.5E6/3600 # hours\n",
    "    # Replace observed output OH and its chemical age based on MCMBBVOC results.    \n",
    "    df_obs_OH_conc_output['Observation']   = np.interp(df_obs_OH_conc_output.index, df_mod_OH_conc_output.index, df_mod_OH_conc_output['MCM + FUR'])    \n",
    "    df_obs_chem_age_output['Observation']  = np.interp(df_obs_chem_age_output.index, df_mod_chem_age_output.index, df_mod_chem_age_output['MCM + FUR'])\n",
    "    # -----------------------------\n",
    "    # Save the data for each flight\n",
    "    # -----------------------------\n",
    "    nemr_o3_per_flight_obs[Flight_ID]      = df_obs_nemr_o3.reset_index()\n",
    "    nemr_o3_nox_per_flight_obs[Flight_ID]  = df_obs_nemr_o3_nox.reset_index()\n",
    "    nemr_ox_per_flight_obs[Flight_ID]      = df_obs_nemr_ox.reset_index()\n",
    "    co_per_flight_obs[Flight_ID]           = df_obs_co.reset_index()\n",
    "    no_per_flight_obs[Flight_ID]           = df_obs_no.reset_index()\n",
    "    no2_per_flight_obs[Flight_ID]          = df_obs_no2.reset_index()\n",
    "    no_no2_per_flight_obs[Flight_ID]       = df_obs_no_no2.reset_index()\n",
    "    nox_per_flight_obs[Flight_ID]          = df_obs_nox.reset_index()\n",
    "    o3_per_flight_obs[Flight_ID]           = df_obs_o3.reset_index()\n",
    "    ox_per_flight_obs[Flight_ID]           = df_obs_ox.reset_index()\n",
    "\n",
    "    pan_per_flight_obs[Flight_ID]          = df_obs_pan.reset_index()\n",
    "\n",
    "    ch2o_per_flight_obs[Flight_ID]         = df_obs_ch2o.reset_index()\n",
    "    ch2o_no2_per_flight_obs[Flight_ID]     = df_obs_ch2o_no2.reset_index()\n",
    "    \n",
    "    calOH_conc_stat_per_flight_obs[Flight_ID]      = calOH_conc_obs_stat.reset_index()\n",
    "    calOH_conc_stat_per_flight_obs_wide[Flight_ID] = calOH_conc_obs_stat_wide.reset_index()\n",
    "    calOH_conc_vocs_per_flight_obs[Flight_ID]      = Cal_OH_conc_df_obs.reset_index()\n",
    "    calOH_conc_vocs_per_flight_obs_wide[Flight_ID] = Cal_OH_conc_df_obs_wide.reset_index()\n",
    "    outputOH_conc_per_flight_obs[Flight_ID]        = df_obs_OH_conc_output.reset_index()\n",
    "\n",
    "    cal_chem_age_stat_per_flight_obs[Flight_ID]    = cal_chem_age_obs_stat.reset_index()\n",
    "    cal_chem_age_vocs_per_flight_obs[Flight_ID]    = Cal_chem_age_df_obs.reset_index()\n",
    "    output_chem_age_per_flight_obs[Flight_ID]      = df_obs_chem_age_output.reset_index()\n",
    "\n",
    "    vocr_per_flight_obs[Flight_ID]         = df_obs_vocr.reset_index()\n",
    "    noxr_per_flight_obs[Flight_ID]         = df_obs_OHRnox.reset_index()\n",
    "    OHRvoc_OHRnox_per_flight_obs[Flight_ID]= df_obs_OHRvoc_OHRnox.reset_index()\n",
    "    OHRnox_OHRvoc_per_flight_obs[Flight_ID]= df_obs_OHRnox_OHRvoc.reset_index()\n",
    "    \n",
    "    nemr_hno2_per_flight_obs[Flight_ID]    = df_obs_nemr_hno2.reset_index()\n",
    "    hno2_per_flight_obs[Flight_ID]         = df_obs_hno2.reset_index()\n",
    "    ald2_per_flight_obs[Flight_ID]         = df_obs_ald2.reset_index()\n",
    "    glyx_per_flight_obs[Flight_ID]         = df_obs_glyx.reset_index()\n",
    "    mgly_per_flight_obs[Flight_ID]         = df_obs_mgly.reset_index()\n",
    "    biacet_per_flight_obs[Flight_ID]       = df_obs_biacet.reset_index()\n",
    "    \n",
    "    # Propanal, important, TBD\n",
    "    propanal_per_flight_obs[Flight_ID]     = df_obs_propanal.reset_index()\n",
    "    # Butanal, important, TBD\n",
    "    butanal_per_flight_obs[Flight_ID]      = df_obs_butanal.reset_index()\n",
    "    \n",
    "    acet_per_flight_obs[Flight_ID]         = df_obs_acet.reset_index()\n",
    "    mek_per_flight_obs[Flight_ID]          = df_obs_mek.reset_index()\n",
    "    acr_per_flight_obs[Flight_ID]          = df_obs_acr.reset_index()\n",
    "    macr_per_flight_obs[Flight_ID]         = df_obs_macr.reset_index()\n",
    "    mvk_per_flight_obs[Flight_ID]          = df_obs_mvk.reset_index()\n",
    "    glyc_per_flight_obs[Flight_ID]         = df_obs_glyc.reset_index()\n",
    "    hac_per_flight_obs[Flight_ID]          = df_obs_hac.reset_index()\n",
    "    furfural_per_flight_obs[Flight_ID]     = df_obs_furfural.reset_index()\n",
    "    met_per_flight_obs[Flight_ID]          = df_obs_met.reset_index()\n",
    "\n",
    "    sesq_per_flight_obs[Flight_ID]         = df_obs_sesq.reset_index()\n",
    "    dmf_per_flight_obs[Flight_ID]          = df_obs_dmf.reset_index()\n",
    "\n",
    "    ch2o_per_flight_dil_obs[Flight_ID]         = df_obs_ch2o_dil.reset_index()\n",
    "    ald2_per_flight_dil_obs[Flight_ID]         = df_obs_ald2_dil.reset_index()\n",
    "    ma_per_flight_dil_obs[Flight_ID]           = df_obs_ma_dil.reset_index()\n",
    "    furanoids_excl_per_flight_dil_obs[Flight_ID]= df_obs_furanoids_excl_dil.reset_index()\n",
    "    furanoids_excl_per_flight_obs[Flight_ID]    = df_obs_furanoids_excl.reset_index()\n",
    "\n",
    "    methylfuran_per_flight_dil_obs[Flight_ID]  = df_obs_methylfuran_dil.reset_index()\n",
    "    acr_per_flight_dil_obs[Flight_ID]          = df_obs_acr_dil.reset_index()\n",
    "    butd_per_flight_dil_obs[Flight_ID]         = df_obs_butd_dil.reset_index()\n",
    "    o3_per_flight_dil_obs[Flight_ID]           = df_obs_o3_dil.reset_index()\n",
    "    pan_per_flight_dil_obs[Flight_ID]          = df_obs_pan_dil.reset_index()\n",
    "\n",
    "    # other primary vocs\n",
    "    isop_per_flight_dil_obs[Flight_ID]         = df_obs_isop_dil.reset_index()\n",
    "    mtpa_per_flight_dil_obs[Flight_ID]         = df_obs_mtpa_dil.reset_index()\n",
    "    xyle_per_flight_dil_obs[Flight_ID]         = df_obs_xyle_dil.reset_index()\n",
    "    butenal_per_flight_dil_obs[Flight_ID]      = df_obs_butenal_dil.reset_index()\n",
    "    cresol_per_flight_dil_obs[Flight_ID]       = df_obs_cresol_dil.reset_index()\n",
    "    dmf_per_flight_dil_obs[Flight_ID]          = df_obs_dmf_dil.reset_index()\n",
    "    guaiacol_per_flight_dil_obs[Flight_ID]     = df_obs_guaiacol_dil.reset_index()\n",
    "    syringol_per_flight_dil_obs[Flight_ID]     = df_obs_syringol_dil.reset_index()\n",
    "    sesq_per_flight_dil_obs[Flight_ID]         = df_obs_sesq_dil.reset_index()\n",
    "\n",
    "    # other secondary vocs\n",
    "    rcho_per_flight_dil_obs[Flight_ID]         = df_obs_rcho_dil.reset_index()\n",
    "    glyx_per_flight_dil_obs[Flight_ID]         = df_obs_glyx_dil.reset_index()\n",
    "    hcooh_per_flight_dil_obs[Flight_ID]        = df_obs_hcooh_dil.reset_index()\n",
    "    acta_per_flight_dil_obs[Flight_ID]         = df_obs_acta_dil.reset_index()\n",
    "    macr_mvk_per_flight_dil_obs[Flight_ID]     = df_obs_macr_mvk_dil.reset_index()\n",
    "    mek_per_flight_dil_obs[Flight_ID]          = df_obs_mek_dil.reset_index()\n",
    "    glyc_per_flight_dil_obs[Flight_ID]         = df_obs_glyc_dil.reset_index()\n",
    "    mgly_per_flight_dil_obs[Flight_ID]         = df_obs_mgly_dil.reset_index()\n",
    "    hac_per_flight_dil_obs[Flight_ID]          = df_obs_hac_dil.reset_index()\n",
    "    phen_per_flight_dil_obs[Flight_ID]         = df_obs_phen_dil.reset_index()\n",
    "    bald_per_flight_dil_obs[Flight_ID]         = df_obs_bald_dil.reset_index()\n",
    "    furanone_per_flight_dil_obs[Flight_ID]     = df_obs_furanone_dil.reset_index()\n",
    "    acr_per_flight_dil_obs[Flight_ID]          = df_obs_acr_dil.reset_index()\n",
    "    ma_per_flight_dil_obs[Flight_ID]           = df_obs_ma_dil.reset_index()\n",
    "    butanedione_per_flight_dil_obs[Flight_ID]  = df_obs_butanedione_dil.reset_index()\n",
    "\n",
    "    TM123B_per_flight_dil_obs[Flight_ID]       = df_obs_TM123B_dil.reset_index()\n",
    "    TM135B_per_flight_dil_obs[Flight_ID]       = df_obs_TM135B_dil.reset_index()\n",
    "    C9arom_per_flight_dil_obs[Flight_ID]       = df_obs_C9arom_dil.reset_index()\n",
    "\n",
    "    \n",
    "    # Other photochemical indicators\n",
    "    lrox_lnox_per_flight_obs[Flight_ID]        = df_obs_lrox_lnox_broad.reset_index()\n",
    "    ln_q_per_flight_obs[Flight_ID]             = df_obs_ln_q.reset_index()\n",
    "    h2o2_hno3_per_flight_obs[Flight_ID]        = df_obs_h2o2_hno3.reset_index()\n",
    "\n",
    "    ch2o_co_per_flight_obs[Flight_ID]          = df_obs_ch2o_co.reset_index()\n",
    "    vocr_co_per_flight_obs[Flight_ID]          = df_obs_vocr_co.reset_index()\n",
    "    noxr_co_per_flight_obs[Flight_ID]          = df_obs_noxr_co.reset_index()\n",
    "    no_co_per_flight_obs[Flight_ID]            = df_obs_no_co.reset_index()\n",
    "    no2_co_per_flight_obs[Flight_ID]           = df_obs_no2_co.reset_index()\n",
    "    nox_co_per_flight_obs[Flight_ID]           = df_obs_nox_co.reset_index()\n",
    "    pan_co_per_flight_obs[Flight_ID]           = df_obs_pan_co.reset_index()\n",
    "    hno2_co_per_flight_obs[Flight_ID]          = df_obs_hno2_co.reset_index()\n",
    "    noz_co_per_flight_obs[Flight_ID]           = df_obs_noz_co.reset_index()\n",
    "\n",
    "    furan_co_per_flight_obs[Flight_ID]         = df_obs_furan_co.reset_index()\n",
    "    mefuran_co_per_flight_obs[Flight_ID]       = df_obs_mefuran_co.reset_index()\n",
    "    dmf_co_per_flight_obs[Flight_ID]           = df_obs_dmf_co.reset_index()\n",
    "    furfural_co_per_flight_obs[Flight_ID]      = df_obs_furfural_co.reset_index()\n",
    "    mefurfural_co_per_flight_obs[Flight_ID]    = df_obs_mefurfural_co.reset_index()\n",
    "    furanone_co_per_flight_obs[Flight_ID]      = df_obs_furanone_co.reset_index()\n",
    "    butd_co_per_flight_obs[Flight_ID]          = df_obs_butd_co.reset_index()\n",
    "    acr_co_per_flight_obs[Flight_ID]           = df_obs_acr_co.reset_index()\n",
    "\n",
    "    ho2_per_flight_obs[Flight_ID]              = df_obs_ho2.reset_index()\n",
    "    ro2_per_flight_obs[Flight_ID]              = df_obs_ro2.reset_index()\n",
    "\n",
    "    po3_per_flight_obs[Flight_ID]              = df_obs_po3.reset_index()\n",
    "    pox_per_flight_obs[Flight_ID]              = df_obs_pox.reset_index()\n",
    "    lo3_per_flight_obs[Flight_ID]              = df_obs_lo3.reset_index()\n",
    "    lox_per_flight_obs[Flight_ID]              = df_obs_lox.reset_index()\n",
    "\n",
    "\n",
    "    # Nitrate\n",
    "    #pno3_per_flight_obs[Flight_ID]           = df_obs_pno3.reset_index()\n",
    "    hno3_per_flight_obs[Flight_ID]           = df_obs_hno3.reset_index()\n",
    "    hno4_per_flight_obs[Flight_ID]           = df_obs_hno4.reset_index()\n",
    "    ppn_per_flight_obs[Flight_ID]            = df_obs_ppn.reset_index()\n",
    "    pns_per_flight_obs[Flight_ID]            = df_obs_pns.reset_index()\n",
    "    ans_per_flight_obs[Flight_ID]            = df_obs_ans.reset_index()\n",
    "\n",
    "\n",
    "    no_per_flight_dil_obs[Flight_ID]        = df_obs_no_dil.reset_index()\n",
    "    no2_per_flight_dil_obs[Flight_ID]       = df_obs_no2_dil.reset_index()\n",
    "    hno2_per_flight_dil_obs[Flight_ID]      = df_obs_hno2_dil.reset_index()\n",
    "    #pno3_per_flight_dil_obs[Flight_ID]       = df_obs_pno3_dil.reset_index()\n",
    "    hno3_per_flight_dil_obs[Flight_ID]       = df_obs_hno3_dil.reset_index()\n",
    "    hno4_per_flight_dil_obs[Flight_ID]       = df_obs_hno4_dil.reset_index()\n",
    "    ppn_per_flight_dil_obs[Flight_ID]        = df_obs_ppn_dil.reset_index()\n",
    "    pns_per_flight_dil_obs[Flight_ID]        = df_obs_pns_dil.reset_index()\n",
    "    ans_per_flight_dil_obs[Flight_ID]        = df_obs_ans_dil.reset_index()\n",
    "    pns_excl_per_flight_dil_obs[Flight_ID]   = df_obs_pns_excl_dil.reset_index()\n",
    "    pan_per_flight_dil_obs[Flight_ID]        = df_obs_pan_dil.reset_index()\n",
    "    \n",
    "    nemr_no_per_flight_obs[Flight_ID]        = df_obs_nemr_no.reset_index()\n",
    "    nemr_no2_per_flight_obs[Flight_ID]       = df_obs_nemr_no2.reset_index()\n",
    "    nemr_hno2_per_flight_obs[Flight_ID]      = df_obs_nemr_hno2.reset_index()\n",
    "    #nemr_pno3_per_flight_obs[Flight_ID]       = df_obs_nemr_pno3.reset_index()\n",
    "    nemr_hno3_per_flight_obs[Flight_ID]       = df_obs_nemr_hno3.reset_index()\n",
    "    nemr_hno4_per_flight_obs[Flight_ID]       = df_obs_nemr_hno4.reset_index()\n",
    "    nemr_ppn_per_flight_obs[Flight_ID]        = df_obs_nemr_ppn.reset_index()\n",
    "    nemr_pns_per_flight_obs[Flight_ID]        = df_obs_nemr_pns.reset_index()\n",
    "    nemr_ans_per_flight_obs[Flight_ID]        = df_obs_nemr_ans.reset_index()\n",
    "    nemr_pns_excl_per_flight_obs[Flight_ID]   = df_obs_nemr_pns_excl.reset_index()\n",
    "    nemr_pan_per_flight_obs[Flight_ID]        = df_obs_nemr_pan.reset_index()\n",
    "\n",
    "    # Response to reviewers\n",
    "    furan_per_flight_obs[Flight_ID]        = df_obs_furan.reset_index()\n",
    "    mefuran_per_flight_obs[Flight_ID]      = df_obs_mefuran.reset_index()\n",
    "    dmf_per_flight_obs[Flight_ID]          = df_obs_dmf.reset_index()\n",
    "    furfural_per_flight_obs[Flight_ID]     = df_obs_furfural.reset_index()\n",
    "    mefurfural_per_flight_obs[Flight_ID]   = df_obs_mefurfural.reset_index()\n",
    "    furanone_per_flight_obs[Flight_ID]     = df_obs_furanone.reset_index()\n",
    "    benzene_per_flight_obs[Flight_ID]      = df_obs_benzene.reset_index()\n",
    "    nemr_benzene_per_flight_obs[Flight_ID] = df_obs_nemr_benzene.reset_index()\n",
    "\n",
    "    \n",
    "    if (Flight_ID in Lagrangian_flights): # This is because model evalution is only for these flights\n",
    "        nemr_o3_per_flight_mod[Flight_ID]      = df_mod_nemr_o3.reset_index()\n",
    "        nemr_o3_nox_per_flight_mod[Flight_ID]  = df_mod_nemr_o3_nox.reset_index()\n",
    "        nemr_ox_per_flight_mod[Flight_ID]      = df_mod_nemr_ox.reset_index()\n",
    "        co_per_flight_mod[Flight_ID]           = df_mod_co.reset_index()\n",
    "        no_per_flight_mod[Flight_ID]           = df_mod_no.reset_index()\n",
    "        no2_per_flight_mod[Flight_ID]          = df_mod_no2.reset_index()\n",
    "        no_no2_per_flight_mod[Flight_ID]       = df_mod_no_no2.reset_index()\n",
    "        nox_per_flight_mod[Flight_ID]          = df_mod_nox.reset_index()\n",
    "        o3_per_flight_mod[Flight_ID]           = df_mod_o3.reset_index()\n",
    "        ox_per_flight_mod[Flight_ID]           = df_mod_ox.reset_index()\n",
    "\n",
    "        pan_per_flight_mod[Flight_ID]          = df_mod_pan.reset_index()\n",
    "\n",
    "        ch2o_per_flight_mod[Flight_ID]         = df_mod_ch2o.reset_index()\n",
    "        ch2o_no2_per_flight_mod[Flight_ID]     = df_mod_ch2o_no2.reset_index()\n",
    "        \n",
    "        calOH_conc_stat_per_flight_mod[Flight_ID]      = calOH_conc_mod_stat.reset_index()\n",
    "        calOH_conc_stat_per_flight_mod_wide[Flight_ID] = calOH_conc_mod_stat_wide.reset_index()\n",
    "        calOH_conc_vocs_per_flight_mod[Flight_ID]      = Cal_OH_conc_df_mod.reset_index()\n",
    "        calOH_conc_vocs_per_flight_mod_wide[Flight_ID] = Cal_OH_conc_df_mod_wide.reset_index()\n",
    "        outputOH_conc_per_flight_mod[Flight_ID]        = df_mod_OH_conc_output.reset_index()\n",
    "\n",
    "        cal_chem_age_stat_per_flight_mod[Flight_ID] = cal_chem_age_mod_stat.reset_index()\n",
    "        cal_chem_age_vocs_per_flight_mod[Flight_ID] = Cal_chem_age_df_mod.reset_index()\n",
    "        output_chem_age_per_flight_mod[Flight_ID]   = df_mod_chem_age_output.reset_index()\n",
    "\n",
    "        vocr_per_flight_mod[Flight_ID]         = df_mod_vocr.reset_index()\n",
    "        noxr_per_flight_mod[Flight_ID]         = df_mod_OHRnox.reset_index()\n",
    "        OHRvoc_OHRnox_per_flight_mod[Flight_ID]= df_mod_OHRvoc_OHRnox.reset_index()\n",
    "        OHRnox_OHRvoc_per_flight_mod[Flight_ID]= df_mod_OHRnox_OHRvoc.reset_index()\n",
    "        \n",
    "        nemr_hno2_per_flight_mod[Flight_ID]    = df_mod_nemr_hno2.reset_index()\n",
    "        hno2_per_flight_mod[Flight_ID]         = df_mod_hno2.reset_index()\n",
    "        ald2_per_flight_mod[Flight_ID]         = df_mod_ald2.reset_index()\n",
    "        glyx_per_flight_mod[Flight_ID]         = df_mod_glyx.reset_index()\n",
    "        mgly_per_flight_mod[Flight_ID]         = df_mod_mgly.reset_index()\n",
    "        biacet_per_flight_mod[Flight_ID]       = df_mod_biacet.reset_index()\n",
    "        \n",
    "        # Propanal, important, TBD\n",
    "        propanal_per_flight_mod[Flight_ID]     = df_mod_propanal.reset_index()\n",
    "        # Butanal, important, TBD\n",
    "        butanal_per_flight_mod[Flight_ID]      = df_mod_butanal.reset_index()\n",
    "\n",
    "        acet_per_flight_mod[Flight_ID]         = df_mod_acet.reset_index()\n",
    "        mek_per_flight_mod[Flight_ID]          = df_mod_mek.reset_index()\n",
    "        acr_per_flight_mod[Flight_ID]          = df_mod_acr.reset_index()\n",
    "        macr_per_flight_mod[Flight_ID]         = df_mod_macr.reset_index()\n",
    "        mvk_per_flight_mod[Flight_ID]          = df_mod_mvk.reset_index()\n",
    "        glyc_per_flight_mod[Flight_ID]         = df_mod_glyc.reset_index()\n",
    "        hac_per_flight_mod[Flight_ID]          = df_mod_hac.reset_index()\n",
    "        furfural_per_flight_mod[Flight_ID]     = df_mod_furfural.reset_index()\n",
    "\n",
    "        sesq_per_flight_mod[Flight_ID]         = df_mod_sesq.reset_index()\n",
    "        dmf_per_flight_mod[Flight_ID]          = df_mod_dmf.reset_index()\n",
    "\n",
    "        ch2o_per_flight_dil_mod[Flight_ID]         = df_mod_ch2o_dil.reset_index()\n",
    "        ald2_per_flight_dil_mod[Flight_ID]         = df_mod_ald2_dil.reset_index()\n",
    "        ma_per_flight_dil_mod[Flight_ID]           = df_mod_ma_dil.reset_index()\n",
    "        furanoids_excl_per_flight_dil_mod[Flight_ID]= df_mod_furanoids_excl_dil.reset_index()\n",
    "        furanoids_excl_per_flight_mod[Flight_ID]   = df_mod_furanoids_excl.reset_index()\n",
    "        methylfuran_per_flight_dil_mod[Flight_ID]  = df_mod_methylfuran_dil.reset_index()\n",
    "        acr_per_flight_dil_mod[Flight_ID]          = df_mod_acr_dil.reset_index()\n",
    "        butd_per_flight_dil_mod[Flight_ID]         = df_mod_butd_dil.reset_index()\n",
    "        o3_per_flight_dil_mod[Flight_ID]           = df_mod_o3_dil.reset_index()\n",
    "        pan_per_flight_dil_mod[Flight_ID]          = df_mod_pan_dil.reset_index()\n",
    "\n",
    "        # other primary vocs\n",
    "        isop_per_flight_dil_mod[Flight_ID]         = df_mod_isop_dil.reset_index()\n",
    "        mtpa_per_flight_dil_mod[Flight_ID]         = df_mod_mtpa_dil.reset_index()\n",
    "        xyle_per_flight_dil_mod[Flight_ID]         = df_mod_xyle_dil.reset_index()\n",
    "        butenal_per_flight_dil_mod[Flight_ID]      = df_mod_butenal_dil.reset_index()\n",
    "        cresol_per_flight_dil_mod[Flight_ID]       = df_mod_cresol_dil.reset_index()\n",
    "        dmf_per_flight_dil_mod[Flight_ID]          = df_mod_dmf_dil.reset_index()\n",
    "        guaiacol_per_flight_dil_mod[Flight_ID]      = df_mod_guaiacol_dil.reset_index()\n",
    "        syringol_per_flight_dil_mod[Flight_ID]     = df_mod_syringol_dil.reset_index()\n",
    "        sesq_per_flight_dil_mod[Flight_ID]         = df_mod_sesq_dil.reset_index()\n",
    "        # other secondary vocs\n",
    "        rcho_per_flight_dil_mod[Flight_ID]         = df_mod_rcho_dil.reset_index()\n",
    "        glyx_per_flight_dil_mod[Flight_ID]         = df_mod_glyx_dil.reset_index()\n",
    "        hcooh_per_flight_dil_mod[Flight_ID]        = df_mod_hcooh_dil.reset_index()\n",
    "        acta_per_flight_dil_mod[Flight_ID]         = df_mod_acta_dil.reset_index()\n",
    "        macr_mvk_per_flight_dil_mod[Flight_ID]     = df_mod_macr_mvk_dil.reset_index()\n",
    "        mek_per_flight_dil_mod[Flight_ID]          = df_mod_mek_dil.reset_index()\n",
    "        glyc_per_flight_dil_mod[Flight_ID]         = df_mod_glyc_dil.reset_index()\n",
    "        mgly_per_flight_dil_mod[Flight_ID]         = df_mod_mgly_dil.reset_index()\n",
    "        hac_per_flight_dil_mod[Flight_ID]          = df_mod_hac_dil.reset_index()\n",
    "        phen_per_flight_dil_mod[Flight_ID]         = df_mod_phen_dil.reset_index()\n",
    "        bald_per_flight_dil_mod[Flight_ID]         = df_mod_bald_dil.reset_index()\n",
    "        furanone_per_flight_dil_mod[Flight_ID]     = df_mod_furanone_dil.reset_index()\n",
    "        acr_per_flight_dil_mod[Flight_ID]          = df_mod_acr_dil.reset_index()\n",
    "        ma_per_flight_dil_mod[Flight_ID]           = df_mod_ma_dil.reset_index()\n",
    "        butanedione_per_flight_dil_mod[Flight_ID]  = df_mod_butanedione_dil.reset_index()\n",
    "\n",
    "        TM123B_per_flight_dil_mod[Flight_ID]       = df_mod_TM123B_dil.reset_index()\n",
    "        TM135B_per_flight_dil_mod[Flight_ID]       = df_mod_TM135B_dil.reset_index()\n",
    "        C9arom_per_flight_dil_mod[Flight_ID]       = df_mod_C9arom_dil.reset_index()\n",
    "\n",
    "        \n",
    "        # Other photochemical indicators\n",
    "        lrox_lnox_per_flight_mod[Flight_ID]        = df_mod_lrox_lnox_broad.reset_index()\n",
    "        ln_q_per_flight_mod[Flight_ID]             = df_mod_ln_q.reset_index()\n",
    "        h2o2_hno3_per_flight_mod[Flight_ID]        = df_mod_h2o2_hno3.reset_index()\n",
    "\n",
    "        ch2o_co_per_flight_mod[Flight_ID]          = df_mod_ch2o_co.reset_index()\n",
    "        vocr_co_per_flight_mod[Flight_ID]          = df_mod_vocr_co.reset_index()\n",
    "        noxr_co_per_flight_mod[Flight_ID]          = df_mod_noxr_co.reset_index()\n",
    "        no_co_per_flight_mod[Flight_ID]            = df_mod_no_co.reset_index()\n",
    "        no2_co_per_flight_mod[Flight_ID]           = df_mod_no2_co.reset_index()\n",
    "        nox_co_per_flight_mod[Flight_ID]           = df_mod_nox_co.reset_index()\n",
    "        pan_co_per_flight_mod[Flight_ID]           = df_mod_pan_co.reset_index()\n",
    "        hno2_co_per_flight_mod[Flight_ID]          = df_mod_hno2_co.reset_index()\n",
    "        noz_co_per_flight_mod[Flight_ID]           = df_mod_noz_co.reset_index()\n",
    "\n",
    "        furan_co_per_flight_mod[Flight_ID]         = df_mod_furan_co.reset_index()\n",
    "        mefuran_co_per_flight_mod[Flight_ID]       = df_mod_mefuran_co.reset_index()\n",
    "        dmf_co_per_flight_mod[Flight_ID]           = df_mod_dmf_co.reset_index()\n",
    "        furfural_co_per_flight_mod[Flight_ID]      = df_mod_furfural_co.reset_index()\n",
    "        mefurfural_co_per_flight_mod[Flight_ID]    = df_mod_mefurfural_co.reset_index()\n",
    "        furanone_co_per_flight_mod[Flight_ID]      = df_mod_furanone_co.reset_index()\n",
    "        butd_co_per_flight_mod[Flight_ID]          = df_mod_butd_co.reset_index()\n",
    "        acr_co_per_flight_mod[Flight_ID]           = df_mod_acr_co.reset_index()\n",
    "        \n",
    "        ho2_per_flight_mod[Flight_ID]           = df_mod_ho2.reset_index()\n",
    "        ro2_per_flight_mod[Flight_ID]           = df_mod_ro2.reset_index()\n",
    "\n",
    "        po3_per_flight_mod[Flight_ID]           = df_mod_po3.reset_index()\n",
    "        pox_per_flight_mod[Flight_ID]           = df_mod_pox.reset_index()\n",
    "\n",
    "        lo3_per_flight_mod[Flight_ID]           = df_mod_lo3.reset_index()\n",
    "        lox_per_flight_mod[Flight_ID]           = df_mod_lox.reset_index()\n",
    "\n",
    "\n",
    "        # Nitrate\n",
    "        #pno3_per_flight_mod[Flight_ID]           = df_mod_pno3.reset_index()\n",
    "        hno3_per_flight_mod[Flight_ID]           = df_mod_hno3.reset_index()\n",
    "        hno4_per_flight_mod[Flight_ID]           = df_mod_hno4.reset_index()\n",
    "        ppn_per_flight_mod[Flight_ID]            = df_mod_ppn.reset_index()\n",
    "        pns_per_flight_mod[Flight_ID]            = df_mod_pns.reset_index()\n",
    "        ans_per_flight_mod[Flight_ID]            = df_mod_ans.reset_index()\n",
    "\n",
    "        no_per_flight_dil_mod[Flight_ID]        = df_mod_no_dil.reset_index()\n",
    "        no2_per_flight_dil_mod[Flight_ID]       = df_mod_no2_dil.reset_index()\n",
    "        hno2_per_flight_dil_mod[Flight_ID]      = df_mod_hno2_dil.reset_index()\n",
    "        #pno3_per_flight_dil_mod[Flight_ID]       = df_mod_pno3_dil.reset_index()\n",
    "        hno3_per_flight_dil_mod[Flight_ID]       = df_mod_hno3_dil.reset_index()\n",
    "        hno4_per_flight_dil_mod[Flight_ID]       = df_mod_hno4_dil.reset_index()\n",
    "        ppn_per_flight_dil_mod[Flight_ID]        = df_mod_ppn_dil.reset_index()\n",
    "        pns_per_flight_dil_mod[Flight_ID]        = df_mod_pns_dil.reset_index()\n",
    "        ans_per_flight_dil_mod[Flight_ID]        = df_mod_ans_dil.reset_index()\n",
    "        pns_excl_per_flight_dil_mod[Flight_ID]   = df_mod_pns_excl_dil.reset_index()\n",
    "        pan_per_flight_dil_mod[Flight_ID]        = df_mod_pan_dil.reset_index()\n",
    "\n",
    "        nemr_no_per_flight_mod[Flight_ID]        = df_mod_nemr_no.reset_index()\n",
    "        nemr_no2_per_flight_mod[Flight_ID]       = df_mod_nemr_no2.reset_index()\n",
    "        nemr_hno2_per_flight_mod[Flight_ID]      = df_mod_nemr_hno2.reset_index()\n",
    "        #nemr_pno3_per_flight_mod[Flight_ID]       = df_mod_nemr_pno3.reset_index()\n",
    "        nemr_hno3_per_flight_mod[Flight_ID]       = df_mod_nemr_hno3.reset_index()\n",
    "        nemr_hno4_per_flight_mod[Flight_ID]       = df_mod_nemr_hno4.reset_index()\n",
    "        nemr_ppn_per_flight_mod[Flight_ID]        = df_mod_nemr_ppn.reset_index()\n",
    "        nemr_pns_per_flight_mod[Flight_ID]        = df_mod_nemr_pns.reset_index()\n",
    "        nemr_ans_per_flight_mod[Flight_ID]        = df_mod_nemr_ans.reset_index()\n",
    "        nemr_pns_excl_per_flight_mod[Flight_ID]   = df_mod_nemr_pns_excl.reset_index()\n",
    "        nemr_pan_per_flight_mod[Flight_ID]        = df_mod_nemr_pan.reset_index()\n",
    "\n",
    "        # response to reviewers\n",
    "        furan_per_flight_mod[Flight_ID]         = df_mod_furan.reset_index()\n",
    "        mefuran_per_flight_mod[Flight_ID]       = df_mod_mefuran.reset_index()\n",
    "        dmf_per_flight_mod[Flight_ID]           = df_mod_dmf.reset_index()\n",
    "        furfural_per_flight_mod[Flight_ID]      = df_mod_furfural.reset_index()\n",
    "        mefurfural_per_flight_mod[Flight_ID]    = df_mod_mefurfural.reset_index()\n",
    "        furanone_per_flight_mod[Flight_ID]      = df_mod_furanone.reset_index()\n",
    "        \n",
    "        benzene_per_flight_mod[Flight_ID]      = df_mod_benzene.reset_index()\n",
    "        nemr_benzene_per_flight_mod[Flight_ID] = df_mod_nemr_benzene.reset_index()\n",
    "\n",
    "    # ------------------------------\n",
    "    # Check if the lengths are equal\n",
    "    # ------------------------------\n",
    "    len_nemr_o3_obs    = len(nemr_o3_per_flight_obs[Flight_ID])\n",
    "    len_nemr_o3_nox_obs= len(nemr_o3_nox_per_flight_obs[Flight_ID])\n",
    "    len_nemr_ox_obs    = len(nemr_ox_per_flight_obs[Flight_ID])\n",
    "    len_co_obs         = len(co_per_flight_obs[Flight_ID])\n",
    "    len_no_obs         = len(no_per_flight_obs[Flight_ID])\n",
    "    len_no2_obs        = len(no2_per_flight_obs[Flight_ID])\n",
    "    len_nox_obs        = len(nox_per_flight_obs[Flight_ID])\n",
    "    len_o3_obs         = len(o3_per_flight_obs[Flight_ID])\n",
    "    len_ox_obs         = len(ox_per_flight_obs[Flight_ID])\n",
    "    len_pan_obs        = len(pan_per_flight_obs[Flight_ID])\n",
    "    len_nemr_pan_obs   = len(nemr_pan_per_flight_obs[Flight_ID])\n",
    "    len_ch2o_obs       = len(ch2o_per_flight_obs[Flight_ID])\n",
    "    len_ch2o_no2_obs   = len(ch2o_no2_per_flight_obs[Flight_ID])\n",
    "\n",
    "    len_vocr_obs         = len(vocr_per_flight_obs[Flight_ID])\n",
    "    len_noxr_obs         = len(noxr_per_flight_obs[Flight_ID])\n",
    "    len_calOH_conc_obs   = len(calOH_conc_stat_per_flight_obs[Flight_ID])\n",
    "    len_actOH_conc_obs   = len(outputOH_conc_per_flight_obs[Flight_ID])\n",
    "    len_OHRvoc_OHRnox_obs= len(OHRvoc_OHRnox_per_flight_obs[Flight_ID])\n",
    "    len_OHRnox_OHRvoc_obs= len(OHRnox_OHRvoc_per_flight_obs[Flight_ID])\n",
    "\n",
    "    len_hno2_obs    = len(hno2_per_flight_obs[Flight_ID])\n",
    "    len_ald2_obs    = len(ald2_per_flight_obs[Flight_ID])\n",
    "    len_glyx_obs    = len(glyx_per_flight_obs[Flight_ID])\n",
    "    len_mgly_obs    = len(mgly_per_flight_obs[Flight_ID])\n",
    "    len_biacet_obs  = len(biacet_per_flight_obs[Flight_ID])\n",
    "\n",
    "    len_propanal_obs= len(propanal_per_flight_obs[Flight_ID])\n",
    "    len_butanal_obs = len(butanal_per_flight_obs[Flight_ID])\n",
    "    \n",
    "    len_acet_obs    = len(acet_per_flight_obs[Flight_ID])\n",
    "    len_mek_obs     = len(mek_per_flight_obs[Flight_ID])\n",
    "    len_acr_obs     = len(acr_per_flight_obs[Flight_ID])\n",
    "    len_macr_obs    = len(macr_per_flight_obs[Flight_ID])\n",
    "    len_mvk_obs     = len(mvk_per_flight_obs[Flight_ID])\n",
    "    len_glyc_obs    = len(glyc_per_flight_obs[Flight_ID])\n",
    "    len_hac_obs     = len(hac_per_flight_obs[Flight_ID])\n",
    "    len_furfural_obs= len(furfural_per_flight_obs[Flight_ID])\n",
    "\n",
    "    len_met_obs     = len(met_per_flight_obs[Flight_ID])\n",
    "\n",
    "    len_ch2o_dil_obs     = len(ch2o_per_flight_dil_obs[Flight_ID])\n",
    "    len_ald2_dil_obs     = len(ald2_per_flight_dil_obs[Flight_ID])\n",
    "    len_ma_dil_obs       = len(ma_per_flight_dil_obs[Flight_ID])\n",
    "    len_furanoids_excl_dil_obs= len(furanoids_excl_per_flight_dil_obs[Flight_ID])\n",
    "    len_acr_dil_obs      = len(acr_per_flight_dil_obs[Flight_ID])\n",
    "    len_butd_dil_obs     = len(butd_per_flight_dil_obs[Flight_ID])\n",
    "\n",
    "    len_isop_dil_obs     = len(isop_per_flight_dil_obs[Flight_ID])\n",
    "    len_mtpa_dil_obs     = len(mtpa_per_flight_dil_obs[Flight_ID])\n",
    "    len_xyle_dil_obs     = len(xyle_per_flight_dil_obs[Flight_ID])\n",
    "    len_butenal_dil_obs  = len(butenal_per_flight_dil_obs[Flight_ID])\n",
    "    len_cresol_dil_obs   = len(cresol_per_flight_dil_obs[Flight_ID])\n",
    "    len_dmf_dil_obs      = len(dmf_per_flight_dil_obs[Flight_ID])\n",
    "    len_guaiacol_dil_obs  = len(guaiacol_per_flight_dil_obs[Flight_ID])    \n",
    "\n",
    "    # other secondary vocs\n",
    "    len_rcho_dil_obs     = len(rcho_per_flight_dil_obs[Flight_ID])    \n",
    "    len_glyx_dil_obs     = len(glyx_per_flight_dil_obs[Flight_ID])    \n",
    "    len_hcooh_dil_obs    = len(hcooh_per_flight_dil_obs[Flight_ID])    \n",
    "    len_acta_dil_obs     = len(acta_per_flight_dil_obs[Flight_ID])    \n",
    "    len_macr_mvk_dil_obs = len(macr_mvk_per_flight_dil_obs[Flight_ID])    \n",
    "    len_mek_dil_obs      = len(mek_per_flight_dil_obs[Flight_ID])    \n",
    "    len_glyc_dil_obs     = len(glyc_per_flight_dil_obs[Flight_ID])    \n",
    "    len_mgly_dil_obs     = len(mgly_per_flight_dil_obs[Flight_ID])    \n",
    "    len_hac_dil_obs      = len(hac_per_flight_dil_obs[Flight_ID])    \n",
    "    len_phen_dil_obs     = len(phen_per_flight_dil_obs[Flight_ID])    \n",
    "    len_bald_dil_obs     = len(bald_per_flight_dil_obs[Flight_ID])    \n",
    "    len_furanone_dil_obs = len(furanone_per_flight_dil_obs[Flight_ID])    \n",
    "    len_acr_dil_obs      = len(acr_per_flight_dil_obs[Flight_ID])    \n",
    "    len_ma_dil_obs       = len(ma_per_flight_dil_obs[Flight_ID])    \n",
    "    len_butanedione_dil_obs= len(butanedione_per_flight_dil_obs[Flight_ID])    \n",
    "\n",
    "    # Other photochemical indicators\n",
    "    len_lrox_lnox_obs  = len(lrox_lnox_per_flight_obs[Flight_ID])    \n",
    "    len_ln_q_obs       = len(ln_q_per_flight_obs[Flight_ID])    \n",
    "    len_h2o2_hno3_obs  = len(h2o2_hno3_per_flight_obs[Flight_ID])    \n",
    "    \n",
    "    len_ch2o_co_obs    = len(ch2o_co_per_flight_obs[Flight_ID])    \n",
    "    len_vocr_co_obs    = len(vocr_co_per_flight_obs[Flight_ID])    \n",
    "    len_noxr_co_obs    = len(noxr_co_per_flight_obs[Flight_ID])    \n",
    "    len_no_co_obs      = len(no_co_per_flight_obs[Flight_ID])    \n",
    "    len_no2_co_obs     = len(no2_co_per_flight_obs[Flight_ID])    \n",
    "    len_nox_co_obs     = len(nox_co_per_flight_obs[Flight_ID])    \n",
    "    len_pan_co_obs     = len(pan_co_per_flight_obs[Flight_ID])    \n",
    "    len_hno2_co_obs    = len(hno2_co_per_flight_obs[Flight_ID])    \n",
    "    len_noz_co_obs     = len(noz_co_per_flight_obs[Flight_ID])    \n",
    "    if (Flight_ID in Lagrangian_flights):\n",
    "        len_nemr_o3_mod     = len(nemr_o3_per_flight_mod[Flight_ID])\n",
    "        len_nemr_o3_nox_mod = len(nemr_o3_nox_per_flight_mod[Flight_ID])\n",
    "        len_nemr_ox_mod = len(nemr_ox_per_flight_mod[Flight_ID])\n",
    "        len_co_mod      = len(co_per_flight_mod[Flight_ID])\n",
    "        len_no_mod      = len(no_per_flight_mod[Flight_ID])\n",
    "        len_no2_mod     = len(no2_per_flight_mod[Flight_ID])\n",
    "        len_nox_mod     = len(nox_per_flight_mod[Flight_ID])\n",
    "        len_o3_mod      = len(o3_per_flight_mod[Flight_ID])\n",
    "        len_ox_mod      = len(ox_per_flight_mod[Flight_ID])\n",
    "        len_pan_mod     = len(pan_per_flight_mod[Flight_ID])\n",
    "        len_ch2o_mod       = len(ch2o_per_flight_mod[Flight_ID])\n",
    "        len_ch2o_no2_mod   = len(ch2o_no2_per_flight_mod[Flight_ID])\n",
    "\n",
    "        len_no2_mod   = len(hno2_per_flight_mod[Flight_ID])\n",
    "        len_ald2_mod  = len(ald2_per_flight_mod[Flight_ID])\n",
    "        len_glyx_mod  = len(glyx_per_flight_mod[Flight_ID])\n",
    "        len_mgly_mod  = len(mgly_per_flight_mod[Flight_ID])\n",
    "        len_biacet_mod= len(biacet_per_flight_mod[Flight_ID])\n",
    "\n",
    "        len_acet_mod    = len(acet_per_flight_mod[Flight_ID])\n",
    "        len_mek_mod     = len(mek_per_flight_mod[Flight_ID])\n",
    "        len_acr_mod     = len(acr_per_flight_mod[Flight_ID])\n",
    "        len_macr_mod    = len(macr_per_flight_mod[Flight_ID])\n",
    "        len_mvk_mod     = len(mvk_per_flight_mod[Flight_ID])\n",
    "        len_glyc_mod    = len(glyc_per_flight_mod[Flight_ID])\n",
    "        len_hac_mod     = len(hac_per_flight_mod[Flight_ID])\n",
    "        len_furfural_mod= len(furfural_per_flight_mod[Flight_ID])\n",
    "\n",
    "        len_ch2o_dil_mod     = len(ch2o_per_flight_dil_mod[Flight_ID])\n",
    "        len_ald2_dil_mod     = len(ald2_per_flight_dil_mod[Flight_ID])\n",
    "        len_ma_dil_mod       = len(ma_per_flight_dil_mod[Flight_ID])\n",
    "        len_furanoids_excl_dil_mod= len(furanoids_excl_per_flight_dil_mod[Flight_ID])\n",
    "        len_acr_dil_mod      = len(acr_per_flight_dil_mod[Flight_ID])\n",
    "        len_butd_dil_mod     = len(butd_per_flight_dil_mod[Flight_ID])\n",
    "    \n",
    "        len_isop_dil_mod     = len(isop_per_flight_dil_mod[Flight_ID])\n",
    "        len_mtpa_dil_mod     = len(mtpa_per_flight_dil_mod[Flight_ID])\n",
    "        len_xyle_dil_mod     = len(xyle_per_flight_dil_mod[Flight_ID])\n",
    "        len_butenal_dil_mod  = len(butenal_per_flight_dil_mod[Flight_ID])\n",
    "        len_cresol_dil_mod   = len(cresol_per_flight_dil_mod[Flight_ID])\n",
    "        len_dmf_dil_mod      = len(dmf_per_flight_dil_mod[Flight_ID])\n",
    "        len_guaiacol_dil_mod  = len(guaiacol_per_flight_dil_mod[Flight_ID])    \n",
    "\n",
    "        # other secondary vocs\n",
    "        len_rcho_dil_mod     = len(rcho_per_flight_dil_mod[Flight_ID])    \n",
    "        len_glyx_dil_mod     = len(glyx_per_flight_dil_mod[Flight_ID])    \n",
    "        len_hcooh_dil_mod    = len(hcooh_per_flight_dil_mod[Flight_ID])    \n",
    "        len_acta_dil_mod     = len(acta_per_flight_dil_mod[Flight_ID])    \n",
    "        len_macr_mvk_dil_mod = len(macr_mvk_per_flight_dil_mod[Flight_ID])    \n",
    "        len_mek_dil_mod      = len(mek_per_flight_dil_mod[Flight_ID])    \n",
    "        len_glyc_dil_mod     = len(glyc_per_flight_dil_mod[Flight_ID])    \n",
    "        len_mgly_dil_mod     = len(mgly_per_flight_dil_mod[Flight_ID])    \n",
    "        len_hac_dil_mod      = len(hac_per_flight_dil_mod[Flight_ID])    \n",
    "        len_phen_dil_mod     = len(phen_per_flight_dil_mod[Flight_ID])    \n",
    "        len_bald_dil_mod     = len(bald_per_flight_dil_mod[Flight_ID])    \n",
    "        len_furanone_dil_mod = len(furanone_per_flight_dil_mod[Flight_ID])    \n",
    "        len_acr_dil_mod      = len(acr_per_flight_dil_mod[Flight_ID])    \n",
    "        len_ma_dil_mod       = len(ma_per_flight_dil_mod[Flight_ID])    \n",
    "        len_butanedione_dil_mod= len(butanedione_per_flight_dil_mod[Flight_ID])    \n",
    "\n",
    "        # Other photochemical indicators\n",
    "        len_lrox_lnox_mod  = len(lrox_lnox_per_flight_mod[Flight_ID])    \n",
    "        len_ln_q_mod       = len(ln_q_per_flight_mod[Flight_ID])    \n",
    "        len_h2o2_hno3_mod  = len(h2o2_hno3_per_flight_mod[Flight_ID])    \n",
    "\n",
    "        len_ch2o_co_mod    = len(ch2o_co_per_flight_mod[Flight_ID])    \n",
    "        len_vocr_co_mod    = len(vocr_co_per_flight_mod[Flight_ID])    \n",
    "        len_noxr_co_mod    = len(noxr_co_per_flight_mod[Flight_ID])    \n",
    "        len_no_co_mod      = len(no_co_per_flight_mod[Flight_ID])    \n",
    "        len_no2_co_mod     = len(no2_co_per_flight_mod[Flight_ID])    \n",
    "        len_nox_co_mod     = len(nox_co_per_flight_mod[Flight_ID])    \n",
    "        len_pan_co_mod     = len(pan_co_per_flight_mod[Flight_ID])    \n",
    "        len_hno2_co_mod    = len(hno2_co_per_flight_mod[Flight_ID])    \n",
    "        len_noz_co_mod     = len(noz_co_per_flight_mod[Flight_ID])    \n",
    "        \n",
    "        len_no_per_dil_mod        = len(no_per_flight_dil_mod[Flight_ID])\n",
    "        len_no2_per_dil_mod       = len(no2_per_flight_dil_mod[Flight_ID])\n",
    "        len_hno2_per_dil_mod      = len(hno2_per_flight_dil_mod[Flight_ID])\n",
    "        # len_pno3_per_flight_dil_mod    = len(pno3_per_flight_dil_mod[Flight_ID])  # Uncomment if needed\n",
    "        len_hno3_per_dil_mod      = len(hno3_per_flight_dil_mod[Flight_ID])\n",
    "        len_hno4_per_dil_mod      = len(hno4_per_flight_dil_mod[Flight_ID])\n",
    "        len_ppn_per_dil_mod       = len(ppn_per_flight_dil_mod[Flight_ID])\n",
    "        len_pns_per_dil_mod       = len(pns_per_flight_dil_mod[Flight_ID])\n",
    "        len_ans_per_dil_mod       = len(ans_per_flight_dil_mod[Flight_ID])\n",
    "        len_pns_excl_per_dil_mod  = len(pns_excl_per_flight_dil_mod[Flight_ID])\n",
    "        len_pan_per_dil_mod       = len(pan_per_flight_dil_mod[Flight_ID])\n",
    "    \n",
    "        len_nemr_no_per_mod       = len(nemr_no_per_flight_mod[Flight_ID])\n",
    "        len_nemr_no2_per_mod      = len(nemr_no2_per_flight_mod[Flight_ID])\n",
    "        len_nemr_hno2_per_mod     = len(nemr_hno2_per_flight_mod[Flight_ID])\n",
    "        # len_nemr_pno3_per_mod   = len(nemr_pno3_per_flight_mod[Flight_ID])  # Uncomment if needed\n",
    "        len_nemr_hno3_per_mod     = len(nemr_hno3_per_flight_mod[Flight_ID])\n",
    "        len_nemr_hno4_per_mod     = len(nemr_hno4_per_flight_mod[Flight_ID])\n",
    "        len_nemr_ppn_per_mod      = len(nemr_ppn_per_flight_mod[Flight_ID])\n",
    "        len_nemr_pns_per_mod      = len(nemr_pns_per_flight_mod[Flight_ID])\n",
    "        len_nemr_ans_per_mod      = len(nemr_ans_per_flight_mod[Flight_ID])\n",
    "        len_nemr_pns_excl_per_mod = len(nemr_pns_excl_per_flight_mod[Flight_ID])\n",
    "        len_nemr_pan_per_mod      = len(nemr_pan_per_flight_mod[Flight_ID])\n",
    "        \n",
    "\n",
    "    \n",
    "    if (len_nemr_o3_obs == len_nemr_o3_nox_obs == len_nemr_ox_obs == len_co_obs == len_no_obs == len_no2_obs == len_nox_obs == len_o3_obs == \\\n",
    "        len_ox_obs == len_pan_obs == len_nemr_pan_obs == len_ch2o_obs == len_ch2o_no2_obs == \\\n",
    "        len_hno2_obs == len_ald2_obs == len_glyx_obs == len_mgly_obs == len_biacet_obs == \\\n",
    "        len_vocr_obs == len_noxr_obs == len_calOH_conc_obs == len_actOH_conc_obs == len_OHRvoc_OHRnox_obs == len_OHRnox_OHRvoc_obs == len_propanal_obs == len_butanal_obs == \\\n",
    "        len_acet_obs == len_mek_obs == len_acr_obs == len_macr_obs == len_mvk_obs == len_glyc_obs == len_hac_obs == len_furfural_obs == len_met_obs == \\\n",
    "        len_ch2o_dil_obs == len_ald2_dil_obs == len_ma_dil_obs == len_furanoids_excl_dil_obs == len_acr_dil_obs == len_butd_dil_obs == \\\n",
    "        len_isop_dil_obs == len_mtpa_dil_obs == len_xyle_dil_obs == len_butenal_dil_obs == len_cresol_dil_obs == len_dmf_dil_obs == len_guaiacol_dil_obs == \\\n",
    "        len_rcho_dil_obs == len_glyx_dil_obs == len_hcooh_dil_obs == len_acta_dil_obs == len_macr_mvk_dil_obs == len_mek_dil_obs == len_glyc_dil_obs == \\\n",
    "        len_mgly_dil_obs == len_hac_dil_obs == len_phen_dil_obs == len_bald_dil_obs == len_furanone_dil_obs == len_acr_dil_obs == len_ma_dil_obs == len_butanedione_dil_obs == \\\n",
    "        len_lrox_lnox_obs == len_ln_q_obs == len_h2o2_hno3_obs == \\\n",
    "        len_ch2o_co_obs == len_vocr_co_obs == len_noxr_co_obs == len_no_co_obs == len_no2_co_obs == len_nox_co_obs == len_pan_co_obs == len_hno2_co_obs == len_noz_co_obs):\n",
    "        print(\"All lengths match.\")\n",
    "    else:\n",
    "        print(Flight_ID)\n",
    "        print(\"Error (obs): The lengths do not match.\")\n",
    "        print(f\"NEMR O3 length: {len_nemr_o3_obs}\")\n",
    "        print(f\"NEMR O3_NOx length: {len_nemr_o3_nox_obs}\")\n",
    "        print(f\"NEMR Ox length: {len_nemr_ox_obs}\")\n",
    "        print(f\"CO length: {len_co_obs}\")\n",
    "        print(f\"NO length: {len_no_obs}\")\n",
    "        print(f\"NO2 length: {len_no2_obs}\")\n",
    "        print(f\"NOx length: {len_nox_obs}\")\n",
    "        print(f\"O3 length: {len_o3_obs}\")\n",
    "        print(f\"Ox length: {len_ox_obs}\")\n",
    "        print(f\"PAN length: {len_pan_obs}\")\n",
    "        print(f\"CH2O length: {len_ch2o_obs}\")\n",
    "        print(f\"CH2O: NO2 length: {len_ch2o_no2_obs}\")\n",
    "        print(f\"HNO2 length: {len_hno2_obs}\")\n",
    "        print(f\"ALD2 length: {len_ald2_obs}\")\n",
    "        print(f\"GLYX length: {len_glyx_obs}\")\n",
    "        print(f\"MGLY length: {len_mgly_obs}\")\n",
    "        print(f\"BIACET length: {len_biacet_obs}\")\n",
    "        print(f\"VOCR length: {len_vocr_obs}\")\n",
    "        print(f\"NOxR length: {len_noxr_obs}\")\n",
    "        print(f\"CalOH length: {len_calOH_conc_obs}\")\n",
    "        print(f\"ActOH length: {len_actOH_conc_obs}\")\n",
    "        print(f\"OHRvoc/OHRnox length: {len_OHRvoc_OHRnox_obs}\")\n",
    "        print(f\"OHRnox/OHRvoc length: {len_OHRnox_OHRvoc_obs}\")\n",
    "        print(f\"Propanal length: {len_propanal_obs}\")\n",
    "        print(f\"Butanal length: {len_butanal_obs}\")\n",
    "        \n",
    "        print(f\"ACET length: {len_acet_obs}\")\n",
    "        print(f\"MEK length: {len_mek_obs}\")\n",
    "        print(f\"ACR length: {len_acr_obs}\")\n",
    "        print(f\"MACR length: {len_macr_obs}\")\n",
    "        print(f\"MVK length: {len_mvk_obs}\")\n",
    "        print(f\"GLYC length: {len_glyc_obs}\")\n",
    "        print(f\"HAC length: {len_hac_obs}\")\n",
    "        print(f\"Furfural length: {len_furfural_obs}\")\n",
    "        print(f\"MET length: {len_met_obs}\")\n",
    "        error\n",
    "\n",
    "    if (Flight_ID in Lagrangian_flights):\n",
    "        if (len_nemr_o3_mod == len_nemr_o3_nox_mod == len_nemr_ox_mod == len_co_mod == len_no_mod == len_no2_mod == len_nox_mod == len_o3_mod == \\\n",
    "            len_ox_mod == len_pan_mod == len_ch2o_mod == len_ch2o_no2_mod == \\\n",
    "            len_ald2_mod == len_glyx_mod == len_mgly_mod == len_biacet_mod == \\\n",
    "            len_acet_mod == len_mek_mod == len_acr_mod == len_macr_mod == len_mvk_mod == len_glyc_mod == len_hac_mod == len_furfural_mod == \\\n",
    "            len_ch2o_dil_mod == len_ald2_dil_mod == len_ma_dil_mod == len_furanoids_excl_dil_mod == len_acr_dil_mod == len_butd_dil_mod == \\\n",
    "            len_isop_dil_mod == len_mtpa_dil_mod == len_xyle_dil_mod == len_butenal_dil_mod == len_cresol_dil_mod == len_dmf_dil_mod == len_guaiacol_dil_mod == \\\n",
    "            len_rcho_dil_mod == len_glyx_dil_mod == len_hcooh_dil_mod == len_acta_dil_mod == len_macr_mvk_dil_mod == len_mek_dil_mod == len_glyc_dil_mod == \\\n",
    "            len_mgly_dil_mod == len_hac_dil_mod == len_phen_dil_mod == len_bald_dil_mod == len_furanone_dil_mod == len_acr_dil_mod == len_ma_dil_mod == len_butanedione_dil_mod == \\\n",
    "            len_lrox_lnox_mod == len_ln_q_mod == len_h2o2_hno3_mod == \\\n",
    "            len_ch2o_co_mod == len_vocr_co_mod == len_noxr_co_mod == len_no_co_mod == len_no2_co_mod == len_nox_co_mod == len_pan_co_mod == len_hno2_co_mod == len_noz_co_mod == \\\n",
    "            len_no_per_dil_mod == len_no2_per_dil_mod == len_hno2_per_dil_mod == \\\n",
    "            len_hno3_per_dil_mod == len_hno4_per_dil_mod == len_ppn_per_dil_mod == len_pns_per_dil_mod == len_ans_per_dil_mod == \\\n",
    "            len_pns_excl_per_dil_mod == len_pan_per_dil_mod == \\\n",
    "            len_nemr_no_per_mod == len_nemr_no2_per_mod == len_nemr_hno2_per_mod == \\\n",
    "            len_nemr_hno3_per_mod == len_nemr_hno4_per_mod == len_nemr_ppn_per_mod == len_nemr_pns_per_mod == len_nemr_ans_per_mod == \\\n",
    "            len_nemr_pns_excl_per_mod == len_nemr_pan_per_mod):\n",
    "            print(\"All lengths match.\")\n",
    "        else:\n",
    "            print(Flight_ID)\n",
    "            print(f\"NEMR O3 length: {len_nemr_o3_mod}\")\n",
    "            print(f\"NEMR O3_NOx length: {len_nemr_o3_nox_mod}\")\n",
    "            print(f\"NEMR Ox length: {len_nemr_ox_mod}\")\n",
    "            print(f\"CO length: {len_co_mod}\")\n",
    "            print(f\"NO length: {len_no_mod}\")\n",
    "            print(f\"NO2 length: {len_no2_mod}\")\n",
    "            print(f\"NOx length: {len_nox_mod}\")\n",
    "            print(f\"O3 length: {len_o3_mod}\")\n",
    "            print(f\"Ox length: {len_ox_mod}\")\n",
    "            print(f\"PAN length: {len_pan_mod}\")\n",
    "            print(f\"CH2O length: {len_ch2o_mod}\")\n",
    "            print(f\"CH2O: NO2 length: {len_ch2o_no2_mod}\")\n",
    "            print(f\"NO2 length: {len_no2_mod}\")\n",
    "            print(f\"ALD2 length: {len_ald2_mod}\")\n",
    "            print(f\"GLYX length: {len_glyx_mod}\")\n",
    "            print(f\"MGLY length: {len_mgly_mod}\")\n",
    "            print(f\"BIACET length: {len_biacet_mod}\")\n",
    "            print(f\"ACET length: {len_acet_mod}\")\n",
    "            print(f\"MEK length: {len_mek_mod}\")\n",
    "            print(f\"ACR length: {len_acr_mod}\")\n",
    "            print(f\"MACR length: {len_macr_mod}\")\n",
    "            print(f\"MVK length: {len_mvk_mod}\")\n",
    "            print(f\"GLYC length: {len_glyc_mod}\")\n",
    "            print(f\"HAC length: {len_hac_mod}\")\n",
    "            print(f\"Furfural length: {len_furfural_mod}\")\n",
    "            print(f\"NO (dil) length: {len_no_per_dil_mod}\")\n",
    "            print(f\"NO2 (dil) length: {len_no2_per_dil_mod}\")\n",
    "            print(f\"HONO (dil) length: {len_hno2_per_dil_mod}\")\n",
    "            print(f\"HNO3 (dil) length: {len_hno3_per_dil_mod}\")\n",
    "            print(f\"HNO4 (dil) length: {len_hno4_per_dil_mod}\")\n",
    "            print(f\"PPN (dil) length: {len_ppn_per_dil_mod}\")\n",
    "            print(f\"PNs (dil) length: {len_pns_per_dil_mod}\")\n",
    "            print(f\"ANs (dil) length: {len_ans_per_dil_mod}\")\n",
    "            print(f\"PNs excl. (dil) length: {len_pns_excl_per_dil_mod}\")\n",
    "            print(f\"PAN (dil) length: {len_pan_per_dil_mod}\")\n",
    "            print(f\"NEMR NO length: {len_nemr_no_per_mod}\")\n",
    "            print(f\"NEMR NO2 length: {len_nemr_no2_per_mod}\")\n",
    "            print(f\"NEMR HONO length: {len_nemr_hno2_per_mod}\")\n",
    "            print(f\"NEMR HNO3 length: {len_nemr_hno3_per_mod}\")\n",
    "            print(f\"NEMR HNO4 length: {len_nemr_hno4_per_mod}\")\n",
    "            print(f\"NEMR PPN length: {len_nemr_ppn_per_mod}\")\n",
    "            print(f\"NEMR PNs length: {len_nemr_pns_per_mod}\")\n",
    "            print(f\"NEMR ANs length: {len_nemr_ans_per_mod}\")\n",
    "            print(f\"NEMR PNs excl. length: {len_nemr_pns_excl_per_mod}\")\n",
    "            print(f\"PAN length: {len_nemr_pan_mod}\")\n",
    "            error\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfa1f9-b497-4a12-9ecb-5f4f0ace21cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd17773-93bb-4be1-a73e-8a7ee0029aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5f44c-5159-4290-96f0-8d8ee5afc6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015fbc4-1efa-4478-8387-abe49ce75bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c59887-c345-4404-9bbd-d6a06131b24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77013860-1cb1-4dd7-b869-b9b1425105d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149b79a-f123-4d68-8569-2a14ce57a5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28744fde-279b-43a9-b07a-e7c808519882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd4206-c93b-4691-a298-b326ce14d4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b91f6-6c0a-41f4-8c27-4ded5d78ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081f48b8-7f43-4a86-b390-f9b602771286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fire names</th>\n",
       "      <th>Field campaign</th>\n",
       "      <th>Plume age (min)</th>\n",
       "      <th>OH VOCR (s-1)</th>\n",
       "      <th>OH NOxR (s-1)</th>\n",
       "      <th>CO (ppm)</th>\n",
       "      <th>HONO (ppb)</th>\n",
       "      <th>OHRvoc:OHRnox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Creek Fire</td>\n",
       "      <td>(WE-CAN)</td>\n",
       "      <td>21–147</td>\n",
       "      <td>142.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donnell Fire</td>\n",
       "      <td>(WE-CAN)</td>\n",
       "      <td>121–296</td>\n",
       "      <td>94.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bear Trap Fire</td>\n",
       "      <td>(WE-CAN)</td>\n",
       "      <td>25–277</td>\n",
       "      <td>86.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black Water Fire</td>\n",
       "      <td>(FIREX-AQ)</td>\n",
       "      <td>10–107</td>\n",
       "      <td>109.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Managed Understory Fire</td>\n",
       "      <td>(DISCOVER-AQ)</td>\n",
       "      <td>0–61</td>\n",
       "      <td>54.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Fire names Field campaign Plume age (min) OH VOCR (s-1)  \\\n",
       "0        Taylor Creek Fire       (WE-CAN)          21–147         142.2   \n",
       "1             Donnell Fire       (WE-CAN)         121–296          94.5   \n",
       "2           Bear Trap Fire       (WE-CAN)          25–277          86.1   \n",
       "3         Black Water Fire     (FIREX-AQ)          10–107         109.1   \n",
       "4  Managed Understory Fire  (DISCOVER-AQ)            0–61          54.4   \n",
       "\n",
       "  OH NOxR (s-1) CO (ppm) HONO (ppb) OHRvoc:OHRnox  \n",
       "0          15.7      5.0       48.7           9.0  \n",
       "1           2.2      3.3        3.3          42.9  \n",
       "2           1.5      2.0        2.7          57.0  \n",
       "3          12.6      2.1        5.8           8.7  \n",
       "4           2.8      1.1        1.2          19.6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Inital conditions for each flight (maintext Table)\n",
    "# ===================================================\n",
    "# Sample data initialization\n",
    "data = {\n",
    "    'Fire names'     : [],\n",
    "    'Field campaign' : [], \n",
    "    'Plume age (min)': [],\n",
    "    'OH VOCR (s-1)'  : [],\n",
    "    'OH NOxR (s-1)'  : [],\n",
    "    'CO (ppm)'       : [], \n",
    "    'HONO (ppb)'     : [],\n",
    "    'OHRvoc:OHRnox'  : [],\n",
    "}\n",
    "\n",
    "# Desired order of the keys\n",
    "desired_order = ['RF03', 'RF07', 'RF09', 'FN19', 'P-3B']\n",
    "# Create an OrderedDict with the desired order\n",
    "co_per_flight_obs_ordered = OrderedDict((key, co_per_flight_obs[key]) for key in desired_order if key in co_per_flight_obs and key in Lagrangian_flights)\n",
    "for flight in co_per_flight_obs_ordered.keys():\n",
    "    fire_name        = id2fire_name[flight]\n",
    "    plume_name, campaign = fire_name.split('\\n')\n",
    "    plume_age_start   = co_per_flight_obs[flight]['Avg_physical_age_min'].min()\n",
    "    plume_age_end     = co_per_flight_obs[flight]['Avg_physical_age_min'].max()\n",
    "    OHRvoc_init       = vocr_per_flight_obs[flight]['Observation'][0]\n",
    "    OHRnox_init       = noxr_per_flight_obs[flight]['Observation'][0]\n",
    "    co_init           = co_per_flight_obs[flight]['Observation'][0]\n",
    "    OHRvoc_OHRnox_init= OHRvoc_OHRnox_per_flight_obs[flight]['Observation'][0]\n",
    "    hno2_co_init      = hno2_co_per_flight_obs[flight]['Observation'][0]\n",
    "    hno2_init         = hno2_per_flight_obs[flight]['Observation'][0]\n",
    "    # Append data to the dictionary\n",
    "    data['Fire names'].append(plume_name)\n",
    "    data['Field campaign'].append(campaign)\n",
    "    data['Plume age (min)'].append(f\"{plume_age_start:.0f}–{plume_age_end:.0f}\")\n",
    "    data['OH VOCR (s-1)'].append(f\"{(OHRvoc_init):.1f}\")\n",
    "    data['OH NOxR (s-1)'].append(f\"{(OHRnox_init):.1f}\")\n",
    "    data['CO (ppm)'].append(f\"{(co_init/1000):.1f}\")\n",
    "    data['HONO (ppb)'].append(f\"{hno2_init:.1f}\")\n",
    "    data['OHRvoc:OHRnox'].append(f\"{OHRvoc_OHRnox_init:.1f}\")\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f02a0b-8c14-469d-a956-8604b54786aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Prepare a DataFrame to store all data points\n",
    "# ============================================\n",
    "# Set up dummy dataframe\n",
    "all_data_obs       = pd.DataFrame(columns=['Flight_ID', 'Plume_Age'])\n",
    "all_data_gc        = pd.DataFrame(columns=['Flight_ID', 'Plume_Age']) \n",
    "all_data_mcm_gcvoc = pd.DataFrame(columns=['Flight_ID', 'Plume_Age']) \n",
    "all_data_mcm_bbvoc = pd.DataFrame(columns=['Flight_ID', 'Plume_Age']) \n",
    "\n",
    "J_columns = ['JNO2_NO_O3P', 'JHNO2_OH_NO',\n",
    "                'JH2O2_2OH', 'JHNO3_OH_NO2', 'JO3_O2_O1D', 'JCH2O_H_HCO', 'JCH2O_H2_CO',\n",
    "                'JNO3_NO_O2', 'JNO3_NO2_O3P', 'JN2O5_NO3_NO2',\n",
    "                'JHNO4_HO2_NO2_UV_VISonly', 'JCH3CHO_CH3_HCO', 'JPropanal_C2H5_HCO',\n",
    "                'JCH3OOH_CH3O_OH', 'JMeONO2_CH3O_NO2', 'JEthONO2_CH3CH2O_NO2',\n",
    "                'JCH3COOONO2_CH3COOO_NO2', 'JCH3COOONO2_CH3COO_NO3', 'JMAC_Products',\n",
    "                'JMVK_Products', 'JAcetone_CH3CO_CH3', 'JMEK_CH3CO_CH2CH3',\n",
    "                'JHydroxyacetone_CH3COO_CH3', 'JHydroxyacetone_CH3CO_CH3O',\n",
    "                'JCHOCHO_HCO_HCO', 'JCHOCHO_H2_2CO', 'JCHOCHO_CH2O_CO',\n",
    "                'JCH3COCHO_CH3CO_HCO', 'J23Butanedione_Products', 'JCl2_Cl_Cl',\n",
    "                'JClO_Cl_O3P', 'JClNO2_Cl_NO2', 'JClONO_Cl_NO2', 'JClONO2_Cl_NO3',\n",
    "                'JClONO2_ClO_NO2', 'JBr2_Br_Br', 'JBrO_Br_O', 'JHOBr_OH_Br',\n",
    "                'JBrNO_Br_NO', 'JBrONO_Br_NO2', 'JBrONO_BrO_NO', 'JBrNO2_Br_NO2',\n",
    "                'JBrONO2_BrO_NO2', 'JBrONO2_Br_NO3', 'JBrCl_Br_Cl', 'JCHBr3_Products']\n",
    "\n",
    "# Read in observation values\n",
    "for Flight_ID, data in calOH_conc_stat_per_flight_obs.items():\n",
    "    # Also retrieve calcualted chem age\n",
    "    data_chem_age = cal_chem_age_stat_per_flight_obs[Flight_ID]\n",
    "    data_wide     = calOH_conc_stat_per_flight_obs_wide[Flight_ID]\n",
    "    # Rename the columns\n",
    "    rename_dict = {\n",
    "        'TIME': 'Avg_physical_age_min',\n",
    "        'TimeDownwind_s': 'Avg_physical_age_min',\n",
    "    }\n",
    "    \n",
    "    data.rename(columns=rename_dict, inplace=True)\n",
    "    data_wide.rename(columns=rename_dict, inplace=True)\n",
    "    data_chem_age.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    dummy_df_obs = pd.DataFrame({'Flight_ID': Flight_ID, \n",
    "                                 'Plume_Age': data['Avg_physical_age_min'].astype(float), \n",
    "\n",
    "                                 'CO': co_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NO': no_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NO2': no2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NO: NO2': no_no2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NOx': nox_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'O3': o3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'Ox': ox_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'PAN':pan_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'CH2O':ch2o_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'CH2O: NO2':ch2o_no2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'VOCR': vocr_per_flight_obs[Flight_ID]['Observation'],     \n",
    "                                 'NOxR': noxr_per_flight_obs[Flight_ID]['Observation'],     \n",
    "                                 'cal_OH_mean': data['Mean'],\n",
    "                                 'cal_OH_std': data['Std Dev'],\n",
    "                                 'cal_OH_median': data['Median'],\n",
    "                                 'cal_OH_iqr': data['IQR'],\n",
    "\n",
    "                                 'cal_OH_wide_mean': data_wide['Mean'],\n",
    "                                 'cal_OH_wide_std': data_wide['Std Dev'],\n",
    "                                 'cal_OH_wide_median': data_wide['Median'],\n",
    "                                 'cal_OH_wide_iqr': data_wide['IQR'],\n",
    "                                 \n",
    "                                 'output_OH': outputOH_conc_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'cal_chem_age_mean': data_chem_age['Mean'],\n",
    "                                 'cal_chem_age_std': data_chem_age['Std Dev'],\n",
    "                                 'cal_chem_age_median': data_chem_age['Median'],\n",
    "                                 'cal_chem_age_iqr': data_chem_age['IQR'],\n",
    "                                 'output_chem_age': output_chem_age_per_flight_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 'OH turnover rate':(vocr_per_flight_obs[Flight_ID]['Observation'] * data['Mean'] / 2.46E10 * 60 * 60).astype(float),\n",
    "                                 'OHRvoc: OHRnox': OHRvoc_OHRnox_per_flight_obs[Flight_ID]['Observation'].values,\n",
    "                                 'OHRnox: OHRvoc': OHRnox_OHRvoc_per_flight_obs[Flight_ID]['Observation'].values,\n",
    "\n",
    "                                 'NEMR_HONO': nemr_hno2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'HONO': hno2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'ALD2': ald2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'GLYX': glyx_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'MGLY': mgly_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'BIACET': biacet_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'Propanal': propanal_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'Butanal': butanal_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'ACET': acet_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'MEK': mek_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'ACR': acr_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'MACR': macr_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'MVK': mvk_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'GLYC': glyc_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'HAC': hac_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'Furfural': furfural_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 \n",
    "                                 '2,5-Dimethylfuran': dmf_per_flight_obs[Flight_ID]['Observation'], \n",
    "                                 'Sesquiterpenes': sesq_per_flight_obs[Flight_ID]['Observation'], \n",
    "\n",
    "                                 'Formaldehyde (dil)'    : ch2o_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Acetaldehyde (dil)'    : ald2_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Maleic anhydride (dil)': ma_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Furanoids excl. (dil)': furanoids_excl_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Furanoids excl.'      : furanoids_excl_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'Methylfuran (dil)'    : methylfuran_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Acrolein (dil)'       : acr_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 '1,3-Butadiene (dil)'  : butd_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 'O3 (dil)': o3_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'PAN (dil)': pan_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 'Isoprene (dil)': isop_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Monoterpenes (dil)': mtpa_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Xylenes (dil)': xyle_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 '2-Butenal (dil)': butenal_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Cresol (dil)': cresol_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 '2,5-Dimethylfuran (dil)': dmf_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Guaiacol (dil)': guaiacol_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Syringol (dil)': syringol_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Sesquiterpenes (dil)': sesq_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 # other secondary VOCs\n",
    "                                 'Lumped C>=3 aldehydes (dil)': rcho_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Glyoxal (dil)': glyx_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Formic acid (dil)': hcooh_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Acetic acid (dil)': acta_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Acetic acid + glycolaldehyde (dil)': acta_per_flight_dil_obs[Flight_ID]['Observation'] + glyc_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'MACR + MVK (dil)': macr_mvk_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'MEK (dil)': mek_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Glycolaldehyde (dil)': glyc_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Methylglyoxal (dil)': mgly_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Hydroxy acetone (dil)': hac_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Phenol (dil)': phen_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Benzaldehyde (dil)': bald_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Furanone (dil)': furanone_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Acrolein (dil)': acr_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Maleic anhydride (dil)': ma_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Butanedione (dil)': butanedione_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'Diacetyl (dil)': butanedione_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 '1,2,3-Trimethylbenzene (dil)': TM123B_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 '1,3,5-Trimethylbenzene (dil)': TM135B_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'C9 aromatics (dil)'          : C9arom_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 # Other photochemical indicators\n",
    "                                 'Ln: Q': ln_q_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'LROx: LNOx': lrox_lnox_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'H2O2: HNO3': h2o2_hno3_per_flight_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 'CH2O: CO': ch2o_co_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'VOCR: CO': vocr_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 'NO: CO': no_co_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NO2: CO': no2_co_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NOx: CO': nox_co_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'PAN: CO': pan_co_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'HONO: CO': hno2_co_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NOz: CO': noz_co_per_flight_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 'Furan: CO': furan_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 'Methylfuran: CO': mefuran_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 '2,5-Dimethylfuran: CO': dmf_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 'Furfural: CO': furfural_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 'Methylfurfural: CO': mefurfural_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 'Furanone: CO': furanone_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 '1,3-Butadiene: CO': butd_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "                                 'Acrolein: CO': acr_co_per_flight_obs[Flight_ID]['Observation']*1000,\n",
    "\n",
    "                                 'HO2': ho2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'RO2': ro2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'P(O3)': po3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'P(Ox)': pox_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'L(O3)': lo3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'L(Ox)': lox_per_flight_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 #'pNO3': pno3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'HNO3': hno3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'HNO4': hno4_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'PPN': ppn_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'PNs': pns_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'ANs': ans_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 \n",
    "                                 'NO (dil)': no_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'NO2 (dil)': no2_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'HONO (dil)': hno2_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 #'pNO3 (dil)': pno3_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'HNO3 (dil)': hno3_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'HNO4 (dil)': hno4_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'PPN (dil)': ppn_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'PNs (dil)': pns_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'ANs (dil)': ans_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'PNs_excl (dil)': pns_excl_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "                                 'PAN (dil)': pan_per_flight_dil_obs[Flight_ID]['Observation'],\n",
    "\n",
    "                                 'NEMR_O3': nemr_o3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_O3_rate': nemr_o3_per_flight_obs[Flight_ID]['Observation']/(data['Avg_physical_age_min'].astype(float)/60.0),\n",
    "                                 'NEMR_O3_NOx': nemr_o3_nox_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_Ox': nemr_ox_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 \n",
    "                                 'NEMR_NO': nemr_no_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_NO2': nemr_no2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_NOx': nemr_no_per_flight_obs[Flight_ID]['Observation'] + nemr_no2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_HONO': nemr_hno2_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 #'NEMR_pNO3': nemr_pno3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_HNO3': nemr_hno3_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_HNO4': nemr_hno4_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_PPN': nemr_ppn_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_PNs': nemr_pns_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_ANs': nemr_ans_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_PNs_excl': nemr_pns_excl_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_PAN': nemr_pan_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'NEMR_PAN_rate': nemr_pan_per_flight_obs[Flight_ID]['Observation']/(data['Avg_physical_age_min'].astype(float)/60.0),\n",
    "\n",
    "                                 # Response to reviewers\n",
    "                                 'Furan': furan_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'Methylfuran': mefuran_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 '2,5-Dimethylfuran': dmf_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'Furfural': furfural_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'Methylfurfural': mefurfural_per_flight_obs[Flight_ID]['Observation'],\n",
    "                                 'Furanone': furanone_per_flight_obs[Flight_ID]['Observation'],                                 \n",
    "                                 'Benzene': benzene_per_flight_obs[Flight_ID]['Observation'],                                 \n",
    "                                 'NEMR_Benzene': nemr_benzene_per_flight_obs[Flight_ID]['Observation'],                                 \n",
    "                                })\n",
    "\n",
    "                                 \n",
    "    \n",
    "    # Add each J value column to the DataFrame\n",
    "    for J_col in J_columns: dummy_df_obs[J_col] = met_per_flight_obs[Flight_ID][J_col]\n",
    "\n",
    "    all_data_obs = pd.concat([all_data_obs, dummy_df_obs], ignore_index=True)\n",
    "\n",
    "\n",
    "# Read in model values\n",
    "for Flight_ID, data in calOH_conc_stat_per_flight_mod.items():\n",
    "    # Also retrieve calcualted chem age\n",
    "    data_chem_age = cal_chem_age_stat_per_flight_mod[Flight_ID]\n",
    "    data_wide     = calOH_conc_stat_per_flight_mod_wide[Flight_ID]\n",
    "    \n",
    "    # Rename the columns\n",
    "    rename_dict = {\n",
    "        'index': 'Avg_physical_age_min',\n",
    "    }\n",
    "    data.rename(columns=rename_dict, inplace=True)\n",
    "    data_wide.rename(columns=rename_dict, inplace=True)\n",
    "    data_chem_age.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    \n",
    "    dummy_df_gc = pd.DataFrame({'Flight_ID': [Flight_ID]*len(data), \n",
    "                                'Plume_Age': data['Avg_physical_age_min'].astype(float), \n",
    "\n",
    "                                'CO': co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'NO': no_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'NO2': no2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                'NO: NO2': no_no2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                'NOx': nox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'O3': o3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'Ox': ox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'PAN':pan_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'CH2O':ch2o_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'CH2O: NO2':ch2o_no2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'VOCR': vocr_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],     \n",
    "                                'NOxR': noxr_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],     \n",
    "                                'cal_OH_mean': data['Mean'].astype(float),\n",
    "                                'cal_OH_std': data['Std Dev'].astype(float),\n",
    "                                'cal_OH_median': data['Median'].astype(float),\n",
    "                                'cal_OH_iqr': data['IQR'].astype(float),                     \n",
    "\n",
    "                                'cal_OH_wide_mean': data_wide['Mean'].astype(float),\n",
    "                                'cal_OH_wide_std': data_wide['Std Dev'].astype(float),\n",
    "                                'cal_OH_wide_median': data_wide['Median'].astype(float),\n",
    "                                'cal_OH_wide_iqr': data_wide['IQR'].astype(float),                     \n",
    "\n",
    "                                'output_OH': outputOH_conc_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                'cal_chem_age_mean': data_chem_age['Mean'].astype(float),\n",
    "                                'cal_chem_age_std': data_chem_age['Std Dev'].astype(float),\n",
    "                                'cal_chem_age_median': data_chem_age['Median'].astype(float),\n",
    "                                'cal_chem_age_iqr': data_chem_age['IQR'].astype(float),                              \n",
    "                                'output_chem_age': output_chem_age_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                'OH turnover rate':(vocr_per_flight_mod[Flight_ID]['GEOS-Chem (base)'] * data['Mean'] / 2.46E10 * 60 * 60).astype(float),\n",
    "                                'OHRvoc: OHRnox': OHRvoc_OHRnox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'].values, \n",
    "                                'OHRnox: OHRvoc': OHRnox_OHRvoc_per_flight_mod[Flight_ID]['GEOS-Chem (base)'].values, \n",
    "                                \n",
    "                                'NEMR_HONO': nemr_hno2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'HONO': hno2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'ALD2': ald2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'GLYX': glyx_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'MGLY': mgly_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'BIACET': biacet_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'Propanal': propanal_per_flight_mod[Flight_ID]['GEOS-Chem (base)'], \n",
    "                                'Butanal': butanal_per_flight_mod[Flight_ID]['GEOS-Chem (base)'], \n",
    "                                'ACET': acet_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'MEK': mek_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'ACR': acr_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'MACR': macr_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'MVK': mvk_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'GLYC': glyc_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'HAC': hac_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                'Furfural': furfural_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 \n",
    "                                '2,5-Dimethylfuran': dmf_per_flight_mod[Flight_ID]['GEOS-Chem (base)'], \n",
    "                                'Sesquiterpenes': sesq_per_flight_mod[Flight_ID]['GEOS-Chem (base)'], \n",
    "                                \n",
    "                                 'Formaldehyde (dil)'   : ch2o_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Acetaldehyde (dil)'   : ald2_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Maleic anhydride (dil)': ma_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Furanoids excl. (dil)': furanoids_excl_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Furanoids excl.'      : furanoids_excl_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Methylfuran (dil)'    : methylfuran_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Acrolein (dil)'       : acr_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 '1,3-Butadiene (dil)'  : butd_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                 'O3 (dil)': o3_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PAN (dil)': pan_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                 'Isoprene (dil)': isop_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Monoterpenes (dil)': mtpa_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Xylenes (dil)': xyle_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 '2-Butenal (dil)': butenal_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Cresol (dil)': cresol_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 '2,5-Dimethylfuran (dil)': dmf_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Guaiacol (dil)': guaiacol_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Syringol (dil)': syringol_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Sesquiterpenes (dil)': sesq_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                 # other secondary VOCs\n",
    "                                 'Lumped C>=3 aldehydes (dil)': rcho_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Glyoxal (dil)': glyx_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Formic acid (dil)': hcooh_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Acetic acid (dil)': acta_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Acetic acid + glycolaldehyde (dil)': acta_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'] + glyc_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'MACR + MVK (dil)': macr_mvk_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'MEK (dil)': mek_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Glycolaldehyde (dil)': glyc_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Methylglyoxal (dil)': mgly_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Hydroxy acetone (dil)': hac_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Phenol (dil)': phen_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Benzaldehyde (dil)': bald_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Furanone (dil)': furanone_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Acrolein (dil)': acr_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Maleic anhydride (dil)': ma_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Butanedione (dil)': butanedione_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Diacetyl (dil)': butanedione_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                 '1,2,3-Trimethylbenzene (dil)': TM123B_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 '1,3,5-Trimethylbenzene (dil)': TM135B_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'C9 aromatics (dil)'          : C9arom_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                \n",
    "                                 # Other photochemical indicators\n",
    "                                 'Ln: Q': ln_q_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'LROx: LNOx': lrox_lnox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'H2O2: HNO3': h2o2_hno3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                \n",
    "                                 'CH2O: CO': ch2o_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'VOCR: CO': vocr_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 'NO: CO': no_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NO2: CO': no2_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NOx: CO': nox_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PAN: CO': pan_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'HONO: CO': hno2_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NOz: CO': noz_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                 'Furan: CO': furan_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 'Methylfuran: CO': mefuran_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 '2,5-Dimethylfuran: CO': dmf_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 'Furfural: CO': furfural_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 'Methylfurfural: CO': mefurfural_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 'Furanone: CO': furanone_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 '1,3-Butadiene: CO': butd_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "                                 'Acrolein: CO': acr_co_per_flight_mod[Flight_ID]['GEOS-Chem (base)']*1000,\n",
    "\n",
    "                                 'HO2': ho2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'RO2': ro2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'P(O3)': po3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'P(Ox)': pox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'L(O3)': lo3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'L(Ox)': lox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                 #'pNO3': pno3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'HNO3': hno3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'HNO4': hno4_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PPN': ppn_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PNs': pns_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'ANs': ans_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "\n",
    "                                 'NO (dil)': no_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NO2 (dil)': no2_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'HONO (dil)': hno2_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 #'pNO3 (dil)': pno3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'HNO3 (dil)': hno3_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'HNO4 (dil)': hno4_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PPN (dil)': ppn_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PNs (dil)': pns_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'ANs (dil)': ans_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PNs_excl (dil)': pns_excl_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'PAN (dil)': pan_per_flight_dil_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "\n",
    "                                 'NEMR_O3': nemr_o3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_O3_rate': nemr_o3_per_flight_mod[Flight_ID]['GEOS-Chem (base)']/(data['Avg_physical_age_min'].astype(float)/60.0),     \n",
    "                                 'NEMR_O3_NOx': nemr_o3_nox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_Ox': nemr_ox_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                \n",
    "                                 'NEMR_NO': nemr_no_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_NO2': nemr_no2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_NOx': nemr_no_per_flight_mod[Flight_ID]['GEOS-Chem (base)'] + nemr_no2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_HONO': nemr_hno2_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 #'NEMR_pNO3': nemr_pno3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_HNO3': nemr_hno3_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_HNO4': nemr_hno4_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_PPN': nemr_ppn_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_PNs': nemr_pns_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_ANs': nemr_ans_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_PNs_excl': nemr_pns_excl_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_PAN': nemr_pan_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'NEMR_PAN_rate': nemr_pan_per_flight_mod[Flight_ID]['GEOS-Chem (base)']/(data['Avg_physical_age_min'].astype(float)/60.0),        \n",
    "                                 \n",
    "                                 # Response to reviewers\n",
    "                                 'Furan': furan_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Methylfuran': mefuran_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 '2,5-Dimethylfuran': dmf_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Furfural': furfural_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Methylfurfural': mefurfural_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Furanone': furanone_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],\n",
    "                                 'Benzene': benzene_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],                        \n",
    "                                 'NEMR_Benzene': nemr_benzene_per_flight_mod[Flight_ID]['GEOS-Chem (base)'],                 \n",
    "                               })\n",
    "                                \n",
    "\n",
    "    \n",
    "    \n",
    "    dummy_df_mcm_gcvoc = pd.DataFrame({'Flight_ID': Flight_ID, \n",
    "                                       'Plume_Age': data['Avg_physical_age_min'].astype(float), \n",
    "\n",
    "                                       'CO': co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'NO': no_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'NO2': no2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'NO: NO2': no_no2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                       \n",
    "                                       'NOx': nox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'O3': o3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Ox': ox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'PAN':pan_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'CH2O':ch2o_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'CH2O: NO2':ch2o_no2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'VOCR': vocr_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       \n",
    "                                       'cal_OH_mean': data['Mean'].astype(float),\n",
    "                                       'cal_OH_std': data['Std Dev'].astype(float),\n",
    "                                       'cal_OH_median': data['Median'].astype(float),\n",
    "                                       'cal_OH_iqr': data['IQR'].astype(float),\n",
    "                                       'output_OH': outputOH_conc_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       \n",
    "                                       'cal_OH_wide_mean': data_wide['Mean'].astype(float),\n",
    "                                       'cal_OH_wide_std': data_wide['Std Dev'].astype(float),\n",
    "                                       'cal_OH_wide_median': data_wide['Median'].astype(float),\n",
    "                                       'cal_OH_wide_iqr': data_wide['IQR'].astype(float),\n",
    "                                       'output_OH': outputOH_conc_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       \n",
    "                                       'cal_chem_age_mean': data_chem_age['Mean'].astype(float),\n",
    "                                       'cal_chem_age_std': data_chem_age['Std Dev'].astype(float),\n",
    "                                       'cal_chem_age_median': data_chem_age['Median'].astype(float),\n",
    "                                       'cal_chem_age_iqr': data_chem_age['IQR'].astype(float),                              \n",
    "                                       'output_chem_age': output_chem_age_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                       'OH turnover rate':(vocr_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'] * data['Mean'] / 2.46E10 * 60 * 60).astype(float),\n",
    "                                       'OHRvoc: OHRnox': OHRvoc_OHRnox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'].values, \n",
    "                                       'OHRnox: OHRvoc': OHRnox_OHRvoc_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'].values, \n",
    "                                       \n",
    "                                       'NEMR_HONO': nemr_hno2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'HONO': hno2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'ALD2': ald2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'GLYX': glyx_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'MGLY': mgly_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'BIACET': biacet_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Propanal': propanal_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Butanal': butanal_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'], \n",
    "                                       'ACET': acet_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'MEK': mek_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'ACR': acr_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'MACR': macr_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'MVK': mvk_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'GLYC': glyc_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'HAC': hac_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Furfural': furfural_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       \n",
    "                                       '2,5-Dimethylfuran': dmf_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Sesquiterpenes': sesq_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       \n",
    "                                       'Formaldehyde (dil)'    : ch2o_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Acetaldehyde (dil)'    : ald2_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Maleic anhydride (dil)': ma_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Furanoids excl. (dil)' : furanoids_excl_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Furanoids excl.'       : furanoids_excl_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Methylfuran (dil)'     : methylfuran_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Acrolein (dil)'        : acr_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       '1,3-Butadiene (dil)'   : butd_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                       'O3 (dil)': o3_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'PAN (dil)': pan_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                       'Isoprene (dil)': isop_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Monoterpenes (dil)': mtpa_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Xylenes (dil)': xyle_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       '2-Butenal (dil)': butenal_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Cresol (dil)': cresol_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       '2,5-Dimethylfuran (dil)': dmf_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Guaiacol (dil)': guaiacol_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Syringol (dil)': syringol_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Sesquiterpenes (dil)': sesq_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                       # other secondary VOCs\n",
    "                                       'Lumped C>=3 aldehydes (dil)': rcho_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Glyoxal (dil)': glyx_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Formic acid (dil)': hcooh_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Acetic acid (dil)': acta_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Acetic acid + glycolaldehyde (dil)': acta_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'] + glyc_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'MACR + MVK (dil)': macr_mvk_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'MEK (dil)': mek_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Glycolaldehyde (dil)': glyc_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Methylglyoxal (dil)': mgly_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Hydroxy acetone (dil)': hac_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Phenol (dil)': phen_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Benzaldehyde (dil)': bald_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Furanone (dil)': furanone_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Acrolein (dil)': acr_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Maleic anhydride (dil)': ma_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Butanedione (dil)': butanedione_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'Diacetyl (dil)': butanedione_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                       \n",
    "                                       '1,2,3-Trimethylbenzene (dil)': TM123B_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       '1,3,5-Trimethylbenzene (dil)': TM135B_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       'C9 aromatics (dil)'          : C9arom_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       \n",
    "                                        # Other photochemical indicators\n",
    "                                        'Ln: Q': ln_q_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'LROx: LNOx': lrox_lnox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'H2O2: HNO3': h2o2_hno3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                        'CH2O: CO': ch2o_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'VOCR: CO': vocr_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                        'NO: CO': no_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'NO2: CO': no2_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'NOx: CO': nox_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'PAN: CO': pan_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'HONO: CO': hno2_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                        'NOz: CO': noz_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "        \n",
    "                                         'Furan: CO': furan_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                         'Methylfuran: CO': mefuran_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                         '2,5-Dimethylfuran: CO': dmf_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                         'Furfural: CO': furfural_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                         'Methylfurfural: CO': mefurfural_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                         'Furanone: CO': furanone_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                         '1,3-Butadiene: CO': butd_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "                                         'Acrolein: CO': acr_co_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']*1000,\n",
    "\n",
    "                                         'HO2': ho2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'RO2': ro2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'P(O3)': po3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'P(Ox)': pox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'L(O3)': lo3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'L(Ox)': lox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                               \n",
    "                                         #'pNO3': pno3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'HNO3': hno3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'HNO4': hno4_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'PPN': ppn_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'PNs': pns_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'ANs': ans_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                         'NO (dil)': no_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NO2 (dil)': no2_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'HONO (dil)': hno2_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         #'pNO3 (dil)': pno3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'HNO3 (dil)': hno3_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'HNO4 (dil)': hno4_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'PPN (dil)': ppn_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'PNs (dil)': pns_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'ANs (dil)': ans_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'PNs_excl (dil)': pns_excl_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'PAN (dil)': pan_per_flight_dil_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "\n",
    "                                         'NEMR_O3': nemr_o3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_O3_rate': nemr_o3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']/(data['Avg_physical_age_min'].astype(float)/60.0),     \n",
    "                                         'NEMR_O3_NOx': nemr_o3_nox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_Ox': nemr_ox_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                       \n",
    "                                         'NEMR_NO': nemr_no_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_NO2': nemr_no2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_NOx': nemr_no_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'] + nemr_no2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_HONO': nemr_hno2_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         #'NEMR_pNO3': nemr_pno3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_HNO3': nemr_hno3_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_HNO4': nemr_hno4_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_PPN': nemr_ppn_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_PNs': nemr_pns_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_ANs': nemr_ans_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_PNs_excl': nemr_pns_excl_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_PAN': nemr_pan_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'NEMR_PAN_rate': nemr_pan_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs']/(data['Avg_physical_age_min'].astype(float)/60.0),  \n",
    "        \n",
    "                                         # Response to reviewers\n",
    "                                         'Furan': furan_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'Methylfuran': mefuran_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         '2,5-Dimethylfuran': dmf_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'Furfural': furfural_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'Methylfurfural': mefurfural_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],\n",
    "                                         'Furanone': furanone_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],                        \n",
    "                                         'Benzene': benzene_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],                       \n",
    "                                         'NEMR_Benzene': nemr_benzene_per_flight_mod[Flight_ID]['MCM + GEOS-Chem VOCs'],   \n",
    "                                    })\n",
    "\n",
    "    dummy_df_mcm_bbvoc = pd.DataFrame({'Flight_ID': Flight_ID, \n",
    "                                       'Plume_Age': data['Avg_physical_age_min'].astype(float), \n",
    "                                       'CO': co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'NO': no_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'NO2': no2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'NO: NO2': no_no2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                       'NOx': nox_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'O3': o3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Ox': ox_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'PAN':pan_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'CH2O':ch2o_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'CH2O: NO2':ch2o_no2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'VOCR': vocr_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                       'cal_OH_mean': data['Mean'].astype(float),\n",
    "                                       'cal_OH_std': data['Std Dev'].astype(float),\n",
    "                                       'cal_OH_median': data['Median'].astype(float),\n",
    "                                       'cal_OH_iqr': data['IQR'].astype(float),\n",
    "                                       'output_OH': outputOH_conc_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                       'cal_OH_wide_mean': data_wide['Mean'].astype(float),\n",
    "                                       'cal_OH_wide_std': data_wide['Std Dev'].astype(float),\n",
    "                                       'cal_OH_wide_median': data_wide['Median'].astype(float),\n",
    "                                       'cal_OH_wide_iqr': data_wide['IQR'].astype(float),\n",
    "                                       'output_OH': outputOH_conc_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                       'cal_chem_age_mean': data_chem_age['Mean'].astype(float),\n",
    "                                       'cal_chem_age_std': data_chem_age['Std Dev'].astype(float),\n",
    "                                       'cal_chem_age_median': data_chem_age['Median'].astype(float),\n",
    "                                       'cal_chem_age_iqr': data_chem_age['IQR'].astype(float),                              \n",
    "                                       'output_chem_age': output_chem_age_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                       'OH turnover rate':(vocr_per_flight_mod[Flight_ID]['MCM + FUR'] * data['Mean'] / 2.46E10 * 60 * 60).astype(float),\n",
    "                                       'OHRvoc: OHRnox': OHRvoc_OHRnox_per_flight_mod[Flight_ID]['MCM + FUR'].values, \n",
    "                                       'OHRnox: OHRvoc': OHRnox_OHRvoc_per_flight_mod[Flight_ID]['MCM + FUR'].values, \n",
    "                                       \n",
    "                                       'NEMR_HONO': nemr_hno2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'HONO': hno2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'ALD2': ald2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'GLYX': glyx_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'MGLY': mgly_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'BIACET': biacet_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Propanal': propanal_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Butanal': butanal_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                       'ACET': acet_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'MEK': mek_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'ACR': acr_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'MACR': macr_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'MVK': mvk_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'GLYC': glyc_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'HAC': hac_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Furfural': furfural_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                       '2,5-Dimethylfuran': dmf_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Sesquiterpenes': sesq_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                       'Formaldehyde (dil)'    : ch2o_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Acetaldehyde (dil)'    : ald2_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Maleic anhydride (dil)': ma_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Furanoids excl. (dil)' : furanoids_excl_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Furanoids excl.'       : furanoids_excl_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Methylfuran (dil)'     : methylfuran_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Acrolein (dil)'        : acr_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       '1,3-Butadiene (dil)'   : butd_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                       'O3 (dil)': o3_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'PAN (dil)': pan_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                       'Isoprene (dil)': isop_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Monoterpenes (dil)': mtpa_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Xylenes (dil)': xyle_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       '2-Butenal (dil)': butenal_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Cresol (dil)': cresol_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       '2,5-Dimethylfuran (dil)': dmf_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Guaiacol (dil)': guaiacol_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Syringol (dil)': syringol_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       'Sesquiterpenes (dil)': sesq_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                        # other secondary VOCs\n",
    "                                        'Lumped C>=3 aldehydes (dil)': rcho_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Glyoxal (dil)': glyx_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Formic acid (dil)': hcooh_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Acetic acid (dil)': acta_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Acetic acid + glycolaldehyde (dil)': acta_per_flight_dil_mod[Flight_ID]['MCM + FUR'] + glyc_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'MACR + MVK (dil)': macr_mvk_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'MEK (dil)': mek_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Glycolaldehyde (dil)': glyc_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Methylglyoxal (dil)': mgly_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Hydroxy acetone (dil)': hac_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Phenol (dil)': phen_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Benzaldehyde (dil)': bald_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Furanone (dil)': furanone_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Acrolein (dil)': acr_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Maleic anhydride (dil)': ma_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Butanedione (dil)': butanedione_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'Diacetyl (dil)': butanedione_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "\n",
    "                                       \n",
    "                                        '1,2,3-Trimethylbenzene (dil)': TM123B_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        '1,3,5-Trimethylbenzene (dil)': TM135B_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                        'C9 aromatics (dil)'          : C9arom_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                         # Other photochemical indicators\n",
    "                                         'Ln: Q': ln_q_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'LROx: LNOx': lrox_lnox_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'H2O2: HNO3': h2o2_hno3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                         'CH2O: CO': ch2o_co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'VOCR: CO': vocr_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         'NO: CO': no_co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NO2: CO': no2_co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NOx: CO': nox_co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'PAN: CO': pan_co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'HONO: CO': hno2_co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NOz: CO': noz_co_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                         'Furan: CO': furan_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         'Methylfuran: CO': mefuran_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         '2,5-Dimethylfuran: CO': dmf_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         'Furfural: CO': furfural_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         'Methylfurfural: CO': mefurfural_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         'Furanone: CO': furanone_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         '1,3-Butadiene: CO': butd_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                         'Acrolein: CO': acr_co_per_flight_mod[Flight_ID]['MCM + FUR']*1000,\n",
    "                                       \n",
    "                                         'HO2': ho2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'RO2': ro2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'P(O3)': po3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'P(Ox)': pox_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'L(O3)': lo3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'L(Ox)': lox_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                         #'pNO3': pno3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'HNO3': hno3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'HNO4': hno4_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'PPN': ppn_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'PNs': pns_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'ANs': ans_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                         'NO (dil)': no_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NO2 (dil)': no2_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'HONO (dil)': hno2_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         #'pNO3 (dil)': pno3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'HNO3 (dil)': hno3_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'HNO4 (dil)': hno4_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'PPN (dil)': ppn_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'PNs (dil)': pns_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'ANs (dil)': ans_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'PNs_excl (dil)': pns_excl_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'PAN (dil)': pan_per_flight_dil_mod[Flight_ID]['MCM + FUR'],\n",
    "\n",
    "                                         'NEMR_O3': nemr_o3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_O3_rate': nemr_o3_per_flight_mod[Flight_ID]['MCM + FUR']/(data['Avg_physical_age_min'].astype(float)/60.0),                                \n",
    "                                       \n",
    "                                         'NEMR_O3_NOx': nemr_o3_nox_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_Ox': nemr_ox_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                       \n",
    "                                         'NEMR_NO': nemr_no_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_NO2': nemr_no2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_NOx': nemr_no_per_flight_mod[Flight_ID]['MCM + FUR'] + nemr_no2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_HONO': nemr_hno2_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         #'NEMR_pNO3': nemr_pno3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_HNO3': nemr_hno3_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_HNO4': nemr_hno4_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_PPN': nemr_ppn_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_PNs': nemr_pns_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_ANs': nemr_ans_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_PNs_excl': nemr_pns_excl_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_PAN': nemr_pan_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'NEMR_PAN_rate': nemr_pan_per_flight_mod[Flight_ID]['MCM + FUR']/(data['Avg_physical_age_min'].astype(float)/60.0),  \n",
    "\n",
    "                                         # Response to reviewers\n",
    "                                         'Furan': furan_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'Methylfuran': mefuran_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         '2,5-Dimethylfuran': dmf_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'Furfural': furfural_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'Methylfurfural': mefurfural_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         'Furanone': furanone_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                         \n",
    "                                         'Benzene': benzene_per_flight_mod[Flight_ID]['MCM + FUR'],           \n",
    "                                         'NEMR_Benzene': nemr_benzene_per_flight_mod[Flight_ID]['MCM + FUR'],\n",
    "                                    })\n",
    "\n",
    "                                           \n",
    "    all_data_gc        = pd.concat([all_data_gc, dummy_df_gc], ignore_index=True)\n",
    "    all_data_mcm_gcvoc = pd.concat([all_data_mcm_gcvoc, dummy_df_mcm_gcvoc], ignore_index=True)\n",
    "    all_data_mcm_bbvoc = pd.concat([all_data_mcm_bbvoc, dummy_df_mcm_bbvoc], ignore_index=True)\n",
    "\n",
    "# -------------------------\n",
    "# Plume age unit conversion\n",
    "# -------------------------\n",
    "all_data_obs['Plume_Age']               = all_data_obs['Plume_Age']/60\n",
    "all_data_gc['Plume_Age']                = all_data_gc['Plume_Age']/60\n",
    "all_data_mcm_gcvoc['Plume_Age']         = all_data_mcm_gcvoc['Plume_Age']/60\n",
    "all_data_mcm_bbvoc['Plume_Age']         = all_data_mcm_bbvoc['Plume_Age']/60\n",
    "\n",
    "all_data_obs['cal_chem_age_iqr']        = all_data_obs['cal_chem_age_iqr']\n",
    "all_data_gc['cal_chem_age_iqr']         = all_data_gc['cal_chem_age_iqr']\n",
    "all_data_mcm_gcvoc['cal_chem_age_iqr']  = all_data_mcm_gcvoc['cal_chem_age_iqr']\n",
    "all_data_mcm_bbvoc['cal_chem_age_iqr']  = all_data_mcm_bbvoc['cal_chem_age_iqr']\n",
    "\n",
    "all_data_obs['cal_chem_age_mean']       = all_data_obs['cal_chem_age_mean']\n",
    "all_data_gc['cal_chem_age_mean']        = all_data_gc['cal_chem_age_mean']\n",
    "all_data_mcm_gcvoc['cal_chem_age_mean'] = all_data_mcm_gcvoc['cal_chem_age_mean']\n",
    "all_data_mcm_bbvoc['cal_chem_age_mean'] = all_data_mcm_bbvoc['cal_chem_age_mean']\n",
    "\n",
    "all_data_obs['cal_chem_age_median']      = all_data_obs['cal_chem_age_median']\n",
    "all_data_gc['cal_chem_age_median']       = all_data_gc['cal_chem_age_median']\n",
    "all_data_mcm_gcvoc['cal_chem_age_median']= all_data_mcm_gcvoc['cal_chem_age_median']\n",
    "all_data_mcm_bbvoc['cal_chem_age_median']= all_data_mcm_bbvoc['cal_chem_age_median']\n",
    "\n",
    "all_data_obs['cal_chem_age_std']         = all_data_obs['cal_chem_age_std']\n",
    "all_data_gc['cal_chem_age_std']          = all_data_gc['cal_chem_age_std']\n",
    "all_data_mcm_gcvoc['cal_chem_age_std']   = all_data_mcm_gcvoc['cal_chem_age_std']\n",
    "all_data_mcm_bbvoc['cal_chem_age_std']   = all_data_mcm_bbvoc['cal_chem_age_std']\n",
    "\n",
    "all_data_obs['output_chem_age']          = all_data_obs['output_chem_age']\n",
    "all_data_gc['output_chem_age']           = all_data_gc['output_chem_age']\n",
    "all_data_mcm_gcvoc['output_chem_age']    = all_data_mcm_gcvoc['output_chem_age']\n",
    "all_data_mcm_bbvoc['output_chem_age']    = all_data_mcm_bbvoc['output_chem_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67ea14-ce81-46d3-8789-0957a7c765d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c1d66-1bf8-4be1-8ba9-514129f35ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "727e07f4-712c-478f-b4d6-feac4dee1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move those 4 ACN outliers\n",
    "# Values of Plume_Age that should be NaN\n",
    "plume_ages_to_nan = [3.226667, 3.306667, 3.503667, 3.519500]\n",
    "\n",
    "# Round both the DataFrame column and the target list to 6 decimals\n",
    "rounded_plume_ages_to_nan = [round(x, 6) for x in plume_ages_to_nan]\n",
    "\n",
    "# Create a mask: True if the rounded Plume_Age is in the list\n",
    "mask = all_data_obs['Plume_Age'].round(6).isin(rounded_plume_ages_to_nan)\n",
    "\n",
    "# Set all columns to NaN for rows where the mask is True\n",
    "all_data_obs.loc[mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54c7d9-9d63-4ba8-8616-e1cff3ad46b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae87544-a37c-4c64-b1f3-74faa297771c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94993e70-e257-41f6-bd25-0ebb00bf98e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEMR_O3\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Post data processing\n",
    "# --------------------\n",
    "# remove the first 5 min of the P-3B in models\n",
    "all_data_obs       = all_data_obs[~((all_data_obs['Flight_ID'] == 'P-3B') & (all_data_obs['Plume_Age'] < 10/60.0))]\n",
    "all_data_gc        = all_data_gc[~((all_data_gc['Flight_ID'] == 'P-3B') & (all_data_gc['Plume_Age'] < 10/60.0))]\n",
    "all_data_mcm_gcvoc = all_data_mcm_gcvoc[~((all_data_mcm_gcvoc['Flight_ID'] == 'P-3B') & (all_data_mcm_gcvoc['Plume_Age'] < 10/60.0))]\n",
    "all_data_mcm_bbvoc = all_data_mcm_bbvoc[~((all_data_mcm_bbvoc['Flight_ID'] == 'P-3B') & (all_data_mcm_bbvoc['Plume_Age'] < 10/60.0))]\n",
    "\n",
    "# Ox\n",
    "all_data_obs['Ox'] = all_data_obs['O3'] + all_data_obs['NO2']\n",
    "all_data_gc['Ox'] = all_data_gc['O3'] + all_data_gc['NO2']\n",
    "all_data_mcm_gcvoc['Ox'] = all_data_mcm_gcvoc['O3'] + all_data_mcm_gcvoc['NO2']\n",
    "all_data_mcm_bbvoc['Ox'] = all_data_mcm_bbvoc['O3'] + all_data_mcm_bbvoc['NO2']\n",
    "\n",
    "# sort the all_data by plume_Age\n",
    "all_data_obs = all_data_obs.sort_values(by='Plume_Age', ascending=True)  # Use ascending=False to sort in descending order\n",
    "all_data_gc = all_data_gc.sort_values(by='Plume_Age', ascending=True)  # Use ascending=False to sort in descending order\n",
    "all_data_mcm_gcvoc = all_data_mcm_gcvoc.sort_values(by='Plume_Age', ascending=True)  # Use ascending=False to sort in descending order\n",
    "all_data_mcm_bbvoc = all_data_mcm_bbvoc.sort_values(by='Plume_Age', ascending=True)  # Use ascending=False to sort in descending order\n",
    "\n",
    "# -----------------------------------\n",
    "# Make nan for negative observations\n",
    "# -----------------------------------\n",
    "# Replace negative values with NaN in all_data_obs DataFrame\n",
    "for col in all_data_obs.select_dtypes(include=np.number).columns:\n",
    "    if col != 'NEMR_O3': all_data_obs.loc[all_data_obs[col] < 0, col] = np.nan\n",
    "    if col == 'NEMR_O3': print(col)\n",
    "\n",
    "# -------------------------\n",
    "# Categorize data into bins\n",
    "# -------------------------\n",
    "# Define bins for grouping - adjust these based on your data\n",
    "VOCR_NOxR_bins = [0, 20, 100, np.inf]\n",
    "NOxR_VOCR_bins = [0, 0.01, 0.2, np.inf]\n",
    "VOCR_bins      = [0, 10, 100, np.inf]\n",
    "CH2O_NO2_bins  = [0, 2, 4, 6, 8, 10, np.inf]\n",
    "#theta_bins     = [0, 2, 4, 6, 8, 10, np.inf]\n",
    "\n",
    "# Generate group names based on bins\n",
    "VOCR_NOxR_group_names = [f'{VOCR_NOxR_bins[i]}-{VOCR_NOxR_bins[i+1]}' for i in range(len(VOCR_NOxR_bins)-2)]\n",
    "VOCR_NOxR_group_names.append(f'>{VOCR_NOxR_bins[-2]}')\n",
    "\n",
    "NOxR_VOCR_group_names = [f'{NOxR_VOCR_bins[i]}-{NOxR_VOCR_bins[i+1]}' for i in range(len(NOxR_VOCR_bins)-2)]\n",
    "NOxR_VOCR_group_names.append(f'>{NOxR_VOCR_bins[-2]}')\n",
    "\n",
    "CH2O_NO2_group_names = [f'{CH2O_NO2_bins[i]}-{CH2O_NO2_bins[i+1]}' for i in range(len(CH2O_NO2_bins)-2)]\n",
    "CH2O_NO2_group_names.append(f'>{CH2O_NO2_bins[-2]}')\n",
    "\n",
    "#theta_group_names = [f'{theta_bins[i]}-{theta_bins[i+1]}' for i in range(len(theta_bins)-2)]\n",
    "#theta_group_names.append(f'>{theta_bins[-2]}')\n",
    "\n",
    "VOCR_group_names = [f'{VOCR_bins[i]}-{VOCR_bins[i+1]}' for i in range(len(VOCR_bins)-2)]\n",
    "VOCR_group_names.append(f'>{VOCR_bins[-2]}')\n",
    "\n",
    "# Assign groups to dataframes\n",
    "all_data_obs['VOCR_NOxR_group'] = pd.cut(all_data_obs['OHRvoc: OHRnox'], VOCR_NOxR_bins, labels=VOCR_NOxR_group_names)\n",
    "all_data_gc['VOCR_NOxR_group'] = pd.cut(all_data_gc['OHRvoc: OHRnox'], VOCR_NOxR_bins, labels=VOCR_NOxR_group_names)\n",
    "all_data_mcm_gcvoc['VOCR_NOxR_group'] = pd.cut(all_data_mcm_gcvoc['OHRvoc: OHRnox'], VOCR_NOxR_bins, labels=VOCR_NOxR_group_names)\n",
    "all_data_mcm_bbvoc['VOCR_NOxR_group'] = pd.cut(all_data_mcm_bbvoc['OHRvoc: OHRnox'], VOCR_NOxR_bins, labels=VOCR_NOxR_group_names)\n",
    "\n",
    "all_data_obs['NOxR_VOCR_group'] = pd.cut(all_data_obs['OHRnox: OHRvoc'], VOCR_NOxR_bins, labels=NOxR_VOCR_group_names)\n",
    "all_data_gc['NOxR_VOCR_group'] = pd.cut(all_data_gc['OHRnox: OHRvoc'], VOCR_NOxR_bins, labels=NOxR_VOCR_group_names)\n",
    "all_data_mcm_gcvoc['NOxR_VOCR_group'] = pd.cut(all_data_mcm_gcvoc['OHRnox: OHRvoc'], VOCR_NOxR_bins, labels=NOxR_VOCR_group_names)\n",
    "all_data_mcm_bbvoc['NOxR_VOCR_group'] = pd.cut(all_data_mcm_bbvoc['OHRnox: OHRvoc'], VOCR_NOxR_bins, labels=NOxR_VOCR_group_names)\n",
    "\n",
    "all_data_obs['CH2O_NO2_group']      = pd.cut(all_data_obs['CH2O: NO2'], CH2O_NO2_bins, labels=CH2O_NO2_group_names)\n",
    "all_data_gc['CH2O_NO2_group']      = pd.cut(all_data_gc['CH2O: NO2'], CH2O_NO2_bins, labels=CH2O_NO2_group_names)\n",
    "all_data_mcm_gcvoc['CH2O_NO2_group']      = pd.cut(all_data_mcm_gcvoc['CH2O: NO2'], CH2O_NO2_bins, labels=CH2O_NO2_group_names)\n",
    "all_data_mcm_bbvoc['CH2O_NO2_group']      = pd.cut(all_data_mcm_bbvoc['CH2O: NO2'], CH2O_NO2_bins, labels=CH2O_NO2_group_names)\n",
    "\n",
    "all_data_obs['VOCR_group']      = pd.cut(all_data_obs['VOCR'], VOCR_bins, labels=VOCR_group_names)\n",
    "all_data_gc['VOCR_group']      = pd.cut(all_data_gc['VOCR'], VOCR_bins, labels=VOCR_group_names)\n",
    "all_data_mcm_gcvoc['VOCR_group']      = pd.cut(all_data_mcm_gcvoc['VOCR'], VOCR_bins, labels=VOCR_group_names)\n",
    "all_data_mcm_bbvoc['VOCR_group']      = pd.cut(all_data_mcm_bbvoc['VOCR'], VOCR_bins, labels=VOCR_group_names)\n",
    "\n",
    "# Extra category for ozone and Ox\n",
    "all_data_obs['O3_category'] = all_data_obs['O3'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "all_data_gc['O3_category'] = all_data_gc['O3'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "all_data_mcm_gcvoc['O3_category'] = all_data_mcm_gcvoc['O3'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "all_data_mcm_bbvoc['O3_category'] = all_data_mcm_bbvoc['O3'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "\n",
    "all_data_obs['Ox_category'] = all_data_obs['Ox'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "all_data_gc['Ox_category'] = all_data_gc['Ox'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "all_data_mcm_gcvoc['Ox_category'] = all_data_mcm_gcvoc['Ox'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "all_data_mcm_bbvoc['Ox_category'] = all_data_mcm_bbvoc['Ox'].apply(lambda x: 'Above 70 ppb' if x > 70 else 'Below 70 ppb')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Make the flight_ID into others if not in Lagrangian flights\n",
    "# ============================================================\n",
    "all_data_obs_combined = all_data_obs.copy()\n",
    "all_data_obs_combined.loc[~all_data_obs_combined['Flight_ID'].isin(Lagrangian_flights), 'Flight_ID'] = 'Other WE-CAN flights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c0f1e-40f7-4b3d-9123-c45fd02902aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f0ab2-d0a8-4eb3-8aeb-488c2e716cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0b6118-f581-49d4-82ee-c792f74fe400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def photolysis_retriver(all_data, var_compound, var_jvalue, aggregation):\n",
    "    # Drop rows where either the compound or J-value is missing\n",
    "    temp_obs = all_data.dropna(subset=[var_compound, var_jvalue])\n",
    "    # Group by time bins and calculate statistical aggregations\n",
    "    #binned_obs_stat = temp_obs.groupby('time_bin').agg(['mean', 'std', 'median', iqr])\n",
    "    # only aggregate numeric columns\n",
    "    numeric_cols = temp_obs.select_dtypes(include=[np.number]).columns\n",
    "    binned_obs_stat = (\n",
    "        temp_obs[numeric_cols]\n",
    "        .groupby(temp_obs['time_bin'])\n",
    "        .agg(['mean', 'std', 'median', iqr])\n",
    "    )\n",
    "    # Calculate the photolysis rate\n",
    "    data_obs = binned_obs_stat[var_compound, aggregation].mul(binned_obs_stat[var_jvalue, aggregation].values, axis=0)\n",
    "\n",
    "    return data_obs, binned_obs_stat[var_jvalue, aggregation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067a2a55-7ef9-4a63-86e4-d08396dc1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def photolysis_retriver(all_data, var_compound, var_jvalue, aggregation, aggregation_err='std', return_error=False):\n",
    "    # Drop rows where either the compound or J-value is missing\n",
    "    temp_obs = all_data.dropna(subset=[var_compound, var_jvalue])\n",
    "\n",
    "    # Only aggregate numeric columns\n",
    "    numeric_cols = temp_obs.select_dtypes(include=[np.number]).columns\n",
    "    binned_obs_stat = (\n",
    "        temp_obs[numeric_cols]\n",
    "        .groupby(temp_obs['time_bin'])\n",
    "        .agg(['mean', 'std', 'median', iqr])\n",
    "    )\n",
    "\n",
    "    # Aggregates\n",
    "    C_agg  = binned_obs_stat[var_compound, aggregation]\n",
    "    J_agg  = binned_obs_stat[var_jvalue, aggregation]\n",
    "\n",
    "    # Photolysis rate\n",
    "    rate = C_agg.mul(J_agg.values, axis=0)\n",
    "\n",
    "    if not return_error:\n",
    "        # original behavior (2-tuple)\n",
    "        return rate, J_agg\n",
    "\n",
    "    # Uncertainties (default = std); iqr is also allowed since you already compute it\n",
    "    C_err = binned_obs_stat[var_compound, aggregation_err]\n",
    "    J_err = binned_obs_stat[var_jvalue, aggregation_err]\n",
    "\n",
    "    # Propagate uncertainty: sigma_rate = sqrt((J*sigma_C)^2 + (C*sigma_J)^2)\n",
    "    rate_err = np.sqrt((J_agg.values * C_err.values)**2 + (C_agg.values * J_err.values)**2)\n",
    "    rate_err = pd.Series(rate_err, index=rate.index, name='rate_err')\n",
    "\n",
    "    # return 3-tuple to keep backward compatibility\n",
    "    return rate, J_agg, rate_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42861f7-ed32-4c72-a66f-b8e7af151630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125eefd-9219-4b46-8bff-eb40190b078c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2954897-84f8-4a5f-867b-678a38faee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs_with_err(df, var_compound, var_jvalue,\n",
    "                     yield_factor=1.0,\n",
    "                     time_bin_col='time_bin',\n",
    "                     default_bin_hours=0.5):\n",
    "    \"\"\"\n",
    "    Compute the binned photolysis production rate (value) and its 1σ uncertainty (error)\n",
    "    for an observed compound and its corresponding photolysis frequency.\n",
    "\n",
    "    The photolysis production is defined as:\n",
    "        value = f * mean(C) * mean(J)\n",
    "        error = f * sqrt( (std(C)*mean(J))^2 + (mean(C)*std(J))^2 )\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input data containing at least the compound concentration and J-value columns.\n",
    "        Must also include either `time_bin_col` (default: 'time_bin') or 'Plume_Age'.\n",
    "    var_compound : str\n",
    "        Column name for the observed concentration (e.g., 'HONO', 'CH2O').\n",
    "    var_jvalue : str\n",
    "        Column name for the corresponding photolysis frequency (e.g., 'JHNO2_OH_NO').\n",
    "    yield_factor : float, optional\n",
    "        Scalar multiplier applied to BOTH the value and error (default = 1.0).\n",
    "        Use this to account for stoichiometric yield (e.g., 2.0 for CH2O photolysis).\n",
    "    time_bin_col : str, optional\n",
    "        Name of the column to group data into time bins (default = 'time_bin').\n",
    "    default_bin_hours : float, optional\n",
    "        Width of each time bin in hours if auto-binning from 'Plume_Age' (default = 0.5).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    val : pandas.Series\n",
    "        Mean photolysis production per time bin, scaled by `yield_factor`.\n",
    "    err : pandas.Series\n",
    "        Corresponding 1σ uncertainty, also scaled by `yield_factor`.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create a working copy to avoid modifying the original DataFrame\n",
    "    d = df.copy()\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Ensure a valid binning column exists:\n",
    "    #   1. If time_bin_col exists, use it directly.\n",
    "    #   2. If not, create bins based on 'Plume_Age' using `default_bin_hours`.\n",
    "    # ----------------------------------------------------------------------\n",
    "    if time_bin_col not in d.columns:\n",
    "        if 'Plume_Age' not in d.columns:\n",
    "            raise ValueError(f\"Need '{time_bin_col}' or 'Plume_Age' in the input DataFrame.\")\n",
    "\n",
    "        # Determine bin edges up to the maximum plume age\n",
    "        max_age = np.nanmax(d['Plume_Age'].values)\n",
    "        edges = np.arange(0, max_age + default_bin_hours, default_bin_hours)\n",
    "\n",
    "        # Guard against degenerate cases (e.g., very short time span)\n",
    "        if len(edges) < 2:\n",
    "            edges = np.array([0, default_bin_hours])\n",
    "\n",
    "        # Create categorical bins labeled by bin midpoints (for easy plotting)\n",
    "        d[time_bin_col] = pd.cut(\n",
    "            d['Plume_Age'],\n",
    "            bins=edges,\n",
    "            labels=edges[:-1] + default_bin_hours,\n",
    "            right=False\n",
    "        )\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Drop rows where either the compound or J-value is missing.\n",
    "    # ----------------------------------------------------------------------\n",
    "    d = d.dropna(subset=[var_compound, var_jvalue])\n",
    "    if d.empty:\n",
    "        # Return empty Series with correct names and float dtype\n",
    "        return (pd.Series(dtype=float, name=var_compound),\n",
    "                pd.Series(dtype=float, name=var_compound + \"_err\"))\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Compute mean and standard deviation of each variable within each bin.\n",
    "    # The result is a MultiIndex DataFrame with ('mean', 'std') subcolumns.\n",
    "    # ----------------------------------------------------------------------\n",
    "    g = d.groupby(time_bin_col)[[var_compound, var_jvalue]].agg(['mean', 'std'])\n",
    "\n",
    "    # Extract each component for readability\n",
    "    c_mean = g[(var_compound, 'mean')]\n",
    "    c_std  = g[(var_compound, 'std')].fillna(0.0)  # handle single-point bins\n",
    "    j_mean = g[(var_jvalue, 'mean')]\n",
    "    j_std  = g[(var_jvalue, 'std')].fillna(0.0)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Apply the photolysis rate formula and propagate uncertainties.\n",
    "    # ----------------------------------------------------------------------\n",
    "    val = yield_factor * (c_mean * j_mean)\n",
    "    err = yield_factor * np.sqrt((c_std * j_mean)**2 + (c_mean * j_std)**2)\n",
    "\n",
    "    # Name the Series for easier merging or plotting later\n",
    "    val.name = var_compound\n",
    "    err.name = var_compound + \"_err\"\n",
    "\n",
    "    return val, err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dccce43f-f1b4-430c-bc50-12dbce918e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Observed photlysis rates\n",
    "# ------------------------\n",
    "sure_values_HONO = [31.64, 39.45, 56.49, 59.01, 88.39, 146.91, 236.04, 280.05] # RF06, RF09, RF10, 13\n",
    "not_sure_HONO = [110.64, 122.98] # RF02\n",
    "all_data_obs.loc[all_data_obs['Plume_Age'].isin(sure_values_HONO), 'HONO'] = np.nan\n",
    "all_data_obs.loc[all_data_obs['Plume_Age'].isin(not_sure_HONO), 'HONO'] = np.nan\n",
    "\n",
    "all_data_obs.loc[all_data_obs['Plume_Age'].isin(sure_values_HONO), 'NEMR_HONO'] = np.nan\n",
    "all_data_obs.loc[all_data_obs['Plume_Age'].isin(not_sure_HONO), 'NEMR_HONO'] = np.nan\n",
    "\n",
    "\n",
    "# Create bin edges for every X minutes\n",
    "#interval_X = 30\n",
    "interval_X = 0.5\n",
    "bin_edges_obs = np.arange(0, all_data_obs['Plume_Age'].max() + interval_X, interval_X)\n",
    "#aggregation, aggregation_err = 'median', iqr\n",
    "aggregation, aggregation_err = 'mean', 'std'\n",
    "# Use the `cut` function to bin the data  \n",
    "all_data_obs['time_bin']       = pd.cut(all_data_obs['Plume_Age'], bins=bin_edges_obs, labels=bin_edges_obs[:-1] + interval_X, right=False)\n",
    "\n",
    "# use the function to get the observed photlyiss rates\n",
    "#data_obs_hno2    = photolysis_retriver(all_data_obs, var_compound='HONO', var_jvalue='JHNO2_OH_NO', aggregation = aggregation)[0]\n",
    "#data_obs_o3      = 0.5 * photolysis_retriver(all_data_obs, var_compound='O3', var_jvalue='JO3_O2_O1D', aggregation = aggregation)[0]\n",
    "#data_obs_ch2o    = 2 * photolysis_retriver(all_data_obs, var_compound='CH2O', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0]\n",
    "#data_obs_ald2    = 2 * photolysis_retriver(all_data_obs, var_compound='ALD2', var_jvalue='JCH3CHO_CH3_HCO', aggregation = aggregation)[0]\n",
    "#data_obs_glyx    = 2 * photolysis_retriver(all_data_obs, var_compound='GLYX', var_jvalue='JCHOCHO_HCO_HCO', aggregation = aggregation)[0]\n",
    "#data_obs_mgly    = 1.3 * photolysis_retriver(all_data_obs, var_compound='MGLY', var_jvalue='JCH3COCHO_CH3CO_HCO', aggregation = aggregation)[0]\n",
    "#data_obs_biacet  = 0.6 * photolysis_retriver(all_data_obs, var_compound='BIACET', var_jvalue='J23Butanedione_Products', aggregation = aggregation)[0]\n",
    "\n",
    "#data_obs_propanal = 2 * photolysis_retriver(all_data_obs, var_compound='Propanal', var_jvalue='JPropanal_C2H5_HCO', aggregation = aggregation)[0]\n",
    "#data_obs_butanal  = 2 * photolysis_retriver(all_data_obs, var_compound='Butanal', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0]*1.094\n",
    "\n",
    "#data_obs_acet   = 1.3 * photolysis_retriver(all_data_obs, var_compound='ACET', var_jvalue='JAcetone_CH3CO_CH3', aggregation = aggregation)[0]\n",
    "#data_obs_mek    = 1.3 * photolysis_retriver(all_data_obs, var_compound='MEK', var_jvalue='JMEK_CH3CO_CH2CH3', aggregation = aggregation)[0]\n",
    "#data_obs_acr    = 0.39 * photolysis_retriver(all_data_obs, var_compound='ACR', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.03\n",
    "#data_obs_macr   = 1.51 * photolysis_retriver(all_data_obs, var_compound='MACR', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.061\n",
    "#data_obs_mvk    = 1.3 * photolysis_retriver(all_data_obs, var_compound='MVK', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.066\n",
    "#data_obs_glyc   = 2 * photolysis_retriver(all_data_obs, var_compound='GLYC', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.346\n",
    "#data_obs_hac    = 2 * photolysis_retriver(all_data_obs, var_compound='HAC', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.346  # Assuming 'HAC' is the correct variable name\n",
    "#data_obs_furfural= 1.3 * photolysis_retriver(all_data_obs, var_compound='Furfural', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.056\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Observed photolysis rates + errors (ppt s^-1)\n",
    "# ---------------------------------------------\n",
    "data_obs_hno2,    err_obs_hno2    = get_obs_with_err(all_data_obs, 'HONO',   'JHNO2_OH_NO',          1.0)\n",
    "data_obs_o3,      err_obs_o3      = get_obs_with_err(all_data_obs, 'O3',     'JO3_O2_O1D',           0.5)\n",
    "data_obs_ch2o,    err_obs_ch2o    = get_obs_with_err(all_data_obs, 'CH2O',   'JCH2O_H_HCO',          2.0)\n",
    "data_obs_ald2,    err_obs_ald2    = get_obs_with_err(all_data_obs, 'ALD2',   'JCH3CHO_CH3_HCO',      2.0)\n",
    "data_obs_glyx,    err_obs_glyx    = get_obs_with_err(all_data_obs, 'GLYX',   'JCHOCHO_HCO_HCO',      2.0)\n",
    "data_obs_mgly,    err_obs_mgly    = get_obs_with_err(all_data_obs, 'MGLY',   'JCH3COCHO_CH3CO_HCO',  1.3)\n",
    "data_obs_biacet,  err_obs_biacet  = get_obs_with_err(all_data_obs, 'BIACET', 'J23Butanedione_Products', 0.6)\n",
    "\n",
    "# Aldehydes/ketones with extra factors\n",
    "data_obs_propanal, err_obs_propanal = get_obs_with_err(all_data_obs, 'Propanal', 'JPropanal_C2H5_HCO', 2.0)\n",
    "# For Butanal you used \"*2\" then \"*1.094\" — combine to a single factor for value and error\n",
    "data_obs_butanal,  err_obs_butanal  = get_obs_with_err(all_data_obs, 'Butanal',  'JCH2O_H_HCO',        2.0 * 1.094)\n",
    "\n",
    "data_obs_acet,   err_obs_acet   = get_obs_with_err(all_data_obs, 'ACET', 'JAcetone_CH3CO_CH3', 1.3)\n",
    "data_obs_mek,    err_obs_mek    = get_obs_with_err(all_data_obs, 'MEK',  'JMEK_CH3CO_CH2CH3',  1.3)\n",
    "\n",
    "# For ACR, MACR, MVK, GLYC, HAC, Furfural you had two multiplicative factors; multiply them together and apply to both value & error\n",
    "data_obs_acr,    err_obs_acr    = get_obs_with_err(all_data_obs, 'ACR',      'JCH2O_H_HCO', 0.39 * 0.03)\n",
    "data_obs_macr,   err_obs_macr   = get_obs_with_err(all_data_obs, 'MACR',     'JCH2O_H_HCO', 1.51 * 0.061)\n",
    "data_obs_mvk,    err_obs_mvk    = get_obs_with_err(all_data_obs, 'MVK',      'JCH2O_H_HCO', 1.30 * 0.066)\n",
    "data_obs_glyc,   err_obs_glyc   = get_obs_with_err(all_data_obs, 'GLYC',     'JCH2O_H_HCO', 2.00 * 0.346)\n",
    "data_obs_hac,    err_obs_hac    = get_obs_with_err(all_data_obs, 'HAC',      'JCH2O_H_HCO', 2.00 * 0.346)\n",
    "data_obs_furfural, err_obs_furfural = get_obs_with_err(all_data_obs, 'Furfural','JCH2O_H_HCO', 1.30 * 0.056)\n",
    "\n",
    "\n",
    "# -----------------------------------------------=\n",
    "# Combine the mean values into a single DataFrame\n",
    "# ------------------------------------------------\n",
    "# Observation\n",
    "combined_df_obs = pd.DataFrame({\n",
    "    'HONO': data_obs_hno2,\n",
    "    'Ozone': data_obs_o3,\n",
    "    'Formaldehyde': data_obs_ch2o,\n",
    "    'Acetaldehyde': data_obs_ald2,\n",
    "    'Glyoxal': data_obs_glyx,\n",
    "    'Methylglyoxal': data_obs_mgly,\n",
    "    '2,3-Butanedione': data_obs_biacet,\n",
    "    #'Propanal': data_obs_propanal,\n",
    "    #'Butanal': data_obs_butanal,\n",
    "    #'Acetone': data_obs_acet,\n",
    "    #'MEK': data_obs_mek,\n",
    "    #'Acrolein': data_obs_acr,\n",
    "    #'Methylacrolein': data_obs_macr,\n",
    "    #'MVK': data_obs_mvk,\n",
    "    'Glycolaldehyde': data_obs_glyc,\n",
    "    #'Hydroxacetone': data_obs_hac,\n",
    "    #'Furfural': data_obs_furfural,\n",
    "})*1000\n",
    "\n",
    "# Corresponding 1σ errors (same units)\n",
    "combined_df_obs_err = pd.DataFrame({\n",
    "    'HONO':              err_obs_hno2,\n",
    "    'Ozone':             err_obs_o3,\n",
    "    'Formaldehyde':      err_obs_ch2o,\n",
    "    'Acetaldehyde':      err_obs_ald2,\n",
    "    'Glyoxal':           err_obs_glyx,\n",
    "    'Methylglyoxal':     err_obs_mgly,\n",
    "    '2,3-Butanedione':   err_obs_biacet,\n",
    "    # 'Propanal':          err_obs_propanal,\n",
    "    # 'Butanal':           err_obs_butanal,\n",
    "    # 'Acetone':           err_obs_acet,\n",
    "    # 'MEK':               err_obs_mek,\n",
    "    # 'Acrolein':          err_obs_acr,\n",
    "    # 'Methylacrolein':    err_obs_macr,\n",
    "    # 'MVK':               err_obs_mvk,\n",
    "    'Glycolaldehyde':    err_obs_glyc,\n",
    "    # 'Hydroxacetone':     err_obs_hac,\n",
    "    # 'Furfural':          err_obs_furfural,\n",
    "}) * 1000\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Modeled photolyisis\n",
    "# -------------------\n",
    "# Only select Lagrangian\n",
    "all_data_obs_lagrangian  = all_data_obs[all_data_obs['Flight_ID'].isin(Lagrangian_flights)]\n",
    "\n",
    "# Create bin edges\n",
    "bin_edges_obs_lagrangian = np.arange(0, all_data_obs_lagrangian['Plume_Age'].max() + interval_X, interval_X)\n",
    "bin_edges_gc             = np.arange(0, all_data_gc['Plume_Age'].max() + interval_X, interval_X)\n",
    "bin_edges_mcm_gcvoc      = np.arange(0, all_data_mcm_gcvoc['Plume_Age'].max() + interval_X, interval_X) # should be the same as gc\n",
    "bin_edges_mcm_bbvoc      = np.arange(0, all_data_mcm_bbvoc['Plume_Age'].max() + interval_X, interval_X)\n",
    "\n",
    "# Use the `cut` function to bin the data  \n",
    "all_data_obs_lagrangian['time_bin']  = pd.cut(all_data_obs_lagrangian['Plume_Age'], bins=bin_edges_obs_lagrangian, \n",
    "                                                labels=bin_edges_obs_lagrangian[:-1] + interval_X, right=False)\n",
    "all_data_gc['time_bin']              = pd.cut(all_data_gc['Plume_Age'], bins=bin_edges_gc, labels=bin_edges_gc[:-1] + interval_X, right=False)\n",
    "all_data_mcm_gcvoc['time_bin']       = pd.cut(all_data_mcm_gcvoc['Plume_Age'], bins=bin_edges_mcm_gcvoc, labels=bin_edges_mcm_gcvoc[:-1] + interval_X, right=False)\n",
    "all_data_mcm_bbvoc['time_bin']       = pd.cut(all_data_mcm_bbvoc['Plume_Age'], bins=bin_edges_mcm_bbvoc, labels=bin_edges_mcm_bbvoc[:-1] + interval_X, right=False)\n",
    "\n",
    "# Binned model concentrations\n",
    "# only aggregate numeric cols\n",
    "numeric_gc = all_data_gc.select_dtypes(include=[np.number]).columns\n",
    "binned_mod_gc = (\n",
    "    all_data_gc[numeric_gc]\n",
    "    .groupby(all_data_gc['time_bin'])\n",
    "    .agg(['mean', 'std', 'median', iqr])\n",
    ")\n",
    "\n",
    "numeric_gcvoc = all_data_mcm_gcvoc.select_dtypes(include=[np.number]).columns\n",
    "binned_mod_mcm_gcvoc = (\n",
    "    all_data_mcm_gcvoc[numeric_gcvoc]\n",
    "    .groupby(all_data_mcm_gcvoc['time_bin'])\n",
    "    .agg(['mean', 'std', 'median', iqr])\n",
    ")\n",
    "\n",
    "numeric_bbvoc = all_data_mcm_bbvoc.select_dtypes(include=[np.number]).columns\n",
    "binned_mod_mcm_bbvoc = (\n",
    "    all_data_mcm_bbvoc[numeric_bbvoc]\n",
    "    .groupby(all_data_mcm_bbvoc['time_bin'])\n",
    "    .agg(['mean', 'std', 'median', iqr])\n",
    ")\n",
    "\n",
    "\n",
    "# Binned J values for model\n",
    "J_hno2_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='HONO', var_jvalue='JHNO2_OH_NO', aggregation = aggregation)[1]\n",
    "J_o3_lagrangian      = photolysis_retriver(all_data_obs_lagrangian, var_compound='O3', var_jvalue='JO3_O2_O1D', aggregation = aggregation)[1]\n",
    "J_ch2o_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='CH2O', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1]\n",
    "J_ald2_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='ALD2', var_jvalue='JCH3CHO_CH3_HCO', aggregation = aggregation)[1]\n",
    "J_glyx_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='GLYX', var_jvalue='JCHOCHO_HCO_HCO', aggregation = aggregation)[1]\n",
    "J_mgly_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='MGLY', var_jvalue='JCH3COCHO_CH3CO_HCO', aggregation = aggregation)[1]\n",
    "J_biacet_lagrangian  = photolysis_retriver(all_data_obs_lagrangian, var_compound='BIACET', var_jvalue='J23Butanedione_Products', aggregation = aggregation)[1]\n",
    "\n",
    "J_propanal_lagrangian = photolysis_retriver(all_data_obs_lagrangian, var_compound='Propanal', var_jvalue='JPropanal_C2H5_HCO', aggregation = aggregation)[1]\n",
    "J_butanal_lagrangian  = photolysis_retriver(all_data_obs_lagrangian, var_compound='Butanal', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1]*1.094\n",
    "\n",
    "J_acet_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='ACET', var_jvalue='JAcetone_CH3CO_CH3', aggregation = aggregation)[1]\n",
    "J_mek_lagrangian     = photolysis_retriver(all_data_obs_lagrangian, var_compound='MEK', var_jvalue='JMEK_CH3CO_CH2CH3', aggregation = aggregation)[1]\n",
    "J_acr_lagrangian     = photolysis_retriver(all_data_obs_lagrangian, var_compound='ACR', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1] * 0.03\n",
    "J_macr_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='MACR', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1] * 0.061\n",
    "J_mvk_lagrangian     = photolysis_retriver(all_data_obs_lagrangian, var_compound='MVK', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1] * 0.066\n",
    "J_glyc_lagrangian    = photolysis_retriver(all_data_obs_lagrangian, var_compound='GLYC', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1] * 0.346\n",
    "J_hac_lagrangian     = photolysis_retriver(all_data_obs_lagrangian, var_compound='HAC', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1] * 0.346  # Assuming 'HAC' is the correct variable name\n",
    "J_furfural_lagrangian= photolysis_retriver(all_data_obs_lagrangian, var_compound='Furfural', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[1] * 0.056\n",
    "\n",
    "\n",
    "# Calculate the photolysis rate (yield * concentration * photolysis)\n",
    "# Observation\n",
    "data_obs_lagrangian_hno2    = photolysis_retriver(all_data_obs_lagrangian, var_compound='HONO', var_jvalue='JHNO2_OH_NO', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_o3      = 0.5 * photolysis_retriver(all_data_obs_lagrangian, var_compound='O3', var_jvalue='JO3_O2_O1D', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_ch2o    = 2 * photolysis_retriver(all_data_obs_lagrangian, var_compound='CH2O', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_ald2    = 2 * photolysis_retriver(all_data_obs_lagrangian, var_compound='ALD2', var_jvalue='JCH3CHO_CH3_HCO', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_glyx    = 2 * photolysis_retriver(all_data_obs_lagrangian, var_compound='GLYX', var_jvalue='JCHOCHO_HCO_HCO', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_mgly    = 1.3 * photolysis_retriver(all_data_obs_lagrangian, var_compound='MGLY', var_jvalue='JCH3COCHO_CH3CO_HCO', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_biacet  = 0.6 * photolysis_retriver(all_data_obs_lagrangian, var_compound='BIACET', var_jvalue='J23Butanedione_Products', aggregation = aggregation)[0]\n",
    "\n",
    "data_obs_lagrangian_propanal = 2 * photolysis_retriver(all_data_obs_lagrangian, var_compound='Propanal', var_jvalue='JPropanal_C2H5_HCO', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_butanal  = 2 * photolysis_retriver(all_data_obs_lagrangian, var_compound='Butanal', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0]*1.094\n",
    "\n",
    "data_obs_lagrangian_acet    = 1.3 * photolysis_retriver(all_data_obs_lagrangian, var_compound='ACET', var_jvalue='JAcetone_CH3CO_CH3', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_mek     = 1.3 * photolysis_retriver(all_data_obs_lagrangian, var_compound='MEK', var_jvalue='JMEK_CH3CO_CH2CH3', aggregation = aggregation)[0]\n",
    "data_obs_lagrangian_acr     = 0.39 * photolysis_retriver(all_data_obs_lagrangian, var_compound='ACR', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.03\n",
    "data_obs_lagrangian_macr    = 1.51 * photolysis_retriver(all_data_obs_lagrangian, var_compound='MACR', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.061\n",
    "data_obs_lagrangian_mvk     = 1.3 * photolysis_retriver(all_data_obs_lagrangian, var_compound='MVK', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.066\n",
    "data_obs_lagrangian_glyc    = 2 * photolysis_retriver(all_data_obs_lagrangian, var_compound='GLYC', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.346\n",
    "data_obs_lagrangian_hac     = 2 * photolysis_retriver(all_data_obs_lagrangian, var_compound='HAC', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.346  # Assuming 'HAC' is the correct variable name\n",
    "data_obs_lagrangian_furfural= 1.3 * photolysis_retriver(all_data_obs_lagrangian, var_compound='Furfural', var_jvalue='JCH2O_H_HCO', aggregation = aggregation)[0] * 0.056\n",
    "\n",
    "# GEOS-Chem\n",
    "data_mod_gc_hno2     = binned_mod_gc['HONO', aggregation]*J_hno2_lagrangian\n",
    "data_mod_gc_o3       = 0.5*binned_mod_gc['O3', aggregation]*J_o3_lagrangian\n",
    "data_mod_gc_ch2o     = 2*binned_mod_gc['CH2O', aggregation]*J_ch2o_lagrangian\n",
    "data_mod_gc_ald2     = 2*binned_mod_gc['ALD2', aggregation]*J_ald2_lagrangian\n",
    "data_mod_gc_glyx     = 2*binned_mod_gc['GLYX', aggregation]*J_glyx_lagrangian\n",
    "data_mod_gc_mgly     = 1.3*binned_mod_gc['MGLY', aggregation]*J_mgly_lagrangian\n",
    "data_mod_gc_biacet   = 0.6*binned_mod_gc['BIACET', aggregation]*J_biacet_lagrangian\n",
    "\n",
    "data_mod_gc_propanal = 2*binned_mod_gc['Propanal', aggregation]*J_propanal_lagrangian\n",
    "data_mod_gc_butanal  = 2*binned_mod_gc['Butanal', aggregation]*J_butanal_lagrangian\n",
    "\n",
    "data_mod_gc_acet     = 1.3*binned_mod_gc['ACET', aggregation]*J_acet_lagrangian\n",
    "data_mod_gc_mek      = 1.3*binned_mod_gc['MEK', aggregation]*J_mek_lagrangian\n",
    "data_mod_gc_acr      = 0.39*binned_mod_gc['ACR', aggregation]*J_acr_lagrangian\n",
    "data_mod_gc_macr     = 1.51*binned_mod_gc['MACR', aggregation]*J_macr_lagrangian\n",
    "data_mod_gc_mvk      = 1.3*binned_mod_gc['MVK', aggregation]*J_mvk_lagrangian\n",
    "data_mod_gc_glyc     = 2*binned_mod_gc['GLYC', aggregation]*J_glyc_lagrangian\n",
    "data_mod_gc_hac      = 2*binned_mod_gc['HAC', aggregation]*J_hac_lagrangian\n",
    "\n",
    "data_mod_gc_furfural = 1.3*binned_mod_gc['Furfural', aggregation]*J_furfural_lagrangian\n",
    "\n",
    "# MCM + BBVOC\n",
    "data_mod_mcm_bbvoc_hno2     = binned_mod_mcm_bbvoc['HONO', aggregation]*J_hno2_lagrangian\n",
    "data_mod_mcm_bbvoc_o3       = 0.5*binned_mod_mcm_bbvoc['O3', aggregation]*J_o3_lagrangian\n",
    "data_mod_mcm_bbvoc_ch2o     = 2*binned_mod_mcm_bbvoc['CH2O', aggregation]*J_ch2o_lagrangian\n",
    "data_mod_mcm_bbvoc_ald2     = 2*binned_mod_mcm_bbvoc['ALD2', aggregation]*J_ald2_lagrangian\n",
    "data_mod_mcm_bbvoc_glyx     = 2*binned_mod_mcm_bbvoc['GLYX', aggregation]*J_glyx_lagrangian\n",
    "data_mod_mcm_bbvoc_mgly     = 1.3*binned_mod_mcm_bbvoc['MGLY', aggregation]*J_mgly_lagrangian\n",
    "data_mod_mcm_bbvoc_biacet   = 0.6*binned_mod_mcm_bbvoc['BIACET', aggregation]*J_biacet_lagrangian\n",
    "\n",
    "data_mod_mcm_bbvoc_propanal = 2*binned_mod_mcm_bbvoc['Propanal', aggregation]*J_propanal_lagrangian\n",
    "data_mod_mcm_bbvoc_butanal  = 2*binned_mod_mcm_bbvoc['Butanal', aggregation]*J_butanal_lagrangian\n",
    "\n",
    "data_mod_mcm_bbvoc_acet     = 1.3*binned_mod_mcm_bbvoc['ACET', aggregation]*J_acet_lagrangian\n",
    "data_mod_mcm_bbvoc_mek      = 1.3*binned_mod_mcm_bbvoc['MEK', aggregation]*J_mek_lagrangian\n",
    "data_mod_mcm_bbvoc_acr      = 0.39*binned_mod_mcm_bbvoc['ACR', aggregation]*J_acr_lagrangian\n",
    "data_mod_mcm_bbvoc_macr     = 1.51*binned_mod_mcm_bbvoc['MACR', aggregation]*J_macr_lagrangian\n",
    "data_mod_mcm_bbvoc_mvk      = 1.3*binned_mod_mcm_bbvoc['MVK', aggregation]*J_mvk_lagrangian\n",
    "data_mod_mcm_bbvoc_glyc     = 2*binned_mod_mcm_bbvoc['GLYC', aggregation]*J_glyc_lagrangian\n",
    "data_mod_mcm_bbvoc_hac      = 2*binned_mod_mcm_bbvoc['HAC', aggregation]*J_hac_lagrangian\n",
    "\n",
    "data_mod_mcm_bbvoc_furfural = 1.3*binned_mod_mcm_bbvoc['Furfural', aggregation]*J_furfural_lagrangian\n",
    "# MCM + GCVOC\n",
    "data_mod_mcm_gcvoc_hno2     = binned_mod_mcm_gcvoc['HONO', aggregation]*J_hno2_lagrangian\n",
    "data_mod_mcm_gcvoc_o3       = 0.5*binned_mod_mcm_gcvoc['O3', aggregation]*J_o3_lagrangian\n",
    "data_mod_mcm_gcvoc_ch2o     = 2*binned_mod_mcm_gcvoc['CH2O', aggregation]*J_ch2o_lagrangian\n",
    "data_mod_mcm_gcvoc_ald2     = 2*binned_mod_mcm_gcvoc['ALD2', aggregation]*J_ald2_lagrangian\n",
    "data_mod_mcm_gcvoc_glyx     = 2*binned_mod_mcm_gcvoc['GLYX', aggregation]*J_glyx_lagrangian\n",
    "data_mod_mcm_gcvoc_mgly     = 1.3*binned_mod_mcm_gcvoc['MGLY', aggregation]*J_mgly_lagrangian\n",
    "data_mod_mcm_gcvoc_biacet   = 0.6*binned_mod_mcm_gcvoc['BIACET', aggregation]*J_biacet_lagrangian\n",
    "\n",
    "data_mod_mcm_gcvoc_propanal = 2*binned_mod_mcm_gcvoc['Propanal', aggregation]*J_propanal_lagrangian\n",
    "data_mod_mcm_gcvoc_butanal  = 2*binned_mod_mcm_gcvoc['Butanal', aggregation]*J_butanal_lagrangian\n",
    "\n",
    "data_mod_mcm_gcvoc_acet     = 1.3*binned_mod_mcm_gcvoc['ACET', aggregation]*J_acet_lagrangian\n",
    "data_mod_mcm_gcvoc_mek      = 1.3*binned_mod_mcm_gcvoc['MEK', aggregation]*J_mek_lagrangian\n",
    "data_mod_mcm_gcvoc_acr      = 0.39*binned_mod_mcm_gcvoc['ACR', aggregation]*J_acr_lagrangian\n",
    "data_mod_mcm_gcvoc_macr     = 1.51*binned_mod_mcm_gcvoc['MACR', aggregation]*J_macr_lagrangian\n",
    "data_mod_mcm_gcvoc_mvk      = 1.3*binned_mod_mcm_gcvoc['MVK', aggregation]*J_mvk_lagrangian\n",
    "data_mod_mcm_gcvoc_glyc     = 2*binned_mod_mcm_gcvoc['GLYC', aggregation]*J_glyc_lagrangian\n",
    "data_mod_mcm_gcvoc_hac      = 2*binned_mod_mcm_gcvoc['HAC', aggregation]*J_hac_lagrangian\n",
    "\n",
    "data_mod_mcm_gcvoc_furfural = 1.3*binned_mod_mcm_gcvoc['Furfural', aggregation]*J_furfural_lagrangian\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Combine the mean values into a single DataFrame\n",
    "# ------------------------------------------------\n",
    "# Observation for Lagrangian flights\n",
    "combined_df_obs_lagrangian = pd.DataFrame({\n",
    "        'HONO': data_obs_lagrangian_hno2,\n",
    "        'Ozone': data_obs_lagrangian_o3,\n",
    "        'Formaldehyde': data_obs_lagrangian_ch2o,\n",
    "        'Acetaldehyde': data_obs_lagrangian_ald2,\n",
    "        'Glyoxal': data_obs_lagrangian_glyx,\n",
    "        'Methylglyoxal': data_obs_lagrangian_mgly,\n",
    "        '2,3-Butanedione': data_obs_lagrangian_biacet,\n",
    "        'Glycolaldehyde': data_obs_lagrangian_glyc,\n",
    "})*1000\n",
    "\n",
    "# GEOS-Chem\n",
    "combined_df_mod_gc = pd.DataFrame({\n",
    "    'HONO': data_mod_gc_hno2,\n",
    "    'Ozone': data_mod_gc_o3,\n",
    "    'Formaldehyde': data_mod_gc_ch2o,\n",
    "    'Acetaldehyde': data_mod_gc_ald2,\n",
    "    'Glyoxal': data_mod_gc_glyx,\n",
    "    'Methylglyoxal': data_mod_gc_mgly,\n",
    "    '2,3-Butanedione': data_mod_gc_biacet,\n",
    "    'Glycolaldehyde': data_mod_gc_glyc,\n",
    "})*1000\n",
    "\n",
    "# MCM + BBVOC\n",
    "combined_df_mod_mcm_bbvoc = pd.DataFrame({\n",
    "    'HONO': data_mod_mcm_bbvoc_hno2,\n",
    "    'Ozone': data_mod_mcm_bbvoc_o3,\n",
    "    'Formaldehyde': data_mod_mcm_bbvoc_ch2o,\n",
    "    'Acetaldehyde': data_mod_mcm_bbvoc_ald2,\n",
    "    'Glyoxal': data_mod_mcm_bbvoc_glyx,\n",
    "    'Methylglyoxal': data_mod_mcm_bbvoc_mgly,\n",
    "    '2,3-Butanedione': data_mod_mcm_bbvoc_biacet,\n",
    "    'Glycolaldehyde': data_mod_mcm_bbvoc_glyc,\n",
    "})*1000\n",
    "# MCM + GCVOC\n",
    "combined_df_mod_mcm_gcvoc = pd.DataFrame({\n",
    "    'HONO': data_mod_mcm_gcvoc_hno2,\n",
    "    'Ozone': data_mod_mcm_gcvoc_o3,\n",
    "    'Formaldehyde': data_mod_mcm_gcvoc_ch2o,\n",
    "    'Acetaldehyde': data_mod_mcm_gcvoc_ald2,\n",
    "    'Glyoxal': data_mod_mcm_gcvoc_glyx,\n",
    "    'Methylglyoxal': data_mod_mcm_gcvoc_mgly,\n",
    "    '2,3-Butanedione': data_mod_mcm_gcvoc_biacet,\n",
    "    'Glycolaldehyde': data_mod_mcm_gcvoc_glyc,\n",
    "})*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d255725-0a46-43a0-846a-8078fb3a0023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbf58bb-e557-4362-a346-ce8d9ca488de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Per-flight observed photolysis rates + 1σ errors (ppt s^-1)\n",
    "# Mirrors your main get_obs_with_err → combined_df_obs flow\n",
    "# ============================================================\n",
    "\n",
    "def build_obs_block_with_err(all_data_subset):\n",
    "    # Core contributors (match your main combined_df keys & yields)\n",
    "    data_obs_hno2,    err_obs_hno2    = get_obs_with_err(all_data_subset, 'HONO',   'JHNO2_OH_NO',              1.0)\n",
    "    data_obs_o3,      err_obs_o3      = get_obs_with_err(all_data_subset, 'O3',     'JO3_O2_O1D',               0.5)\n",
    "    data_obs_ch2o,    err_obs_ch2o    = get_obs_with_err(all_data_subset, 'CH2O',   'JCH2O_H_HCO',              2.0)\n",
    "    data_obs_ald2,    err_obs_ald2    = get_obs_with_err(all_data_subset, 'ALD2',   'JCH3CHO_CH3_HCO',          2.0)\n",
    "    data_obs_glyx,    err_obs_glyx    = get_obs_with_err(all_data_subset, 'GLYX',   'JCHOCHO_HCO_HCO',          2.0)\n",
    "    data_obs_mgly,    err_obs_mgly    = get_obs_with_err(all_data_subset, 'MGLY',   'JCH3COCHO_CH3CO_HCO',      1.3)\n",
    "    data_obs_biacet,  err_obs_biacet  = get_obs_with_err(all_data_subset, 'BIACET', 'J23Butanedione_Products',  0.6)\n",
    "    data_obs_glyc,    err_obs_glyc    = get_obs_with_err(all_data_subset, 'GLYC',   'JCH2O_H_HCO',              2.0 * 0.346)\n",
    "\n",
    "    # Assemble (×1000 to ppt s^-1), keep exact keys as your main block (incl. \"Formaldehyde\")\n",
    "    df_mean = pd.DataFrame({\n",
    "        'HONO':              data_obs_hno2,\n",
    "        'Ozone':             data_obs_o3,\n",
    "        'Formaldehyde':      data_obs_ch2o,      # keep your original key\n",
    "        'Acetaldehyde':      data_obs_ald2,\n",
    "        'Glyoxal':           data_obs_glyx,\n",
    "        'Methylglyoxal':     data_obs_mgly,\n",
    "        '2,3-Butanedione':   data_obs_biacet,\n",
    "        'Glycolaldehyde':    data_obs_glyc,\n",
    "    }) * 1000\n",
    "\n",
    "    df_err = pd.DataFrame({\n",
    "        'HONO':              err_obs_hno2,\n",
    "        'Ozone':             err_obs_o3,\n",
    "        'Formaldehyde':      err_obs_ch2o,\n",
    "        'Acetaldehyde':      err_obs_ald2,\n",
    "        'Glyoxal':           err_obs_glyx,\n",
    "        'Methylglyoxal':     err_obs_mgly,\n",
    "        '2,3-Butanedione':   err_obs_biacet,\n",
    "        'Glycolaldehyde':    err_obs_glyc,\n",
    "    }) * 1000\n",
    "\n",
    "    return df_mean, df_err\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Build per-flight RF03/07/09\n",
    "# (assumes all_data_obs['time_bin'] already exists)\n",
    "# -----------------------------\n",
    "all_data_obs_rf03 = all_data_obs[all_data_obs['Flight_ID'] == 'RF03'].copy()\n",
    "all_data_obs_rf07 = all_data_obs[all_data_obs['Flight_ID'] == 'RF07'].copy()\n",
    "all_data_obs_rf09 = all_data_obs[all_data_obs['Flight_ID'] == 'RF09'].copy()\n",
    "\n",
    "combined_df_obs_rf03, combined_df_obs_rf03_err = build_obs_block_with_err(all_data_obs_rf03)\n",
    "combined_df_obs_rf07, combined_df_obs_rf07_err = build_obs_block_with_err(all_data_obs_rf07)\n",
    "combined_df_obs_rf09, combined_df_obs_rf09_err = build_obs_block_with_err(all_data_obs_rf09)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Optional: enforce the same contributor order as your main\n",
    "# (uses `combined_df_obs` from your main block if available)\n",
    "# ----------------------------------------------------------\n",
    "try:\n",
    "    col_order = list(combined_df_obs.columns)  # from your main block\n",
    "except NameError:\n",
    "    # Fallback: use RF03 mean order\n",
    "    col_order = combined_df_obs_rf03.mean(axis=0).sort_values(ascending=False).index.tolist()\n",
    "\n",
    "def _reorder(df, cols):\n",
    "    return df.reindex(columns=cols)\n",
    "\n",
    "combined_df_obs_rf03      = _reorder(combined_df_obs_rf03,      col_order)\n",
    "combined_df_obs_rf03_err  = _reorder(combined_df_obs_rf03_err,  col_order)\n",
    "combined_df_obs_rf07      = _reorder(combined_df_obs_rf07,      col_order)\n",
    "combined_df_obs_rf07_err  = _reorder(combined_df_obs_rf07_err,  col_order)\n",
    "combined_df_obs_rf09      = _reorder(combined_df_obs_rf09,      col_order)\n",
    "combined_df_obs_rf09_err  = _reorder(combined_df_obs_rf09_err,  col_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42c845-6f0b-4eef-9367-cbe869481155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6997c-7618-4006-9791-09d10857dc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f732f-d1d9-4aa6-9750-5203649e974c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6bfc0d4-4d90-4b70-90be-25be1cb89cf2",
   "metadata": {},
   "source": [
    "### The analysis of OH\n",
    "Reproduce what Peng 2019 had (https://pubs.acs.org/doi/epdf/10.1021/acs.est.0c00126)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832edb53-19c7-4005-991e-f47ebf333348",
   "metadata": {},
   "source": [
    "#### Figure S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa0873-a6ff-4b06-9312-b5ca0716f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "colors = [\n",
    "    \"darkred\",  \n",
    "    \"royalblue\",  \n",
    "    \"darkgreen\",  \n",
    "    \"darkorange\", \n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\", \n",
    "    \"darkgray\", \n",
    "    \"gold\",      # yellow\n",
    "    \"indigo\",  # purple\n",
    "    \"black\", \n",
    "    \"lawngreen\", \n",
    "]\n",
    "# -----------------\n",
    "# Bin the data\n",
    "# Put it above after\n",
    "# ------------------\n",
    "# set up the dataframe\n",
    "df_OH_mod_mcm_bbvoc = all_data_mcm_bbvoc[['Flight_ID', 'Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "df_OH_mod_mcm_gcvoc = all_data_mcm_gcvoc[['Flight_ID', 'Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "df_OH_mod_gc        = all_data_gc[['Flight_ID', 'Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "df_OH_obs = all_data_obs_combined[['Flight_ID', 'Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "df_OH_mod_mcm_bbvoc = df_OH_mod_mcm_bbvoc.set_index('Plume_Age')\n",
    "df_OH_mod_mcm_gcvoc = df_OH_mod_mcm_gcvoc.set_index('Plume_Age')\n",
    "df_OH_mod_gc        = df_OH_mod_gc.set_index('Plume_Age')\n",
    "df_OH_obs = df_OH_obs.set_index('Plume_Age')\n",
    "# For model: create an empty DataFrame to store binned data\n",
    "df_OH_mod_mcm_bbvoc_bin = pd.DataFrame()\n",
    "df_OH_mod_mcm_gcvoc_bin = pd.DataFrame()\n",
    "df_OH_mod_gc_bin        = pd.DataFrame()\n",
    "# Iterate over unique 'Flight_ID' values and bin data for each\n",
    "for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "    # Filter data for the current 'Flight_ID'\n",
    "    subset_df_mcm_bbvoc = df_OH_mod_mcm_bbvoc[df_OH_mod_mcm_bbvoc['Flight_ID'] == flight_id]\n",
    "    subset_df_mcm_gcvoc = df_OH_mod_mcm_gcvoc[df_OH_mod_mcm_gcvoc['Flight_ID'] == flight_id]\n",
    "    subset_df_gc        = df_OH_mod_gc[df_OH_mod_gc['Flight_ID'] == flight_id]\n",
    "    # Use your bin_df function to bin the data for the current 'Flight_ID'\n",
    "    binned_subset_mcm_bbvoc = bin_df(subset_df_mcm_bbvoc, 0.25)\n",
    "    binned_subset_mcm_gcvoc = bin_df(subset_df_mcm_gcvoc, 0.25)\n",
    "    binned_subset_gc        = bin_df(subset_df_gc, 0.25)\n",
    "    # Add a 'Flight_ID' column to the binned data\n",
    "    binned_subset_mcm_bbvoc['Flight_ID'] = flight_id\n",
    "    binned_subset_mcm_gcvoc['Flight_ID'] = flight_id\n",
    "    binned_subset_gc['Flight_ID']        = flight_id\n",
    "    # Concatenate the binned data for the current 'Flight_ID' with the overall binned_data\n",
    "    df_OH_mod_mcm_bbvoc_bin = pd.concat([df_OH_mod_mcm_bbvoc_bin, binned_subset_mcm_bbvoc])\n",
    "    df_OH_mod_mcm_gcvoc_bin = pd.concat([df_OH_mod_mcm_gcvoc_bin, binned_subset_mcm_gcvoc])\n",
    "    df_OH_mod_gc_bin        = pd.concat([df_OH_mod_gc_bin, binned_subset_gc])\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# OH validation in two ways\n",
    "# 1) [OH]cal vs actual OH from model\n",
    "# 2) [OH]cal from different VOC pairs\n",
    "# Supplement figure\n",
    "# ===================================\n",
    "# Common settings\n",
    "Flight_IDs = ['RF03', 'RF07', 'RF09']\n",
    "#Flight_IDs = ['RF03', 'RF07', 'RF09', 'P-3B', 'FN19',]\n",
    "#Flight_IDs = ['RF03', 'RF07', 'RF09', 'FN19']\n",
    "\n",
    "stat     = 'median'\n",
    "stat_err = 'iqr'\n",
    "# Define plot settings for each row\n",
    "plot_settings = [\n",
    "    {'Val_method': 'VOCs'},\n",
    "    {'Val_method': 'Cal vs Act'},\n",
    "    {'Val_method': 'Combined'},\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store CV DataFrames\n",
    "cv_dfs_list = []\n",
    "\n",
    "fig, axes = plt.subplots(len(plot_settings), len(Flight_IDs), figsize=(6*len(Flight_IDs), 4*len(plot_settings)), sharex='col', sharey='row')\n",
    "# Ensure axes is always a 2D array even if there's only one plot\n",
    "axes = np.atleast_2d(axes)\n",
    "for row, settings in enumerate(plot_settings):\n",
    "    for col, Flight_ID in enumerate(Flight_IDs):\n",
    "        ax = axes[row, col]\n",
    "        if settings['Val_method'] == 'VOCs':\n",
    "            flight_data = calOH_conc_vocs_per_flight_obs[Flight_ID]\n",
    "            # Replace the values in the second row with NaN for all columns\n",
    "            #df.iloc[1] = np.nan\n",
    "            time = flight_data['Avg_physical_age_min'] / 60  # Convert minutes to hours\n",
    "            color_cycle = iter(colors)  # Create an iterator over the colors\n",
    "            for comp in flight_data:\n",
    "                if comp != 'Avg_physical_age_min': \n",
    "                    color = next(color_cycle, 'grey')  # Use grey if we run out of specified colors\n",
    "                    OH_cal = flight_data[comp].copy()\n",
    "                    if Flight_ID == 'RF09': \n",
    "                        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "                        target_ages = [3.744000,  4.620500, 4.093667]\n",
    "                        OH_cal[time.round(6).isin(target_ages)] = np.nan\n",
    "                    if Flight_ID == 'RF07': \n",
    "                        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "                        target_ages = [3.541500]\n",
    "                        OH_cal[time.round(6).isin(target_ages)] = np.nan\n",
    "\n",
    "                    # Mask NaN values before plotting\n",
    "                    valid_mask = ~OH_cal.isna()\n",
    "                    time_valid = time[valid_mask]\n",
    "                    OH_valid = OH_cal[valid_mask]\n",
    "        \n",
    "                    # Plot the valid data\n",
    "                    ax.plot(time_valid, OH_valid, label=comp, color=color, linewidth=10)\n",
    "                    ax.fill_between(time_valid, OH_valid * (1 - name2uncertainty[comp]), OH_valid * (1 + name2uncertainty[comp]), color=color, alpha=0.3)\n",
    "            \n",
    "            # Calculate the coefficient of variance (CV) for the selected VOCs\n",
    "            df_transposed  = flight_data.copy().set_index('Avg_physical_age_min').T\n",
    "            cv_across_vocs = df_transposed.apply(lambda x: np.nanstd(x, ddof=1) / np.nanmean(x) * 100, axis=0)\n",
    "            # Store the CV DataFrame\n",
    "            cv_dfs_list.append(cv_across_vocs.to_frame(name=Flight_ID))\n",
    "\n",
    "        elif settings['Val_method'] == 'Cal vs Act':\n",
    "            df_OH_mod_mcm_bbvoc_bin_per_flight = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == Flight_ID]  # Placeholder for actual data access\n",
    "            # Line plot for output model data - Solid Line\n",
    "            ax.errorbar(df_OH_mod_mcm_bbvoc_bin_per_flight.index, \n",
    "                        df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat)], \n",
    "                        yerr=df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat_err)], \n",
    "                        color='black', \n",
    "                        linewidth=3, linestyle='', capsize=5, marker='o', label='Actual OH')\n",
    "            # Line plot for calculated model data - Dashed Line with shaded error\n",
    "            x_values = df_OH_mod_mcm_bbvoc_bin_per_flight.index + 0 # + offset\n",
    "            y_values = df_OH_mod_mcm_bbvoc_bin_per_flight[(f'cal_OH_{stat}', stat)]\n",
    "            if stat == 'median': yerr = df_OH_mod_mcm_bbvoc_bin_per_flight[('cal_OH_iqr', stat)]\n",
    "            if stat == 'mean': yerr = df_OH_mod_mcm_bbvoc_bin_per_flight[('cal_OH_std', stat)]\n",
    "            ax.plot(x_values, y_values, color='black', label='Calculated OH', linestyle='--')\n",
    "            ax.fill_between(x_values, y_values - yerr, y_values + yerr, color='black', alpha=0.3)\n",
    "            # Calculate NMB\n",
    "            #nmb =np.mean((df_OH_mod_mcm_bbvoc_bin_per_flight[(f'cal_OH_{stat}', stat)] - df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat)]) / df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat)] * 100)\n",
    "            nmb = (df_OH_mod_mcm_bbvoc_bin_per_flight[(f'cal_OH_{stat}', stat)] - \n",
    "                   df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat)]).sum() / \\\n",
    "                   df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat)].sum() * 100\n",
    "            \n",
    "            # Annotate NMB on the plot\n",
    "            ax.annotate(f'NMB: {nmb:.0f}%', xy=(1.0, 0.7), xycoords='axes fraction', ha='right', va='top', fontsize=20, color='black')\n",
    "\n",
    "            #--------------------------------------------------------------------------------------\n",
    "            # Calculate the correlation matrix of different cal and actual OH from model results\n",
    "            # <2.5 hours and after 2.5 hours\n",
    "            #--------------------------------------------------------------------------------------\n",
    "            df_OH_individual = calOH_conc_vocs_per_flight_mod[Flight_ID]\n",
    "            df_OH_actual     = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == Flight_ID][('output_OH', stat)]\n",
    "            # Interpolation\n",
    "            df_OH_actual = df_OH_actual.reindex(df_OH_actual.index.union(df_OH_individual['Avg_physical_age_min']/60.0)).interpolate(method='index').reindex(df_OH_individual['Avg_physical_age_min']/60.0)\n",
    "            # Add interpolated values to the original DataFrame\n",
    "            df_OH_individual['Actual OH'] = df_OH_actual.values\n",
    "            # Calculate the correlation matrix for the dataset before 2.5 hours\n",
    "            print(Flight_ID) \n",
    "            correlation_matrix = df_OH_individual[['Furan', 'Furfural', 'Furanone']].corr()\n",
    "            print(\"Different VOC-CO set from model results:\\n\", correlation_matrix)\n",
    "            print()\n",
    "            print(f\"Diff between Cal and act OH from model: {nmb:.0f}%\")\n",
    "            print()\n",
    "        \n",
    "        elif settings['Val_method'] == 'Combined':\n",
    "            # VOCs method\n",
    "            flight_data = calOH_conc_vocs_per_flight_obs[Flight_ID]\n",
    "            #flight_data.loc[1] = np.nan\n",
    "            time = flight_data['Avg_physical_age_min'] / 60  # Convert minutes to hours\n",
    "            color_cycle = iter(colors)  # Create an iterator over the colors\n",
    "            for comp in flight_data:\n",
    "                if comp != 'Avg_physical_age_min': \n",
    "                    color = next(color_cycle, 'grey')  # Use grey if we run out of specified colors\n",
    "                    OH_cal = flight_data[comp].copy()\n",
    "                    if Flight_ID == 'RF09': \n",
    "                        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "                        target_ages = [3.744000,  4.620500, 4.093667]\n",
    "                        OH_cal[time.round(6).isin(target_ages)] = np.nan\n",
    "                    if Flight_ID == 'RF07': \n",
    "                        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "                        target_ages = [3.541500]\n",
    "                        OH_cal[time.round(6).isin(target_ages)] = np.nan\n",
    "                    # Mask NaN values before plotting\n",
    "                    valid_mask = ~OH_cal.isna()\n",
    "                    time_valid = time[valid_mask]\n",
    "                    OH_valid = OH_cal[valid_mask]\n",
    "                    ax.plot(time_valid, OH_valid, label=comp,\n",
    "                            color=color, linewidth=10)\n",
    "                    ax.fill_between(time_valid, OH_valid * (1 - name2uncertainty[comp]), OH_valid * (1 + name2uncertainty[comp]), color=color, alpha=0.3)\n",
    "            x_obs, y_obs = flight_data['Avg_physical_age_min']/60, flight_data.drop(columns=['Avg_physical_age_min']).median(axis=1)\n",
    "\n",
    "                    \n",
    "            # Models\n",
    "            df_OH_mod_mcm_bbvoc_bin_per_flight = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == Flight_ID]  # Placeholder for actual data access\n",
    "            # Line plot for output model data - Solid Line\n",
    "            ax.errorbar(df_OH_mod_mcm_bbvoc_bin_per_flight.index, \n",
    "                        df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat)], \n",
    "                        yerr=df_OH_mod_mcm_bbvoc_bin_per_flight[('output_OH', stat_err)], \n",
    "                        color='black', \n",
    "                        linewidth=3, linestyle='', capsize=5, marker='o', label='Actual OH')\n",
    "            # Line plot for calculated model data - Dashed Line with shaded error\n",
    "            x_values = df_OH_mod_mcm_bbvoc_bin_per_flight.index + 0 # + offset\n",
    "            y_values = df_OH_mod_mcm_bbvoc_bin_per_flight[(f'cal_OH_{stat}', stat)]\n",
    "            if stat == 'median': yerr = df_OH_mod_mcm_bbvoc_bin_per_flight[('cal_OH_iqr', stat)]\n",
    "            if stat == 'mean': yerr = df_OH_mod_mcm_bbvoc_bin_per_flight[('cal_OH_std', stat)]\n",
    "            ax.plot(x_values, y_values, color='black', label='Calculated OH', linestyle='--')\n",
    "\n",
    "\n",
    "            #print(df_OH_mod_mcm_bbvoc_bin_per_flight[(f'cal_OH_{stat}', stat)])\n",
    "            #test_stop\n",
    "\n",
    "            x_mod,y_mod  = x_values, y_values\n",
    "            #x_mod,y_mod  = df_OH_mod_mcm_bbvoc.index, df_OH_mod_mcm_bbvoc[f'cal_OH_{stat}']\n",
    "\n",
    "            #--------------------------------------\n",
    "            # Create a polynomial regression model\n",
    "            # NMB for individual VOC selection\n",
    "            #--------------------------------------\n",
    "            # Fit polynomial regression model on valid observational data\n",
    "            degree = 2\n",
    "            time_threshold = 2.5\n",
    "\n",
    "            valid_obs_indices = (~np.isnan(x_obs)) & (~np.isnan(y_obs))\n",
    "            x_obs_valid, y_obs_valid = x_obs[valid_obs_indices], y_obs[valid_obs_indices]\n",
    "            poly_model = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "            poly_model.fit(x_obs_valid.values.reshape(-1, 1), y_obs_valid.values)\n",
    "\n",
    "            valid_mod_indices = (x_mod < time_threshold)\n",
    "            x_mod_valid, y_mod_valid = x_mod[valid_mod_indices], y_mod[valid_mod_indices]\n",
    "\n",
    "\n",
    "        \n",
    "            y_predicted = poly_model.predict(x_mod_valid.values.reshape(-1, 1))\n",
    "            \n",
    "            #nmb_mcm_bbvoc = 100 * (np.nanmedian(y_mod_valid) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            #nmb_mcm_bbvoc = 100 * (np.nanmean(y_mod_valid) - np.nanmean(y_predicted)) / np.nanmean(y_predicted)\n",
    "            nmb_mcm_bbvoc = 100 * np.nansum(y_mod_valid - y_predicted) / np.nansum(y_predicted)\n",
    "            #print(y_mod_valid)\n",
    "            #test_stop\n",
    "\n",
    "            print(f'NMB MCM_BB_VOC for {Flight_ID}: {nmb_mcm_bbvoc:.2f}%')\n",
    "            \n",
    "            # Fit polynomial regression model on valid observational data where x < 2.5\n",
    "            valid_obs_indices_less = (~np.isnan(x_obs) & ~np.isnan(y_obs) & (x_obs < time_threshold))\n",
    "            if valid_obs_indices_less.any():\n",
    "                x_obs_valid_less, y_obs_valid_less = x_obs[valid_obs_indices_less], y_obs[valid_obs_indices_less]\n",
    "                poly_model_less = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "                poly_model_less.fit(x_obs_valid_less.values.reshape(-1, 1), y_obs_valid_less.values)\n",
    "    \n",
    "                valid_mod_indices_less = (x_mod < time_threshold)\n",
    "                x_mod_valid_less, y_mod_valid_less = x_mod[valid_mod_indices_less], y_mod[valid_mod_indices_less]\n",
    "                y_predicted_less = poly_model_less.predict(x_mod_valid_less.values.reshape(-1, 1))\n",
    "                \n",
    "                #nmb_mcm_bbvoc_less = 100 * (np.nanmedian(y_mod_valid_less) - np.nanmedian(y_predicted_less)) / np.nanmedian(y_predicted_less)\n",
    "                #nmb_mcm_bbvoc_less = 100 * (np.nanmean(y_mod_valid_less) - np.nanmean(y_predicted_less)) / np.nanmean(y_predicted_less)\n",
    "                nmb_mcm_bbvoc_less = 100 * np.nansum(y_mod_valid_less - y_predicted_less) / np.nansum(y_predicted_less)\n",
    "            \n",
    "                print(f'NMB MCM_BB_VOC for {Flight_ID} (x < {time_threshold}): {nmb_mcm_bbvoc_less:.2f}%')\n",
    "            else:\n",
    "                print(f'No valid observational data for {Flight_ID} where x < {time_threshold}')\n",
    "\n",
    "            # Check if there are valid samples for x > 2.5\n",
    "            valid_obs_indices_more = (~np.isnan(x_obs) & ~np.isnan(y_obs) & (x_obs > time_threshold))\n",
    "            if valid_obs_indices_more.any():\n",
    "                x_obs_valid_more, y_obs_valid_more = x_obs[valid_obs_indices_more], y_obs[valid_obs_indices_more]\n",
    "                poly_model_more = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "                poly_model_more.fit(x_obs_valid_more.values.reshape(-1, 1), y_obs_valid_more.values)\n",
    "            \n",
    "                valid_mod_indices_more = (x_mod > time_threshold)\n",
    "                x_mod_valid_more, y_mod_valid_more = x_mod[valid_mod_indices_more], y_mod[valid_mod_indices_more]\n",
    "                y_predicted_more = poly_model_more.predict(x_mod_valid_more.values.reshape(-1, 1))\n",
    "            \n",
    "                #nmb_mcm_bbvoc_more = 100 * (np.nanmedian(y_mod_valid_more) - np.nanmedian(y_predicted_more)) / np.nanmedian(y_predicted_more)\n",
    "                #nmb_mcm_bbvoc_more = 100 * (np.nanmean(y_mod_valid_more) - np.nanmean(y_predicted_more)) / np.nanmean(y_predicted_more)\n",
    "                nmb_mcm_bbvoc_more = 100 * np.nansum(y_mod_valid_more - y_predicted_more) / np.nansum(y_predicted_more)\n",
    "\n",
    "                \n",
    "                print(f'NMB MCM_BB_VOC for {Flight_ID} (x > {time_threshold}): {nmb_mcm_bbvoc_more:.2f}%')\n",
    "            else:\n",
    "                print(f'No valid observational data for {Flight_ID} where x > {time_threshold}')\n",
    "\n",
    "        # ------------------------------\n",
    "        # General setting for the figure\n",
    "        # ------------------------------\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "        ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "        ax.yaxis.get_offset_text().set_fontsize(15)\n",
    "        \n",
    "        # Set the lower limit of y-axis to 0\n",
    "        ax.set_ylim(bottom=0)\n",
    "                    \n",
    "\n",
    "\n",
    "        if Flight_ID == 'RF09':ax.set_ylim(top=2E7)\n",
    "            \n",
    "        if row == 0: ax.set_title(id2fire_name.get(Flight_ID, Flight_ID), fontsize=20)\n",
    "        if col == 2: ax.legend(fontsize=15, loc='upper right')\n",
    "        if col == 0:\n",
    "            # Add minor ticks (small sticks) on y-axis\n",
    "            ax.yaxis.set_minor_locator(AutoMinorLocator(2))  # 2 minor ticks between each major tick\n",
    "            ax.tick_params(axis='y', which='minor', length=4, width=1)  # Customize the minor tick appearance\n",
    "            '''\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "            yticks = np.arange(np.floor(ymin), np.ceil(ymax) + 0.1, 0.5)\n",
    "            ax.set_yticks(yticks)\n",
    "            ax.set_yticklabels([f\"{y/1e7:.1f}\" for y in yticks])  \n",
    "            '''\n",
    "                    \n",
    "        # Add specified texts as transparent boxes\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"white\", lw=2, alpha=0.5)\n",
    "        if row == 0 and col == 0:\n",
    "            #ax.text(0.2, 0.9, 'Observed Cal OH', transform=ax.transAxes, fontsize=15, ha='center', bbox=bbox_props)\n",
    "            ax.text(0.05, 0.95, 'A', transform=ax.transAxes, fontsize=25, fontweight='bold', va='top', ha='left')\n",
    "        if row == 1 and col == 0:\n",
    "            #ax.text(0.2, 0.9, 'Cal vs Actual OH', transform=ax.transAxes, fontsize=15, ha='center', bbox=bbox_props)\n",
    "            ax.text(0.05, 0.95, 'B', transform=ax.transAxes, fontsize=25, fontweight='bold', va='top', ha='left')\n",
    "        if row == 2 and col == 0:\n",
    "            #ax.text(0.2, 0.9, 'Cal vs Actual OH', transform=ax.transAxes, fontsize=15, ha='center', bbox=bbox_props)\n",
    "            ax.text(0.05, 0.95, 'C', transform=ax.transAxes, fontsize=25, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(wspace=0.1)  # Adjust space between plots\n",
    "# Set common x and y labels\n",
    "fig.text(0.5, 0.06, 'Plume age (hour)', ha='center', va='center', fontsize=28)\n",
    "fig.text(0.08, 0.5, 'OH (molecule cm$^{-3}$)', ha='center', va='center', rotation='vertical', fontsize=28)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/OH_evaluation.jpg', bbox_inches='tight', pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------\n",
    "# Print output\n",
    "# ------------\n",
    "# Combine all CV DataFrames\n",
    "combined_cv_df = pd.concat(cv_dfs_list, axis=1)\n",
    "# Combine all CV DataFrames into one column per flight\n",
    "# Ensure no repeated index\n",
    "combined_cv_df = combined_cv_df.sort_index().reindex(pd.Index(sorted(set(combined_cv_df.index))))\n",
    "# Combine into a single column DataFrame by stacking and dropping NaNs\n",
    "combined_cv_single_column = combined_cv_df.stack().reset_index(level=1, drop=True).to_frame(name='CV')\n",
    "within_2_5_hours = combined_cv_single_column[combined_cv_single_column.index <= 2.5*60]\n",
    "after_2_5_hours = combined_cv_single_column[combined_cv_single_column.index > 2.5*60]\n",
    "# Calculate and print the mean CV for each subset\n",
    "print(f'CV (within 2.5 hours): {within_2_5_hours[\"CV\"].mean():.0f}%')\n",
    "print(f'CV (after 2.5 hours): {after_2_5_hours[\"CV\"].mean():.0f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7c393-f735-42fa-8634-862cbdddd613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea9bef-80e0-454a-9a69-fade0b5e2aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688af15-54cb-4c7e-965f-50be5c1d6e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf604a4-21d7-4177-9e99-22b810db47d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c72a1-4f24-4e19-b491-767d1913f82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08650c16-f24c-4923-aa57-7b0cab26168f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556998c-22ad-4da8-a302-f5647dd19179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12e217-518f-4c94-a356-2c0d199f3d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc029c-d160-4273-b0ff-5d128307304f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec561b1-0c45-47de-8a61-806cb216823d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c3d91-396f-41e1-8991-78544cc311d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot data\n",
    "def plot_data_helper(group_column, var_x, var_y, ax, title, set_ylabel, show_legend, set_xlabel=True, set_annotate=True):\n",
    "    # Select group names and corresponding legend title\n",
    "    if group_column == 'VOCR_NOxR_group': \n",
    "        unique_groups = VOCR_NOxR_group_names\n",
    "        legend_title = 'OHRvoc: OHRnox'\n",
    "    elif group_column == 'NOxR_VOCR_group':\n",
    "        unique_groups = NOxR_VOCR_group_names\n",
    "        legend_title = 'OHRnox: OHRvoc'    \n",
    "    elif group_column == 'VOCR_group':\n",
    "        unique_groups = all_data_obs_combined['VOCR_group'].unique()\n",
    "        unique_groups = np.sort(unique_groups)\n",
    "        legend_title = 'VOC reactivity'    \n",
    "    elif group_column == 'Flight_ID':\n",
    "        unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "        legend_title = 'Flight ID'\n",
    "    elif group_column == 'O3_category':\n",
    "        unique_groups = all_data_obs_combined['O3_cateplot_data_helpergory'].unique()\n",
    "        #unique_groups = np.sort(unique_groups)\n",
    "        legend_title = 'O3 concentration'\n",
    "    elif group_column == 'Ox_category':\n",
    "        unique_groups = all_data_obs_combined['Ox_category'].unique()\n",
    "        #unique_groups = np.sort(unique_groups)\n",
    "        legend_title = 'Ox concentration'\n",
    "    elif group_column == 'CH2O_NO2_group':\n",
    "        unique_groups = all_data_obs_combined['CH2O_NO2_group'].unique()\n",
    "        legend_title = 'CH$_{2}$O: NO$_{2}$'\n",
    "\n",
    "    # The slope of NEMR O3 vs plume age\n",
    "    mean_lagrangian = []\n",
    "    nmb_values_mcm_bbvoc = {}\n",
    "    nmb_values_mcm_gcvoc = {}\n",
    "    nmb_values_gc = {}\n",
    "    color_flight = {}\n",
    "    \n",
    "    # Set up colors\n",
    "    if group_column == 'Flight_ID':\n",
    "        unique_groups = desired_order_flights\n",
    "    if len(unique_groups) == 6:\n",
    "        group_colors = np.array([\n",
    "            [0.80645161, 1.0, 0.16129032, 1.0],\n",
    "            [0.5, 0.0, 0.0, 1.0],\n",
    "            [0.0, 0.0, 0.5, 1.0],\n",
    "            [0.0, 0.3, 1.0, 1.0],\n",
    "            [1.0, 0.40740741, 0.0, 1.0],\n",
    "            [0.16129032, 1.0, 0.80645161, 1.0],\n",
    "        ])\n",
    "\n",
    "        group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "    \n",
    "    else:\n",
    "        group_colors = plt.cm.jet(np.linspace(0, 1, len(unique_groups)))\n",
    "\n",
    "    OH_cal_VOCs = ['Furan', 'Furfural', 'Furanone', 'Furan: CO', 'Furfural: CO', 'Furanone: CO']\n",
    "    for idx, group in enumerate(unique_groups):\n",
    "        skip_P3B_conditions     = ((group == 'P-3B') and ('PAN' in var_y)) or  \\\n",
    "                                    ((group == 'P-3B') and (var_y in OH_cal_VOCs)) or  \\\n",
    "                                    ((group == 'P-3B') and ('NO2' in var_y)) \n",
    "        skip_GCVOC_conditions   =  var_y in OH_cal_VOCs\n",
    "        skip_nonLang_conditions = ('output' in var_x) and ('NEMR_O3' in var_y or 'NEMR_PAN' in var_y) and (group == 'Other WE-CAN flights') \n",
    "        # Skip P-3B for calculated chemical age\n",
    "        if skip_P3B_conditions:\n",
    "            print('skip P-3B for missing PAN data')\n",
    "            continue\n",
    "        if skip_nonLang_conditions:\n",
    "            print('skip non-Lagrangian flights')\n",
    "            continue\n",
    "\n",
    "        # Replace calculated OH/chemical age from actual OH in MCMBBVOC        \n",
    "        group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]            \n",
    "        group_data_obs  = group_data_obs.dropna(subset=[var_x, var_y])\n",
    "        x_obs, y_obs    = (group_data_obs[var_x]).astype(float), (group_data_obs[var_y]).astype(float)\n",
    "        valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "        \n",
    "        if group in Lagrangian_flights: mean_lagrangian.append(y_obs[valid_indices].mean())\n",
    "\n",
    "        # Plot observational data if available\n",
    "        if valid_indices.any():\n",
    "            # Determine if the circle should be solid or open based on the flight\n",
    "            face_color = group_colors[idx]\n",
    "            # 1) Plot dots even they are not in Lagrangian flights\n",
    "            if \"dil\" not in var_y:\n",
    "                if group_column == 'Flight_ID': \n",
    "                    if group not in Lagrangian_flights: continue\n",
    "                    face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "                    #face_color = 'none' # To make Lu happy, VOC plot\n",
    "                    ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, s=8, label=id2fire_name.get(group,group))\n",
    "                else:\n",
    "                    ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, s=8, label=group)\n",
    "                    \n",
    "            # 2) Plot dots only when they are in Lagrangian flights and var_y is specific.\n",
    "            # dil for model VOC evalutions, \n",
    "            if 'dil' in var_y and group in Lagrangian_flights:\n",
    "                if np.all(y_obs[valid_indices] == 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    if group_column == 'Flight_ID': \n",
    "                        face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "                        #face_color = 'none' # To make Lu happy, VOC plot\n",
    "                        ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, s=8, label=id2fire_name.get(group,group))\n",
    "                    else:\n",
    "                        ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, s=8, label=group)\n",
    "            # Perform linear regression\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "            \n",
    "        # Group model results with flight ID instead.\n",
    "        if (group_column == 'Flight_ID') and (group in Lagrangian_flights):            \n",
    "            group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "            group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "            group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "\n",
    "            # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "            bin_size = 10/60 if var_y == 'LROx: LNOx' else 0.25 # 30/15 minutes in hours\n",
    "            group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "            group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "            group_data_gc_binned             = group_data_gc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "            # Choose what we want to smooth the model results\n",
    "            # Binned model data if we are using actual OH related varialbe\n",
    "            if ('output' in var_y or 'output' in var_x) or (var_x=='Plume_Age' and var_y=='LROx: LNOx'):\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x]).astype(float), (group_data_mcm_bbvoc_binned[var_y]).astype(float)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x]).astype(float), (group_data_mcm_gcvoc_binned[var_y]).astype(float)\n",
    "                x_gc, y_gc               = (group_data_gc_binned[var_x]).astype(float), (group_data_gc_binned[var_y]).astype(float)\n",
    "            else:\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc[var_x]).astype(float), (group_data_mcm_bbvoc[var_y]).astype(float)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc[var_x]).astype(float), (group_data_mcm_gcvoc[var_y]).astype(float)\n",
    "                x_gc, y_gc               = (group_data_gc[var_x]).astype(float), (group_data_gc[var_y]).astype(float)\n",
    "            \n",
    "            valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                                ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                                ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "            \n",
    "            x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "            x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "            x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "\n",
    "            # Smoothen the data, Lixu\n",
    "            if (var_x, var_y) == ('Plume_Age', 'CH2O: NO2') or (var_x, var_y) == ('Plume_Age', 'OHRnox: OHRvoc'):\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=10/60)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=10/60)\n",
    "                x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=10/60)\n",
    "\n",
    "            if (var_x, var_y) == ('Plume_Age', 'LROx: LNOx'):\n",
    "                if group == 'P-3B':\n",
    "                    x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=10/60)\n",
    "                    x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=10/60)\n",
    "                    x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=10/60)\n",
    "                else:\n",
    "                    x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=30/60)\n",
    "                    x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=30/60)\n",
    "                    x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=30/60)\n",
    "\n",
    "            \n",
    "            # Add solid lines for model output\n",
    "            if valid_indices_mod.any():\n",
    "                ax.plot(x_mcm_bbvoc, y_mcm_bbvoc, \n",
    "                        color = group_colors[idx], linestyle='-', linewidth=2, label=id2fire_name.get(group,group))\n",
    "                # Define keys to check in corresponding dictionaries\n",
    "                check_conditions = {\n",
    "                    var_x: ['output'],\n",
    "                    var_y: ['Furanoids excl.', 'Acrolein', 'BIACET', 'Butadiene', 'Butanedione', 'Diacetyl',  'Maleic anhydride']\n",
    "                }\n",
    "                \n",
    "                # Check if all specified keys are missing in their respective dictionaries\n",
    "                if all(key not in dictionary for dictionary, keys in check_conditions.items() for key in keys):\n",
    "                    if not skip_GCVOC_conditions:\n",
    "                        ax.plot(x_mcm_gcvoc, y_mcm_gcvoc, \n",
    "                                color=group_colors[idx], linestyle='--', linewidth=2)\n",
    "                        ax.plot(x_gc, y_gc, \n",
    "                                color=group_colors[idx], linestyle=':', linewidth=2)\n",
    "            \n",
    "            # ------------------------\n",
    "            # Calculate the model error\n",
    "            # -------------------------\n",
    "            # Only when observation exists\n",
    "            if valid_indices.any():\n",
    "                # Define the degree of the polynomial model       \n",
    "                degree = 2 if group!='FN19' else 1\n",
    "                # Create a polynomial regression model\n",
    "                poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "                # Fit the polynomial regression model on observational data\n",
    "                poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "                # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "                x_model       = x_mcm_bbvoc\n",
    "                y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "            # Using mcmbbvoc as the observation\n",
    "            else:\n",
    "                y_predicted = y_mcm_bbvoc\n",
    "            # Calculate Normalized Median Bias (NMB)\n",
    "            #nmb_mcm_bbvoc               = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            #nmb_mcm_gcvoc               = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            #nmb_gc                      = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            nmb_mcm_bbvoc = 100 * np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "            nmb_mcm_gcvoc = 100 * np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "            nmb_gc        = 100 * np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "            \n",
    "            # After calculating NMB\n",
    "            nmb_values_mcm_bbvoc[group] = nmb_mcm_bbvoc\n",
    "            nmb_values_mcm_gcvoc[group] = nmb_mcm_gcvoc\n",
    "            nmb_values_gc[group]        = nmb_gc\n",
    "            color_flight[group]         = group_colors[idx]\n",
    "\n",
    "        # Defalt setting for title, ticks, and labels\n",
    "        if set_xlabel: ax.set_xlabel(text_labels.get(var_x, var_x), fontsize=8)\n",
    "        if set_ylabel: ax.set_ylabel(text_labels.get(var_y, var_y), fontsize=8)\n",
    "        ax.set_title(title, fontsize=8)\n",
    "        ax.tick_params(axis='both', labelsize=8)\n",
    "        # Legend        \n",
    "        if show_legend:\n",
    "            if var_y == 'NEMR_PAN' and group_column == 'Flight_ID':\n",
    "                legend_fontsize = 7.5\n",
    "            elif var_y == 'NEMR_O3' and group_column == 'Flight_ID':\n",
    "                legend_fontsize = 7.5\n",
    "            #elif var_y == 'CH2O: NO2' and group_column == 'Flight_ID':\n",
    "            #    legend_fontsize = 13\n",
    "            elif var_y == 'OHRnox: OHRvoc' and group_column == 'Flight_ID':\n",
    "                legend_fontsize = 7.5\n",
    "\n",
    "            elif skip_GCVOC_conditions:\n",
    "                legend_fontsize = 7.5\n",
    "\n",
    "            else:\n",
    "                legend_fontsize = 7.5\n",
    "            if group_column == 'Flight_ID':\n",
    "                desired_order = desired_order_flights\n",
    "                reorder_legend(ax, desired_order, id2fire_name, fontsize=legend_fontsize, title_fontsize = 7.5, legend_loc='upper right')\n",
    "            elif group_column == 'CH2O_NO2_group':\n",
    "                desired_order = CH2O_NO2_group_names\n",
    "                reorder_legend(ax, desired_order, id2fire_name, legend_title='FNR', fontsize=7.5, title_fontsize = 7.5, legend_loc='upper right')\n",
    "            else:\n",
    "                ax.legend(title=legend_title, fontsize=7.5, title_fontsize = 7.5, loc='upper right')\n",
    "    # -------------------\n",
    "    # Annotation settings\n",
    "    # -------------------\n",
    "    if var_x=='Plume_Age' or 'cal_chem' in var_x:\n",
    "        # Calculate median and interquartile range (IQR)\n",
    "        nmb_values_mcm_bbvoc_array = np.array(list(nmb_values_mcm_bbvoc.values()), dtype=float)\n",
    "        nmb_values_mcm_gcvoc_array = np.array(list(nmb_values_mcm_gcvoc.values()), dtype=float)\n",
    "        nmb_values_gc_array        = np.array(list(nmb_values_gc.values()), dtype=float)\n",
    "        median_mcm_bbvoc, q1_mcm_bbvoc, q3_mcm_bbvoc = np.nanmedian(nmb_values_mcm_bbvoc_array), np.nanpercentile(nmb_values_mcm_bbvoc_array, 25), np.nanpercentile(nmb_values_mcm_bbvoc_array, 75)\n",
    "        median_mcm_gcvoc, q1_mcm_gcvoc, q3_mcm_gcvoc = np.nanmedian(nmb_values_mcm_gcvoc_array), np.nanpercentile(nmb_values_mcm_gcvoc_array, 25), np.nanpercentile(nmb_values_mcm_gcvoc_array, 75)\n",
    "        median_gc, q1_gc, q3_gc                      = np.nanmedian(nmb_values_gc_array), np.nanpercentile(nmb_values_gc_array, 25), np.nanpercentile(nmb_values_gc_array, 75)\n",
    "        iqr_mcm_bbvoc = q3_mcm_bbvoc - q1_mcm_bbvoc\n",
    "        iqr_mcm_gcvoc = q3_mcm_gcvoc - q1_mcm_gcvoc\n",
    "        iqr_gc        = q3_gc - q1_gc\n",
    "        # Calculate mean and standard deviation\n",
    "        mean_mcm_bbvoc, std_mcm_bbvoc = np.nanmean(nmb_values_mcm_bbvoc_array), np.nanstd(nmb_values_mcm_bbvoc_array)\n",
    "        mean_mcm_gcvoc, std_mcm_gcvoc = np.nanmean(nmb_values_mcm_gcvoc_array), np.nanstd(nmb_values_mcm_gcvoc_array)\n",
    "        mean_gc, std_gc               = np.nanmean(nmb_values_gc_array), np.nanstd(nmb_values_gc_array)\n",
    "\n",
    "        # Annotate mean ± std in each subplot\n",
    "        # Determine if we want to show bias for each individual flights or the average of flights.\n",
    "        annotate_condition1 = ('dil' in var_y) or ('cal' in var_y)  # or ('PAN' in var_y) \n",
    "        annotate_condition2 = ('O3' in var_y)  or ('NEMR_PAN' in var_y and var_x=='Plume_Age') or ('VOCR' in var_y)\n",
    "        if annotate_condition1:\n",
    "            #stop\n",
    "\n",
    "            if 'dil' in var_y: xy, ha, va, color =(0.05, 0.0), 'left', 'bottom', 'black'\n",
    "            if 'cal' in var_y: xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "            if 'O3' in var_y:\n",
    "                if var_x=='Plume_Age': xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "                if 'cal' in var_x: xy, ha, va, color =(0.95, 0.55), 'right', 'bottom', 'black'\n",
    "            if 'PAN' in var_y and var_x=='Plume_Age': xy, ha, va, color =(0.95, 0.55), 'right', 'bottom', 'black'\n",
    "            if 'VOCR' in var_y and var_x=='Plume_Age': xy, ha, va, color =(0.95, 0.05), 'right', 'bottom', 'black'\n",
    "            if set_annotate: \n",
    "                ax.annotate(f\"NMB:({median_mcm_bbvoc:.0f}±{iqr_mcm_bbvoc:.0f})%\", \n",
    "                         xy=xy,  # Position of the annotation\n",
    "                         xycoords='axes fraction',\n",
    "                         ha=ha, va=va,  # Alignment of the text\n",
    "                         fontsize=8,  # Font size of the text\n",
    "                         color=color)  # Color of the text\n",
    "        if annotate_condition2:\n",
    "            if 'cal' in var_x: \n",
    "                start_x = 0.95\n",
    "                start_y = 0.38\n",
    "                step_y  = 0.05\n",
    "                ha='right'\n",
    "                va='bottom'    \n",
    "            elif (var_y in ['NEMR_O3', 'NEMR_O3_rate']):\n",
    "                start_x = 0.95\n",
    "                start_y = 0.22\n",
    "                step_y  = 0.05\n",
    "                ha='right'\n",
    "                va='bottom'\n",
    "            elif (var_y in ['NEMR_PAN', 'NEMR_PAN_rate']):\n",
    "                start_x = 0.95\n",
    "                start_y = 0.15\n",
    "                step_y  = 0.05\n",
    "                ha='right'\n",
    "                va='bottom'\n",
    "            \n",
    "            elif ('VOCR' in var_y):\n",
    "                start_x = 0.7\n",
    "                start_y = 0.87\n",
    "                step_y  = 0.1\n",
    "                ha='right'\n",
    "                va='top'\n",
    "            else:\n",
    "                start_x = 0.95\n",
    "                start_y = 0.45\n",
    "                step_y  = 0.05\n",
    "                ha='right'\n",
    "                va='bottom'\n",
    "            # Desired order of keys\n",
    "            desired_order = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']\n",
    "\n",
    "            # Desired order of keys\n",
    "            nmb_values_mcm_bbvoc_ordered = OrderedDict((key, nmb_values_mcm_bbvoc[key]) for key in desired_order if key in nmb_values_mcm_bbvoc)\n",
    "            nmb_values_mcm_gcvoc_ordered = OrderedDict((key, nmb_values_mcm_gcvoc[key]) for key in desired_order if key in nmb_values_mcm_gcvoc)\n",
    "            nmb_values_gc_ordered        = OrderedDict((key, nmb_values_gc[key]) for key in desired_order if key in nmb_values_gc)\n",
    "\n",
    "            # Annotations            \n",
    "            # Set up for details\n",
    "            if (var_x, var_y) ==  ('Plume_Age', 'VOCR: CO'):\n",
    "                nmb_fontsize = 8\n",
    "            else:\n",
    "                nmb_fontsize = 8\n",
    "\n",
    "            if 'rate' in var_y:\n",
    "                print(x_obs)\n",
    "            if 'rate' not in var_y:\n",
    "                if set_annotate: \n",
    "                    ax.annotate(f'$MCM_{{BBVOC}}$, $MCM_{{GCVOC}}$, GEOS-Chem',\n",
    "                                xy=(start_x, start_y+step_y),  # Position of the annotation\n",
    "                                xycoords='axes fraction',\n",
    "                                ha=ha, va=va,  # Alignment of the text\n",
    "                                fontsize=nmb_fontsize,  # Font size of the text\n",
    "                                color='black')  # Color of the text, + 1 to skip P-3B\n",
    "    \n",
    "                for idx, group in enumerate(nmb_values_mcm_bbvoc_ordered):\n",
    "                    # Extract the name and perform the split operation outside the f-string\n",
    "                    nmb_value_mcm_bbvoc = nmb_values_mcm_bbvoc_ordered[group]\n",
    "                    nmb_value_mcm_gcvoc = nmb_values_mcm_gcvoc_ordered[group]\n",
    "                    nmb_value_gc        = nmb_values_gc_ordered[group]\n",
    "                    color     = color_flight[group]\n",
    "                    # Check if the group requires a box\n",
    "                    if group in ['FN19', 'RF03'] and 'NEMR_O3' in var_y:\n",
    "                        bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"none\", lw=1, ec=color, alpha=0.7)\n",
    "                    else:\n",
    "                        bbox_props = None\n",
    "                    if set_annotate:\n",
    "                        ax.annotate(f'{nmb_value_mcm_bbvoc:.0f}%, {nmb_value_mcm_gcvoc:.0f}%, {nmb_value_gc:.0f}%', \n",
    "                                    xy=(start_x, start_y-idx*step_y),  # Position of the annotation\n",
    "                                    xycoords='axes fraction',\n",
    "                                    ha=ha, va=va,  # Alignment of the text\n",
    "                                    fontsize=nmb_fontsize,  # Font size of the text\n",
    "                                    color=color,   # Color of the text, + 1 to skip P-3B\n",
    "                                    bbox=bbox_props)  # Apply box properties if specified\n",
    "\n",
    "    if (var_x,var_y)==('CH2O: NO2', 'OHRvoc: OHRnox') or (var_x,var_y)==('CH2O: CO', 'VOCR: CO'):\n",
    "        # Calculate and annotate overall slope and R-squared for all observations\n",
    "        all_x_obs, all_y_obs = all_data_obs_combined[var_x], all_data_obs_combined[var_y]\n",
    "        valid_indices_all = ~np.isnan(all_x_obs) & ~np.isnan(all_y_obs)\n",
    "        slope_all, intercept_all, r_value_all, p_value_all, std_err_all = linregress(np.array(all_x_obs)[valid_indices_all], np.array(all_y_obs)[valid_indices_all])\n",
    "        r_squared_all = r_value_all ** 2\n",
    "        if set_annotate:\n",
    "            plt.annotate(f\"Slope={slope_all:.1f}±{std_err_all:.1f}, $R^2$={r_squared_all:.2f}\", \n",
    "                         xy=(0.95, 0.05), xycoords='axes fraction', \n",
    "                         ha='right', va='top', fontsize=8, color='black')\n",
    "\n",
    "    \n",
    "    # Conditional to check if we are analyzing the right variables\n",
    "    #if (var_x, var_y) == ('output_chem_age', 'NEMR_O3') or (var_x, var_y) == ('output_chem_age', 'NEMR_PAN'):\n",
    "    if var_x == 'output_chem_age':\n",
    "        # Compute valid indices (indices where neither x nor y are NaN)\n",
    "        valid_indices_all = ~np.isnan(all_data_obs_lagrangian[var_x]) & ~np.isnan(all_data_obs_lagrangian[var_y])\n",
    "    \n",
    "        # Use valid indices to select data for R^2 calculation\n",
    "        valid_r2_x = all_data_obs_lagrangian[var_x][valid_indices_all]\n",
    "        valid_r2_y = all_data_obs_lagrangian[var_y][valid_indices_all]\n",
    "    \n",
    "        # Compute R^2 value only if there are enough valid data points\n",
    "        if len(valid_r2_x) > 1:\n",
    "            # Calculate correlation coefficient\n",
    "            correlation_matrix = np.corrcoef(valid_r2_x, valid_r2_y)\n",
    "            correlation_xy = correlation_matrix[0, 1]\n",
    "            r2 = correlation_xy**2\n",
    "            print(f'This is r2: {r2}')\n",
    "            \n",
    "            # Annotate R2 value on the plot\n",
    "            #if set_annotate:\n",
    "            ax.annotate(f'R² = {r2:.2f}', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=8, \n",
    "                        horizontalalignment='right', verticalalignment='top', backgroundcolor='white')\n",
    "        else:\n",
    "            print(\"Not enough valid data to calculate R².\")\n",
    "            \n",
    "    # --------------------\n",
    "    # Print out analysis\n",
    "    # --------------------\n",
    "    if var_x == 'Plume_Age' and var_y in ['cal_OH_mean', 'cal_OH_median', 'cal_OH_wide_mean', 'cal_OH_wide_median']:\n",
    "        # ---------------------\n",
    "        # The first timeframe\n",
    "        # The first hour\n",
    "        # ---------------------\n",
    "        filtered_data_obs_first = all_data_obs_combined[all_data_obs_combined[var_x] < 40/60]\n",
    "        filtered_data_obs_first = filtered_data_obs_first.dropna(subset=[var_y])\n",
    "        # Calculate the slope\n",
    "        slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress((filtered_data_obs_first[var_x]).astype(float),  (filtered_data_obs_first[var_y]).astype(float))\n",
    "        # Calculate the mean values and std err within the timeframe\n",
    "        mean_value, std_dev = filtered_data_obs_first[var_y].mean(), filtered_data_obs_first[var_y].std()\n",
    "        median_value, iqr_val = filtered_data_obs_first[var_y].median(), iqr(filtered_data_obs_first[var_y])\n",
    "        # Print the mean and standard deviation\n",
    "        print(f'The mean/std value of first hour (1E6 molec/cm3): {mean_value/1E6:.1f}±{std_dev/1E6:.1f}')\n",
    "        print(f'The median/iqr value of first hour (1E6 molec/cm3): {median_value/1E6:.1f}±{iqr_val/1E6:.1f}')\n",
    "        # --------------------\n",
    "        # The second timeframe\n",
    "        # 1-3 hours\n",
    "        # --------------------\n",
    "        filtered_data_obs_second = all_data_obs_combined[(all_data_obs_combined[var_x] > 1) & (all_data_obs_combined[var_x] < 3)]\n",
    "        filtered_data_obs_second = filtered_data_obs_second.dropna(subset=[var_y])\n",
    "        # Calculate the slope\n",
    "        slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress((filtered_data_obs_second[var_x]).astype(float),  (filtered_data_obs_second[var_y]).astype(float))\n",
    "        # Calculate the mean values and std err within the timeframe\n",
    "        mean_value, std_dev = filtered_data_obs_second[var_y].mean(), filtered_data_obs_second[var_y].std()\n",
    "        median_value, iqr_val = filtered_data_obs_second[var_y].median(), iqr(filtered_data_obs_second[var_y])\n",
    "        # Print the mean and standard deviation\n",
    "        print(f'The mean/std value of second hour (1E6 molec/cm3): {mean_value/1E6:.1f}±{std_dev/1E6:.1f}')\n",
    "        print(f'The median/iqr value of second hour (1E6 molec/cm3): {median_value/1E6:.1f}±{iqr_val/1E6:.1f}')\n",
    "        # --------------------\n",
    "        # Reference datapoints\n",
    "        # --------------------\n",
    "        x_points = [40/60, 40/60, 1.2, 20/60, 21/60, 45/60, 53/60, 56/60, 32/60]\n",
    "        y_points = [1.7E7, 1.14E7, 4.1E6, 4E6, 8.9E6, 4E6, 3E6, 2.8E6, 3.5E6]\n",
    "        labels = ['Hobbs et al. (2003)', 'Yokelson et al. (2009)', 'Yokelson et al. (2009)', 'Palm et al. (2021)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)']\n",
    "        markers = ['*', 's', 's', 'P', '^', '^', '^', '^', '^']\n",
    "        \n",
    "        # Track labels that have been annotated\n",
    "        annotated_labels = set()\n",
    "        \n",
    "        # Plot each point using corresponding marker and size\n",
    "        for xp, yp, label, marker in zip(x_points, y_points, labels, markers):\n",
    "            ax.scatter(xp, yp, marker=marker, color='black', s=8, label='_nolegend_')  # Use corresponding marker\n",
    "        \n",
    "            # Mute the annotation to make Lu happy\n",
    "            # Annotate the first occurrence of each label with text and a longer arrow\n",
    "            #if label not in annotated_labels:\n",
    "            #    ax.annotate(label, \n",
    "            #                xy=(xp, yp), xytext=(xp + 2, yp+8E6), \n",
    "            #                textcoords='data', fontsize=14, \n",
    "            #                arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            #                ha='left')\n",
    "            #    annotated_labels.add(label)  # Mark label as annotated\n",
    "        \n",
    "    #if var_x == 'Plume_Age' and var_y == 'NEMR_HONO':\n",
    "    #    pct_first_data  = []\n",
    "    #    pct_second_data = []\n",
    "    #    for idx, group in enumerate(all_data_obs['Flight_ID'].unique()):\n",
    "    #        group_data_obs       = all_data_obs[all_data_obs[group_column] == group]\n",
    "    #        group_data_obs       = group_data_obs.dropna(subset=[var_x, var_y])\n",
    "    #        group_data_obs_first  = group_data_obs[group_data_obs[var_x] < 0.5]\n",
    "    #        group_data_obs_second = group_data_obs[(group_data_obs[var_x] < 1.5) & (group_data_obs[var_x] > 1)]\n",
    "    #        group_data_obs_third  = group_data_obs[(group_data_obs[var_x] < 2.5) & (group_data_obs[var_x] > 2)]\n",
    "    #        try:\n",
    "    #            pct_first  = 1 - group_data_obs_second[var_y].mean(skipna=True)/group_data_obs_first[var_y].mean(skipna=True)\n",
    "    #        except:\n",
    "    #            pct_first = np.nan\n",
    "    #        try:\n",
    "    #            pct_second = 1 - group_data_obs_third[var_y].mean(skipna=True)/group_data_obs_first[var_y].mean(skipna=True)\n",
    "    #        except:\n",
    "    #            pct_second = np.nan\n",
    "    #        pct_first_data.append(pct_first*100)\n",
    "    #        pct_second_data.append(pct_second*100)\n",
    "    #    print(f'The consumed HONO in the first hour: {np.nanmean(np.array(pct_first_data)):.1f}±{np.nanstd(np.array(pct_first_data)):.1f}%')\n",
    "    #    print(f'The consumed HONO in the second hour: {np.nanmean(np.array(pct_second_data)):.1f}±{np.nanstd(np.array(pct_second_data)):.1f}%')\n",
    "    if var_x == 'Plume_Age' and var_y == 'NEMR_HONO':\n",
    "        # Collect per-hour % consumption across flights\n",
    "        per_hour_pct = {}  # hour -> list of % across flights\n",
    "    \n",
    "        # Determine max hour to report (based on data)\n",
    "        max_age = np.nanmax(all_data_obs[var_x].values)\n",
    "        max_hour = int(np.floor(max_age))  # e.g., 5 -> up to bin (5,5.5]\n",
    "    \n",
    "        flights = all_data_obs[group_column].dropna().unique()\n",
    "    \n",
    "        for group in flights:\n",
    "            group_data_obs = all_data_obs[all_data_obs[group_column] == group].dropna(subset=[var_x, var_y])\n",
    "    \n",
    "            # Baseline (first half-hour)\n",
    "            base = group_data_obs[group_data_obs[var_x] < 0.5][var_y].mean(skipna=True)\n",
    "    \n",
    "            if not np.isfinite(base):\n",
    "                # skip this flight if no baseline\n",
    "                continue\n",
    "    \n",
    "            for h in range(1, max_hour + 1):\n",
    "                # Hour bin: (h, h+0.5] to match your previous style (>h & <h+0.5)\n",
    "                bin_mask = (group_data_obs[var_x] > h) & (group_data_obs[var_x] < (h + 0.5))\n",
    "                bin_mean = group_data_obs.loc[bin_mask, var_y].mean(skipna=True)\n",
    "    \n",
    "                if h not in per_hour_pct:\n",
    "                    per_hour_pct[h] = []\n",
    "    \n",
    "                if np.isfinite(bin_mean):\n",
    "                    pct = (1 - bin_mean / base) * 100.0\n",
    "                    per_hour_pct[h].append(pct)\n",
    "                else:\n",
    "                    per_hour_pct[h].append(np.nan)\n",
    "    \n",
    "        # Print summary for each hour (mean ± std across flights)\n",
    "        for h in sorted(per_hour_pct.keys()):\n",
    "            arr = np.array(per_hour_pct[h], dtype=float)\n",
    "            mean_h = np.nanmean(arr)\n",
    "            std_h  = np.nanstd(arr)\n",
    "            print(f'HONO consumed by hour {h}: {mean_h:.1f}±{std_h:.1f}% (relative to <0.5 h baseline)')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # --------------------------------------\n",
    "    # Average NEMR O3 per hour in each plume\n",
    "    # --------------------------------------\n",
    "    if (var_x == 'Plume_Age' or 'output' in var_x) and var_y == 'NEMR_O3':\n",
    "        nemr_o3_rate = {}\n",
    "        # Calculate the slope\n",
    "        for flight_id in all_data_obs['Flight_ID'].unique():\n",
    "            all_data_obs_each = all_data_obs[all_data_obs['Flight_ID'] == flight_id]\n",
    "            x = (all_data_obs_each[var_x]).astype(float)\n",
    "            y = (all_data_obs_each[var_y]).astype(float)\n",
    "            \n",
    "            # Remove NaN values\n",
    "            mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "            x_clean = x[mask]\n",
    "            y_clean = y[mask]\n",
    "            \n",
    "            #if len(x_clean) > 1 and len(y_clean) > 1:  # Ensure there are enough points to perform regression\n",
    "            #    # Use np.linalg.lstsq to force the intercept to zero\n",
    "            #    slope_obs_each, _, _, _ = np.linalg.lstsq(x_clean[:, np.newaxis], y_clean, rcond=None)\n",
    "            #    slope_obs_each = slope_obs_each[0]\n",
    "            #    nemr_o3_rate[flight_id] = slope_obs_each\n",
    "\n",
    "\n",
    "            # convert to numpy arrays (to allow multidimensional indexing)\n",
    "            x_arr = x_clean.to_numpy()\n",
    "            y_arr = y_clean.to_numpy()\n",
    "            mask = ~np.isnan(x_arr) & ~np.isnan(y_arr)\n",
    "        \n",
    "            if np.sum(mask) > 1:  # ensure at least two valid points\n",
    "                x_fit = x_arr[mask][:, None]\n",
    "                y_fit = y_arr[mask]\n",
    "                # least‐squares with zero intercept\n",
    "                slope_obs_each, _, _, _ = np.linalg.lstsq(x_fit, y_fit, rcond=None)\n",
    "                slope_obs_each = slope_obs_each[0]\n",
    "                nemr_o3_rate[flight_id] = slope_obs_each\n",
    "        print(f'This is NEMR O3 rate (ppb/h)')\n",
    "        rounded_nemr_o3_rate = {key: round(value, 2) for key, value in nemr_o3_rate.items()}\n",
    "        print(rounded_nemr_o3_rate)\n",
    "\n",
    "    if (var_x == 'Plume_Age') and (('NEMR_O3' in var_y) or ('NEMR_PAN' in var_y)):\n",
    "        # ---------------------------------\n",
    "        # Average NEMR O3 from observations\n",
    "        # ---------------------------------\n",
    "        if var_y in ['NEMR_O3', 'NEMR_PAN']:\n",
    "            scale = 100\n",
    "            unit  = '%'\n",
    "        elif var_y in ['NEMR_O3_rate', 'NEMR_PAN_rate']:\n",
    "            scale = 100\n",
    "            unit  = '% per hour'\n",
    "        else:\n",
    "            scale = 1\n",
    "            unit = 'undefined'            \n",
    "        nemr_mean          = all_data_obs[var_y].describe()['mean'] *scale\n",
    "        nemr_std           = all_data_obs[var_y].describe()['std'] * scale\n",
    "        nemr_max, nemr_min = all_data_obs[var_y].describe()['max'] * scale, all_data_obs[var_y].describe()['min'] * scale\n",
    "        mean_lagrangian_dummy = np.array(mean_lagrangian) * scale\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'The range of {var_y} for Lagarangian flights: {np.min(mean_lagrangian_dummy):.1f}, {np.max(mean_lagrangian_dummy):.1f}{unit}')\n",
    "        print(f'The stat of {var_y} for Lagarangian flights: {np.mean(mean_lagrangian_dummy):.1f}±{np.std(mean_lagrangian_dummy):.1f}{unit}')\n",
    "        print(f'The range of {var_y} for all flights: {nemr_min:.1f}{unit}, {nemr_max:.1f}{unit}')\n",
    "        print(f'The stat of {var_y} for all flights: {nemr_mean:.1f}±{nemr_std:.1f}{unit}')\n",
    "    # --------------------\n",
    "    # Reference datapoints\n",
    "    # --------------------\n",
    "    if var_y == 'NEMR_O3' and var_x == 'Plume_Age':\n",
    "        # Set up data points and their references\n",
    "        x_points = [0.5, 2, 4.5, 0.5, 2, 1, 1, 2, 1]\n",
    "        y_points = [0.015, 0.08, 0.09, 0.015,0.1, 0.09, 0.15, 0.078, 0.1]\n",
    "        markers = ['*', 's', 'P', 'P', 'P', '^', '^', '^', 'D']\n",
    "        labels = ['Hobbs et al.', 'Goode et al.', 'Akagi et al.', 'Akagi et al.', 'Akagi et al.', 'Yokelson et al.', 'Yokelson et al.', 'Yokelson et al.', 'Liu et al.']\n",
    "        arrow_lengths = [0.4, 0.12, 0.25, 0.25, 0.25, 0.2, 0.2, 0.2, 0.2]  # Example lengths in pixels\n",
    "        x_max, y_max  = ax.get_xlim()[1], ax.get_ylim()[1]\n",
    "        \n",
    "        '''\n",
    "        labels = ['Hobbs et al. (1996)', 'Goode  et al. (2000)', 'Akagi et al. (2011)',  'Akagi et al. (2012)', \n",
    "                  #'Akagi et al. (2013)', \n",
    "                  'Akagi et al. (2013)', 'Yokelson et al. (2003)', 'Yokelson et al. (2003)', 'Yokelson et al. (2009)', 'Liu et al. (2016)']\n",
    "        markers = ['*', 's', 'P', \n",
    "                   #'^', \n",
    "                   '^', 'D', 'D', 'X', 'h']\n",
    "        '''\n",
    "        # Track labels that have been annotated\n",
    "        annotated_labels = set() \n",
    "        # Mute the markers for ozone NEMR\n",
    "        #for xp, yp, label, marker, length in zip(x_points, y_points, labels, markers, arrow_lengths):\n",
    "        #    # Plot the scatters\n",
    "        #    ax.scatter(xp, yp, marker=marker, color='black', s=100, label='_nolegend_')  # Ensure markers are visible\n",
    "        #    # Define a consistent direction (e.g., upward-right)\n",
    "        #    direction = np.array([1, 2])\n",
    "        #    direction_norm = direction / np.linalg.norm(direction)\n",
    "        #    offset = direction_norm * length\n",
    "        #    offset_x, offset_y = offset[0]*x_max, offset[1]*y_max\n",
    "            \n",
    "            #Mute the arorws to make Lu happy\n",
    "    \n",
    "            #if label not in annotated_labels:\n",
    "            #    ax.annotate(label, xy=(xp, yp), \n",
    "            #                xytext=(xp+offset_x, yp + offset_y),  # Adjusting the text position relative to the data point\n",
    "            #                textcoords='data', fontsize=14,\n",
    "            #                arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            #                ha='left')\n",
    "            #    annotated_labels.add(label)  # Mark label as annotated\n",
    "            \n",
    "    # ----------------------------\n",
    "    # Calculate e-folding lifetime\n",
    "    # ----------------------------\n",
    "    def calculate_efolding_lifetime(df, var_x, var_y, flight_id):\n",
    "        \"\"\"\n",
    "        Calculates and prints the e-folding lifetime of a given variable (compound concentration) against time.\n",
    "        \"\"\"\n",
    "        # Filtering out non-positive concentrations for log transformation\n",
    "        df_filtered = df[df[var_y] > 0]\n",
    "        if df_filtered.empty:\n",
    "            print(f\"Skipping {flight_id} for {var_y} because no data is available after filtering.\")\n",
    "            return\n",
    "    \n",
    "        # Calculate natural log of concentration\n",
    "        ln_conc = np.log(df_filtered[var_y])\n",
    "        # Perform linear regression\n",
    "        slope, _, _, _, _ = linregress(df_filtered[var_x], ln_conc)\n",
    "        # Calculate e-folding lifetime (tau)\n",
    "        if slope != 0:\n",
    "            tau = -1 / slope\n",
    "            print(f\"E-folding lifetime ({flight_id}): {tau:.1f} hours ({var_y})\")\n",
    "        else:\n",
    "            print(f\"Skipping calculation for {flight_id} as slope is zero, leading to division by zero.\")\n",
    "\n",
    "    #VOC_list = ['Furanoids (dil)', 'Acrolein (dil)', '1,3-Butadiene (dil)', 'Formaldehyde (dil)', 'Acetaldehyde (dil)', 'Maleic anhydride (dil)']\n",
    "    VOC_list = ['Furanoids excl.', 'BIACET']\n",
    "\n",
    "    for flight_id in all_data_obs_combined['Flight_ID'].unique():\n",
    "        if var_x == 'Plume_Age' and var_y in VOC_list:\n",
    "            df_each_obs = all_data_obs_lagrangian[all_data_obs_lagrangian['Flight_ID'] == flight_id]\n",
    "            df_each_mod = all_data_mcm_bbvoc[all_data_mcm_bbvoc['Flight_ID'] == flight_id]\n",
    "            print('Observed efolding lifetime')\n",
    "            calculate_efolding_lifetime(df_each_obs, 'Plume_Age', var_y, flight_id)\n",
    "            print('Modeled efolding lifetime')\n",
    "            calculate_efolding_lifetime(df_each_mod, 'Plume_Age', var_y, flight_id)\n",
    "            print()\n",
    "    # ===============================================\n",
    "    # Define the NMB data for three different models\n",
    "    # ===============================================\n",
    "    nmb_data = {\n",
    "        f'$MCM_{{BBVOC}}$':nmb_values_mcm_bbvoc,\n",
    "        f'$MCM_{{GCVOC}}$': nmb_values_mcm_gcvoc,\n",
    "        'GEOS-Chem': nmb_values_gc,\n",
    "    }\n",
    "    # Create a DataFrame from the dictionary\n",
    "    df_nmb = pd.DataFrame(nmb_data)\n",
    "    print()\n",
    "    print(f'{var_y} vs {var_x} (NMB)')\n",
    "    if df_nmb.isna().any().any() or np.isinf(df_nmb).any().any():\n",
    "        print(\"Data contains NaN or Infinite values, handling...\")\n",
    "    \n",
    "        # Step 2: Handle NaNs and Infinite values\n",
    "        df_nmb = df_nmb.fillna(0)  # Replace NaNs with 0 or another appropriate value\n",
    "        df_nmb.replace([np.inf, -np.inf], 0, inplace=True)  # Replace infinities if necessary\n",
    "    # Step 3: Convert to integer safely\n",
    "    df_nmb = df_nmb.astype(int)\n",
    "\n",
    "    print(df_nmb.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d490968-f889-4673-a616-821522fa0533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# How many HONO will be consumed with the first hour of plume aging?\n",
    "# -----------------------------------------------------------------\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8*4, 6*1), sharex=True)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_HONO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "'''\n",
    "var_x, var_y = 'Plume_Age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "var_x, var_y = 'Plume_Age', 'NOx: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[2], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "var_x, var_y = 'Plume_Age', 'OHRnox: OHRvoc'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[3], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "'''\n",
    "# Close the figure to prevent it from being displayed\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fda14-2fee-4899-95b3-7b8882ceb22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9d646-f4b7-4620-8718-141b24f38117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a9ea226-3fa7-4c7e-8376-547eff828be0",
   "metadata": {},
   "source": [
    "#### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de35e1f-a447-449e-9b36-c84473b3f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# ---------------------\n",
    "# OH calculation method\n",
    "# ---------------------\n",
    "# Plotting\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7.25, 3), sharey=False)\n",
    "# ==================================================\n",
    "# Calculated OH concentration vs direct model output\n",
    "# Analysis in the maintext\n",
    "# ==================================================\n",
    "# Select variable\n",
    "var_x_obs, var_y_obs = 'Plume_Age', 'cal_OH_mean'\n",
    "var_x_mod, var_y_mod = 'Plume_Age', 'output_OH'\n",
    "group_column = 'Flight_ID'\n",
    "set_ylabel=True\n",
    "show_legend=True\n",
    "title = 'Plume-center OH concentrations'\n",
    "# Legend\n",
    "legend_title = 'Flight ID'\n",
    "show_legend  = True\n",
    "# The slope of NEMR O3 vs plume age\n",
    "mean_lagrangian = []\n",
    "nmb_values_mcm_bbvoc = {}\n",
    "nmb_values_mcm_gcvoc = {}\n",
    "nmb_values_gc = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time = {}\n",
    "nmb_values_mcm_gcvoc_less_time = {}\n",
    "nmb_values_gc_less_time        = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_more_time = {}\n",
    "nmb_values_mcm_gcvoc_more_time = {}\n",
    "nmb_values_gc_more_time        = {}\n",
    "\n",
    "nmb_values_voc_numbers1 = {}\n",
    "nmb_values_voc_numbers2 = {}\n",
    "nmb_values_mechanisms  = {}\n",
    "color_flight = {}\n",
    "# Set up colors\n",
    "unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "unique_groups = np.array(['P-3B', 'RF03', 'RF07', 'RF09', 'FN19', 'Other WE-CAN flights'])\n",
    "\n",
    "if len(unique_groups) == 6:\n",
    "    group_colors = np.array([\n",
    "        [0.80645161, 1.0, 0.16129032, 1.0],\n",
    "        [0.5, 0.0, 0.0, 1.0],\n",
    "        [0.0, 0.0, 0.5, 1.0],\n",
    "        [0.0, 0.3, 1.0, 1.0],\n",
    "        [1.0, 0.40740741, 0.0, 1.0],\n",
    "        [0.16129032, 1.0, 0.80645161, 1.0],\n",
    "    ])\n",
    "\n",
    "    group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "\n",
    "for idx, group in enumerate(unique_groups):\n",
    "    '''\n",
    "    # Skip P-3B for calculated chemical age\n",
    "    if group == 'P-3B' and conditions:\n",
    "        print('skip P-3B for its unresonable chemical age')\n",
    "        continue\n",
    "    '''\n",
    "    group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]\n",
    "    group_data_obs  = group_data_obs.dropna(subset=[var_x_obs, var_y_obs])\n",
    "    x_obs, y_obs    = (group_data_obs[var_x_obs]).astype(float), (group_data_obs[var_y_obs]).astype(float)\n",
    "\n",
    "    \n",
    "    if group == 'RF07': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.541500] # Based on CO and HONO\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    if group == 'RF09': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.744000,  4.620500, 4.093667] #4.391833,\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "    \n",
    "    # Plot observational data if available\n",
    "    if valid_indices.any():\n",
    "        # Determine if the circle should be solid or open based on the flight\n",
    "        face_color = group_colors[idx]\n",
    "        # Plot dots even they are not in Lagrangian flights\n",
    "        if group_column == 'Flight_ID': \n",
    "            if group not in Lagrangian_flights: continue\n",
    "            \n",
    "            '''\n",
    "            face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "            axes.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "            '''\n",
    "            \n",
    "            # Determine the face color based on the flight\n",
    "            edge_color  = group_colors[idx]  # Color from your color map\n",
    "            marker_size = 8  # Adjust this value as needed\n",
    "            alpha_value = 1\n",
    "            #edge_color = \"none\" # comment it out if we want to remove dots\n",
    "            \n",
    "            if group in ['RF03', 'RF07', 'RF09']:\n",
    "                edge_color  = edge_color\n",
    "                face_color  = edge_color  # Use the edge color to fill markers\n",
    "                #face_color = \"none\"  # comment it out if we want to remove dots\n",
    "                linewidth  = 2\n",
    "            else:\n",
    "                edge_color = \"none\"\n",
    "                face_color = \"none\"  # remove dots\n",
    "                linewidth  = 2\n",
    "\n",
    "            # Plot actual scatter data with hollow markers\n",
    "            axes[0].scatter(x_obs[valid_indices], y_obs[valid_indices]/1E6, edgecolors=edge_color, facecolors=face_color, label='_nolegend_', s=marker_size, alpha=alpha_value)\n",
    "            # Plot dummy scatter just for creating the legend entry\n",
    "            axes[0].scatter([], [], edgecolors=group_colors[idx], facecolors=group_colors[idx], label=id2fire_name.get(group, group), s=8)\n",
    "\n",
    "        \n",
    "        # Perform linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "\n",
    "    # Group model results with flight ID instead.\n",
    "    if (group_column == 'Flight_ID') and (group in Lagrangian_flights):\n",
    "        group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "        group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "        group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "        # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "        # Assuming Plume_Age is in hours, 0.25 hours is equivalent to 15 minutes\n",
    "        bin_size = 0.25  # 15 minutes in hours\n",
    "        group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        group_data_gc_binned             = group_data_gc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x_mod]).astype(float), (group_data_mcm_bbvoc_binned[var_y_mod]).astype(float)\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x_mod]).astype(float), (group_data_mcm_gcvoc_binned[var_y_mod]).astype(float)\n",
    "        x_gc, y_gc               = (group_data_gc_binned[var_x_mod]).astype(float), (group_data_gc_binned[var_y_mod]).astype(float)\n",
    "        \n",
    "        '''\n",
    "        group_data_mcm_bbvoc_dummy = group_data_mcm_bbvoc[['Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "        group_data_mcm_gcvoc_dummy = group_data_mcm_gcvoc[['Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "        group_data_gc_dummy = group_data_gc[['Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "        group_data_mcm_bbvoc_binned = bin_df(group_data_mcm_bbvoc_dummy, bin_size)\n",
    "        group_data_mcm_gcvoc_binned = bin_df(group_data_mcm_gcvoc_dummy, bin_size)\n",
    "        group_data_gc_binned        = bin_df(group_data_gc_dummy, bin_size)\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[(var_x_mod, stat)]).astype(float), (group_data_mcm_bbvoc_binned[(var_y_mod, stat)]).astype(float)\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[(var_x_mod, stat)]).astype(float), (group_data_mcm_gcvoc_binned[(var_y_mod, stat)]).astype(float)\n",
    "        x_gc, y_gc               = (group_data_gc_binned[(var_x_mod, stat)]).astype(float), (group_data_gc_binned[(var_y_mod, stat)]).astype(float)\n",
    "        '''\n",
    "        \n",
    "        valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                            ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                            ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "        x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "\n",
    "        # Add solid lines for model output\n",
    "        if valid_indices_mod.any():\n",
    "            axes[0].plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', linewidth = linewidth)\n",
    "            axes[0].plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', linewidth = linewidth) # make Lu happy\n",
    "            axes[0].plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy       \n",
    "        else:\n",
    "            axes[0].plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes[0].plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes[0].plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy\n",
    "        # ---------------------------------------------\n",
    "        # Calculate the model error\n",
    "        # Use the same bin in S1 for result consistency\n",
    "        # ---------------------------------------------  \n",
    "\n",
    "        x_mcm_bbvoc = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == group].index\n",
    "        y_mcm_bbvoc = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "        y_mcm_gcvoc = df_OH_mod_mcm_gcvoc_bin[df_OH_mod_mcm_gcvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "        y_gc        = df_OH_mod_gc_bin[df_OH_mod_mcm_gcvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Only when observation exists\n",
    "        if valid_indices.any():\n",
    "            # Define the degree of the polynomial model       \n",
    "            degree = 2\n",
    "            # Create a polynomial regression model\n",
    "            poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "            # Fit the polynomial regression model on observational data\n",
    "            poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "            # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "            x_model       = x_mcm_bbvoc\n",
    "            y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "        # Using mcmbbvoc as the observation\n",
    "        else:\n",
    "            y_predicted = y_mcm_bbvoc\n",
    "\n",
    "        # Calculate Normalized Median Bias (NMB)        \n",
    "        #nmb_mcm_bbvoc   = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_mcm_gcvoc   = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_gc          = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        nmb_mcm_bbvoc   = 100 *  np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_mcm_gcvoc   = 100 *  np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_gc          = 100 *  np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "\n",
    "        #if group == 'RF03':\n",
    "        #    print(nmb_mcm_bbvoc)\n",
    "        #    print(y_mcm_bbvoc)\n",
    "        #    test_stop\n",
    "        \n",
    "        # Define a new set of valid indices where x_obs is less than 2\n",
    "        indices_less_time       = x_model < 2.5        \n",
    "        #nmb_mcm_bbvoc_less_time = 100 * (np.nanmedian(y_mcm_bbvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_mcm_gcvoc_less_time = 100 * (np.nanmedian(y_mcm_gcvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_gc_less_time        = 100 * (np.nanmedian(y_gc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        nmb_mcm_bbvoc_less_time = 100 * np.nansum(y_mcm_bbvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_mcm_gcvoc_less_time = 100 * np.nansum(y_mcm_gcvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_gc_less_time        = 100 * np.nansum(y_gc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "\n",
    "\n",
    "        # Define a new set of valid indices where x_obs is more than 2\n",
    "        indices_more_time       = x_model >= 2.5        \n",
    "        nmb_mcm_bbvoc_more_time = 100 * np.nansum(y_mcm_bbvoc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "        nmb_mcm_gcvoc_more_time = 100 * np.nansum(y_mcm_gcvoc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "        nmb_gc_more_time        = 100 * np.nansum(y_gc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "\n",
    "        \n",
    "        # Calculate differences among models\n",
    "        #nmb_voc_numbers1= 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_voc_numbers2= 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_mechanisms  = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_gcvoc)) / np.nanmedian(y_mcm_gcvoc)\n",
    "        nmb_voc_numbers1= 100 * np.nansum(y_mcm_gcvoc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_voc_numbers2= 100 * np.nansum(y_gc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_mechanisms  = 100 * np.nansum(y_gc - y_mcm_gcvoc) / np.nansum(y_mcm_gcvoc)\n",
    "        \n",
    "        # After calculating NMB\n",
    "        nmb_values_mcm_bbvoc[group]   = nmb_mcm_bbvoc\n",
    "        nmb_values_mcm_gcvoc[group]   = nmb_mcm_gcvoc\n",
    "        nmb_values_gc[group]          = nmb_gc\n",
    "\n",
    "        nmb_values_mcm_bbvoc_less_time[group]   = nmb_mcm_bbvoc_less_time\n",
    "        nmb_values_mcm_gcvoc_less_time[group]   = nmb_mcm_gcvoc_less_time\n",
    "        nmb_values_gc_less_time[group]          = nmb_gc_less_time\n",
    "\n",
    "        nmb_values_mcm_bbvoc_more_time[group]   = nmb_mcm_bbvoc_more_time\n",
    "        nmb_values_mcm_gcvoc_more_time[group]   = nmb_mcm_gcvoc_more_time\n",
    "        nmb_values_gc_more_time[group]          = nmb_gc_more_time\n",
    "        \n",
    "        nmb_values_voc_numbers1[group]= nmb_voc_numbers1\n",
    "        nmb_values_voc_numbers2[group]= nmb_voc_numbers2\n",
    "        nmb_values_mechanisms[group]  = nmb_mechanisms\n",
    "        color_flight[group]           = group_colors[idx]\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Annotation settings\n",
    "# -------------------\n",
    "# Calculate median and interquartile range (IQR)\n",
    "nmb_values_mcm_bbvoc_array    = np.array(list(nmb_values_mcm_bbvoc.values()), dtype=float)\n",
    "nmb_values_mcm_gcvoc_array    = np.array(list(nmb_values_mcm_gcvoc.values()), dtype=float)\n",
    "nmb_values_gc_array           = np.array(list(nmb_values_gc.values()), dtype=float)\n",
    "nmb_values_voc_numbers1_array = np.array(list(nmb_values_voc_numbers1.values()), dtype=float)\n",
    "nmb_values_voc_numbers2_array = np.array(list(nmb_values_voc_numbers2.values()), dtype=float)\n",
    "nmb_values_mechanisms_array   = np.array(list(nmb_values_mechanisms.values()), dtype=float)\n",
    "\n",
    "\n",
    "median_mcm_bbvoc, q1_mcm_bbvoc, q3_mcm_bbvoc          = np.nanmedian(nmb_values_mcm_bbvoc_array), np.nanpercentile(nmb_values_mcm_bbvoc_array, 25), np.nanpercentile(nmb_values_mcm_bbvoc_array, 75)\n",
    "median_mcm_gcvoc, q1_mcm_gcvoc, q3_mcm_gcvoc          = np.nanmedian(nmb_values_mcm_gcvoc_array), np.nanpercentile(nmb_values_mcm_gcvoc_array, 25), np.nanpercentile(nmb_values_mcm_gcvoc_array, 75)\n",
    "median_gc, q1_gc, q3_gc                               = np.nanmedian(nmb_values_gc_array), np.nanpercentile(nmb_values_gc_array, 25), np.nanpercentile(nmb_values_gc_array, 75)\n",
    "median_voc_numbers1, q1_voc_numbers1, q3_voc_numbers1 = np.nanmedian(nmb_values_voc_numbers1_array), np.nanpercentile(nmb_values_voc_numbers1_array, 25), np.nanpercentile(nmb_values_voc_numbers1_array, 75)\n",
    "median_voc_numbers2, q1_voc_numbers2, q3_voc_numbers2 = np.nanmedian(nmb_values_voc_numbers2_array), np.nanpercentile(nmb_values_voc_numbers2_array, 25), np.nanpercentile(nmb_values_voc_numbers2_array, 75)\n",
    "median_mechanisms, q1_mechanisms, q3_mechanisms       = np.nanmedian(nmb_values_mechanisms_array), np.nanpercentile(nmb_values_mechanisms_array, 25), np.nanpercentile(nmb_values_mechanisms_array, 75)\n",
    "\n",
    "iqr_mcm_bbvoc    = q3_mcm_bbvoc - q1_mcm_bbvoc\n",
    "iqr_mcm_gcvoc    = q3_mcm_gcvoc - q1_mcm_gcvoc\n",
    "iqr_gc           = q3_gc - q1_gc\n",
    "iqr_voc_numbers1 = q3_voc_numbers1 - q1_voc_numbers1\n",
    "iqr_voc_numbers2 = q3_voc_numbers2 - q1_voc_numbers2\n",
    "iqr_mechanisms   = q3_mechanisms - q1_mechanisms\n",
    "# Calculate mean and standard deviation\n",
    "mean_mcm_bbvoc, std_mcm_bbvoc       = np.nanmean(nmb_values_mcm_bbvoc_array), np.nanstd(nmb_values_mcm_bbvoc_array)\n",
    "mean_mcm_gcvoc, std_mcm_gcvoc       = np.nanmean(nmb_values_mcm_gcvoc_array), np.nanstd(nmb_values_mcm_gcvoc_array)\n",
    "mean_gc, std_gc                     = np.nanmean(nmb_values_gc_array), np.nanstd(nmb_values_gc_array)\n",
    "mean_voc_numbers1, std_voc_numbers1 = np.nanmean(nmb_values_voc_numbers1_array), np.nanstd(nmb_values_voc_numbers1_array)\n",
    "mean_voc_numbers2, std_voc_numbers2 = np.nanmean(nmb_values_voc_numbers2_array), np.nanstd(nmb_values_voc_numbers2_array)\n",
    "mean_mechanisms, std_mechanisms     = np.nanmean(nmb_values_mechanisms_array), np.nanstd(nmb_values_mechanisms_array)\n",
    "\n",
    "'''\n",
    "# Annotate mean ± std in each subplot\n",
    "# Determine if we want to show bias for each individual flights or the average of flights.\n",
    "xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "axes.annotate(f\"NMB:({median_mcm_bbvoc:.0f}±{iqr_mcm_bbvoc:.0f})%\", \n",
    "             xy=xy,  # Position of the annotation\n",
    "             xycoords='axes fraction',\n",
    "             ha=ha, va=va,  # Alignment of the text\n",
    "             fontsize=20,  # Font size of the text\n",
    "             color=color)  # Color of the text\n",
    "'''\n",
    "\n",
    "\n",
    "# Desired order of keys\n",
    "desired_order = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']\n",
    "# Desired order of keys\n",
    "nmb_values_mcm_bbvoc_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc[key]) for key in desired_order if key in nmb_values_mcm_bbvoc)\n",
    "nmb_values_mcm_gcvoc_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc[key]) for key in desired_order if key in nmb_values_mcm_gcvoc)\n",
    "nmb_values_gc_ordered           = OrderedDict((key, nmb_values_gc[key]) for key in desired_order if key in nmb_values_gc)\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_less_time)\n",
    "nmb_values_mcm_gcvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_less_time)\n",
    "nmb_values_gc_less_time_ordered           = OrderedDict((key, nmb_values_gc_less_time[key]) for key in desired_order if key in nmb_values_gc_less_time)\n",
    "\n",
    "nmb_values_mcm_bbvoc_more_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_more_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_more_time)\n",
    "nmb_values_mcm_gcvoc_more_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_more_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_more_time)\n",
    "nmb_values_gc_more_time_ordered           = OrderedDict((key, nmb_values_gc_more_time[key]) for key in desired_order if key in nmb_values_gc_more_time)\n",
    "\n",
    "nmb_values_voc_numbers1_ordered = OrderedDict((key, nmb_values_voc_numbers1[key]) for key in desired_order if key in nmb_values_voc_numbers1)\n",
    "nmb_values_voc_numbers2_ordered = OrderedDict((key, nmb_values_voc_numbers2[key]) for key in desired_order if key in nmb_values_voc_numbers2)\n",
    "nmb_values_mechanisms_ordered   = OrderedDict((key, nmb_values_mechanisms[key]) for key in desired_order if key in nmb_values_mechanisms)\n",
    "\n",
    "for idx, group in enumerate(nmb_values_mcm_bbvoc_ordered):\n",
    "    # Extract the name and perform the split operation outside the f-string\n",
    "    nmb_value_mcm_bbvoc    = nmb_values_mcm_bbvoc_ordered[group]\n",
    "    nmb_value_mcm_gcvoc    = nmb_values_mcm_gcvoc_ordered[group]\n",
    "    nmb_value_gc           = nmb_values_gc_ordered[group]\n",
    "    nmb_value_voc_numbers1 = nmb_values_voc_numbers1_ordered[group]\n",
    "    nmb_value_voc_numbers2 = nmb_values_voc_numbers2_ordered[group]\n",
    "    nmb_value_mechanisms   = nmb_values_mechanisms_ordered[group]\n",
    "    color     = color_flight[group]\n",
    "    # Check if the group requires a box\n",
    "    if group in ['FN19', 'RF03']:\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"none\", lw=2, ec=color, alpha=0.7)\n",
    "    else:\n",
    "        bbox_props = None\n",
    "# Assuming you want to align floating-point numbers with up to 1 decimal place\n",
    "max_width = 2  # total digits for integer part\n",
    "decimal_places = 0  # digits after decimal\n",
    "start_y = 0.4\n",
    "\n",
    "\n",
    "# Showing NMB for RF03 with white background for text\n",
    "axes[0].annotate(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=8,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.07),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=8,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"GEOS-Chem: {nmb_values_gc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.14),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=8,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "'''\n",
    "print(\"-----------------------------------\")\n",
    "print(\"RF03 (<2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "\n",
    "print(\"RF07 (>2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "print(\"RF09  (<2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(\"-----------------------------------\")\n",
    "'''\n",
    "\n",
    "# --------------------\n",
    "# Reference datapoints\n",
    "# --------------------\n",
    "x_points = [40/60, 40/60, 1.2, 20/60, 21/60, 45/60, 53/60, 56/60, 32/60]\n",
    "y_points = [1.7E7, 1.14E7, 4.1E6, 4E6, 8.9E6, 4E6, 3E6, 2.8E6, 3.5E6]\n",
    "labels = ['Hobbs et al. (2003)', 'Yokelson et al. (2009)', 'Yokelson et al. (2009)', 'Palm et al. (2021)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)']\n",
    "\n",
    "markers = ['*', 's', 's', 'P', '^', '^', '^', '^', '^']\n",
    "# Track labels that have been annotated\n",
    "annotated_labels = set()\n",
    "# Plot each point using corresponding marker and size\n",
    "for xp, yp, label, marker in zip(x_points, y_points, labels, markers):\n",
    "    axes[0].scatter(xp, yp/1E6, marker=marker, color='black', s=8, label='_nolegend_', zorder=888)  # Use corresponding marker\n",
    "    # Mute the annotation to make Lu happy\n",
    "    '''\n",
    "    # Annotate the first occurrence of each label with text and a longer arrow\n",
    "    if label not in annotated_labels:\n",
    "        axes[0].annotate(label, \n",
    "                    #xy=(xp, yp), xytext=(xp + 2, yp+8E6), \n",
    "                    xy=(xp, yp/1E6), xytext=(xp + 1, (yp+8E6)/1E6), \n",
    "                    textcoords='data', fontsize=14, \n",
    "                    arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "                    ha='left')\n",
    "        annotated_labels.add(label)  # Mark label as annotated\n",
    "    '''\n",
    "# --------------------\n",
    "# Print out analysis\n",
    "# Maintext analysis\n",
    "# --------------------\n",
    "# Function to calculate statistics for each hour time frame\n",
    "def calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour):\n",
    "    # Calculate the slope\n",
    "    slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress(filtered_data_obs[var_x_obs].astype(float), filtered_data_obs[var_y_obs].astype(float))\n",
    "    # Calculate the mean values and std err within the timeframe\n",
    "    mean_val, std_dev   = filtered_data_obs[var_y_obs].mean(), filtered_data_obs[var_y_obs].std()\n",
    "    median_val, iqr_val = filtered_data_obs[var_y_obs].median(), iqr(filtered_data_obs[var_y_obs])\n",
    "    min_value, max_value= __builtins__.min(filtered_data_obs[var_y_obs]), __builtins__.max(filtered_data_obs[var_y_obs])\n",
    "    if var_y_obs in ['output_OH', 'cal_OH_mean']: \n",
    "        unit  = '1E6 molec/cm3'\n",
    "        scale =  1/1E6\n",
    "    elif var_y_obs in ['NEMR_PAN', 'NEMR_PAN_rate']:\n",
    "        unit  = '%'\n",
    "        scale =  100\n",
    "    else:\n",
    "        unit  = 'non-defined'\n",
    "        scale =  1\n",
    "    \n",
    "    # Print the mean and standard deviation\n",
    "    print(f'Time Frame: {hour} hour')\n",
    "    print(f'The mean/std value ({unit}): {mean_val*scale:.1f}±{std_dev*scale:.1f}')\n",
    "    print(f'The median/iqr value ({unit}): {median_val*scale:.1f}±{iqr_val*scale:.1f}')\n",
    "    print(f'min and max value ({unit}): {min_value*scale:.1f}, {max_value*scale:.1f}')\n",
    "    print()\n",
    "\n",
    "# The observed OH concentration over the initial 40 minutes\n",
    "initial_minutes = 40 / 60  # Convert 40 minutes into hours for comparison with Plume_Age in hours\n",
    "# Filter data for the initial 40 minutes\n",
    "filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] <= initial_minutes)]\n",
    "filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "# Check if the DataFrame is not empty before proceeding\n",
    "if not filtered_data_obs.empty:\n",
    "    # Calculate statistics for the initial 40 minutes\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "else:\n",
    "    print(\"No data available for the initial 40 minutes.\")\n",
    "# Calculate it for each flight\n",
    "for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "    all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "    filtered_data_obs_each = all_data_obs_combined_each[all_data_obs_combined_each[var_x_obs] <= initial_minutes]\n",
    "    # Check if the DataFrame is empty\n",
    "    if not filtered_data_obs_each.empty:\n",
    "        print(f\"Calculating for Flight ID: {flight_id} for the initial 40 minutes\")\n",
    "        calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "    else:\n",
    "        print(f\"Skipping {flight_id} for the initial 40 minutes because the data is empty.\")\n",
    "\n",
    "# The observed OH concentration over time\n",
    "for hour in range(1, 6):\n",
    "    # Filter data for the current time frame\n",
    "    filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] > (hour - 1)) & (all_data_obs_combined[var_x_obs] < hour)]\n",
    "    filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "    # Calculate statistics for the current time frame\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour)\n",
    "\n",
    "    # Calculate it for each flight\n",
    "    for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "        all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "        filtered_data_obs_each     = all_data_obs_combined_each[(all_data_obs_combined_each[var_x_obs] > (hour - 1)) & (all_data_obs_combined_each[var_x_obs] < hour)]\n",
    "        # Check if the DataFrame is empty\n",
    "        if not filtered_data_obs_each.empty:\n",
    "            print(flight_id)\n",
    "            calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, hour)\n",
    "        else:\n",
    "            print(f\"Skipping {flight_id} at hour {hour} because the data is empty.\")\n",
    "\n",
    "# The model differences among model simulations\n",
    "# Print the mean +/- std\n",
    "print('Model differences among three model simulations')\n",
    "print(f'Mean ± Std (VOC init 1) : {nmb_values_voc_numbers1_array.mean():.0f} ± {nmb_values_voc_numbers1_array.std():.0f}')\n",
    "print(f'Mean ± Std (VOC init 2) : {nmb_values_voc_numbers2_array.mean():.0f} ± {nmb_values_voc_numbers2_array.std():.0f}')\n",
    "print(f'Mean ± Std (mechanism): {nmb_values_mechanisms_array.mean():.0f} ± {nmb_values_mechanisms_array.std():.0f}')\n",
    "\n",
    "# ----------------------------\n",
    "# Chemical age vs Physical age\n",
    "# ----------------------------\n",
    "# Define age segments and corresponding colors\n",
    "# Define age segments and corresponding colors\n",
    "age_segments = [(0, 0.5), (0.5, 1), (1, 1.5), (1.5, 2), (2, 2.5), (2.5, 3), (3, np.inf)]\n",
    "age_segments = [(0,  1), (1, 2), (2, 3), (3, 4), (4, 5), (5, np.inf)]\n",
    "#colors       = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange', 'tab:grey']\n",
    "colors = [\n",
    "    'tab:red',  # 🔴 Red (Vermilion – keep this)\n",
    "    '#0072B2',  # 🔵 Blue\n",
    "    '#CC79A7',  # 🟣 Purple (for contrast)\n",
    "    '#E69F00',   # 🟠 Orange (warm, distinct from red)\n",
    "    '#999999',  # ⚪ Gray (neutral)\n",
    "]\n",
    "# Set up figure and axes\n",
    "var_x = 'Plume_Age'\n",
    "var_y = 'output_chem_age'\n",
    "clean_data = all_data_mcm_bbvoc.dropna(subset=[var_x, var_y])\n",
    "\n",
    "\n",
    "# Resetting min and max if they were overridden\n",
    "try:\n",
    "    del min  # Only if 'min' was redefined\n",
    "    del max  # Only if 'max' was redefined\n",
    "except NameError as e:\n",
    "    print(\"Error:\", e)\n",
    "# Find the overall range for plotting the 1:1 line\n",
    "min_val = __builtins__.min(__builtins__.min(clean_data[var_x]), __builtins__.min(clean_data[var_y]))\n",
    "max_val = __builtins__.max(__builtins__.max(clean_data[var_x]), __builtins__.max(clean_data[var_y]))\n",
    "\n",
    "# Loop through each age segment\n",
    "for (start, end), color in zip(age_segments, colors):\n",
    "    segment = clean_data[(clean_data[var_x] >= start) & (clean_data[var_x] < end)]\n",
    "    bin_size = 30/60.0/60.0  # 15 minutes in hours, adjust if needed\n",
    "    segment['Time_Bin'] = (segment[var_x] // bin_size) * bin_size\n",
    "    segment_binned = segment.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "    axes[1].scatter(segment_binned[var_x], segment_binned[var_y], color=color, alpha=0.5, s=8)\n",
    "\n",
    "    if not segment.empty:\n",
    "        X = segment_binned[var_x].values.reshape(-1, 1)\n",
    "        y = segment_binned[var_y].values\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(X, y)\n",
    "        slope = model.coef_[0]\n",
    "        label = f'>{start} h: Slope={slope:.1f}' if np.isinf(end) else f'{start}-{end} h: Slope={slope:.1f}'\n",
    "        y_vals = np.linspace(0, segment_binned[var_y].max(), 100)\n",
    "        x_vals = y_vals / slope\n",
    "        axes[1].plot(x_vals, y_vals, color=color, label=label, linewidth=2)\n",
    "\n",
    "\n",
    "# Defalt setting for title, ticks, and labels\n",
    "axes[0].set_xlabel(text_labels.get(var_x_obs, var_x_obs), fontsize=8)\n",
    "axes[0].set_ylabel(text_labels.get(var_y_obs, var_y_obs), fontsize=8)\n",
    "axes[0].tick_params(axis='both', labelsize=8)\n",
    "axes[0].set_ylim(0, 3E7/1E6)  # Set y limits from min y to calculated upper limit\n",
    "# Set the x-axis limit\n",
    "axes[0].set_xlim([0, 5])  # None means no lower limit, 8 is the upper limit\n",
    "\n",
    "# Draw horizontal line and add annotation for the first subplot\n",
    "axes[0].axhline(y=1.5, color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "'''\n",
    "axes[0].annotate('Ambient OH level', fontsize=25,\n",
    "                 xy=(0.75, 1.2), xytext=(0.90, 1.2),\n",
    "                 textcoords='data', ha='center', va='top')\n",
    "'''\n",
    "# Legend\n",
    "show_legend=1\n",
    "if show_legend:\n",
    "    if group_column == 'Flight_ID':\n",
    "        desired_order = desired_order_flights\n",
    "        reorder_legend(axes[0], desired_order, id2fire_name, fontsize=6.4, legend_loc='upper right')\n",
    "        #reorder_legend(axes[0], desired_order, id2fire_name, fontsize=20, legend_loc='upper left')\n",
    "\n",
    "# Add the 1:1 line\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'k--', label='1:1 Line')\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=8)\n",
    "axes[1].set_xlabel('Physical age (hour)', fontsize=8)\n",
    "axes[1].set_ylabel('Chemical age (hour)', fontsize=8)\n",
    "axes[1].legend(fontsize=7)\n",
    "axes[1].yaxis.set_major_formatter(ScalarFormatter())  # Optional: To format the y-axis ticks into readable numbers\n",
    "axes[1].xaxis.set_major_formatter(ScalarFormatter())\n",
    "# Set x-axis ticks to every 2 hours\n",
    "axes[1].xaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "\n",
    "\n",
    "# Annotation for subplot (a)\n",
    "axes[0].text(0.05, 0.95, 'A', transform=axes[0].transAxes, fontsize=9, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Set y-axis limits\n",
    "#axes[0].set_ylim(0, 25)  # This sets the minimum to 0 and the maximum to 20\n",
    "axes[0].set_ylim(0, 25)  # This sets the minimum to 0 and the maximum to 20\n",
    "# Annotation for subplot (b)\n",
    "axes[1].text(0.05, 0.95, 'B', transform=axes[1].transAxes, fontsize=9, fontweight='bold', va='top', ha='left')\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "# Save the full figure in high resolution\n",
    "for fmt in ['pdf', 'jpeg', 'tiff']:  # Choose the formats you need\n",
    "    fig.savefig(f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/maintext_figures/Fig1_OH_TS.{fmt}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a006a91-2162-49e3-af9c-5840ae855435",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "var_x_obs, var_y_obs = 'Plume_Age', 'cal_OH_mean'\n",
    "var_x_mod, var_y_mod = 'Plume_Age', 'output_OH'\n",
    "test_obs = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == 'RF03'][[var_x_obs, var_y_obs]]\n",
    "test_mod = all_data_mcm_bbvoc[all_data_mcm_bbvoc['Flight_ID'] == 'RF03'][[var_x_mod, var_y_mod]]\n",
    "\n",
    "# Make sure both tables are sorted by time (required by merge_asof)\n",
    "test_obs = test_obs.sort_values(\"Plume_Age\")\n",
    "test_mod   = test_mod.sort_values(\"Plume_Age\")\n",
    "\n",
    "# Merge “as-of” → each obs row gets the model value at the *closest* age\n",
    "paired = pd.merge_asof(\n",
    "    test_obs,\n",
    "    test_mod,\n",
    "    on=\"Plume_Age\",\n",
    "    direction=\"nearest\",   # pick earlier or later, whichever is closer\n",
    "    tolerance=None         # or set e.g. tolerance=0.02 to require ≤0.02 h match\n",
    ")\n",
    "\n",
    "# Compute the fractional difference; keep NaNs where either value is missing\n",
    "paired[\"frac_diff\"] = (paired[\"output_OH\"] - paired[\"cal_OH_mean\"]) / paired[\"cal_OH_mean\"]\n",
    "\n",
    "print(paired[[\"Plume_Age\", \"cal_OH_mean\", \"output_OH\", \"frac_diff\"]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491059ba-70db-416e-9afa-4eadd5a0a482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c0d86-c2ec-4220-a427-f485344aa1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632f500-9c03-4f10-a560-c55b21c858c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e2351-d0c5-45fd-8122-4ef92afe646e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1755ce7-25a1-4933-96d3-751b790b745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# OH calculation method\n",
    "# ---------------------\n",
    "# Plotting\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12*2, 9), sharey=False)\n",
    "# ==================================================\n",
    "# Calculated OH concentration vs direct model output\n",
    "# Analysis in the maintext\n",
    "# ==================================================\n",
    "# Select variable\n",
    "var_x_obs, var_y_obs = 'Plume_Age', 'cal_OH_mean'\n",
    "var_x_mod, var_y_mod = 'Plume_Age', 'output_OH'\n",
    "group_column = 'Flight_ID'\n",
    "set_ylabel=True\n",
    "show_legend=True\n",
    "title = 'Plume-center OH concentrations'\n",
    "# Legend\n",
    "legend_title = 'Flight ID'\n",
    "show_legend  = True\n",
    "# The slope of NEMR O3 vs plume age\n",
    "mean_lagrangian = []\n",
    "nmb_values_mcm_bbvoc = {}\n",
    "nmb_values_mcm_gcvoc = {}\n",
    "nmb_values_gc = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time = {}\n",
    "nmb_values_mcm_gcvoc_less_time = {}\n",
    "nmb_values_gc_less_time        = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_more_time = {}\n",
    "nmb_values_mcm_gcvoc_more_time = {}\n",
    "nmb_values_gc_more_time        = {}\n",
    "\n",
    "nmb_values_voc_numbers1 = {}\n",
    "nmb_values_voc_numbers2 = {}\n",
    "nmb_values_mechanisms  = {}\n",
    "color_flight = {}\n",
    "# Set up colors\n",
    "unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "unique_groups = np.array(['P-3B', 'RF03', 'RF07', 'RF09', 'FN19', 'Other WE-CAN flights'])\n",
    "\n",
    "if len(unique_groups) == 6:\n",
    "    group_colors = np.array([\n",
    "        [0.80645161, 1.0, 0.16129032, 1.0],\n",
    "        [0.5, 0.0, 0.0, 1.0],\n",
    "        [0.0, 0.0, 0.5, 1.0],\n",
    "        [0.0, 0.3, 1.0, 1.0],\n",
    "        [1.0, 0.40740741, 0.0, 1.0],\n",
    "        [0.16129032, 1.0, 0.80645161, 1.0],\n",
    "    ])\n",
    "\n",
    "    group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "\n",
    "for idx, group in enumerate(unique_groups):\n",
    "    '''\n",
    "    # Skip P-3B for calculated chemical age\n",
    "    if group == 'P-3B' and conditions:\n",
    "        print('skip P-3B for its unresonable chemical age')\n",
    "        continue\n",
    "    '''\n",
    "    group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]\n",
    "    group_data_obs  = group_data_obs.dropna(subset=[var_x_obs, var_y_obs])\n",
    "    x_obs, y_obs    = (group_data_obs[var_x_obs]).astype(float), (group_data_obs[var_y_obs]).astype(float)\n",
    "\n",
    "    \n",
    "    if group == 'RF07': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.541500] # Based on CO and HONO\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    if group == 'RF09': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.744000,  4.620500, 4.093667] #4.391833,\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "    \n",
    "    # Plot observational data if available\n",
    "    if valid_indices.any():\n",
    "        # Determine if the circle should be solid or open based on the flight\n",
    "        face_color = group_colors[idx]\n",
    "        # Plot dots even they are not in Lagrangian flights\n",
    "        if group_column == 'Flight_ID': \n",
    "            if group not in Lagrangian_flights: continue\n",
    "            \n",
    "            '''\n",
    "            face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "            axes.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "            '''\n",
    "            \n",
    "            # Determine the face color based on the flight\n",
    "            edge_color  = group_colors[idx]  # Color from your color map\n",
    "            marker_size = 100  # Adjust this value as needed\n",
    "            alpha_value = 1\n",
    "            #edge_color = \"none\" # comment it out if we want to remove dots\n",
    "            \n",
    "            if group in ['RF03', 'RF07', 'RF09']:\n",
    "                edge_color  = edge_color\n",
    "                face_color  = edge_color  # Use the edge color to fill markers\n",
    "                #face_color = \"none\"  # comment it out if we want to remove dots\n",
    "                linewidth  = 5\n",
    "            else:\n",
    "                edge_color = \"none\"\n",
    "                face_color = \"none\"  # remove dots\n",
    "                linewidth  = 5\n",
    "\n",
    "            # Plot actual scatter data with hollow markers\n",
    "            axes[0].scatter(x_obs[valid_indices], y_obs[valid_indices]/1E6, edgecolors=edge_color, facecolors=face_color, label='_nolegend_', s=marker_size, alpha=alpha_value)\n",
    "            # Plot dummy scatter just for creating the legend entry\n",
    "            axes[0].scatter([], [], edgecolors=group_colors[idx], facecolors=group_colors[idx], label=id2fire_name.get(group, group), s=100)\n",
    "\n",
    "        \n",
    "        # Perform linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "\n",
    "    # Group model results with flight ID instead.\n",
    "    if (group_column == 'Flight_ID') and (group in Lagrangian_flights):\n",
    "        group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "        group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "        group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "        # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "        # Assuming Plume_Age is in hours, 0.25 hours is equivalent to 15 minutes\n",
    "        bin_size = 0.25  # 15 minutes in hours\n",
    "        group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        group_data_gc_binned             = group_data_gc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x_mod]).astype(float), (group_data_mcm_bbvoc_binned[var_y_mod]).astype(float)\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x_mod]).astype(float), (group_data_mcm_gcvoc_binned[var_y_mod]).astype(float)\n",
    "        x_gc, y_gc               = (group_data_gc_binned[var_x_mod]).astype(float), (group_data_gc_binned[var_y_mod]).astype(float)\n",
    "        \n",
    "        '''\n",
    "        group_data_mcm_bbvoc_dummy = group_data_mcm_bbvoc[['Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "        group_data_mcm_gcvoc_dummy = group_data_mcm_gcvoc[['Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "        group_data_gc_dummy = group_data_gc[['Plume_Age', 'cal_OH_mean', 'cal_OH_median', 'cal_OH_std', 'cal_OH_iqr', 'output_OH']]\n",
    "        group_data_mcm_bbvoc_binned = bin_df(group_data_mcm_bbvoc_dummy, bin_size)\n",
    "        group_data_mcm_gcvoc_binned = bin_df(group_data_mcm_gcvoc_dummy, bin_size)\n",
    "        group_data_gc_binned        = bin_df(group_data_gc_dummy, bin_size)\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[(var_x_mod, stat)]).astype(float), (group_data_mcm_bbvoc_binned[(var_y_mod, stat)]).astype(float)\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[(var_x_mod, stat)]).astype(float), (group_data_mcm_gcvoc_binned[(var_y_mod, stat)]).astype(float)\n",
    "        x_gc, y_gc               = (group_data_gc_binned[(var_x_mod, stat)]).astype(float), (group_data_gc_binned[(var_y_mod, stat)]).astype(float)\n",
    "        '''\n",
    "        \n",
    "        valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                            ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                            ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "        x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "\n",
    "        # Add solid lines for model output\n",
    "        if valid_indices_mod.any():\n",
    "            axes[0].plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', linewidth = linewidth)\n",
    "            axes[0].plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', linewidth = linewidth) # make Lu happy\n",
    "            #axes[0].plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy       \n",
    "        else:\n",
    "            axes[0].plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes[0].plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            #axes[0].plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy\n",
    "        # ---------------------------------------------\n",
    "        # Calculate the model error\n",
    "        # Use the same bin in S1 for result consistency\n",
    "        # ---------------------------------------------  \n",
    "\n",
    "        x_mcm_bbvoc = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == group].index\n",
    "        y_mcm_bbvoc = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "        y_mcm_gcvoc = df_OH_mod_mcm_gcvoc_bin[df_OH_mod_mcm_gcvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "        y_gc        = df_OH_mod_gc_bin[df_OH_mod_mcm_gcvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Only when observation exists\n",
    "        if valid_indices.any():\n",
    "            # Define the degree of the polynomial model       \n",
    "            degree = 2\n",
    "            # Create a polynomial regression model\n",
    "            poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "            # Fit the polynomial regression model on observational data\n",
    "            poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "            # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "            x_model       = x_mcm_bbvoc\n",
    "            y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "        # Using mcmbbvoc as the observation\n",
    "        else:\n",
    "            y_predicted = y_mcm_bbvoc\n",
    "\n",
    "        # Calculate Normalized Median Bias (NMB)        \n",
    "        #nmb_mcm_bbvoc   = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_mcm_gcvoc   = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_gc          = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        nmb_mcm_bbvoc   = 100 *  np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_mcm_gcvoc   = 100 *  np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_gc          = 100 *  np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "\n",
    "        #if group == 'RF03':\n",
    "        #    print(nmb_mcm_bbvoc)\n",
    "        #    print(y_mcm_bbvoc)\n",
    "        #    test_stop\n",
    "        \n",
    "        # Define a new set of valid indices where x_obs is less than 2\n",
    "        indices_less_time       = x_model < 2.5        \n",
    "        #nmb_mcm_bbvoc_less_time = 100 * (np.nanmedian(y_mcm_bbvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_mcm_gcvoc_less_time = 100 * (np.nanmedian(y_mcm_gcvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_gc_less_time        = 100 * (np.nanmedian(y_gc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        nmb_mcm_bbvoc_less_time = 100 * np.nansum(y_mcm_bbvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_mcm_gcvoc_less_time = 100 * np.nansum(y_mcm_gcvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_gc_less_time        = 100 * np.nansum(y_gc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "\n",
    "\n",
    "        # Define a new set of valid indices where x_obs is more than 2\n",
    "        indices_more_time       = x_model >= 2.5        \n",
    "        nmb_mcm_bbvoc_more_time = 100 * np.nansum(y_mcm_bbvoc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "        nmb_mcm_gcvoc_more_time = 100 * np.nansum(y_mcm_gcvoc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "        nmb_gc_more_time        = 100 * np.nansum(y_gc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "\n",
    "        \n",
    "        # Calculate differences among models\n",
    "        #nmb_voc_numbers1= 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_voc_numbers2= 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_mechanisms  = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_gcvoc)) / np.nanmedian(y_mcm_gcvoc)\n",
    "        nmb_voc_numbers1= 100 * np.nansum(y_mcm_gcvoc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_voc_numbers2= 100 * np.nansum(y_gc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_mechanisms  = 100 * np.nansum(y_gc - y_mcm_gcvoc) / np.nansum(y_mcm_gcvoc)\n",
    "        \n",
    "        # After calculating NMB\n",
    "        nmb_values_mcm_bbvoc[group]   = nmb_mcm_bbvoc\n",
    "        nmb_values_mcm_gcvoc[group]   = nmb_mcm_gcvoc\n",
    "        nmb_values_gc[group]          = nmb_gc\n",
    "\n",
    "        nmb_values_mcm_bbvoc_less_time[group]   = nmb_mcm_bbvoc_less_time\n",
    "        nmb_values_mcm_gcvoc_less_time[group]   = nmb_mcm_gcvoc_less_time\n",
    "        nmb_values_gc_less_time[group]          = nmb_gc_less_time\n",
    "\n",
    "        nmb_values_mcm_bbvoc_more_time[group]   = nmb_mcm_bbvoc_more_time\n",
    "        nmb_values_mcm_gcvoc_more_time[group]   = nmb_mcm_gcvoc_more_time\n",
    "        nmb_values_gc_more_time[group]          = nmb_gc_more_time\n",
    "        \n",
    "        nmb_values_voc_numbers1[group]= nmb_voc_numbers1\n",
    "        nmb_values_voc_numbers2[group]= nmb_voc_numbers2\n",
    "        nmb_values_mechanisms[group]  = nmb_mechanisms\n",
    "        color_flight[group]           = group_colors[idx]\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Annotation settings\n",
    "# -------------------\n",
    "# Calculate median and interquartile range (IQR)\n",
    "nmb_values_mcm_bbvoc_array    = np.array(list(nmb_values_mcm_bbvoc.values()), dtype=float)\n",
    "nmb_values_mcm_gcvoc_array    = np.array(list(nmb_values_mcm_gcvoc.values()), dtype=float)\n",
    "nmb_values_gc_array           = np.array(list(nmb_values_gc.values()), dtype=float)\n",
    "nmb_values_voc_numbers1_array = np.array(list(nmb_values_voc_numbers1.values()), dtype=float)\n",
    "nmb_values_voc_numbers2_array = np.array(list(nmb_values_voc_numbers2.values()), dtype=float)\n",
    "nmb_values_mechanisms_array   = np.array(list(nmb_values_mechanisms.values()), dtype=float)\n",
    "\n",
    "\n",
    "median_mcm_bbvoc, q1_mcm_bbvoc, q3_mcm_bbvoc          = np.nanmedian(nmb_values_mcm_bbvoc_array), np.nanpercentile(nmb_values_mcm_bbvoc_array, 25), np.nanpercentile(nmb_values_mcm_bbvoc_array, 75)\n",
    "median_mcm_gcvoc, q1_mcm_gcvoc, q3_mcm_gcvoc          = np.nanmedian(nmb_values_mcm_gcvoc_array), np.nanpercentile(nmb_values_mcm_gcvoc_array, 25), np.nanpercentile(nmb_values_mcm_gcvoc_array, 75)\n",
    "median_gc, q1_gc, q3_gc                               = np.nanmedian(nmb_values_gc_array), np.nanpercentile(nmb_values_gc_array, 25), np.nanpercentile(nmb_values_gc_array, 75)\n",
    "median_voc_numbers1, q1_voc_numbers1, q3_voc_numbers1 = np.nanmedian(nmb_values_voc_numbers1_array), np.nanpercentile(nmb_values_voc_numbers1_array, 25), np.nanpercentile(nmb_values_voc_numbers1_array, 75)\n",
    "median_voc_numbers2, q1_voc_numbers2, q3_voc_numbers2 = np.nanmedian(nmb_values_voc_numbers2_array), np.nanpercentile(nmb_values_voc_numbers2_array, 25), np.nanpercentile(nmb_values_voc_numbers2_array, 75)\n",
    "median_mechanisms, q1_mechanisms, q3_mechanisms       = np.nanmedian(nmb_values_mechanisms_array), np.nanpercentile(nmb_values_mechanisms_array, 25), np.nanpercentile(nmb_values_mechanisms_array, 75)\n",
    "\n",
    "iqr_mcm_bbvoc    = q3_mcm_bbvoc - q1_mcm_bbvoc\n",
    "iqr_mcm_gcvoc    = q3_mcm_gcvoc - q1_mcm_gcvoc\n",
    "iqr_gc           = q3_gc - q1_gc\n",
    "iqr_voc_numbers1 = q3_voc_numbers1 - q1_voc_numbers1\n",
    "iqr_voc_numbers2 = q3_voc_numbers2 - q1_voc_numbers2\n",
    "iqr_mechanisms   = q3_mechanisms - q1_mechanisms\n",
    "# Calculate mean and standard deviation\n",
    "mean_mcm_bbvoc, std_mcm_bbvoc       = np.nanmean(nmb_values_mcm_bbvoc_array), np.nanstd(nmb_values_mcm_bbvoc_array)\n",
    "mean_mcm_gcvoc, std_mcm_gcvoc       = np.nanmean(nmb_values_mcm_gcvoc_array), np.nanstd(nmb_values_mcm_gcvoc_array)\n",
    "mean_gc, std_gc                     = np.nanmean(nmb_values_gc_array), np.nanstd(nmb_values_gc_array)\n",
    "mean_voc_numbers1, std_voc_numbers1 = np.nanmean(nmb_values_voc_numbers1_array), np.nanstd(nmb_values_voc_numbers1_array)\n",
    "mean_voc_numbers2, std_voc_numbers2 = np.nanmean(nmb_values_voc_numbers2_array), np.nanstd(nmb_values_voc_numbers2_array)\n",
    "mean_mechanisms, std_mechanisms     = np.nanmean(nmb_values_mechanisms_array), np.nanstd(nmb_values_mechanisms_array)\n",
    "\n",
    "'''\n",
    "# Annotate mean ± std in each subplot\n",
    "# Determine if we want to show bias for each individual flights or the average of flights.\n",
    "xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "axes.annotate(f\"NMB:({median_mcm_bbvoc:.0f}±{iqr_mcm_bbvoc:.0f})%\", \n",
    "             xy=xy,  # Position of the annotation\n",
    "             xycoords='axes fraction',\n",
    "             ha=ha, va=va,  # Alignment of the text\n",
    "             fontsize=20,  # Font size of the text\n",
    "             color=color)  # Color of the text\n",
    "'''\n",
    "\n",
    "\n",
    "# Desired order of keys\n",
    "desired_order = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']\n",
    "# Desired order of keys\n",
    "nmb_values_mcm_bbvoc_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc[key]) for key in desired_order if key in nmb_values_mcm_bbvoc)\n",
    "nmb_values_mcm_gcvoc_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc[key]) for key in desired_order if key in nmb_values_mcm_gcvoc)\n",
    "nmb_values_gc_ordered           = OrderedDict((key, nmb_values_gc[key]) for key in desired_order if key in nmb_values_gc)\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_less_time)\n",
    "nmb_values_mcm_gcvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_less_time)\n",
    "nmb_values_gc_less_time_ordered           = OrderedDict((key, nmb_values_gc_less_time[key]) for key in desired_order if key in nmb_values_gc_less_time)\n",
    "\n",
    "nmb_values_mcm_bbvoc_more_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_more_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_more_time)\n",
    "nmb_values_mcm_gcvoc_more_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_more_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_more_time)\n",
    "nmb_values_gc_more_time_ordered           = OrderedDict((key, nmb_values_gc_more_time[key]) for key in desired_order if key in nmb_values_gc_more_time)\n",
    "\n",
    "nmb_values_voc_numbers1_ordered = OrderedDict((key, nmb_values_voc_numbers1[key]) for key in desired_order if key in nmb_values_voc_numbers1)\n",
    "nmb_values_voc_numbers2_ordered = OrderedDict((key, nmb_values_voc_numbers2[key]) for key in desired_order if key in nmb_values_voc_numbers2)\n",
    "nmb_values_mechanisms_ordered   = OrderedDict((key, nmb_values_mechanisms[key]) for key in desired_order if key in nmb_values_mechanisms)\n",
    "\n",
    "for idx, group in enumerate(nmb_values_mcm_bbvoc_ordered):\n",
    "    # Extract the name and perform the split operation outside the f-string\n",
    "    nmb_value_mcm_bbvoc    = nmb_values_mcm_bbvoc_ordered[group]\n",
    "    nmb_value_mcm_gcvoc    = nmb_values_mcm_gcvoc_ordered[group]\n",
    "    nmb_value_gc           = nmb_values_gc_ordered[group]\n",
    "    nmb_value_voc_numbers1 = nmb_values_voc_numbers1_ordered[group]\n",
    "    nmb_value_voc_numbers2 = nmb_values_voc_numbers2_ordered[group]\n",
    "    nmb_value_mechanisms   = nmb_values_mechanisms_ordered[group]\n",
    "    color     = color_flight[group]\n",
    "    # Check if the group requires a box\n",
    "    if group in ['FN19', 'RF03']:\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"none\", lw=2, ec=color, alpha=0.7)\n",
    "    else:\n",
    "        bbox_props = None\n",
    "# Assuming you want to align floating-point numbers with up to 1 decimal place\n",
    "max_width = 2  # total digits for integer part\n",
    "decimal_places = 0  # digits after decimal\n",
    "start_y = 0.38\n",
    "\n",
    "'''\n",
    "# Showing NMB for RF03 with white background for text\n",
    "axes[0].annotate(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.08),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "'''\n",
    "'''\n",
    "axes[0].annotate(f\"GEOS-Chem: {nmb_values_gc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.16),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "'''\n",
    "'''\n",
    "print(\"-----------------------------------\")\n",
    "print(\"RF03 (<2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "\n",
    "print(\"RF07 (>2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "print(\"RF09  (<2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(\"-----------------------------------\")\n",
    "'''\n",
    "\n",
    "# --------------------\n",
    "# Reference datapoints\n",
    "# --------------------\n",
    "x_points = [40/60, 40/60, 1.2, 20/60, 21/60, 45/60, 53/60, 56/60, 32/60]\n",
    "y_points = [1.7E7, 1.14E7, 4.1E6, 4E6, 8.9E6, 4E6, 3E6, 2.8E6, 3.5E6]\n",
    "labels = ['Hobbs et al. (2003)', 'Yokelson et al. (2009)', 'Yokelson et al. (2009)', 'Palm et al. (2021)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)']\n",
    "\n",
    "markers = ['*', 's', 's', 'P', '^', '^', '^', '^', '^']\n",
    "# Track labels that have been annotated\n",
    "annotated_labels = set()\n",
    "# Plot each point using corresponding marker and size\n",
    "for xp, yp, label, marker in zip(x_points, y_points, labels, markers):\n",
    "    axes[0].scatter(xp, yp/1E6, marker=marker, color='black', s=300, label='_nolegend_', zorder=888)  # Use corresponding marker\n",
    "    # Mute the annotation to make Lu happy\n",
    "    '''\n",
    "    # Annotate the first occurrence of each label with text and a longer arrow\n",
    "    if label not in annotated_labels:\n",
    "        axes[0].annotate(label, \n",
    "                    #xy=(xp, yp), xytext=(xp + 2, yp+8E6), \n",
    "                    xy=(xp, yp/1E6), xytext=(xp + 1, (yp+8E6)/1E6), \n",
    "                    textcoords='data', fontsize=14, \n",
    "                    arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "                    ha='left')\n",
    "        annotated_labels.add(label)  # Mark label as annotated\n",
    "    '''\n",
    "# --------------------\n",
    "# Print out analysis\n",
    "# Maintext analysis\n",
    "# --------------------\n",
    "# Function to calculate statistics for each hour time frame\n",
    "def calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour):\n",
    "    # Calculate the slope\n",
    "    slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress(filtered_data_obs[var_x_obs].astype(float), filtered_data_obs[var_y_obs].astype(float))\n",
    "    # Calculate the mean values and std err within the timeframe\n",
    "    mean_val, std_dev   = filtered_data_obs[var_y_obs].mean(), filtered_data_obs[var_y_obs].std()\n",
    "    median_val, iqr_val = filtered_data_obs[var_y_obs].median(), iqr(filtered_data_obs[var_y_obs])\n",
    "    min_value, max_value= __builtins__.min(filtered_data_obs[var_y_obs]), __builtins__.max(filtered_data_obs[var_y_obs])\n",
    "    if var_y_obs in ['output_OH', 'cal_OH_mean']: \n",
    "        unit  = '1E6 molec/cm3'\n",
    "        scale =  1/1E6\n",
    "    elif var_y_obs in ['NEMR_PAN', 'NEMR_PAN_rate']:\n",
    "        unit  = '%'\n",
    "        scale =  100\n",
    "    else:\n",
    "        unit  = 'non-defined'\n",
    "        scale =  1\n",
    "    \n",
    "    # Print the mean and standard deviation\n",
    "    print(f'Time Frame: {hour} hour')\n",
    "    print(f'The mean/std value ({unit}): {mean_val*scale:.1f}±{std_dev*scale:.1f}')\n",
    "    print(f'The median/iqr value ({unit}): {median_val*scale:.1f}±{iqr_val*scale:.1f}')\n",
    "    print(f'min and max value ({unit}): {min_value*scale:.1f}, {max_value*scale:.1f}')\n",
    "    print()\n",
    "\n",
    "# The observed OH concentration over the initial 40 minutes\n",
    "initial_minutes = 40 / 60  # Convert 40 minutes into hours for comparison with Plume_Age in hours\n",
    "# Filter data for the initial 40 minutes\n",
    "filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] <= initial_minutes)]\n",
    "filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "# Check if the DataFrame is not empty before proceeding\n",
    "if not filtered_data_obs.empty:\n",
    "    # Calculate statistics for the initial 40 minutes\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "else:\n",
    "    print(\"No data available for the initial 40 minutes.\")\n",
    "# Calculate it for each flight\n",
    "for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "    all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "    filtered_data_obs_each = all_data_obs_combined_each[all_data_obs_combined_each[var_x_obs] <= initial_minutes]\n",
    "    # Check if the DataFrame is empty\n",
    "    if not filtered_data_obs_each.empty:\n",
    "        print(f\"Calculating for Flight ID: {flight_id} for the initial 40 minutes\")\n",
    "        calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "    else:\n",
    "        print(f\"Skipping {flight_id} for the initial 40 minutes because the data is empty.\")\n",
    "\n",
    "# The observed OH concentration over time\n",
    "for hour in range(1, 6):\n",
    "    # Filter data for the current time frame\n",
    "    filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] > (hour - 1)) & (all_data_obs_combined[var_x_obs] < hour)]\n",
    "    filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "    # Calculate statistics for the current time frame\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour)\n",
    "\n",
    "    # Calculate it for each flight\n",
    "    for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "        all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "        filtered_data_obs_each     = all_data_obs_combined_each[(all_data_obs_combined_each[var_x_obs] > (hour - 1)) & (all_data_obs_combined_each[var_x_obs] < hour)]\n",
    "        # Check if the DataFrame is empty\n",
    "        if not filtered_data_obs_each.empty:\n",
    "            print(flight_id)\n",
    "            calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, hour)\n",
    "        else:\n",
    "            print(f\"Skipping {flight_id} at hour {hour} because the data is empty.\")\n",
    "\n",
    "# The model differences among model simulations\n",
    "# Print the mean +/- std\n",
    "print('Model differences among three model simulations')\n",
    "print(f'Mean ± Std (VOC init 1) : {nmb_values_voc_numbers1_array.mean():.0f} ± {nmb_values_voc_numbers1_array.std():.0f}')\n",
    "print(f'Mean ± Std (VOC init 2) : {nmb_values_voc_numbers2_array.mean():.0f} ± {nmb_values_voc_numbers2_array.std():.0f}')\n",
    "print(f'Mean ± Std (mechanism): {nmb_values_mechanisms_array.mean():.0f} ± {nmb_values_mechanisms_array.std():.0f}')\n",
    "\n",
    "# ----------------------------\n",
    "# Chemical age vs Physical age\n",
    "# ----------------------------\n",
    "# Define age segments and corresponding colors\n",
    "# Define age segments and corresponding colors\n",
    "age_segments = [(0, 0.5), (0.5, 1), (1, 1.5), (1.5, 2), (2, 2.5), (2.5, 3), (3, np.inf)]\n",
    "age_segments = [(0,  1), (1, 2), (2, 3), (3, 4), (4, 5), (5, np.inf)]\n",
    "colors       = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange', 'tab:grey']\n",
    "\n",
    "# Set up figure and axes\n",
    "var_x = 'Plume_Age'\n",
    "var_y = 'output_chem_age'\n",
    "clean_data = all_data_mcm_bbvoc.dropna(subset=[var_x, var_y])\n",
    "\n",
    "\n",
    "# Resetting min and max if they were overridden\n",
    "try:\n",
    "    del min  # Only if 'min' was redefined\n",
    "    del max  # Only if 'max' was redefined\n",
    "except NameError as e:\n",
    "    print(\"Error:\", e)\n",
    "# Find the overall range for plotting the 1:1 line\n",
    "min_val = __builtins__.min(__builtins__.min(clean_data[var_x]), __builtins__.min(clean_data[var_y]))\n",
    "max_val = __builtins__.max(__builtins__.max(clean_data[var_x]), __builtins__.max(clean_data[var_y]))\n",
    "\n",
    "# Loop through each age segment\n",
    "for (start, end), color in zip(age_segments, colors):\n",
    "    segment = clean_data[(clean_data[var_x] >= start) & (clean_data[var_x] < end)]\n",
    "    bin_size = 30/60.0/60.0  # 15 minutes in hours, adjust if needed\n",
    "    segment['Time_Bin'] = (segment[var_x] // bin_size) * bin_size\n",
    "    segment_binned = segment.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "    axes[1].scatter(segment_binned[var_x], segment_binned[var_y], color=color, alpha=0.5, s=50)\n",
    "\n",
    "    if not segment.empty:\n",
    "        X = segment_binned[var_x].values.reshape(-1, 1)\n",
    "        y = segment_binned[var_y].values\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(X, y)\n",
    "        slope = model.coef_[0]\n",
    "        label = f'>{start} h: Slope={slope:.1f}' if np.isinf(end) else f'{start}-{end} h: Slope={slope:.1f}'\n",
    "        y_vals = np.linspace(0, segment_binned[var_y].max(), 100)\n",
    "        x_vals = y_vals / slope\n",
    "        axes[1].plot(x_vals, y_vals, color=color, label=label, linewidth=5)\n",
    "\n",
    "\n",
    "# Defalt setting for title, ticks, and labels\n",
    "axes[0].set_xlabel(text_labels.get(var_x_obs, var_x_obs), fontsize=30)\n",
    "axes[0].set_ylabel(text_labels.get(var_y_obs, var_y_obs), fontsize=30)\n",
    "axes[0].tick_params(axis='both', labelsize=30)\n",
    "axes[0].set_ylim(0, 3E7/1E6)  # Set y limits from min y to calculated upper limit\n",
    "# Set the x-axis limit\n",
    "axes[0].set_xlim([0, 5])  # None means no lower limit, 8 is the upper limit\n",
    "\n",
    "# Draw horizontal line and add annotation for the first subplot\n",
    "axes[0].axhline(y=1.5, color='black', linestyle='-', linewidth=3)\n",
    "\n",
    "'''\n",
    "axes[0].annotate('Ambient OH level', fontsize=25,\n",
    "                 xy=(0.75, 1.2), xytext=(0.90, 1.2),\n",
    "                 textcoords='data', ha='center', va='top')\n",
    "'''\n",
    "# Legend\n",
    "show_legend=1\n",
    "if show_legend:\n",
    "    if group_column == 'Flight_ID':\n",
    "        desired_order = desired_order_flights\n",
    "        reorder_legend(axes[0], desired_order, id2fire_name, fontsize=20, legend_loc='upper right')\n",
    "        #reorder_legend(axes[0], desired_order, id2fire_name, fontsize=20, legend_loc='upper left')\n",
    "\n",
    "# Add the 1:1 line\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'k--', label='1:1 Line')\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=30)\n",
    "axes[1].set_xlabel('Physical age (hour)', fontsize=30)\n",
    "axes[1].set_ylabel('Chemical age (hour)', fontsize=30)\n",
    "axes[1].legend(fontsize=25)\n",
    "axes[1].yaxis.set_major_formatter(ScalarFormatter())  # Optional: To format the y-axis ticks into readable numbers\n",
    "axes[1].xaxis.set_major_formatter(ScalarFormatter())\n",
    "# Set x-axis ticks to every 2 hours\n",
    "axes[1].xaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "\n",
    "\n",
    "# Annotation for subplot (a)\n",
    "axes[0].text(0.05, 0.95, 'A', transform=axes[0].transAxes, fontsize=30, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Set y-axis limits\n",
    "axes[0].set_ylim(0, 20)  # This sets the minimum to 0 and the maximum to 20\n",
    "# Annotation for subplot (b)\n",
    "axes[1].text(0.05, 0.95, 'B', transform=axes[1].transAxes, fontsize=30, fontweight='bold', va='top', ha='left')\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Save the full figure in high resolution\n",
    "for fmt in ['pdf', 'jpeg', 'tiff']:  # Choose the formats you need\n",
    "    fig.savefig(f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/maintext_figures/Fig1_OH_TS.{fmt}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565fa6a-b479-4714-9f09-b270a480b81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c969dd-b359-4417-b917-a9c6c1bb8da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb425d-f7d0-45ed-ba60-0b11aa829f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4de00a7-2af3-41f8-9645-f953413e994b",
   "metadata": {},
   "source": [
    "#### Poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ad5bf-30ef-42c6-95ca-e62a472ec435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# OH calculation method\n",
    "# ---------------------\n",
    "# Plotting\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12*1, 9))\n",
    "# ==================================================\n",
    "# Calculated OH concentration vs direct model output\n",
    "# Analysis in the maintext\n",
    "# ==================================================\n",
    "# Select variable\n",
    "var_x_obs, var_y_obs = 'Plume_Age', 'cal_OH_mean'\n",
    "var_x_mod, var_y_mod = 'Plume_Age', 'output_OH'\n",
    "group_column = 'Flight_ID'\n",
    "set_ylabel=True\n",
    "show_legend=True\n",
    "title = 'Plume-center OH concentrations'\n",
    "# Legend\n",
    "legend_title = 'Flight ID'\n",
    "show_legend  = True\n",
    "# The slope of NEMR O3 vs plume age\n",
    "mean_lagrangian = []\n",
    "nmb_values_mcm_bbvoc = {}\n",
    "nmb_values_mcm_gcvoc = {}\n",
    "nmb_values_gc = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time = {}\n",
    "nmb_values_mcm_gcvoc_less_time = {}\n",
    "nmb_values_gc_less_time        = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_more_time = {}\n",
    "nmb_values_mcm_gcvoc_more_time = {}\n",
    "nmb_values_gc_more_time        = {}\n",
    "\n",
    "nmb_values_voc_numbers1 = {}\n",
    "nmb_values_voc_numbers2 = {}\n",
    "nmb_values_mechanisms  = {}\n",
    "color_flight = {}\n",
    "# Set up colors\n",
    "unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "unique_groups = np.array(['P-3B', 'RF03', 'RF07', 'RF09', 'FN19', 'Other WE-CAN flights'])\n",
    "unique_groups = np.array(['RF03'])\n",
    "if len(unique_groups) == 6:\n",
    "    group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "if len(unique_groups) == 1:\n",
    "    group_colors = [[0.5, 0.0, 0.0, 1.0]]\n",
    "\n",
    "for idx, group in enumerate(unique_groups):\n",
    "    '''\n",
    "    # Skip P-3B for calculated chemical age\n",
    "    if group == 'P-3B' and conditions:\n",
    "        print('skip P-3B for its unresonable chemical age')\n",
    "        continue\n",
    "    '''\n",
    "    group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]\n",
    "    group_data_obs  = group_data_obs.dropna(subset=[var_x_obs, var_y_obs])\n",
    "    x_obs, y_obs    = (group_data_obs[var_x_obs]).astype(float), (group_data_obs[var_y_obs]).astype(float)\n",
    "\n",
    "    \n",
    "    if group == 'RF07': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.541500] # Based on CO and HONO\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    if group == 'RF09': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.744000,  4.620500, 4.093667] #4.391833,\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "    \n",
    "    # Plot observational data if available\n",
    "    if valid_indices.any():\n",
    "        # Determine if the circle should be solid or open based on the flight\n",
    "        face_color = group_colors[idx]\n",
    "        # Plot dots even they are not in Lagrangian flights\n",
    "        if group_column == 'Flight_ID': \n",
    "            if group not in Lagrangian_flights: continue\n",
    "            \n",
    "            # Determine the face color based on the flight\n",
    "            edge_color  = group_colors[idx]  # Color from your color map\n",
    "            marker_size = 100  # Adjust this value as needed\n",
    "            alpha_value = 1\n",
    "            #edge_color = \"none\" # comment it out if we want to remove dots\n",
    "            \n",
    "            if group in ['RF03', 'RF07', 'RF09']:\n",
    "                edge_color  = edge_color\n",
    "                face_color  = edge_color  # Use the edge color to fill markers\n",
    "                #face_color = \"none\"  # comment it out if we want to remove dots\n",
    "                linewidth  = 5\n",
    "            else:\n",
    "                edge_color = \"none\"\n",
    "                face_color = \"none\"  # remove dots\n",
    "                linewidth  = 5\n",
    "\n",
    "            # Plot actual scatter data with hollow markers\n",
    "            axes.scatter(x_obs[valid_indices], y_obs[valid_indices]/1E6, edgecolors=edge_color, facecolors=face_color, label='_nolegend_', s=marker_size, alpha=alpha_value)\n",
    "            # Plot dummy scatter just for creating the legend entry\n",
    "            axes.scatter([], [], edgecolors=group_colors[idx], facecolors=group_colors[idx], label='Observation', s=100)\n",
    "\n",
    "        \n",
    "        # Perform linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "\n",
    "    # Group model results with flight ID instead.\n",
    "    if (group_column == 'Flight_ID') and (group in Lagrangian_flights):\n",
    "        group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "        group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "        group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "        # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "        # Assuming Plume_Age is in hours, 0.25 hours is equivalent to 15 minutes\n",
    "        bin_size = 0.25  # 15 minutes in hours\n",
    "        group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        group_data_gc_binned             = group_data_gc.groupby('Time_Bin').median(numeric_only=True)\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x_mod]).astype(float), (group_data_mcm_bbvoc_binned[var_y_mod]).astype(float)\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x_mod]).astype(float), (group_data_mcm_gcvoc_binned[var_y_mod]).astype(float)\n",
    "        x_gc, y_gc               = (group_data_gc_binned[var_x_mod]).astype(float), (group_data_gc_binned[var_y_mod]).astype(float)\n",
    "\n",
    "        \n",
    "        valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                            ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                            ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "        x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "\n",
    "        # Add solid lines for model output\n",
    "        if valid_indices_mod.any():\n",
    "            axes.plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color=group_colors[idx], linestyle='-', linewidth=linewidth, label=r\"MCM$_{BBVOC}$\")\n",
    "            axes.plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth, label=r\"GEOS-Chem\")\n",
    "        else:\n",
    "            axes.plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes.plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "        # ---------------------------------------------\n",
    "        # Calculate the model error\n",
    "        # Use the same bin in S1 for result consistency\n",
    "        # ---------------------------------------------  \n",
    "\n",
    "        x_mcm_bbvoc = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == group].index\n",
    "        y_mcm_bbvoc = df_OH_mod_mcm_bbvoc_bin[df_OH_mod_mcm_bbvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "        y_mcm_gcvoc = df_OH_mod_mcm_gcvoc_bin[df_OH_mod_mcm_gcvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "        y_gc        = df_OH_mod_gc_bin[df_OH_mod_mcm_gcvoc_bin['Flight_ID'] == group][(var_y_mod, 'median')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Only when observation exists\n",
    "        if valid_indices.any():\n",
    "            # Define the degree of the polynomial model       \n",
    "            degree = 2\n",
    "            # Create a polynomial regression model\n",
    "            poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "            # Fit the polynomial regression model on observational data\n",
    "            poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "            # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "            x_model       = x_mcm_bbvoc\n",
    "            y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "        # Using mcmbbvoc as the observation\n",
    "        else:\n",
    "            y_predicted = y_mcm_bbvoc\n",
    "\n",
    "        # Calculate Normalized Median Bias (NMB)        \n",
    "        #nmb_mcm_bbvoc   = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_mcm_gcvoc   = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_gc          = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        nmb_mcm_bbvoc   = 100 *  np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_mcm_gcvoc   = 100 *  np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_gc          = 100 *  np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "\n",
    "        #if group == 'RF03':\n",
    "        #    print(nmb_mcm_bbvoc)\n",
    "        #    print(y_mcm_bbvoc)\n",
    "        #    test_stop\n",
    "        \n",
    "        # Define a new set of valid indices where x_obs is less than 2\n",
    "        indices_less_time       = x_model < 2.5        \n",
    "        #nmb_mcm_bbvoc_less_time = 100 * (np.nanmedian(y_mcm_bbvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_mcm_gcvoc_less_time = 100 * (np.nanmedian(y_mcm_gcvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_gc_less_time        = 100 * (np.nanmedian(y_gc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        nmb_mcm_bbvoc_less_time = 100 * np.nansum(y_mcm_bbvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_mcm_gcvoc_less_time = 100 * np.nansum(y_mcm_gcvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_gc_less_time        = 100 * np.nansum(y_gc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "\n",
    "\n",
    "        # Define a new set of valid indices where x_obs is more than 2\n",
    "        indices_more_time       = x_model >= 2.5        \n",
    "        nmb_mcm_bbvoc_more_time = 100 * np.nansum(y_mcm_bbvoc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "        nmb_mcm_gcvoc_more_time = 100 * np.nansum(y_mcm_gcvoc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "        nmb_gc_more_time        = 100 * np.nansum(y_gc[indices_more_time] - y_predicted[indices_more_time]) / np.nansum(y_predicted[indices_more_time])\n",
    "\n",
    "        \n",
    "        # Calculate differences among models\n",
    "        #nmb_voc_numbers1= 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_voc_numbers2= 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_mechanisms  = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_gcvoc)) / np.nanmedian(y_mcm_gcvoc)\n",
    "        nmb_voc_numbers1= 100 * np.nansum(y_mcm_gcvoc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_voc_numbers2= 100 * np.nansum(y_gc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_mechanisms  = 100 * np.nansum(y_gc - y_mcm_gcvoc) / np.nansum(y_mcm_gcvoc)\n",
    "        \n",
    "        # After calculating NMB\n",
    "        nmb_values_mcm_bbvoc[group]   = nmb_mcm_bbvoc\n",
    "        nmb_values_mcm_gcvoc[group]   = nmb_mcm_gcvoc\n",
    "        nmb_values_gc[group]          = nmb_gc\n",
    "\n",
    "        nmb_values_mcm_bbvoc_less_time[group]   = nmb_mcm_bbvoc_less_time\n",
    "        nmb_values_mcm_gcvoc_less_time[group]   = nmb_mcm_gcvoc_less_time\n",
    "        nmb_values_gc_less_time[group]          = nmb_gc_less_time\n",
    "\n",
    "        nmb_values_mcm_bbvoc_more_time[group]   = nmb_mcm_bbvoc_more_time\n",
    "        nmb_values_mcm_gcvoc_more_time[group]   = nmb_mcm_gcvoc_more_time\n",
    "        nmb_values_gc_more_time[group]          = nmb_gc_more_time\n",
    "        \n",
    "        nmb_values_voc_numbers1[group]= nmb_voc_numbers1\n",
    "        nmb_values_voc_numbers2[group]= nmb_voc_numbers2\n",
    "        nmb_values_mechanisms[group]  = nmb_mechanisms\n",
    "        color_flight[group]           = group_colors[idx]\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Annotation settings\n",
    "# -------------------\n",
    "# Calculate median and interquartile range (IQR)\n",
    "nmb_values_mcm_bbvoc_array    = np.array(list(nmb_values_mcm_bbvoc.values()), dtype=float)\n",
    "nmb_values_mcm_gcvoc_array    = np.array(list(nmb_values_mcm_gcvoc.values()), dtype=float)\n",
    "nmb_values_gc_array           = np.array(list(nmb_values_gc.values()), dtype=float)\n",
    "nmb_values_voc_numbers1_array = np.array(list(nmb_values_voc_numbers1.values()), dtype=float)\n",
    "nmb_values_voc_numbers2_array = np.array(list(nmb_values_voc_numbers2.values()), dtype=float)\n",
    "nmb_values_mechanisms_array   = np.array(list(nmb_values_mechanisms.values()), dtype=float)\n",
    "\n",
    "\n",
    "median_mcm_bbvoc, q1_mcm_bbvoc, q3_mcm_bbvoc          = np.nanmedian(nmb_values_mcm_bbvoc_array), np.nanpercentile(nmb_values_mcm_bbvoc_array, 25), np.nanpercentile(nmb_values_mcm_bbvoc_array, 75)\n",
    "median_mcm_gcvoc, q1_mcm_gcvoc, q3_mcm_gcvoc          = np.nanmedian(nmb_values_mcm_gcvoc_array), np.nanpercentile(nmb_values_mcm_gcvoc_array, 25), np.nanpercentile(nmb_values_mcm_gcvoc_array, 75)\n",
    "median_gc, q1_gc, q3_gc                               = np.nanmedian(nmb_values_gc_array), np.nanpercentile(nmb_values_gc_array, 25), np.nanpercentile(nmb_values_gc_array, 75)\n",
    "median_voc_numbers1, q1_voc_numbers1, q3_voc_numbers1 = np.nanmedian(nmb_values_voc_numbers1_array), np.nanpercentile(nmb_values_voc_numbers1_array, 25), np.nanpercentile(nmb_values_voc_numbers1_array, 75)\n",
    "median_voc_numbers2, q1_voc_numbers2, q3_voc_numbers2 = np.nanmedian(nmb_values_voc_numbers2_array), np.nanpercentile(nmb_values_voc_numbers2_array, 25), np.nanpercentile(nmb_values_voc_numbers2_array, 75)\n",
    "median_mechanisms, q1_mechanisms, q3_mechanisms       = np.nanmedian(nmb_values_mechanisms_array), np.nanpercentile(nmb_values_mechanisms_array, 25), np.nanpercentile(nmb_values_mechanisms_array, 75)\n",
    "\n",
    "iqr_mcm_bbvoc    = q3_mcm_bbvoc - q1_mcm_bbvoc\n",
    "iqr_mcm_gcvoc    = q3_mcm_gcvoc - q1_mcm_gcvoc\n",
    "iqr_gc           = q3_gc - q1_gc\n",
    "iqr_voc_numbers1 = q3_voc_numbers1 - q1_voc_numbers1\n",
    "iqr_voc_numbers2 = q3_voc_numbers2 - q1_voc_numbers2\n",
    "iqr_mechanisms   = q3_mechanisms - q1_mechanisms\n",
    "# Calculate mean and standard deviation\n",
    "mean_mcm_bbvoc, std_mcm_bbvoc       = np.nanmean(nmb_values_mcm_bbvoc_array), np.nanstd(nmb_values_mcm_bbvoc_array)\n",
    "mean_mcm_gcvoc, std_mcm_gcvoc       = np.nanmean(nmb_values_mcm_gcvoc_array), np.nanstd(nmb_values_mcm_gcvoc_array)\n",
    "mean_gc, std_gc                     = np.nanmean(nmb_values_gc_array), np.nanstd(nmb_values_gc_array)\n",
    "mean_voc_numbers1, std_voc_numbers1 = np.nanmean(nmb_values_voc_numbers1_array), np.nanstd(nmb_values_voc_numbers1_array)\n",
    "mean_voc_numbers2, std_voc_numbers2 = np.nanmean(nmb_values_voc_numbers2_array), np.nanstd(nmb_values_voc_numbers2_array)\n",
    "mean_mechanisms, std_mechanisms     = np.nanmean(nmb_values_mechanisms_array), np.nanstd(nmb_values_mechanisms_array)\n",
    "\n",
    "'''\n",
    "# Annotate mean ± std in each subplot\n",
    "# Determine if we want to show bias for each individual flights or the average of flights.\n",
    "xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "axes.annotate(f\"NMB:({median_mcm_bbvoc:.0f}±{iqr_mcm_bbvoc:.0f})%\", \n",
    "             xy=xy,  # Position of the annotation\n",
    "             xycoords='axes fraction',\n",
    "             ha=ha, va=va,  # Alignment of the text\n",
    "             fontsize=20,  # Font size of the text\n",
    "             color=color)  # Color of the text\n",
    "'''\n",
    "\n",
    "\n",
    "# Desired order of keys\n",
    "desired_order = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']\n",
    "# Desired order of keys\n",
    "nmb_values_mcm_bbvoc_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc[key]) for key in desired_order if key in nmb_values_mcm_bbvoc)\n",
    "nmb_values_mcm_gcvoc_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc[key]) for key in desired_order if key in nmb_values_mcm_gcvoc)\n",
    "nmb_values_gc_ordered           = OrderedDict((key, nmb_values_gc[key]) for key in desired_order if key in nmb_values_gc)\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_less_time)\n",
    "nmb_values_mcm_gcvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_less_time)\n",
    "nmb_values_gc_less_time_ordered           = OrderedDict((key, nmb_values_gc_less_time[key]) for key in desired_order if key in nmb_values_gc_less_time)\n",
    "\n",
    "nmb_values_mcm_bbvoc_more_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_more_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_more_time)\n",
    "nmb_values_mcm_gcvoc_more_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_more_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_more_time)\n",
    "nmb_values_gc_more_time_ordered           = OrderedDict((key, nmb_values_gc_more_time[key]) for key in desired_order if key in nmb_values_gc_more_time)\n",
    "\n",
    "nmb_values_voc_numbers1_ordered = OrderedDict((key, nmb_values_voc_numbers1[key]) for key in desired_order if key in nmb_values_voc_numbers1)\n",
    "nmb_values_voc_numbers2_ordered = OrderedDict((key, nmb_values_voc_numbers2[key]) for key in desired_order if key in nmb_values_voc_numbers2)\n",
    "nmb_values_mechanisms_ordered   = OrderedDict((key, nmb_values_mechanisms[key]) for key in desired_order if key in nmb_values_mechanisms)\n",
    "\n",
    "for idx, group in enumerate(nmb_values_mcm_bbvoc_ordered):\n",
    "    # Extract the name and perform the split operation outside the f-string\n",
    "    nmb_value_mcm_bbvoc    = nmb_values_mcm_bbvoc_ordered[group]\n",
    "    nmb_value_mcm_gcvoc    = nmb_values_mcm_gcvoc_ordered[group]\n",
    "    nmb_value_gc           = nmb_values_gc_ordered[group]\n",
    "    nmb_value_voc_numbers1 = nmb_values_voc_numbers1_ordered[group]\n",
    "    nmb_value_voc_numbers2 = nmb_values_voc_numbers2_ordered[group]\n",
    "    nmb_value_mechanisms   = nmb_values_mechanisms_ordered[group]\n",
    "    color     = color_flight[group]\n",
    "    # Check if the group requires a box\n",
    "    if group in ['FN19', 'RF03']:\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"none\", lw=2, ec=color, alpha=0.7)\n",
    "    else:\n",
    "        bbox_props = None\n",
    "# Assuming you want to align floating-point numbers with up to 1 decimal place\n",
    "max_width = 2  # total digits for integer part\n",
    "decimal_places = 0  # digits after decimal\n",
    "start_y = 0.38\n",
    "\n",
    "'''\n",
    "# Showing NMB for RF03 with white background for text\n",
    "axes[0].annotate(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.08),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "'''\n",
    "'''\n",
    "axes[0].annotate(f\"GEOS-Chem: {nmb_values_gc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.16),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "'''\n",
    "\n",
    "# --------------------\n",
    "# Reference datapoints\n",
    "# --------------------\n",
    "x_points = [40/60, 40/60, 1.2, 20/60, 21/60, 45/60, 53/60, 56/60, 32/60]\n",
    "y_points = [1.7E7, 1.14E7, 4.1E6, 4E6, 8.9E6, 4E6, 3E6, 2.8E6, 3.5E6]\n",
    "labels = ['Hobbs et al. (2003)', 'Yokelson et al. (2009)', 'Yokelson et al. (2009)', 'Palm et al. (2021)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)']\n",
    "\n",
    "markers = ['*', 's', 's', 'P', '^', '^', '^', '^', '^']\n",
    "# Track labels that have been annotated\n",
    "annotated_labels = set()\n",
    "# Plot each point using corresponding marker and size\n",
    "for xp, yp, label, marker in zip(x_points, y_points, labels, markers):\n",
    "    axes.scatter(xp, yp/1E6, marker=marker, color='black', s=300, label='_nolegend_', zorder=888)  # Use corresponding marker\n",
    "\n",
    "# --------------------\n",
    "# Print out analysis\n",
    "# Maintext analysis\n",
    "# --------------------\n",
    "# Function to calculate statistics for each hour time frame\n",
    "def calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour):\n",
    "    # Calculate the slope\n",
    "    slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress(filtered_data_obs[var_x_obs].astype(float), filtered_data_obs[var_y_obs].astype(float))\n",
    "    # Calculate the mean values and std err within the timeframe\n",
    "    mean_val, std_dev   = filtered_data_obs[var_y_obs].mean(), filtered_data_obs[var_y_obs].std()\n",
    "    median_val, iqr_val = filtered_data_obs[var_y_obs].median(), iqr(filtered_data_obs[var_y_obs])\n",
    "    min_value, max_value= __builtins__.min(filtered_data_obs[var_y_obs]), __builtins__.max(filtered_data_obs[var_y_obs])\n",
    "    if var_y_obs in ['output_OH', 'cal_OH_mean']: \n",
    "        unit  = '1E6 molec/cm3'\n",
    "        scale =  1/1E6\n",
    "    elif var_y_obs in ['NEMR_PAN', 'NEMR_PAN_rate']:\n",
    "        unit  = '%'\n",
    "        scale =  100\n",
    "    else:\n",
    "        unit  = 'non-defined'\n",
    "        scale =  1\n",
    "    \n",
    "    # Print the mean and standard deviation\n",
    "    print(f'Time Frame: {hour} hour')\n",
    "    print(f'The mean/std value ({unit}): {mean_val*scale:.1f}±{std_dev*scale:.1f}')\n",
    "    print(f'The median/iqr value ({unit}): {median_val*scale:.1f}±{iqr_val*scale:.1f}')\n",
    "    print(f'min and max value ({unit}): {min_value*scale:.1f}, {max_value*scale:.1f}')\n",
    "    print()\n",
    "\n",
    "# The observed OH concentration over the initial 40 minutes\n",
    "initial_minutes = 40 / 60  # Convert 40 minutes into hours for comparison with Plume_Age in hours\n",
    "# Filter data for the initial 40 minutes\n",
    "filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] <= initial_minutes)]\n",
    "filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "# Check if the DataFrame is not empty before proceeding\n",
    "if not filtered_data_obs.empty:\n",
    "    # Calculate statistics for the initial 40 minutes\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "else:\n",
    "    print(\"No data available for the initial 40 minutes.\")\n",
    "# Calculate it for each flight\n",
    "for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "    all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "    filtered_data_obs_each = all_data_obs_combined_each[all_data_obs_combined_each[var_x_obs] <= initial_minutes]\n",
    "    # Check if the DataFrame is empty\n",
    "    if not filtered_data_obs_each.empty:\n",
    "        print(f\"Calculating for Flight ID: {flight_id} for the initial 40 minutes\")\n",
    "        calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "    else:\n",
    "        print(f\"Skipping {flight_id} for the initial 40 minutes because the data is empty.\")\n",
    "\n",
    "# The observed OH concentration over time\n",
    "for hour in range(1, 6):\n",
    "    # Filter data for the current time frame\n",
    "    filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] > (hour - 1)) & (all_data_obs_combined[var_x_obs] < hour)]\n",
    "    filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "    # Calculate statistics for the current time frame\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour)\n",
    "\n",
    "    # Calculate it for each flight\n",
    "    for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "        all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "        filtered_data_obs_each     = all_data_obs_combined_each[(all_data_obs_combined_each[var_x_obs] > (hour - 1)) & (all_data_obs_combined_each[var_x_obs] < hour)]\n",
    "        # Check if the DataFrame is empty\n",
    "        if not filtered_data_obs_each.empty:\n",
    "            print(flight_id)\n",
    "            calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, hour)\n",
    "        else:\n",
    "            print(f\"Skipping {flight_id} at hour {hour} because the data is empty.\")\n",
    "\n",
    "# The model differences among model simulations\n",
    "# Print the mean +/- std\n",
    "print('Model differences among three model simulations')\n",
    "print(f'Mean ± Std (VOC init 1) : {nmb_values_voc_numbers1_array.mean():.0f} ± {nmb_values_voc_numbers1_array.std():.0f}')\n",
    "print(f'Mean ± Std (VOC init 2) : {nmb_values_voc_numbers2_array.mean():.0f} ± {nmb_values_voc_numbers2_array.std():.0f}')\n",
    "print(f'Mean ± Std (mechanism): {nmb_values_mechanisms_array.mean():.0f} ± {nmb_values_mechanisms_array.std():.0f}')\n",
    "\n",
    "# ----------------------------\n",
    "# Chemical age vs Physical age\n",
    "# ----------------------------\n",
    "# Define age segments and corresponding colors\n",
    "# Define age segments and corresponding colors\n",
    "age_segments = [(0, 0.5), (0.5, 1), (1, 1.5), (1.5, 2), (2, 2.5), (2.5, 3), (3, np.inf)]\n",
    "age_segments = [(0,  1), (1, 2), (2, 3), (3, 4), (4, 5), (5, np.inf)]\n",
    "colors       = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange', 'tab:grey']\n",
    "\n",
    "# Set up figure and axes\n",
    "var_x = 'Plume_Age'\n",
    "var_y = 'output_chem_age'\n",
    "clean_data = all_data_mcm_bbvoc.dropna(subset=[var_x, var_y])\n",
    "\n",
    "\n",
    "# Resetting min and max if they were overridden\n",
    "try:\n",
    "    del min  # Only if 'min' was redefined\n",
    "    del max  # Only if 'max' was redefined\n",
    "except NameError as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Defalt setting for title, ticks, and labels\n",
    "axes.set_xlabel(text_labels.get(var_x_obs, var_x_obs), fontsize=30)\n",
    "axes.set_ylabel(text_labels.get(var_y_obs, var_y_obs), fontsize=30)\n",
    "axes.tick_params(axis='both', labelsize=30)\n",
    "axes.set_ylim(0, 3E7/1E6)  # Set y limits from min y to calculated upper limit\n",
    "# Set the x-axis limit\n",
    "axes.set_xlim([0, 3])  # None means no lower limit, 8 is the upper limit\n",
    "\n",
    "# Draw horizontal line and add annotation for the first subplot\n",
    "axes.axhline(y=1.5, color='black', linestyle='-', linewidth=3)\n",
    "\n",
    "\n",
    "# Legend\n",
    "# Retrieve current legend handles and labels\n",
    "handles, labels = axes.get_legend_handles_labels()\n",
    "# Define desired order by label name (case-sensitive match)\n",
    "desired_order = ['Observation', r'MCM$_{BBVOC}$', r'GEOS-Chem']\n",
    "# Create mapping from label to handle\n",
    "label_to_handle = dict(zip(labels, handles))\n",
    "# Reorder handles and labels\n",
    "ordered_handles = [label_to_handle[label] for label in desired_order if label in label_to_handle]\n",
    "ordered_labels  = [label for label in desired_order if label in label_to_handle]\n",
    "# Show legend in custom order\n",
    "axes.legend(handles=ordered_handles, labels=ordered_labels, fontsize=28, frameon=True)\n",
    "\n",
    "axes.set_title(\"OH evolution in biomass burning plumes\", fontsize=32, pad = 10)\n",
    "\n",
    "# Set y-axis limits\n",
    "axes.set_ylim(0, 21)  # This sets the minimum to 0 and the maximum to 20\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53326e65-dd13-4c4f-bd75-ac15825ce759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d033f20-7ccc-4af3-8908-f801c5df610b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5005e0a-e811-4981-abd4-c9af464efc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6eae62-2c7a-406c-b83e-46ded38bdef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb052c3f-f8a4-4e15-be84-cc28509c7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df_nmb_values = pd.DataFrame({\n",
    "    'Flight_ID': list(nmb_values_mcm_bbvoc_ordered.keys()),\n",
    "    'NMB_MCM_BBVOC': list(nmb_values_mcm_bbvoc_ordered.values()),\n",
    "    'NMB_MCM_GCVOC': list(nmb_values_mcm_gcvoc_ordered.values()),\n",
    "    'NMB_GC': list(nmb_values_gc_ordered.values())\n",
    "})\n",
    "\n",
    "df_nmb_values_fresh = pd.DataFrame({\n",
    "    'Flight_ID': list(nmb_values_mcm_bbvoc_less_time_ordered.keys()),\n",
    "    'NMB_MCM_BBVOC': list(nmb_values_mcm_bbvoc_less_time_ordered.values()),\n",
    "    'NMB_MCM_GCVOC': list(nmb_values_mcm_gcvoc_less_time_ordered.values()),\n",
    "    'NMB_GC': list(nmb_values_gc_less_time_ordered.values())\n",
    "})\n",
    "\n",
    "df_nmb_values_aged = pd.DataFrame({\n",
    "    'Flight_ID': list(nmb_values_mcm_bbvoc_more_time_ordered.keys()),\n",
    "    'NMB_MCM_BBVOC': list(nmb_values_mcm_bbvoc_more_time_ordered.values()),\n",
    "    'NMB_MCM_GCVOC': list(nmb_values_mcm_gcvoc_more_time_ordered.values()),\n",
    "    'NMB_GC': list(nmb_values_gc_more_time_ordered.values())\n",
    "})\n",
    "\n",
    "\n",
    "# Replace values for P-3B and FN19 with NaN since not all VOCs are available and thus results are not right.\n",
    "df_nmb_values.loc[df_nmb_values['Flight_ID'].isin(['P-3B', 'FN19']), ['NMB_MCM_BBVOC', 'NMB_MCM_GCVOC', 'NMB_GC']] = float('nan')\n",
    "df_nmb_values_fresh.loc[df_nmb_values_fresh['Flight_ID'].isin(['P-3B', 'FN19']), ['NMB_MCM_BBVOC', 'NMB_MCM_GCVOC', 'NMB_GC']] = float('nan')\n",
    "df_nmb_values_aged.loc[df_nmb_values_aged['Flight_ID'].isin(['P-3B', 'FN19']), ['NMB_MCM_BBVOC', 'NMB_MCM_GCVOC', 'NMB_GC']] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac9cc1-a7ae-4210-9611-747e2333bcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fa45e-5f41-4445-af76-be00535c33b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab877fcc-ee53-4a53-bf53-b1b9a54d0148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2c965-ccc5-4bde-a1f5-0ed48943b17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4e72f-df4b-4e9f-9da2-ef4b1a58aa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162eebd2-6818-4a3d-96d7-3a16eb33f3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d8934-897d-454c-a3f8-16ab89fb1a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40908977-5bd6-4363-8671-8e83f9c6c276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921c774-42ee-4983-86bd-a1b21b8d55a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8578d-4a6b-4717-b95f-2dc3298faa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9683cc-d14f-4467-81bf-1e8128ef7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Calculate average wind speed\n",
    "# ----------------------------\n",
    "# Load the CSV file into a DataFrame\n",
    "columns_to_read = ['Flight_ID', 'Age_physical_avg_min', \n",
    "                   'wind_speed_m_per_s_new', 'wind_speed_m_per_s', 'dist_from_fire_m_new', \n",
    "                   'dist_from_fire_m','closest_fire']\n",
    "\n",
    "df = pd.read_csv('/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/plume_passes_table_exl_edit.csv', delimiter='\\t', usecols=columns_to_read)\n",
    "# Condition to filter out rows where all columns except 'Flight_ID' are NaN\n",
    "condition = df.drop('Flight_ID', axis=1).isna().all(axis=1)\n",
    "# Remove those rows\n",
    "df_cleaned = df[~condition]\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "df_cleaned['wind_speed_m_per_s_new'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a149a4-4977-4321-972c-5d78d0038bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc63e17-e75c-4dab-821f-948371dd645c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22175da8-95e4-4d15-a048-e3321f1c979d",
   "metadata": {},
   "source": [
    "#### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2172fc-a185-4e59-959e-3ccec3929838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Production and loss rate of OH\n",
    "# ------------------------------\n",
    "# Change the time into hour\n",
    "combined_df_obs.index = (combined_df_obs.index).astype(float)\n",
    "\n",
    "# Sort the DataFrame columns based on the mean values\n",
    "sorted_columns  = (combined_df_obs.mean(axis=0)).sort_values(ascending=False).index\n",
    "combined_df_obs = combined_df_obs[sorted_columns]\n",
    "\n",
    "# Apply the function and group by its result\n",
    "processed_df_obs = group_above_threshold(combined_df_obs, threshold=5, group_by_column='time_bin')\n",
    "# Normalize the data\n",
    "processed_df_obs_norm = processed_df_obs.copy()\n",
    "processed_df_obs_norm.iloc[:, :] = processed_df_obs.iloc[:, :].div(processed_df_obs.iloc[:, :].sum(axis=1), axis=0)*100\n",
    "# Define figsize for each subplot\n",
    "figsize_per_subplot = (12, 5)\n",
    "\n",
    "# Create three subplots, with the first two sharing the x-axis\n",
    "#fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(figsize_per_subplot[0], figsize_per_subplot[1] * 3))\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(7.25, 9))\n",
    "\n",
    "\n",
    "# Unpack all axes\n",
    "ax1, ax2, ax3 = axes\n",
    "\n",
    "# First subplot: Stacked bar plot\n",
    "processed_df_obs.plot(kind='bar', stacked=True, ax=ax1)\n",
    "ax1.legend(loc='upper right', fontsize=6)\n",
    "\n",
    "# Second subplot: Normalized stacked bar plot\n",
    "processed_df_obs_norm.plot(kind='bar', stacked=True, ax=ax2)\n",
    "ax2.legend().remove()\n",
    "\n",
    "# Add numbers to the stacked bars in the second subplot\n",
    "for bars in ax2.containers:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 5:\n",
    "            ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2,\n",
    "                     f'{height:.0f}', ha='center', va='center', fontsize=8, color='black')\n",
    "\n",
    "# Third subplot\n",
    "var_x, var_y = 'Plume_Age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y, ax3, '', set_ylabel=False, show_legend=True)\n",
    "\n",
    "# Calculate the contribution of acrolein, 1,3-butadiene, and furanoids to missing OHR\n",
    "all_data_mcm_bbvoc['VOCR_part: CO'] = (all_data_mcm_bbvoc['Furan: CO'] * k_OH_dic['Furan'] + all_data_mcm_bbvoc['Methylfuran: CO'] * k_OH_dic['Methylfuran'] + \\\n",
    "                                            all_data_mcm_bbvoc['2,5-Dimethylfuran: CO'] * k_OH_dic['Dimethylfuran'] + all_data_mcm_bbvoc['Furfural: CO'] * k_OH_dic['Furfural'] + \\\n",
    "                                            all_data_mcm_bbvoc['Methylfurfural: CO'] * k_OH_dic['Methylfurfural'] + all_data_mcm_bbvoc['Furanone: CO'] * k_OH_dic['Furanone'] + \\\n",
    "                                            all_data_mcm_bbvoc['1,3-Butadiene: CO'] * k_OH_dic['Butadiene'] + all_data_mcm_bbvoc['Acrolein: CO'] * k_OH_dic['Acrolein'] )*2.5E10\n",
    "\n",
    "missing_vocr = all_data_mcm_bbvoc['VOCR_part: CO']/(all_data_mcm_bbvoc['VOCR: CO']-all_data_mcm_gcvoc['VOCR: CO'])*100\n",
    "print(f'VOCR from key VOCs: {missing_vocr.mean():.0f}±{missing_vocr.std():.0f}')\n",
    "\n",
    "# -----------------\n",
    "# Plotting setting\n",
    "# -----------------\n",
    "# Adjust spacing\n",
    "plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "\n",
    "# Define a percentage by which to extend the y-axis above the max value\n",
    "extend_percent = 0.1  # for 10% extension\n",
    "\n",
    "for i, ax in enumerate([ax1, ax2, ax3], start=1):\n",
    "    # Get the current y-axis limits\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    # Calculate the range (max - min)\n",
    "    yrange = ymax - ymin\n",
    "    # Extend the max value by the defined percentage\n",
    "    \n",
    "    if i <2: \n",
    "        ax.set_ylim(ymin, ymax + yrange * 0.1)\n",
    "    else:\n",
    "        ax.set_ylim(ymin, ymax + yrange * 0.2)\n",
    "\n",
    "    # Set tick parameters and labels for all subplots\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "    # Annotate each subplot with (a), (b), (c)\n",
    "    ax.text(0.05, 0.97, f'{chr(64+i)}', transform=ax.transAxes, fontsize=8, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "# Set global labels for the entire figure\n",
    "fig.text(0.06, 0.75, 'P(HO$_x$) (ppt s$^{-1}$)', ha='center', va='center', rotation='vertical', fontsize=8)\n",
    "fig.text(0.06, 0.5, 'Normalized P(HO$_x$) (%)', ha='center', va='center', rotation='vertical', fontsize=8)\n",
    "fig.text(0.06, 0.25, 'Norm. OHR$_{VOC}$ (s$^{-1}$ ppm$_{CO}$$^{-1}$)', ha='center', va='center', rotation='vertical', fontsize=8)\n",
    "#fig.text(0.52, 0.9, 'HO$_x$ production and loss', ha='center', va='center', fontsize=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5eea4a-925e-41c8-80e5-3ca1e9e22f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Combined 2×3 bar plot with consistent colors & column order\n",
    "# --------------------------------------\n",
    "\n",
    "# Define consistent color palette for all contributors\n",
    "color_map_poh = {\n",
    "    'HONO': '#1f77b4',\n",
    "    'Ozone': '#ff7f0e',\n",
    "    'Formaldehyde': '#2ca02c',\n",
    "    '2,3-Butanedione': '#d62728',\n",
    "    'Glyoxal': '#9467bd',\n",
    "    'Acetaldehyde': '#8c564b',\n",
    "    'Methylglyoxal': '#e377c2',\n",
    "    'Glycolaldehyde': '#7f7f7f',\n",
    "    'Others': '#cccccc'\n",
    "}\n",
    "\n",
    "# Common species order (stacking order) to enforce across all subplots\n",
    "common_order = [\n",
    "    'HONO',\n",
    "    'Ozone',\n",
    "    'Formaldehyde',\n",
    "    '2,3-Butanedione',\n",
    "    'Glyoxal',\n",
    "    'Acetaldehyde',\n",
    "    'Methylglyoxal',\n",
    "    'Glycolaldehyde',\n",
    "    'Others'  # included in case group_above_threshold creates this column\n",
    "]\n",
    "\n",
    "def prepare_processed_df(combined_df, threshold=5):\n",
    "    combined_df = combined_df.copy()\n",
    "    combined_df.index = combined_df.index.astype(float)\n",
    "    sorted_columns = combined_df.mean(axis=0).sort_values(ascending=False).index\n",
    "    combined_df = combined_df[sorted_columns]\n",
    "    processed_df = group_above_threshold(combined_df, threshold=threshold, group_by_column='time_bin')\n",
    "    processed_df_norm = processed_df.div(processed_df.sum(axis=1), axis=0) * 100\n",
    "    return processed_df, processed_df_norm\n",
    "\n",
    "def reorder_columns(df, order):\n",
    "    df = df.copy()\n",
    "    # ensure all columns in 'order' exist; fill missing with zeros\n",
    "    for col in order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    # keep existing extra columns (if any) at the end, but prefer the common order\n",
    "    cols = [c for c in order if c in df.columns] + [c for c in df.columns if c not in order]\n",
    "    return df[cols]\n",
    "\n",
    "# Prepare per-fire processed data\n",
    "processed03, processed03_norm = prepare_processed_df(combined_df_obs_rf03)\n",
    "processed07, processed07_norm = prepare_processed_df(combined_df_obs_rf07)\n",
    "processed09, processed09_norm = prepare_processed_df(combined_df_obs_rf09)\n",
    "\n",
    "# Enforce identical species order across all panels\n",
    "processed03      = reorder_columns(processed03, common_order)\n",
    "processed07      = reorder_columns(processed07, common_order)\n",
    "processed09      = reorder_columns(processed09, common_order)\n",
    "processed03_norm = reorder_columns(processed03_norm, common_order)\n",
    "processed07_norm = reorder_columns(processed07_norm, common_order)\n",
    "processed09_norm = reorder_columns(processed09_norm, common_order)\n",
    "\n",
    "# ----------------------\n",
    "# Plot: 2 rows × 3 cols\n",
    "# ----------------------\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10.5, 6.5))\n",
    "axs = axes.flatten()\n",
    "\n",
    "flights = ['RF03', 'RF07', 'RF09']\n",
    "processed_list = [processed03, processed07, processed09]\n",
    "processed_norm_list = [processed03_norm, processed07_norm, processed09_norm]\n",
    "\n",
    "# --- First row: absolute P(HOx) ---\n",
    "for i, (ax, df, label) in enumerate(zip(axs[0:3], processed_list, flights)):\n",
    "    df.plot(\n",
    "        kind='bar', stacked=True, ax=ax,\n",
    "        color=[color_map_poh.get(c, '#CCCCCC') for c in df.columns]\n",
    "    )\n",
    "    ax.set_title(label, fontsize=10, pad=4)\n",
    "    ax.legend(loc='upper right', fontsize=6)\n",
    "    ax.set_ylabel('P(HO$_x$) (ppt s$^{-1}$)', fontsize=8 if i == 0 else 0)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_ylim(ymin, ymax + (ymax - ymin) * 0.1)\n",
    "    if i > 0:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "# --- Second row: normalized P(HOx) ---\n",
    "for i, (ax, df, label) in enumerate(zip(axs[3:6], processed_norm_list, flights)):\n",
    "    df.plot(\n",
    "        kind='bar', stacked=True, ax=ax,\n",
    "        color=[color_map_poh.get(c, '#CCCCCC') for c in df.columns]\n",
    "    )\n",
    "    ax.legend().remove()\n",
    "    ax.set_ylabel('Normalized P(HO$_x$) (%)', fontsize=8 if i == 0 else 0)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_ylim(ymin, ymax + (ymax - ymin) * 0.1)\n",
    "    # add percentage labels\n",
    "    for bars in ax.containers:\n",
    "        for bar in bars:\n",
    "            h = bar.get_height()\n",
    "            if h > 5:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_y() + h/2,\n",
    "                        f'{h:.0f}', ha='center', va='center', fontsize=7, color='black')\n",
    "    if i > 0:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "# -----------------\n",
    "# Formatting\n",
    "# -----------------\n",
    "plt.tight_layout(w_pad=0.2, h_pad=0.3)\n",
    "plt.subplots_adjust(left=0.08, right=0.97, bottom=0.08, top=0.93)\n",
    "\n",
    "# Common axis labels\n",
    "fig.text(0.5, 0.04, 'Time bin (hours since emission)', ha='center', fontsize=9)\n",
    "fig.text(0.02, 0.74, 'P(HO$_x$) (ppt s$^{-1}$)', va='center', rotation='vertical', fontsize=9)\n",
    "fig.text(0.02, 0.33, 'Normalized P(HO$_x$) (%)', va='center', rotation='vertical', fontsize=9)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fb162-567a-42f7-8ff6-5e18ade7b5b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# HONO normalized contribution\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Align indices with what you actually plotted\n",
    "idx = processed_df_obs.index  # same bins used in the stacks\n",
    "\n",
    "# Use the ALREADY-SCALED values that feed the bars\n",
    "hono_val = combined_df_obs['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "hono_err = combined_df_obs_err['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "\n",
    "# Total P(HOx) per bin uses the same grouped frame you plotted (after grouping/other folding)\n",
    "total_phox = processed_df_obs.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "# 2) Convert to percent (+ propagate only HONO's own σ; treating total as exact for display)\n",
    "hono_pct     = (100.0 * hono_val / total_phox).fillna(0.0).to_numpy()\n",
    "hono_pct_err = (100.0 * hono_err / total_phox).fillna(0.0).to_numpy()\n",
    "\n",
    "# 3) Find the HONO slice in the normalized stack for smart label placement\n",
    "def _find_hono_col(cols):\n",
    "    if 'HONO' in cols: return 'HONO'\n",
    "    for c in cols:\n",
    "        if 'hono' in str(c).lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "hono_col = _find_hono_col(processed_df_obs_norm.columns)\n",
    "\n",
    "# 4) Annotate ax2 (normalized stacks)\n",
    "def _fmt_pct(val, err):\n",
    "    return (f\"{val:.1f}%±{err:.1f}%\") if val < 10 else (f\"{val:.0f}%±{err:.0f}%\")\n",
    "\n",
    "x = np.arange(len(processed_df_obs_norm.index))\n",
    "y_top = processed_df_obs_norm.sum(axis=1).to_numpy()  # ≈ 100\n",
    "\n",
    "if hono_col is not None:\n",
    "    cols = list(processed_df_obs_norm.columns)\n",
    "    j = cols.index(hono_col)\n",
    "    bottom = processed_df_obs_norm.iloc[:, :j].fillna(0.0).to_numpy().sum(axis=1)\n",
    "    height = processed_df_obs_norm.iloc[:, j].fillna(0.0).to_numpy()\n",
    "    for i in range(len(x)):\n",
    "        if height[i] <= 0: \n",
    "            continue\n",
    "        label = _fmt_pct(hono_pct[i], hono_pct_err[i])\n",
    "        if height[i] < 2.0:  # tiny slice → above bar\n",
    "            ax2.text(x[i], y_top[i] + 1.0, label, ha='center', va='bottom',\n",
    "                     fontsize=8, clip_on=False, zorder=5)\n",
    "        else:               # center in HONO slice\n",
    "            ax2.text(x[i], bottom[i] + height[i]/2.0, label, ha='center',\n",
    "                     va='center', fontsize=8, clip_on=False, zorder=5)\n",
    "else:\n",
    "    # If HONO got folded into \"Others\", still show its % above the bar\n",
    "    for i in range(len(x)):\n",
    "        ax2.text(x[i], y_top[i] + 1.0, _fmt_pct(hono_pct[i], hono_pct_err[i]),\n",
    "                 ha='center', va='bottom', fontsize=8, clip_on=False, zorder=5)\n",
    "\n",
    "# Headroom for above-bar labels\n",
    "ax2.set_ylim(0, 105)\n",
    "\n",
    "# 5) Print a clean table\n",
    "hono_norm_df = pd.DataFrame({\n",
    "    \"HONO_%\": [f\"{v:.3f}%\" for v in hono_pct],\n",
    "    \"HONO_err_%\": [f\"{e:.3f}%\" for e in hono_pct_err]\n",
    "}, index=processed_df_obs_norm.index)\n",
    "\n",
    "print(\"\\n=== Normalized HONO contribution to P(HOx) (per hour/bin) ===\")\n",
    "print(hono_norm_df.to_string())\n",
    "\n",
    "avg_val = float(np.nanmean(hono_pct))\n",
    "avg_err = float(np.nanmean(hono_pct_err))\n",
    "print(f\"\\nAverage HONO contribution: {avg_val:.3f}% ± {avg_err:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c52f6-a4d4-4204-9c54-8e60dd21bfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26227540-8ad2-447f-9eca-b9494d39ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# === Figure + HONO normalized contribution: RF03 only =======\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Define colors and column order\n",
    "# -----------------------------\n",
    "color_map_poh = {\n",
    "    'HONO': '#1f77b4',\n",
    "    'Ozone': '#ff7f0e',\n",
    "    'Formaldehyde': '#2ca02c',\n",
    "    '2,3-Butanedione': '#d62728',\n",
    "    'Glyoxal': '#9467bd',\n",
    "    'Acetaldehyde': '#8c564b',\n",
    "    'Methylglyoxal': '#e377c2',\n",
    "    'Glycolaldehyde': '#7f7f7f',\n",
    "    'Others': '#cccccc'\n",
    "}\n",
    "\n",
    "common_order = [\n",
    "    'HONO',\n",
    "    'Ozone',\n",
    "    'Formaldehyde',\n",
    "    '2,3-Butanedione',\n",
    "    'Glyoxal',\n",
    "    'Acetaldehyde',\n",
    "    'Methylglyoxal',\n",
    "    'Glycolaldehyde',\n",
    "    'Others'\n",
    "]\n",
    "\n",
    "# ---------------------------------------\n",
    "# Process RF03 data\n",
    "# ---------------------------------------\n",
    "def prepare_processed_df(combined_df, threshold=5):\n",
    "    df = combined_df.copy()\n",
    "    df.index = df.index.astype(float)\n",
    "    sorted_columns = df.mean(axis=0).sort_values(ascending=False).index\n",
    "    df = df[sorted_columns]\n",
    "    processed_df = group_above_threshold(df, threshold=threshold, group_by_column='time_bin')\n",
    "    processed_df_norm = processed_df.div(processed_df.sum(axis=1), axis=0) * 100\n",
    "    return processed_df, processed_df_norm\n",
    "\n",
    "def reorder_columns(df, order):\n",
    "    df = df.copy()\n",
    "    for col in order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    cols = [c for c in order if c in df.columns] + [c for c in df.columns if c not in order]\n",
    "    return df[cols]\n",
    "\n",
    "# Prepare RF03 processed data\n",
    "processed03, processed03_norm = prepare_processed_df(combined_df_obs_rf03)\n",
    "processed03 = reorder_columns(processed03, common_order)\n",
    "processed03_norm = reorder_columns(processed03_norm, common_order)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Plot RF03\n",
    "# ---------------------------------------\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(6.5, 6.5))\n",
    "\n",
    "# Absolute P(HOx)\n",
    "processed03.plot(\n",
    "    kind='bar', stacked=True, ax=ax1,\n",
    "    color=[color_map_poh.get(c, '#CCCCCC') for c in processed03.columns]\n",
    ")\n",
    "ax1.set_title(\"RF03\", fontsize=11, pad=4)\n",
    "ax1.legend(loc='upper right', fontsize=7)\n",
    "ax1.set_ylabel('P(HO$_x$) (ppt s$^{-1}$)', fontsize=9)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "ymin, ymax = ax1.get_ylim()\n",
    "ax1.set_ylim(ymin, ymax * 1.1)\n",
    "\n",
    "# Normalized P(HOx)\n",
    "processed03_norm.plot(\n",
    "    kind='bar', stacked=True, ax=ax2,\n",
    "    color=[color_map_poh.get(c, '#CCCCCC') for c in processed03_norm.columns]\n",
    ")\n",
    "ax2.legend().remove()\n",
    "ax2.set_ylabel('Normalized P(HO$_x$) (%)', fontsize=9)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "ymin, ymax = ax2.get_ylim()\n",
    "ax2.set_ylim(ymin, ymax * 1.1)\n",
    "\n",
    "# -----------------------------\n",
    "# HONO normalized contribution\n",
    "# -----------------------------\n",
    "idx = processed03.index\n",
    "hono_val = combined_df_obs_rf03['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "hono_err = combined_df_obs_rf03_err['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "total_phox = processed03.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "hono_pct = (100.0 * hono_val / total_phox).fillna(0.0).to_numpy()\n",
    "hono_pct_err = (100.0 * hono_err / total_phox).fillna(0.0).to_numpy()\n",
    "\n",
    "def _find_hono_col(cols):\n",
    "    if 'HONO' in cols:\n",
    "        return 'HONO'\n",
    "    for c in cols:\n",
    "        if 'hono' in str(c).lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _fmt_pct(val, err):\n",
    "    return f\"{val:.1f}%±{err:.1f}%\" if val < 10 else f\"{val:.0f}%±{err:.0f}%\"\n",
    "\n",
    "hono_col = _find_hono_col(processed03_norm.columns)\n",
    "x = np.arange(len(processed03_norm.index))\n",
    "y_top = processed03_norm.sum(axis=1).to_numpy()\n",
    "\n",
    "if hono_col is not None:\n",
    "    cols = list(processed03_norm.columns)\n",
    "    j = cols.index(hono_col)\n",
    "    bottom = processed03_norm.iloc[:, :j].fillna(0.0).to_numpy().sum(axis=1)\n",
    "    height = processed03_norm.iloc[:, j].fillna(0.0).to_numpy()\n",
    "    for i in range(len(x)):\n",
    "        if height[i] <= 0:\n",
    "            continue\n",
    "        label = _fmt_pct(hono_pct[i], hono_pct_err[i])\n",
    "        if height[i] < 2.0:\n",
    "            ax2.text(x[i], y_top[i] + 1.0, label, ha='center', va='bottom', fontsize=8, clip_on=False)\n",
    "        else:\n",
    "            ax2.text(x[i], bottom[i] + height[i] / 2.0, label, ha='center', va='center', fontsize=8, clip_on=False)\n",
    "else:\n",
    "    for i in range(len(x)):\n",
    "        ax2.text(x[i], y_top[i] + 1.0, _fmt_pct(hono_pct[i], hono_pct_err[i]),\n",
    "                 ha='center', va='bottom', fontsize=8, clip_on=False)\n",
    "\n",
    "ax2.set_ylim(0, 105)\n",
    "\n",
    "# -----------------------------\n",
    "# Print HONO contribution table\n",
    "# -----------------------------\n",
    "hono_norm_df = pd.DataFrame({\n",
    "    \"HONO_%\": [f\"{v:.3f}%\" for v in hono_pct],\n",
    "    \"HONO_err_%\": [f\"{e:.3f}%\" for e in hono_pct_err]\n",
    "}, index=processed03_norm.index)\n",
    "\n",
    "print(\"\\n=== RF03: Normalized HONO contribution to P(HOx) (per hour/bin) ===\")\n",
    "print(hono_norm_df.to_string())\n",
    "\n",
    "avg_val = float(np.nanmean(hono_pct))\n",
    "avg_err = float(np.nanmean(hono_pct_err))\n",
    "print(f\"\\nRF03 average HONO contribution: {avg_val:.3f}% ± {avg_err:.3f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# Formatting\n",
    "# -----------------------------\n",
    "plt.tight_layout(h_pad=0.3)\n",
    "fig.text(0.5, 0.04, 'Time bin (hours since emission)', ha='center', fontsize=9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643760a3-efa9-4aa1-89a3-275903c5214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# === Figure + HONO normalized contribution: RF07 only =======\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Define colors and column order\n",
    "# -----------------------------\n",
    "color_map_poh = {\n",
    "    'HONO': '#1f77b4',\n",
    "    'Ozone': '#ff7f0e',\n",
    "    'Formaldehyde': '#2ca02c',\n",
    "    '2,3-Butanedione': '#d62728',\n",
    "    'Glyoxal': '#9467bd',\n",
    "    'Acetaldehyde': '#8c564b',\n",
    "    'Methylglyoxal': '#e377c2',\n",
    "    'Glycolaldehyde': '#7f7f7f',\n",
    "    'Others': '#cccccc'\n",
    "}\n",
    "\n",
    "common_order = [\n",
    "    'HONO',\n",
    "    'Ozone',\n",
    "    'Formaldehyde',\n",
    "    '2,3-Butanedione',\n",
    "    'Glyoxal',\n",
    "    'Acetaldehyde',\n",
    "    'Methylglyoxal',\n",
    "    'Glycolaldehyde',\n",
    "    'Others'\n",
    "]\n",
    "\n",
    "def prepare_processed_df(combined_df, threshold=5):\n",
    "    df = combined_df.copy()\n",
    "    df.index = df.index.astype(float)\n",
    "    sorted_columns = df.mean(axis=0).sort_values(ascending=False).index\n",
    "    df = df[sorted_columns]\n",
    "    processed_df = group_above_threshold(df, threshold=threshold, group_by_column='time_bin')\n",
    "    processed_df_norm = processed_df.div(processed_df.sum(axis=1), axis=0) * 100\n",
    "    return processed_df, processed_df_norm\n",
    "\n",
    "def reorder_columns(df, order):\n",
    "    df = df.copy()\n",
    "    for col in order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    cols = [c for c in order if c in df.columns] + [c for c in df.columns if c not in order]\n",
    "    return df[cols]\n",
    "\n",
    "# ---------------------------------------\n",
    "# Process RF07 data\n",
    "# (expects combined_df_obs_rf07 and combined_df_obs_rf07_err to exist)\n",
    "# ---------------------------------------\n",
    "processed07, processed07_norm = prepare_processed_df(combined_df_obs_rf07)\n",
    "processed07      = reorder_columns(processed07, common_order)\n",
    "processed07_norm = reorder_columns(processed07_norm, common_order)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Plot RF07\n",
    "# ---------------------------------------\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(6.5, 6.5))\n",
    "\n",
    "# Absolute P(HOx)\n",
    "processed07.plot(\n",
    "    kind='bar', stacked=True, ax=ax1,\n",
    "    color=[color_map_poh.get(c, '#CCCCCC') for c in processed07.columns]\n",
    ")\n",
    "ax1.set_title(\"RF07\", fontsize=11, pad=4)\n",
    "ax1.legend(loc='upper right', fontsize=7)\n",
    "ax1.set_ylabel('P(HO$_x$) (ppt s$^{-1}$)', fontsize=9)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "ymin, ymax = ax1.get_ylim()\n",
    "ax1.set_ylim(ymin, ymax * 1.1)\n",
    "\n",
    "# Normalized P(HOx)\n",
    "processed07_norm.plot(\n",
    "    kind='bar', stacked=True, ax=ax2,\n",
    "    color=[color_map_poh.get(c, '#CCCCCC') for c in processed07_norm.columns]\n",
    ")\n",
    "ax2.legend().remove()\n",
    "ax2.set_ylabel('Normalized P(HO$_x$) (%)', fontsize=9)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "ymin, ymax = ax2.get_ylim()\n",
    "ax2.set_ylim(ymin, ymax * 1.1)\n",
    "\n",
    "# -----------------------------\n",
    "# HONO normalized contribution\n",
    "# -----------------------------\n",
    "idx = processed07.index\n",
    "hono_val = combined_df_obs_rf07['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "hono_err = combined_df_obs_rf07_err['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "total_phox = processed07.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "hono_pct     = (100.0 * hono_val / total_phox).fillna(0.0).to_numpy()\n",
    "hono_pct_err = (100.0 * hono_err / total_phox).fillna(0.0).to_numpy()\n",
    "\n",
    "def _find_hono_col(cols):\n",
    "    if 'HONO' in cols:\n",
    "        return 'HONO'\n",
    "    for c in cols:\n",
    "        if 'hono' in str(c).lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _fmt_pct(val, err):\n",
    "    return f\"{val:.1f}%±{err:.1f}%\" if val < 10 else f\"{val:.0f}%±{err:.0f}%\"\n",
    "\n",
    "hono_col = _find_hono_col(processed07_norm.columns)\n",
    "x = np.arange(len(processed07_norm.index))\n",
    "y_top = processed07_norm.sum(axis=1).to_numpy()  # ~100\n",
    "\n",
    "if hono_col is not None:\n",
    "    cols = list(processed07_norm.columns)\n",
    "    j = cols.index(hono_col)\n",
    "    bottom = processed07_norm.iloc[:, :j].fillna(0.0).to_numpy().sum(axis=1)\n",
    "    height = processed07_norm.iloc[:, j].fillna(0.0).to_numpy()\n",
    "    for i in range(len(x)):\n",
    "        if height[i] <= 0:\n",
    "            continue\n",
    "        label = _fmt_pct(hono_pct[i], hono_pct_err[i])\n",
    "        if height[i] < 2.0:  # tiny slice → above the bar\n",
    "            ax2.text(x[i], y_top[i] + 1.0, label, ha='center', va='bottom',\n",
    "                     fontsize=8, clip_on=False)\n",
    "        else:                # center within HONO slice\n",
    "            ax2.text(x[i], bottom[i] + height[i]/2.0, label, ha='center',\n",
    "                     va='center', fontsize=8, clip_on=False)\n",
    "else:\n",
    "    # HONO got grouped into \"Others\" — still show its % above the bar\n",
    "    for i in range(len(x)):\n",
    "        ax2.text(x[i], y_top[i] + 1.0, _fmt_pct(hono_pct[i], hono_pct_err[i]),\n",
    "                 ha='center', va='bottom', fontsize=8, clip_on=False)\n",
    "\n",
    "# Headroom for above-bar labels\n",
    "ax2.set_ylim(0, 105)\n",
    "\n",
    "# -----------------------------\n",
    "# Print HONO contribution table\n",
    "# -----------------------------\n",
    "hono_norm_df = pd.DataFrame({\n",
    "    \"HONO_%\": [f\"{v:.3f}%\" for v in hono_pct],\n",
    "    \"HONO_err_%\": [f\"{e:.3f}%\" for e in hono_pct_err]\n",
    "}, index=processed07_norm.index)\n",
    "\n",
    "print(\"\\n=== RF07: Normalized HONO contribution to P(HOx) (per hour/bin) ===\")\n",
    "print(hono_norm_df.to_string())\n",
    "\n",
    "avg_val = float(np.nanmean(hono_pct))\n",
    "avg_err = float(np.nanmean(hono_pct_err))\n",
    "print(f\"\\nRF07 average HONO contribution: {avg_val:.3f}% ± {avg_err:.3f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final formatting\n",
    "# -----------------------------\n",
    "plt.tight_layout(h_pad=0.3)\n",
    "fig.text(0.5, 0.04, 'Time bin (hours since emission)', ha='center', fontsize=9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8eccf-9e06-418c-a131-f2ede604e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# === Figure + HONO normalized contribution: RF09 only =======\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Define colors and column order\n",
    "# -----------------------------\n",
    "color_map_poh = {\n",
    "    'HONO': '#1f77b4',\n",
    "    'Ozone': '#ff7f0e',\n",
    "    'Formaldehyde': '#2ca02c',\n",
    "    '2,3-Butanedione': '#d62728',\n",
    "    'Glyoxal': '#9467bd',\n",
    "    'Acetaldehyde': '#8c564b',\n",
    "    'Methylglyoxal': '#e377c2',\n",
    "    'Glycolaldehyde': '#7f7f7f',\n",
    "    'Others': '#cccccc'\n",
    "}\n",
    "\n",
    "common_order = [\n",
    "    'HONO',\n",
    "    'Ozone',\n",
    "    'Formaldehyde',\n",
    "    '2,3-Butanedione',\n",
    "    'Glyoxal',\n",
    "    'Acetaldehyde',\n",
    "    'Methylglyoxal',\n",
    "    'Glycolaldehyde',\n",
    "    'Others'\n",
    "]\n",
    "\n",
    "def prepare_processed_df(combined_df, threshold=5):\n",
    "    df = combined_df.copy()\n",
    "    df.index = df.index.astype(float)\n",
    "    sorted_columns = df.mean(axis=0).sort_values(ascending=False).index\n",
    "    df = df[sorted_columns]\n",
    "    processed_df = group_above_threshold(df, threshold=threshold, group_by_column='time_bin')\n",
    "    processed_df_norm = processed_df.div(processed_df.sum(axis=1), axis=0) * 100\n",
    "    return processed_df, processed_df_norm\n",
    "\n",
    "def reorder_columns(df, order):\n",
    "    df = df.copy()\n",
    "    for col in order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    cols = [c for c in order if c in df.columns] + [c for c in df.columns if c not in order]\n",
    "    return df[cols]\n",
    "\n",
    "# ---------------------------------------\n",
    "# Process RF09 data\n",
    "# (expects combined_df_obs_rf09 and combined_df_obs_rf09_err to exist)\n",
    "# ---------------------------------------\n",
    "processed09, processed09_norm = prepare_processed_df(combined_df_obs_rf09)\n",
    "processed09      = reorder_columns(processed09, common_order)\n",
    "processed09_norm = reorder_columns(processed09_norm, common_order)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Plot RF09\n",
    "# ---------------------------------------\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(6.5, 6.5))\n",
    "\n",
    "# Absolute P(HOx)\n",
    "processed09.plot(\n",
    "    kind='bar', stacked=True, ax=ax1,\n",
    "    color=[color_map_poh.get(c, '#CCCCCC') for c in processed09.columns]\n",
    ")\n",
    "ax1.set_title(\"RF09\", fontsize=11, pad=4)\n",
    "ax1.legend(loc='upper right', fontsize=7)\n",
    "ax1.set_ylabel('P(HO$_x$) (ppt s$^{-1}$)', fontsize=9)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "ymin, ymax = ax1.get_ylim()\n",
    "ax1.set_ylim(ymin, ymax * 1.1)\n",
    "\n",
    "# Normalized P(HOx)\n",
    "processed09_norm.plot(\n",
    "    kind='bar', stacked=True, ax=ax2,\n",
    "    color=[color_map_poh.get(c, '#CCCCCC') for c in processed09_norm.columns]\n",
    ")\n",
    "ax2.legend().remove()\n",
    "ax2.set_ylabel('Normalized P(HO$_x$) (%)', fontsize=9)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "ymin, ymax = ax2.get_ylim()\n",
    "ax2.set_ylim(ymin, ymax * 1.1)\n",
    "\n",
    "# -----------------------------\n",
    "# HONO normalized contribution\n",
    "# -----------------------------\n",
    "idx = processed09.index\n",
    "hono_val = combined_df_obs_rf09['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "hono_err = combined_df_obs_rf09_err['HONO'].reindex(idx).astype(float).fillna(0.0)\n",
    "total_phox = processed09.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "hono_pct     = (100.0 * hono_val / total_phox).fillna(0.0).to_numpy()\n",
    "hono_pct_err = (100.0 * hono_err / total_phox).fillna(0.0).to_numpy()\n",
    "\n",
    "def _find_hono_col(cols):\n",
    "    if 'HONO' in cols:\n",
    "        return 'HONO'\n",
    "    for c in cols:\n",
    "        if 'hono' in str(c).lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _fmt_pct(val, err):\n",
    "    return f\"{val:.1f}%±{err:.1f}%\" if val < 10 else f\"{val:.0f}%±{err:.0f}%\"\n",
    "\n",
    "hono_col = _find_hono_col(processed09_norm.columns)\n",
    "x = np.arange(len(processed09_norm.index))\n",
    "y_top = processed09_norm.sum(axis=1).to_numpy()  # ~100\n",
    "\n",
    "if hono_col is not None:\n",
    "    cols = list(processed09_norm.columns)\n",
    "    j = cols.index(hono_col)\n",
    "    bottom = processed09_norm.iloc[:, :j].fillna(0.0).to_numpy().sum(axis=1)\n",
    "    height = processed09_norm.iloc[:, j].fillna(0.0).to_numpy()\n",
    "    for i in range(len(x)):\n",
    "        if height[i] <= 0:\n",
    "            continue\n",
    "        label = _fmt_pct(hono_pct[i], hono_pct_err[i])\n",
    "        if height[i] < 2.0:  # tiny slice → above the bar\n",
    "            ax2.text(x[i], y_top[i] + 1.0, label, ha='center', va='bottom',\n",
    "                     fontsize=8, clip_on=False)\n",
    "        else:                # center within HONO slice\n",
    "            ax2.text(x[i], bottom[i] + height[i]/2.0, label, ha='center',\n",
    "                     va='center', fontsize=8, clip_on=False)\n",
    "else:\n",
    "    # HONO got grouped into \"Others\" — still show its % above the bar\n",
    "    for i in range(len(x)):\n",
    "        ax2.text(x[i], y_top[i] + 1.0, _fmt_pct(hono_pct[i], hono_pct_err[i]),\n",
    "                 ha='center', va='bottom', fontsize=8, clip_on=False)\n",
    "\n",
    "# Headroom for above-bar labels\n",
    "ax2.set_ylim(0, 105)\n",
    "\n",
    "# -----------------------------\n",
    "# Print HONO contribution table\n",
    "# -----------------------------\n",
    "hono_norm_df = pd.DataFrame({\n",
    "    \"HONO_%\": [f\"{v:.3f}%\" for v in hono_pct],\n",
    "    \"HONO_err_%\": [f\"{e:.3f}%\" for e in hono_pct_err]\n",
    "}, index=processed09_norm.index)\n",
    "\n",
    "print(\"\\n=== RF09: Normalized HONO contribution to P(HOx) (per hour/bin) ===\")\n",
    "print(hono_norm_df.to_string())\n",
    "\n",
    "avg_val = float(np.nanmean(hono_pct))\n",
    "avg_err = float(np.nanmean(hono_pct_err))\n",
    "print(f\"\\nRF09 average HONO contribution: {avg_val:.3f}% ± {avg_err:.3f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final formatting\n",
    "# -----------------------------\n",
    "plt.tight_layout(h_pad=0.3)\n",
    "fig.text(0.5, 0.04, 'Time bin (hours since emission)', ha='center', fontsize=9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b551e4-40b6-41df-bf64-a86be266481c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a9517-418f-4def-861d-7f417565bfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41735df4-35a9-45ab-9a88-5567c29f5dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ae900-d70a-4dfc-823f-06b4f08f0090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a02e72-e2ab-4c72-bab3-07b6667cc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# How many HONO will be consumed with the first hour of plume aging?\n",
    "# -----------------------------------------------------------------\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8*4, 6*1), sharex=True)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_HONO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "'''\n",
    "var_x, var_y = 'Plume_Age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "var_x, var_y = 'Plume_Age', 'NOx: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[2], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "var_x, var_y = 'Plume_Age', 'OHRnox: OHRvoc'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[3], '', set_xlabel=True, set_ylabel=True, show_legend=True)\n",
    "'''\n",
    "# Close the figure to prevent it from being displayed\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4480646-f0bf-401d-9669-25035393c4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb487c5e-71d8-41d3-b7f5-92a2f393f5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed94484-de8e-4f8b-ae46-999a8e78c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# OVOC photolysis to total HOx production (>1hour aging)\n",
    "# Analysis in the P(HOx) section\n",
    "# ------------------------------------------------------\n",
    "processed_df_obs_norm_largerthan1h = processed_df_obs_norm.drop([0.5, 1.0])\n",
    "df = processed_df_obs_norm_largerthan1h.describe()\n",
    "\n",
    "# Printing the mean ± std for each compound\n",
    "for compound, stats in df.items():\n",
    "    print(f\"{compound}: ({stats['mean']:.0f}±{stats['std']:.0f})%\")\n",
    "    print()\n",
    "processed_df_obs_norm_largerthan1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715ee00-2e4d-456c-b666-d92426c72e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15017635-8d06-4281-aff7-6ba11afa0bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c86a5e-9563-47b8-90bf-36f267380cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0860dda8-1bac-45b1-a3cd-5e9baeab7993",
   "metadata": {},
   "source": [
    "### The analysis of VOC\n",
    "Select HCHO, ALD2, MA,\n",
    "Furanoids, acrolein, and 1,3-butadiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9ee69-c4f2-4e49-b060-bc852677ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(7*3, 5*2), sharex=True)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Furanoids excl. (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][0], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'Acrolein (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][1], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "#var_x, var_y = 'Plume_Age', '1,3-Butadiene (dil)'\n",
    "#plot_data_helper('Flight_ID', var_x, var_y,  axes[0][2], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'Butanedione (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][2], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "\n",
    "var_x, var_y = 'Plume_Age', 'Formaldehyde (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][0], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'Acetaldehyde (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][1], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'Maleic anhydride (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][2], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "\n",
    "# Annotate compound names in each subplot\n",
    "compounds = ['Furanoids excl.', 'Acrolein', '1,3-Butadiene', 'Formaldehyde', 'Acetaldehyde', 'Maleic anhydride']\n",
    "compounds = ['Furanoids excl.', 'Acrolein', 'Diacetyl', 'Formaldehyde', 'Acetaldehyde', 'Maleic anhydride']\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.text(0.95, 0.0, compounds[i], transform=ax.transAxes, ha='right', va='bottom', fontsize=25)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=20)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "    #ax.set_xlim(0, 5)  # Set x-axis limit to 5\n",
    "\n",
    "# Add title\n",
    "#fig.text(0.5, 1.02, \"VOC evolution in the biomass burning plumes over US\", ha='center', fontsize=40)\n",
    "\n",
    "# Add x-label and y-label\n",
    "fig.text(0.52, -0.015, \"Plume age (hour)\", ha='center', fontsize=30)\n",
    "fig.text(-0.02, 0.5, \"Dilution corrected mixing ratio (ppb)\", va='center', rotation='vertical', fontsize=30)\n",
    "\n",
    "# Manually show legend for the first subplot\n",
    "desired_order = desired_order_flights\n",
    "reorder_legend(axes[0][0], desired_order, id2fire_name, legend_title='', fontsize=15, title_fontsize=20, legend_loc='upper right', markerscale=1.5)\n",
    "\n",
    "# Tighten layout\n",
    "plt.tight_layout(w_pad=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef7bcc-d631-448f-b77b-673fce8abbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(7*3, 5*2), sharex=True)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_HONO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][0], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'Formaldehyde (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][1], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "#var_x, var_y = 'Plume_Age', '1,3-Butadiene (dil)'\n",
    "#plot_data_helper('Flight_ID', var_x, var_y,  axes[0][2], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'Glyoxal (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][2], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "\n",
    "var_x, var_y = 'Plume_Age', 'Methylglyoxal (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][0], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'Acetaldehyde (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][1], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_O3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][2], '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "\n",
    "\n",
    "\n",
    "# Add title\n",
    "#fig.text(0.5, 1.02, \"VOC evolution in the biomass burning plumes over US\", ha='center', fontsize=40)\n",
    "\n",
    "# Add x-label and y-label\n",
    "fig.text(0.52, -0.015, \"Plume age (hour)\", ha='center', fontsize=30)\n",
    "fig.text(-0.02, 0.5, \"Dilution corrected mixing ratio (ppb)\", va='center', rotation='vertical', fontsize=30)\n",
    "\n",
    "# Manually show legend for the first subplot\n",
    "desired_order = desired_order_flights\n",
    "reorder_legend(axes[0][0], desired_order, id2fire_name, legend_title='', fontsize=15, title_fontsize=20, legend_loc='upper right', markerscale=1.5)\n",
    "\n",
    "# Tighten layout\n",
    "plt.tight_layout(w_pad=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877f2d9-dfa3-4d5e-a72e-9ebe0f63a363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40c093-a715-4c20-bae7-295d33cd689e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d548a-f61b-41c3-933b-d74395cbfac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to collect the initial concentrations of each compound\n",
    "initial_dmf = []\n",
    "initial_sesq = []\n",
    "\n",
    "# Collect initial concentration for each flight\n",
    "for flight_id in all_data_mcm_bbvoc['Flight_ID'].unique():\n",
    "    all_data_mcm_bbvoc_each = all_data_mcm_bbvoc[all_data_mcm_bbvoc['Flight_ID'] == flight_id]\n",
    "    # Collect initial concentration of Dimethylfuran if available\n",
    "    initial_dmf.append(all_data_mcm_bbvoc_each['2,5-Dimethylfuran'].iloc[0])\n",
    "    # Collect initial concentration of Sesquiterpenes if available\n",
    "    initial_sesq.append(all_data_mcm_bbvoc_each['Sesquiterpenes'].iloc[0]*1000)\n",
    "\n",
    "print(\"This is analysis for specific initial VOC concentration.\")\n",
    "# Calculate mean and standard deviation of initial concentrations across all flights\n",
    "if initial_dmf:\n",
    "    dmf_mean = np.mean(initial_dmf)\n",
    "    dmf_std = np.std(initial_dmf)\n",
    "    print(f\"Dimethylfuran: Mean of initial concentrations (ppb) = {dmf_mean:.2f}±{dmf_std:.2f}\")\n",
    "else:\n",
    "    print(\"No Dimethylfuran data available.\")\n",
    "if initial_sesq:\n",
    "    sesq_mean = np.mean(initial_sesq)\n",
    "    sesq_std = np.std(initial_sesq)\n",
    "    print(f\"Sesquiterpenes: Mean of initial concentrations (ppt) = {sesq_mean:.2f}±{sesq_std:.2f}\")\n",
    "else:\n",
    "    print(\"No Sesquiterpenes data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a457e0a-e278-4bf4-b95d-d2116234b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(7, 5), sharex=True)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'BIACET'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_xlabel=False, set_ylabel=False, show_legend=False)\n",
    "\n",
    "\n",
    "axes.tick_params(axis='x', which='major', labelsize=20)\n",
    "axes.tick_params(axis='y', which='major', labelsize=20)\n",
    "axes.set_xlim(0, 5)  # Set x-axis limit to 5\n",
    "\n",
    "# Add title\n",
    "fig.text(0.5, 1.02, \"VOC evolution in the biomass burning plumes over US\", ha='center', fontsize=40)\n",
    "\n",
    "# Add x-label and y-label\n",
    "fig.text(0.52, -0.015, \"Plume age (hour)\", ha='center', fontsize=30)\n",
    "fig.text(-0.02, 0.5, \"Dilution corrected mixing ratio (ppb)\", va='center', rotation='vertical', fontsize=30)\n",
    "\n",
    "# Manually show legend for the first subplot\n",
    "desired_order = desired_order_flights\n",
    "reorder_legend(axes, desired_order, id2fire_name, legend_title='', fontsize=15, title_fontsize=20, legend_loc='upper right', markerscale=1.5)\n",
    "\n",
    "# Tighten layout\n",
    "plt.tight_layout(w_pad=1.5)\n",
    "plt.show()\n",
    "# VOC testing!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ca155-eba4-4196-969b-23199ce91ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Individual VOC testing\n",
    "# ======================\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7*1, 5*1), sharex=True)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Butanedione (dil)'\n",
    "var_x, var_y = 'Plume_Age', 'Acetic acid + glycolaldehyde (dil)'\n",
    "#var_x, var_y = 'output_chem_age', 'MACR + MVK (dil)'\n",
    "\n",
    "\n",
    "#var_x, var_y = 'Plume_Age', 'Methylglyoxal (dil)'\n",
    "#var_x, var_y = 'Plume_Age', 'MACR + MVK (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_xlabel=False, set_ylabel=False, show_legend=True)\n",
    "\n",
    "# Tighten layout\n",
    "plt.tight_layout(w_pad=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b642c0-fe5e-4196-8e1e-2e1f125d86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nmb_for_models(all_data_obs_combined, all_data_mcm_bbvoc, all_data_mcm_gcvoc, all_data_gc, Lagrangian_flights, var_x, var_y_list):\n",
    "    \"\"\"\n",
    "    Calculates and organizes the Normalized Median Bias (NMB) for each VOC across different models using polynomial regression.\n",
    "    \n",
    "    Parameters:\n",
    "    - all_data_obs_combined, all_data_mcm_bbvoc, all_data_mcm_gcvoc, all_data_gc: DataFrames for observational and model data.\n",
    "    - Lagrangian_flights: List of flights considered for analysis.\n",
    "    - var_x: Independent variable.\n",
    "    - var_y_list: List of VOCs to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with VOCs as rows, models as columns, and formatted NMB±std as values.\n",
    "    \"\"\"\n",
    "    var_y_list_dic = [var_y.replace(' (dil)', '') for var_y in var_y_list]\n",
    "    nmb_summary = pd.DataFrame(index=var_y_list_dic, columns=['MCM_BB_VOC', 'MCM_GC_VOC', 'GEOS-Chem'])\n",
    "\n",
    "    for var_y in var_y_list:\n",
    "        nmb_values = {model: [] for model in ['MCM_BB_VOC', 'MCM_GC_VOC', 'GEOS-Chem']}\n",
    "\n",
    "        for group in Lagrangian_flights:\n",
    "            # Define the degree of the polynomial\n",
    "            degree = 2 if group!='FN19' else 1\n",
    "            group_data_obs = all_data_obs_combined[(all_data_obs_combined['Flight_ID'] == group) & (~all_data_obs_combined[var_x].isna()) & (~all_data_obs_combined[var_y].isna())]\n",
    "\n",
    "            if group_data_obs.empty:\n",
    "                continue\n",
    "\n",
    "            x_obs, y_obs = group_data_obs[var_x].values, group_data_obs[var_y].values\n",
    "\n",
    "            # Create a polynomial regression model pipeline\n",
    "            poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "            poly_model.fit(x_obs.reshape(-1, 1), y_obs)\n",
    "\n",
    "            for model_data, model_name in zip([all_data_mcm_bbvoc, all_data_mcm_gcvoc, all_data_gc], ['MCM_BB_VOC', 'MCM_GC_VOC', 'GEOS-Chem']):\n",
    "                group_data_model = model_data[model_data['Flight_ID'] == group]\n",
    "                if group_data_model.empty:\n",
    "                    continue\n",
    "\n",
    "                x_model, y_model = group_data_model[var_x].values, group_data_model[var_y].values\n",
    "                y_predicted = poly_model.predict(x_model.reshape(-1, 1))\n",
    "                nmb = 100 * (np.nanmedian(y_model) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "                nmb_values[model_name].append(nmb)\n",
    "\n",
    "        for model_name, nmb_list in nmb_values.items():\n",
    "            # Replace inf/-inf with 0 in nmb_list\n",
    "            nmb_list = [0 if np.isinf(nmb) else nmb for nmb in nmb_list]\n",
    "\n",
    "            if nmb_list:\n",
    "                #mean_nmb = np.nanmean(nmb_list)\n",
    "                #std_nmb = np.nanstd(nmb_list)\n",
    "                #nmb_summary.loc[var_y.replace(' (dil)', ''), model_name] = f\"({mean_nmb:.0f}±{std_nmb:.0f})%\"\n",
    "                med_nmb = np.nanmedian(nmb_list)\n",
    "                iqr_nmb = np.nanpercentile(nmb_list, 75) - np.nanpercentile(nmb_list, 25)\n",
    "                nmb_summary.loc[var_y.replace(' (dil)', ''), model_name] = f\"({med_nmb:.0f}±{iqr_nmb:.0f})%\"\n",
    "            else:\n",
    "                nmb_summary.loc[var_y.replace(' (dil)', ''), model_name] = np.nan\n",
    "\n",
    "    return nmb_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4ebe4-b8a8-4b85-b597-8ae23c0e0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Print out the data\n",
    "# ---------------------\n",
    "var_x = 'Plume_Age'\n",
    "'''\n",
    "var_y_list = [\n",
    "    'Formaldehyde (dil)',\n",
    "    'Acetaldehyde (dil)',\n",
    "    'Maleic anhydride (dil)',\n",
    "    'Furanoids excl. (dil)',\n",
    "    '2,5-Dimethylfuran (dil)',\n",
    "    'Methylfuran (dil)',\n",
    "    'Acrolein (dil)',\n",
    "    '1,3-Butadiene (dil)',\n",
    "    'Isoprene (dil)',\n",
    "    'Monoterpenes (dil)',\n",
    "    'Xylenes (dil)',\n",
    "    '2-Butenal (dil)',\n",
    "    'Cresol (dil)',\n",
    "    'Guaiacol (dil)',\n",
    "    'Lumped C>=3 aldehydes (dil)',\n",
    "    'Glyoxal (dil)',\n",
    "    'Formic acid (dil)',\n",
    "    'Acetic acid (dil)',\n",
    "    'MACR + MVK (dil)',\n",
    "    'MEK (dil)',\n",
    "    'Glycolaldehyde (dil)',\n",
    "    'Methylglyoxal (dil)',\n",
    "    'Hydroxy acetone (dil)',\n",
    "    'Phenol (dil)',\n",
    "    'Benzaldehyde (dil)',\n",
    "    'Furanone (dil)',\n",
    "    'Acrolein (dil)',\n",
    "    'Maleic anhydride (dil)',\n",
    "    'Butanedione (dil)',\n",
    "]\n",
    "'''\n",
    "\n",
    "var_y_list = [\n",
    "    'Furanoids excl. (dil)',\n",
    "    '2,5-Dimethylfuran (dil)',\n",
    "    '1,3-Butadiene (dil)',\n",
    "    'Isoprene (dil)',\n",
    "    'Monoterpenes (dil)',\n",
    "    'Xylenes (dil)',\n",
    "    '2-Butenal (dil)',\n",
    "    'Cresol (dil)',\n",
    "    'Guaiacol (dil)',\n",
    "    'Syringol (dil)', \n",
    "    'Sesquiterpenes (dil)',\n",
    "    'Phenol (dil)',\n",
    "\n",
    "    'Formaldehyde (dil)',\n",
    "    'Acetaldehyde (dil)',\n",
    "    'Maleic anhydride (dil)',\n",
    "    'Methylfuran (dil)',\n",
    "    'Lumped C>=3 aldehydes (dil)',\n",
    "    'Glyoxal (dil)',\n",
    "    'Formic acid (dil)',\n",
    "    'Acetic acid (dil)',\n",
    "    'Acetic acid + glycolaldehyde (dil)',\n",
    "    'MACR + MVK (dil)',\n",
    "    'MEK (dil)',\n",
    "    'Glycolaldehyde (dil)',\n",
    "    'Methylglyoxal (dil)',\n",
    "    'Hydroxy acetone (dil)',\n",
    "    'Phenol (dil)',\n",
    "    'Benzaldehyde (dil)',\n",
    "    'Acrolein (dil)',\n",
    "    'Butanedione (dil)',\n",
    "]\n",
    "\n",
    "\n",
    "# !!! Make the order right, primary first and then secondary.\n",
    "df = calculate_nmb_for_models(all_data_obs_combined, all_data_mcm_bbvoc, all_data_mcm_gcvoc, all_data_gc, Lagrangian_flights, var_x, var_y_list)\n",
    "\n",
    "# Function to replace \"-100±0\" with np.nan\n",
    "def replace_with_nan(value):\n",
    "    if value == '(-100±0)%':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Applying the function to each cell in the DataFrame\n",
    "df = df.applymap(replace_with_nan)\n",
    "\n",
    "\n",
    "# Create a dictionary for instrument uncertainties\n",
    "uncertainty_mapping = {\n",
    "    \"Formaldehyde\"   : \"±40%\",\n",
    "    \"Acetaldehyde\"   : \"±15%\",\n",
    "    \"Furanoids excl.\": \"±(15–50)%\",\n",
    "    \"Methylfuran\"    : \"±(15–50)%\",\n",
    "    \"Xylenes\"        : \"±(15–50)%\",\n",
    "    \"Acetic acid\"    : \"±15%\",\n",
    "    \"MACR + MVK\"     : \"±15%\",\n",
    "    \"MEK\"            : \"±15%\",\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "# Add 'instrument uncertainty' column with conditional values\n",
    "df.insert(0, 'Measurement uncertainty', df.index.map(lambda x: uncertainty_mapping.get(x, \"±50%\")))\n",
    "\n",
    "# Convert NaN values to the string \"NaN\"\n",
    "df = df.fillna('NaN')\n",
    "\n",
    "# Reset the index to turn it into a column\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Compound'}, inplace=True)\n",
    "\n",
    "\n",
    "# Save out the table\n",
    "df.to_csv('/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/NMB_VOC_dil.csv', index=True)  # Set index=False if you don't want to save row indices\n",
    "\n",
    "# Save out the table to Word document\n",
    "from docx import Document\n",
    "\n",
    "doc = Document()\n",
    "table = doc.add_table(rows=1, cols=len(df.columns))  # Start with a header row\n",
    "\n",
    "# Fill in the header row\n",
    "hdr_cells = table.rows[0].cells\n",
    "for i, column_name in enumerate(df.columns):\n",
    "    hdr_cells[i].text = str(column_name)\n",
    "\n",
    "# Append rows to the table and fill in the data\n",
    "for index, row in df.iterrows():\n",
    "    row_cells = table.add_row().cells  # Add a new row and then access its cells\n",
    "    for col_index, value in enumerate(row):\n",
    "        # Replace np.nan with an empty string, ensure all values are converted to string\n",
    "        row_cells[col_index].text = '' if pd.isna(value) else str(value)\n",
    "\n",
    "# Save the document\n",
    "doc.save('/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/NMB_VOC_dil.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a1a00-d397-45ea-a350-2de437be9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the ozone enhancement\n",
    "df_temp = all_data_obs_lagrangian[['O3 (dil)', 'Flight_ID']]\n",
    "for flight_id in df_temp['Flight_ID'].unique():\n",
    "    df_temp_each = df_temp[df_temp['Flight_ID'] == flight_id]\n",
    "    mean = df_temp_each['O3 (dil)'].mean()\n",
    "    std  = df_temp_each['O3 (dil)'].std()\n",
    "    print(f\"{flight_id}: {mean:.0f}±{std:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52d35a-3baf-4d5f-8b93-0ae609abbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = all_data_obs_combined[['O3 (dil)', 'Flight_ID']]\n",
    "for flight_id in df_temp['Flight_ID'].unique():\n",
    "    df_temp_each = df_temp[df_temp['Flight_ID'] == flight_id]\n",
    "    mean = df_temp_each['O3 (dil)'].mean()\n",
    "    std  = df_temp_each['O3 (dil)'].std()\n",
    "    max  =  df_temp_each['O3 (dil)'].max()\n",
    "    print(f\"{flight_id}: {mean:.0f}±{std:.0f}, {max:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f53704-5746-4858-a191-0bfe127b628b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc5e53-4665-404a-a668-16fcba0bffb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10ed6b-d8a4-4133-84b7-093e1ccc4ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "882e2db7-d503-4cb1-b915-4119fb87e708",
   "metadata": {},
   "source": [
    "### Ozone analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6381e87d-bf96-43a9-9229-0be846c01dc9",
   "metadata": {},
   "source": [
    "#### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fea0d0-2127-4a11-90b0-aa8748612fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7.25, 3), sharey='row')\n",
    "# ------------------------------------------------\n",
    "# 1) Plot your two subplots\n",
    "# ------------------------------------------------\n",
    "# Subplot (a)\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_O3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=False, set_annotate= True)\n",
    "\n",
    "# Subplot (b)\n",
    "var_x, var_y = 'output_chem_age', 'NEMR_O3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False)\n",
    "\n",
    "# Add subplot labels\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Set up y limitation\n",
    "    ax.set_ylim(0)\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.95, labels[i], transform=ax.transAxes, fontsize=9, fontweight='bold', va='top', ha='left')\n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend above the figure\n",
    "# ------------------------------------------------\n",
    "legend_flights  = fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    \n",
    "    #bbox_to_anchor=(0.52, 1.03),\n",
    "    #ncol=5,\n",
    "    #fontsize=13.4,\n",
    "    #columnspacing=0.01,     # Decrease horizontal space between columns\n",
    "    bbox_to_anchor=(0.52, 1.05),\n",
    "    ncol=3,\n",
    "    fontsize=7.8,\n",
    "    columnspacing=1,     # Decrease horizontal space between columns\n",
    "\n",
    "    labelspacing=0.01,      # Decrease vertical space between entries\n",
    "    handletextpad=0,      # Space between handle and text\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', markersize=2, linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes[0].legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',      # or pick another location\n",
    "    fontsize=7.5,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save the full figure in high resolution\n",
    "for fmt in ['pdf', 'jpeg', 'tiff']:  # Choose the formats you need\n",
    "    fig.savefig(f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/maintext_figures/Fig3_O3_TS.{fmt}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0611c4-d500-4585-afd3-f987e2d2323a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f60a00-389d-4235-b935-8ced3b4fc96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e36d3-33c5-4c61-95e4-445d6277213b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5546d-7570-49f7-ad2d-fee554891f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d71982bb-9103-4856-983b-70d5f558e111",
   "metadata": {},
   "source": [
    "#### Updated figure 3, waiting for Lu's approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57cc767-9b06-4c13-8406-5af543dd3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6), sharey='row')\n",
    "# ------------------------------------------------\n",
    "# 1) Plot your two subplots\n",
    "# ------------------------------------------------\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_O3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=False, set_annotate= True)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend on the right side\n",
    "# ------------------------------------------------\n",
    "legend_flights  = fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.535, 1.1),\n",
    "    ncol=2,\n",
    "    fontsize=15,\n",
    "    labelspacing=0.0,      # Decrease vertical space between entries\n",
    "    handletextpad=0.,      # Space between handle and text\n",
    "    columnspacing=-0.1,     # Decrease horizontal space between columns\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes.legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',      # or pick another location\n",
    "    fontsize=25,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323eff5-e902-4df0-80e5-99978bc77f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb44f11-7893-4b95-babd-ec5fe1b0f632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffd05f-5467-4887-baa4-eeb9a767cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig, axes = plt.subplots(2, 2, figsize=(9*2, 7.5*2), sharey='row', sharex='col')\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_O3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0,0], '', set_ylabel=True, show_legend=True, set_xlabel=False)\n",
    "axes[0, 0].set_xlim(0, 8)\n",
    "var_x, var_y = 'output_chem_age', 'NEMR_O3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0, 1], '', set_ylabel=False, show_legend=False, set_xlabel=False)\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_PAN'\n",
    "\n",
    "\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1,0], '', set_ylabel=True, show_legend=False, set_xlabel=True)\n",
    "axes[1, 0].set_xlim(0, 8)\n",
    "axes[1, 0].set_ylim(0, 0.012)\n",
    "\n",
    "var_x, var_y = 'output_chem_age', 'NEMR_PAN'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1, 1], '', set_ylabel=False, show_legend=False, set_xlabel=True)\n",
    "\n",
    "# Adding text labels to each subplot\n",
    "labels = ['(a)', '(b)', '(c)', '(d)']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Set up y limitation\n",
    "    ax.set_ylim(0)\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.95, labels[i], transform=ax.transAxes, fontsize=20, fontweight='bold', va='top', ha='left')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dce175-a0c5-4545-86ba-69cebbc36980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddba19-69b4-4116-b291-a37a99b26973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a939d3b-dad0-4195-b43b-e3190117947a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab458fe3-0afd-4f22-962e-cb3f6779a438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727030d9-3d97-4167-9aa7-222c60f07988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc7d30-92b8-4e4e-9a8f-b1c38e7f41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 6))\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_PAN_rate'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=True)\n",
    "# Set up y limitation\n",
    "axes.set_ylim(0)\n",
    "#ax.set_xlim(0, 5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b39fa8-af66-4a66-8ceb-a6ae68bce176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae2d32-e946-470f-8b72-8138a9ab02c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a2ab2-6fcf-4a09-b130-dddeea957809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f706c-b329-4277-9b12-d32044140f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9c821-58c1-49b1-a67c-7b2b22e365ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3af323-a9bd-4b9f-86c3-37d02f74d475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e4029-263c-414e-b240-6e36550088db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a939cc-1ff6-429b-8c58-38bd4a6c5f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05509971-fa65-41e8-8920-a16ded9efc38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46210f68-f755-4fc5-8a2a-e57b1b2bc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import sys  # Import sys to use sys.stdout\n",
    "\n",
    "def replace_zeros_with_nan(df, column):\n",
    "    df[column] = df[column].replace(0, np.nan)\n",
    "\n",
    "def define_bins_and_labels(plume_age_max):\n",
    "    hour_max = np.ceil(plume_age_max)\n",
    "    bins = np.arange(0, hour_max + 1)\n",
    "    labels = [f\"{int(b)}-{int(b+1)}\" for b in bins[:-1]]\n",
    "    return bins, labels\n",
    "\n",
    "def calculate_statistics(df, bin_column, group_column):\n",
    "    stats = df.groupby(bin_column)[group_column].agg(['mean', 'std', 'min', 'max', 'count']).reset_index()\n",
    "    stats['Mean ± Standard deviation (% per hour)'] = stats.apply(\n",
    "        lambda row: f\"{row['mean']:.1f} ± {row['std']:.1f}\" if pd.notna(row['std']) else f\"{row['mean']:.1f}\", axis=1)\n",
    "    stats['min'] = stats['min'].map(lambda x: f\"{x:.1f}\")\n",
    "    stats['max'] = stats['max'].map(lambda x: f\"{x:.1f}\")\n",
    "    stats.rename(columns={'count': 'Number of datapoints'}, inplace=True)\n",
    "    stats = stats.drop(['mean', 'std'], axis=1)\n",
    "    return stats[['Plume age (hours)', 'Mean ± Standard deviation (% per hour)', 'min', 'max', 'Number of datapoints']]\n",
    "\n",
    "def create_word_document(stats, path):\n",
    "    doc = Document()\n",
    "    table = doc.add_table(rows=1, cols=len(stats.columns))\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    for i, column_name in enumerate(stats.columns):\n",
    "        hdr_cells[i].text = str(column_name)\n",
    "    for index, row in stats.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for col_index, value in enumerate(row):\n",
    "            row_cells[col_index].text = str(value)\n",
    "    doc.save(path)\n",
    "\n",
    "def print_csv(stats):\n",
    "    stats.to_csv(sys.stdout, index=False)\n",
    "\n",
    "def process_dataset(df, path, var):    \n",
    "    replace_zeros_with_nan(df, var)\n",
    "    df[var] *= 100  # Scale the variable by 100 to convert it to percentage\n",
    "    bins, labels = define_bins_and_labels(df['Plume_Age'].max())\n",
    "    df['Plume age (hours)'] = pd.cut(df['Plume_Age'], bins=bins, right=False, labels=labels)\n",
    "    stats = calculate_statistics(df, 'Plume age (hours)', var)\n",
    "    create_word_document(stats, path.replace('.docx', '.docx'))\n",
    "    print_csv(stats)  # Printing the CSV content\n",
    "\n",
    "var = 'NEMR_O3_rate'\n",
    "# Full dataset\n",
    "df_full = all_data_obs[['Flight_ID', 'Plume_Age', 'NEMR_O3_rate']].copy()\n",
    "file_path = f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/{var}_full.docx'\n",
    "process_dataset(df_full, file_path, var)\n",
    "\n",
    "# Lagrangian dataset\n",
    "df_lagrangian = all_data_obs_lagrangian[['Flight_ID', 'Plume_Age', 'NEMR_O3_rate']].copy()\n",
    "file_path = f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/{var}_lagrangian.docx'\n",
    "process_dataset(df_lagrangian, file_path, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648708b4-cc67-4b12-83f9-d8cc86514691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b28d5-eab9-49c2-8d1f-552b57a889c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb672f95-9964-48af-940c-21619675bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Calculate production rate with chemical ages\n",
    "# --------------------------------------------\n",
    "# Assume 'all_data_obs_lagrangian' includes columns for 'NEMR_O3' and 'NEMR_PAN'\n",
    "df_test = all_data_obs_lagrangian[['Flight_ID', 'output_chem_age', 'NEMR_O3', 'NEMR_PAN']].copy()\n",
    "\n",
    "# Replace zeros with NaN for both compounds\n",
    "df_test['NEMR_O3'] = df_test['NEMR_O3'].replace(0, np.nan)\n",
    "df_test['NEMR_PAN'] = df_test['NEMR_PAN'].replace(0, np.nan)\n",
    "\n",
    "# Calculate rates for each compound\n",
    "df_test['NEMR_O3_rates_chem'] = df_test['NEMR_O3'] / df_test['output_chem_age'] * 100\n",
    "df_test['NEMR_PAN_rates_chem'] = df_test['NEMR_PAN'] / df_test['output_chem_age'] * 100\n",
    "\n",
    "# Replace inf with nan for both compounds\n",
    "df_test['NEMR_O3_rates_chem'].replace(np.inf, np.nan, inplace=True)\n",
    "df_test['NEMR_PAN_rates_chem'].replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "# Calculate statistics for O3\n",
    "mean_O3 = df_test['NEMR_O3_rates_chem'].mean()\n",
    "std_O3 = df_test['NEMR_O3_rates_chem'].std()\n",
    "max_O3 = df_test['NEMR_O3_rates_chem'].max()\n",
    "min_O3 = df_test['NEMR_O3_rates_chem'].min()\n",
    "\n",
    "# Calculate statistics for PAN\n",
    "mean_PAN = df_test['NEMR_PAN_rates_chem'].mean()\n",
    "std_PAN = df_test['NEMR_PAN_rates_chem'].std()\n",
    "max_PAN = df_test['NEMR_PAN_rates_chem'].max()\n",
    "min_PAN = df_test['NEMR_PAN_rates_chem'].min()\n",
    "\n",
    "# Print formatted strings\n",
    "print(f\"P(O3) using chemical age (% hr-1): {mean_O3:.1f}±{std_O3:.1f}, max={max_O3:.1f}, min={min_O3:.1f}\")\n",
    "print(f\"P(PAN) using chemical age (% hr-1): {mean_PAN:.1f}±{std_PAN:.1f}, max={max_PAN:.1f}, min={min_PAN:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e28866-bfc4-47c9-9e8d-8472e118dc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d140cf2-b34c-478d-bccf-262f525b0781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62dd29-e4a7-498b-8a90-6914f65d2712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e559857-a667-47f6-8401-9f6936c68330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48b47f-a3c9-4181-a977-80b9c84504d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00f100-384a-48e0-9550-fa4ed2a8bdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df7513-7a8c-4da9-b465-f94ef2fabcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175529d-723a-4e61-91f6-0094f07e71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bin_data(x, y, bin_width=0.2):\n",
    "    \"\"\"\n",
    "    Bin x and y data into fixed intervals, ensuring that the range from min to max x is covered,\n",
    "    and calculate the mean of y in each bin.\n",
    "\n",
    "    Parameters:\n",
    "    x (array-like): The array of x values (e.g., time).\n",
    "    y (array-like): The array of y values (e.g., values corresponding to x).\n",
    "    bin_width (float): Width of each bin.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Tuple containing:\n",
    "        - binned_x (np.array): Midpoints of each bin.\n",
    "        - binned_y (np.array): Average of y values in each bin.\n",
    "    \"\"\"\n",
    "    # Define the range for bins that exactly covers the min to max of x\n",
    "    start_bin = bin_width * np.floor(x.min() / bin_width)\n",
    "    end_bin = bin_width * np.ceil(x.max() / bin_width)\n",
    "    bins = np.arange(start_bin, end_bin + bin_width, bin_width)\n",
    "    bin_indices = np.digitize(x, bins, right=True)\n",
    "\n",
    "    # Aggregate values in each bin\n",
    "    bin_sums = {}\n",
    "    bin_counts = {}\n",
    "    for xi, yi in zip(bin_indices, y):\n",
    "        if xi in bin_sums:\n",
    "            bin_sums[xi] += yi\n",
    "            bin_counts[xi] += 1\n",
    "        else:\n",
    "            bin_sums[xi] = yi\n",
    "            bin_counts[xi] = 1\n",
    "    \n",
    "    # Calculate the mean for each bin\n",
    "    binned_x = np.array([(bins[i-1] + bins[i]) / 2 for i in sorted(bin_sums.keys()) if i > 0 and i <= len(bins)])\n",
    "    binned_y = np.array([bin_sums[i] / bin_counts[i] for i in sorted(bin_sums.keys()) if i > 0 and i <= len(bins)])\n",
    "\n",
    "    # Convert arrays to pandas Series\n",
    "    binned_x = pd.Series(binned_x)\n",
    "    binned_y = pd.Series(binned_y)\n",
    "    return binned_x, binned_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df5505-b0b5-4283-992e-7875b628cbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa4696-f110-46e1-b6f8-a3ab172b1910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d683533-91f0-48c6-a5a4-2f6db63092b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 1x2 figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8*2, 6*2))#, sharey='row')\n",
    "\n",
    "# First plot\n",
    "var_x, var_y = 'Plume_Age', 'CH2O: NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0, 0], '', set_ylabel=True, show_legend=True)\n",
    "\n",
    "# Second plot\n",
    "var_x, var_y = 'NO', 'CH2O: NO2'\n",
    "plot_data_helper('CH2O_NO2_group', var_x, var_y, axes[0, 1], '', set_ylabel=True, show_legend=True)\n",
    "\n",
    "# Third plot\n",
    "var_x, var_y = 'Plume_Age', 'OHRnox: OHRvoc'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1,0], '', set_ylabel=True, show_legend=True)\n",
    "\n",
    "# Fourth plot\n",
    "var_x, var_y = 'Plume_Age', 'LROx: LNOx'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1,1], '', set_ylabel=True, show_legend=True)\n",
    "\n",
    "# Adding text labels to each subplot\n",
    "labels = ['(a)', '(b)', '(c)', '(d)']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.9, labels[i], transform=ax.transAxes, fontsize=16, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Add annotation\n",
    "# The first and second\n",
    "for ax, var_x in zip([axes[0,0], axes[0,1]], ['Plume_Age', 'NO']):\n",
    "    # Get the current limits of the x-axis    \n",
    "    #ax.axhline(y=1, color='black', linestyle='-')  \n",
    "    #ax.axhline(y=4, color='black', linestyle='--')  \n",
    "    ax.axhline(y=1, color='black', linestyle='--')  \n",
    "    ax.axhline(y=4, color='black', linestyle='-')  \n",
    "    # Add text above and below the line\n",
    "    text_position_above = 4.1  # Slightly above the line\n",
    "    text_position_below = 0.8  # Slightly below the line\n",
    "    ax.text(x=all_data_obs_lagrangian[var_x].max()*0.85, y=text_position_above,ha='center', va='bottom', s='↑ NO$_{x}$ limited', fontsize=20)\n",
    "    ax.text(x=all_data_obs_lagrangian[var_x].max()*0.85, y=text_position_below,ha='center', va='top', s='↓ VOC limited', fontsize=20)\n",
    "\n",
    "#axes[1, 1].axhline(y=0.5, color='black', linestyle='-', label='y = 0.5')\n",
    "#axes[1, 1].text(x=all_data_mcm_bbvoc[var_x].max()*0.55, y=0.52, ha='center', va='bottom', s='↑ NO$_{x}$ limited', fontsize=15)\n",
    "#axes[1, 1].text(x=all_data_mcm_bbvoc[var_x].max()*0.55, y=0.48, ha='center', va='top', s='↓ VOC limited', fontsize=15)\n",
    "\n",
    "# Get the current limits of the x-axis    \n",
    "axes[1, 0].axhline(y=0.04, color='black', linestyle='-')  \n",
    "#axes[1, 0].axhline(y=0.2, color='black', linestyle='-')  \n",
    "axes[1, 0].text(x=all_data_obs_combined[var_x].max()*0.28, y=0.04,ha='left', va='bottom', s='↑ VOC limited', fontsize=25)\n",
    "#axes[1, 0].text(x=all_data_obs_combined[var_x].max()*0.10, y=0.2,ha='center', va='bottom', s='↑ VOC limited', fontsize=25)\n",
    "axes[1, 0].text(x=all_data_obs_combined[var_x].max()*0.28, y=0.04,ha='left', va='top', s='↓ NO$_{x}$ limited', fontsize=25)\n",
    "axes[1, 0].set_ylim(top=0.22)\n",
    "\n",
    "axes[1, 1].axhline(y=1, color='black', linestyle='-', label='y = 1')\n",
    "axes[1, 1].text(x=all_data_mcm_bbvoc[var_x].max()*0.35, y=1.1, ha='left', va='bottom', s='↑ NO$_{x}$ limited', fontsize=25)\n",
    "axes[1, 1].text(x=all_data_mcm_bbvoc[var_x].max()*0.35, y=0.9, ha='left', va='top', s='↓ VOC limited', fontsize=25)\n",
    "plt.tight_layout()\n",
    "# Save the figure with DPI 500\n",
    "fig.savefig('/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/Ozone_Sensitivity.png', dpi=500)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the maximum 'Plume_Age' where 'CH2O: NO2' is less than 4\n",
    "hours_FNR     = all_data_obs_combined[all_data_obs_combined['CH2O: NO2'] < 4]['Plume_Age'].max()\n",
    "# Calculate the maximum 'Plume_Age' where 'theta' is larger than 0.01\n",
    "#hours_theta   = all_data_obs_combined[all_data_obs_combined['OHRnox: OHRvoc'] > 0.01]['Plume_Age'].min()\n",
    "hours_theta   = all_data_mcm_bbvoc[all_data_mcm_bbvoc['OHRnox: OHRvoc'] > 0.04]['Plume_Age'].max()\n",
    "# Calculate the maximum 'Plume_Age' where 'LROx: LNOx' is larger than 0.01\n",
    "hours_radical = all_data_mcm_bbvoc[all_data_mcm_bbvoc['LROx: LNOx'] < 1]['Plume_Age'].max()\n",
    "# Print the result formatted to one decimal place\n",
    "print(f'FNR    : {hours_FNR:.1f} hours')\n",
    "print(f'Theta  : {hours_theta:.1f} hours')\n",
    "print(f'Radical: {hours_radical:.1f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8191b01-8605-4b0e-8c4c-43284baafe13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e8e69-2249-4793-9de8-6d9549133726",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = {\n",
    "    'PO3': 'PO$_{3}$ (ppb h$^{-1}$)',\n",
    "    'POx': 'PO$_{x}$ (ppb h$^{-1}$)',\n",
    "    'OH turnover rate': 'OH turnover rate (ppb h$^{-1}$)',\n",
    "    \n",
    "    'TVOCR': 'Total VOC reactivity ($s^{-1}$)',\n",
    "    'OPE': 'OPE (h$^{-1}$)',\n",
    "    \n",
    "    'HO2': 'HO$_{2}$ (molecule cm$^{-3}$)',\n",
    "    'cal_OH_mean': 'OH (1×10$^{6}$ molecule cm$^{-3}$)',\n",
    "\n",
    "    'Physical age': 'Physical age (hour)',\n",
    "    'Chemical age': 'Chemical age (hour)',\n",
    "    'Plume_Age': 'Physical age (hour)',\n",
    "    'cal_chem_age_median': 'Chemical age (hour)',\n",
    "    'cal_chem_age_mean': 'Chemical age (hour)',\n",
    "    'output_chem_age': 'Chemical age (hour)',\n",
    "\n",
    "    'CH2O': 'CH$_{2}$O (ppb)',\n",
    "    'Formaldehyde': 'Formaldehyde (ppb)',\n",
    "    'NOx': 'NO$_{x}$ (ppb)',\n",
    "    'NO2': 'NO$_{2}$ (ppb)',\n",
    "    'NO': 'NO (ppb)' ,\n",
    "    'O3': 'Ozone (ppb)' ,\n",
    "    'Ozone': 'Ozone (ppb)',\n",
    "    \n",
    "    'OHRvoc vs OHRnox': 'OHR$_{VOC}$: OHR$_{NOx}$',\n",
    "    'OHRvoc: OHRnox': 'OHR$_{VOC}$: OHR$_{NOx}$',\n",
    "    'OHRnox vs OHRvoc': 'OHR$_{NOx}$: OHR$_{VOC}$',\n",
    "    'OHRnox: OHRvoc': 'θ value',\n",
    "    \n",
    "    'CH2O vs NO2': 'CH$_{2}$O: NO$_{2}$',\n",
    "    'CH2O: NO2': 'CH$_{2}$O: NO$_{2}$',\n",
    "    \n",
    "    'H2O2 vs HNO3': 'H$_{2}$O$_{2}$: HNO$_{3}$',\n",
    "    'LROx': 'L$_{ROx}$ (ppb h$^{-1}$)',\n",
    "    'LNOx_broad': 'L$_{NOx}$ (ppb h$^{-1}$)',\n",
    "    'LROx vs LNOx_broad': 'L$_{ROx}$: L$_{NOx}$', \n",
    "    'NEMR(O3)': '∆O$_{3}$/∆CO',\n",
    "    'NEMR_O3': '∆O$_{3}$/∆CO',\n",
    "    'NEMR_O3_rate': '∆O$_{3}$/∆CO per hour',\n",
    "    'NEMR(Ox)': '∆(O$_{3}$+ NO$_{2}$)/∆CO',\n",
    "    'NEMR_Ox': '∆(O$_{3}$+ NO$_{2}$)/∆CO',\n",
    "    'NEMR_PAN': '∆(PAN)/∆CO',\n",
    "    'NEMR_PAN_rate': '∆(PAN)/∆CO per hour',\n",
    "\n",
    "    'NEMR_furans': '∆(Lumped furans)/∆CO',\n",
    "    'NEMR_furfurals': '∆(Lumped furfurals)/∆CO',    \n",
    "    'NEMR_MA': '∆(Maleic anhydride)/∆CO',    \n",
    "    'Furans': 'Lumped furans (ppb)',\n",
    "    'Furfurals': 'Lumped furfurals (ppb)',    \n",
    "    'Maleic anhydride': 'Maleic anhydride (ppb)',    \n",
    "\n",
    "    'LROx: LNOx': r'L$_{ROx}$: L$_{NOx}$',\n",
    "    'Ln: Q': r'L$_{n}$: Q',\n",
    "    'H2O2: HNO3': r'H$_{2}$O$_{2}$: HNO$_{3}$',\n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa17cd-9c91-4afa-b55e-7f71117defbe",
   "metadata": {},
   "source": [
    "#### Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb388567-8635-4ffd-a036-794553f291bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 1x2 figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7.25, 3), sharey='row')\n",
    "# ------------------------------------------------\n",
    "# 1) Plot your two subplots\n",
    "# ------------------------------------------------\n",
    "# First plot\n",
    "var_x, var_y = 'Plume_Age', 'CH2O: NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=False, set_annotate=False)\n",
    "# Second plot\n",
    "var_x, var_y = 'NO', 'CH2O: NO2'\n",
    "plot_data_helper('CH2O_NO2_group', var_x, var_y, axes[1], '', set_ylabel=False, show_legend=True)\n",
    "# Adding text labels to each subplot\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.95, labels[i], transform=ax.transAxes, fontsize=9, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Add annotation\n",
    "# The first and second\n",
    "for ax, var_x in zip([axes[0], axes[1]], ['Plume_Age', 'NO']):\n",
    "    # Get the current limits of the x-axis    \n",
    "    #ax.axhline(y=1, color='black', linestyle='-')  \n",
    "    #ax.axhline(y=4, color='black', linestyle='--')  \n",
    "    ax.axhline(y=1, color='black', linestyle='--')  \n",
    "    #ax.axhline(y=4, color='black', linestyle='-')  \n",
    "    ax.axhspan(4, 6, color='black', alpha=0.5, edgecolor='none', linewidth=0)  # Add a thick red semi-transparent span\n",
    "\n",
    "    # Add text above and below the line\n",
    "    text_position_above = 6.1  # Slightly above the line\n",
    "    text_position_below = 0.8  # Slightly below the line\n",
    "    ax.text(x=all_data_obs_lagrangian[var_x].max()*0.85, y=text_position_above,ha='center', va='bottom', s='↑ NO$_{x}$ limited', fontsize=7.5)\n",
    "    ax.text(x=all_data_obs_lagrangian[var_x].max()*0.85, y=text_position_below,ha='center', va='top', s='↓ VOC limited', fontsize=7.5)\n",
    "    \n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    #'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    #'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend above the figure\n",
    "# ------------------------------------------------\n",
    "legend_flights  = axes[0].legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    #bbox_to_anchor=(0.52, 1.03),\n",
    "    #ncol=5,\n",
    "    #fontsize=13.4,\n",
    "    #columnspacing=0.01,     # Decrease horizontal space between columns\n",
    "    bbox_to_anchor=(0.48, 1.12),\n",
    "    ncol=2,\n",
    "    fontsize=6.8,\n",
    "    columnspacing=1,     # Decrease horizontal space between columns\n",
    "    labelspacing=0.01,      # Decrease vertical space between entries\n",
    "    handletextpad=0,      # Space between handle and text\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', markersize=2, linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes[0].legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',   # 'lower right' is valid\n",
    "    fontsize=7,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the full figure in high resolution\n",
    "for fmt in ['pdf', 'jpeg', 'tiff']:  # Choose the formats you need\n",
    "    fig.savefig(f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/maintext_figures/Fig4_O3_Sens_FNR.{fmt}', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97482b4e-fd87-452d-9a32-d77282beb49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7278df-55fc-4468-bcf7-26e6edfff46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b187f-eb3e-4e4f-a75b-dfec95da8ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa7eee-921f-4d53-ae52-9633073bb29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54f6e56d-c805-4ee0-a034-db4eb3340308",
   "metadata": {},
   "source": [
    "#### Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639f1cf-cdf2-4a17-963f-52b5d074efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 1x2 figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7.25, 3))\n",
    "# ------------------------------------------------\n",
    "# 1) Plot your two subplots\n",
    "# ------------------------------------------------\n",
    "# Subplot (a)\n",
    "var_x, var_y = 'Plume_Age', 'OHRnox: OHRvoc'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=False)\n",
    "# Subplot (b)\n",
    "var_x, var_y = 'Plume_Age', 'LROx: LNOx'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=True, show_legend=False)\n",
    "\n",
    "# Adding text labels to each subplot\n",
    "labels = ['A', 'B', 'C', 'd']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.9, labels[i], transform=ax.transAxes, fontsize=9, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Get the current limits of the x-axis    \n",
    "axes[0].axhline(y=0.04, color='black', linestyle='-', linewidth=0.5)  \n",
    "axes[0].axhline(y=0.2, color='black', linestyle='-', linewidth=0.5)  \n",
    "axes[0].text(x=all_data_obs_lagrangian[var_x].max()*0.0, y=0.2,ha='left', va='bottom', s='↑ VOC limited', fontsize=8)\n",
    "axes[0].text(x=all_data_obs_lagrangian[var_x].max()*0.0, y=0.04,ha='left', va='top', s='↓ NO$_{x}$ limited', fontsize=8)\n",
    "axes[0].set_ylim(top=0.22)\n",
    "\n",
    "axes[1].axhline(y=1, color='black', linestyle='-', label='y = 1', linewidth=0.5)\n",
    "axes[1].text(x=all_data_mcm_bbvoc[var_x].max()*0.6, y=1.01, ha='left', va='bottom', s='↑ NO$_{x}$ limited', fontsize=8)\n",
    "axes[1].text(x=all_data_mcm_bbvoc[var_x].max()*0.6, y=0.9, ha='left', va='top', s='↓ VOC limited', fontsize=8)\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend above the figure\n",
    "# ------------------------------------------------\n",
    "legend_flights  = fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    \n",
    "    #bbox_to_anchor=(0.52, 1.03),\n",
    "    #ncol=5,\n",
    "    #fontsize=13.4,\n",
    "    #columnspacing=0.01,     # Decrease horizontal space between columns\n",
    "    bbox_to_anchor=(0.51, 1.05),\n",
    "    ncol=3,\n",
    "    fontsize=7.8,\n",
    "    columnspacing=1,     # Decrease horizontal space between columns\n",
    "\n",
    "    labelspacing=0.01,      # Decrease vertical space between entries\n",
    "    handletextpad=0,      # Space between handle and text\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', markersize=2, linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes[0].legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',      # or pick another location\n",
    "    fontsize=7.5,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save the full figure in high resolution\n",
    "for fmt in ['pdf', 'jpeg', 'tiff']:  # Choose the formats you need\n",
    "    fig.savefig(f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/maintext_figures/Fig5_O3_Sens_other.{fmt}', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e36f4-a4e2-4a65-9cb5-a802f78d7f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26d4a5-428d-4913-a948-c31166771a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45500522-49fd-4204-883a-c35538d02eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ecc6d-67b5-438b-a04e-398d3d3a3b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fb860-c692-42ff-b43d-83d872fb5e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484eeed-4a62-4997-ad6a-99eb3e273468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61331132-0e51-4164-8992-3a1e0719cca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878d067-7727-47df-a8ab-987014e431c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4dfa4-149f-43a4-a0c3-46196cb90cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96ed43-5402-4a64-a654-f036e2347c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0eace-4031-4f0b-bf58-fda859a2809d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92ea04-6e0e-4eb3-845a-3be870f49804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eece153-74fc-4a0d-843c-036c3041f4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e9c75-6959-491e-b53c-66b6f10287ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd475b-bb24-4351-89eb-96de0097c75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a890be-cc1e-478f-adb6-fb01b3f3b274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2e8cc-d86a-48a0-9436-1a9f2e4a90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Set up a 1x2 figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8*2, 6*1))#, sharey='row')\n",
    "\n",
    "var_x, var_y = 'Plume_Age', 'CH2O: NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=False)\n",
    "\n",
    "var_x, var_y = 'Plume_Age', 'OHRnox: OHRvoc'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=True, show_legend=True)\n",
    "\n",
    "\n",
    "# Adding text labels to each subplot\n",
    "labels = ['(a)', '(b)', '(c)', '(d)']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.9, labels[i], transform=ax.transAxes, fontsize=16, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Get the current limits of the x-axis \n",
    "axes[0].axhline(y=1, color='black', linestyle='-')  \n",
    "# Add text above and below the line\n",
    "text_position_below = 1  # Slightly below the line\n",
    "axes[0].text(x=all_data_obs_lagrangian[var_x].max()*0.85, y=text_position_below,ha='center', va='bottom', s='↑ NO$_{x}$ limited', fontsize=20)\n",
    "axes[0].text(x=all_data_obs_lagrangian[var_x].max()*0.85, y=text_position_below,ha='center', va='top', s='↓ VOC limited', fontsize=20)\n",
    "\n",
    "\n",
    "axes[1].axhline(y=0.01, color='black', linestyle='-')  \n",
    "axes[1].axhline(y=0.2, color='black', linestyle='-')  \n",
    "axes[1].text(x=all_data_obs_lagrangian[var_x].max()*0.0, y=0.2,ha='left', va='bottom', s='↑ VOC limited', fontsize=20)\n",
    "axes[1].text(x=all_data_obs_lagrangian[var_x].max()*0.0, y=0.01,ha='left', va='top', s='↓ NO$_{x}$ limited', fontsize=20)\n",
    "axes[1].set_ylim(top=0.22)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a22938-cfe3-47d8-bca6-6c69e1d58b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f6744-a34e-48f7-ad97-1486b12a7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Lu happy\n",
    "# Check if the DataFrame and required columns exist\n",
    "if 'NO' in all_data_obs_combined.columns and 'OHRnox: OHRvoc' in all_data_obs_combined.columns:\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(10, 6))  # Set the size of the figure\n",
    "    plt.scatter(all_data_obs_combined['NO'], 1/all_data_obs_combined['OHRnox: OHRvoc'], alpha=0.5)\n",
    "\n",
    "    # Adding title and labels\n",
    "    plt.title('Scatter Plot of NO vs. OHRnox: OHRvoc')\n",
    "    plt.xlabel('NO (units as per your data)')\n",
    "    plt.ylabel('OHRnox: OHRvoc (units as per your data)')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)  # Optional: add a grid for better visibility\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"One or both columns are missing in your DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027c675-f23a-4325-bff4-f8155d49f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a figure\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 6))#, sharey='row')\n",
    "# Fourth plot\n",
    "var_x, var_y = 'CH2O: NO2', 'OHRvoc: OHRnox'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e2249-14c6-49b1-bba8-dbc6ef5ee9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411044fd-8157-44d8-87f9-dd365c723154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voc_comparisons(df_mod1, df_mod2, mod1_name, mod2_name, var_comp, ax, title, set_ylabel, show_legend, set_xlabel=True, annotate_one_to_one=False, flights=['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']):\n",
    "    unique_groups = flights\n",
    "    group_colors = sns.color_palette(\"bright\", len(unique_groups)) if len(unique_groups) != 2 else np.array([[0.5, 0.0, 0.0, 1.0], [1.0, 0.40740741, 0.0, 1.0]])\n",
    "    df_mod1 = df_mod1[df_mod1['Flight_ID'].isin(unique_groups)]\n",
    "    df_mod2 = df_mod2[df_mod2['Flight_ID'].isin(unique_groups)]\n",
    "    \n",
    "    bin_size = 10 / 60  # 2 minutes converted to hours\n",
    "    \n",
    "    for idx, flight_id in enumerate(unique_groups):\n",
    "        df_mod1_each = df_mod1[df_mod1['Flight_ID'] == flight_id]\n",
    "        df_mod2_each = df_mod2[df_mod2['Flight_ID'] == flight_id]\n",
    "        df_mod1_each['Time_Bin'] = (df_mod1_each['Plume_Age'] // bin_size) * bin_size\n",
    "        df_mod2_each['Time_Bin'] = (df_mod2_each['Plume_Age'] // bin_size) * bin_size\n",
    "        df_mod1_binned = df_mod1_each.groupby('Time_Bin').mean(numeric_only=True)\n",
    "        df_mod2_binned = df_mod2_each.groupby('Time_Bin').mean(numeric_only=True)\n",
    "        \n",
    "        if var_comp == 'XO2':\n",
    "            data_mod1_each = df_mod1_binned['HO2'] + df_mod1_binned['RO2']\n",
    "            data_mod2_each = df_mod2_binned['HO2'] + df_mod2_binned['RO2']\n",
    "        elif var_comp == 'L(Ox)':\n",
    "            data_mod1_each = -df_mod1_binned[var_comp]\n",
    "            data_mod2_each = -df_mod2_binned[var_comp]\n",
    "        else:\n",
    "            data_mod1_each = df_mod1_binned[var_comp]\n",
    "            data_mod2_each = df_mod2_binned[var_comp]\n",
    "\n",
    "        face_color = group_colors[idx]\n",
    "        fire_name = id2fire_name.get(flight_id,flight_id)\n",
    "        ax.scatter(data_mod1_each, data_mod2_each, edgecolors=group_colors[idx], facecolors=face_color, label=fire_name)\n",
    "\n",
    "        x_arr = data_mod1_each.to_numpy()\n",
    "        y_arr = data_mod2_each.to_numpy()\n",
    "        slope_each = np.linalg.lstsq(x_arr[:, None], y_arr, rcond=None)[0][0]\n",
    "        \n",
    "        #slope_each = np.linalg.lstsq(data_mod1_each[:, np.newaxis], data_mod2_each, rcond=None)[0][0]\n",
    "        ax.annotate(f'Slope={slope_each:.2f}', xy=(0.05, 0.85 - 0.1 * idx), xycoords='axes fraction', fontsize=20, color=group_colors[idx], ha='left', va='top')\n",
    "    \n",
    "    if var_comp == 'XO2':\n",
    "        data_mod1 = df_mod1['HO2'] + df_mod1['RO2']\n",
    "        data_mod2 = df_mod2['HO2'] + df_mod2['RO2']\n",
    "    elif var_comp == 'L(Ox)':\n",
    "        data_mod1 = -df_mod1[var_comp]\n",
    "        data_mod2 = -df_mod2[var_comp]\n",
    "    else:\n",
    "        data_mod1 = df_mod1[var_comp]\n",
    "        data_mod2 = df_mod2[var_comp]\n",
    "\n",
    "    #slope = np.linalg.lstsq(data_mod1[:, np.newaxis], data_mod2, rcond=None)[0][0]\n",
    "\n",
    "    # convert Series to numpy arrays so we can reshape\n",
    "    x_arr = data_mod1.to_numpy()\n",
    "    y_arr = data_mod2.to_numpy()\n",
    "    slope = np.linalg.lstsq(x_arr[:, None], y_arr, rcond=None)[0][0]\n",
    "\n",
    "\n",
    "    ax.annotate(f'Slope (all fires)={slope:.2f}', xy=(0.05, 0.95), xycoords='axes fraction', fontsize=20, color='black', ha='left', va='top')\n",
    "\n",
    "    min_val_dummy, max_val_dummy = np.min([np.min(data_mod1), np.min(data_mod2)]), np.max([np.max(data_mod1), np.max(data_mod2)])\n",
    "    x_vals = np.linspace(min_val_dummy, max_val_dummy, 100)\n",
    "    y_vals = slope * x_vals\n",
    "\n",
    "    ax.plot(x_vals, x_vals, 'k--')\n",
    "    if annotate_one_to_one:\n",
    "        ax.annotate('1:1 Slope', xy=(0.7 * max_val_dummy, 0.8 * max_val_dummy + 0.05 * max_val_dummy), fontsize=20, color='black')\n",
    "\n",
    "    ax.plot(x_vals, y_vals, 'r-', color='black')\n",
    "    \n",
    "    if show_legend:\n",
    "        ax.legend(fontsize=18, loc='lower right')\n",
    "\n",
    "    ax.set_title(title, fontsize=25)\n",
    "    ax.tick_params(axis='both', labelsize=20)\n",
    "    if set_xlabel: ax.set_xlabel(mod1_name, fontsize=25)\n",
    "    if set_ylabel: ax.set_ylabel(mod2_name, fontsize=25)\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_ylim(bottom=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51c764-3bf8-4534-8979-6e9d5eedda5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519d192-6d35-4a3c-8ff7-b777f5b1c782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79e7eaaf-636c-4d60-801c-c41cefcf03d8",
   "metadata": {},
   "source": [
    "#### Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403894c9-1214-4c42-a8f8-44321342e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Model comparisons in ozone production and ROx concentartion.\n",
    "# Supplement figure\n",
    "# ==============================================================\n",
    "nrows, ncols = 2, 2 \n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(6*2, 5*2))  # Increase the size for better visibility\n",
    "flights = ['RF03', 'FN19']\n",
    "\n",
    "plot_voc_comparisons(all_data_mcm_gcvoc, all_data_mcm_bbvoc, '$MCM_{GCVOC}$', '$MCM_{BBVOC}$',\n",
    "                     'P(Ox)', axes[0, 0], \n",
    "                     'P(O$_{3}$) (ppb h$^{-1}$)', set_ylabel=True, show_legend=False, set_xlabel=False, flights= flights)\n",
    "plot_voc_comparisons(all_data_mcm_gcvoc, all_data_gc, '$MCM_{GCVOC}$', '$GEOS-Chem$', \n",
    "                     'P(O3)', axes[1, 0], \n",
    "                     '', set_ylabel=True, show_legend=False, set_xlabel=True, flights=flights)\n",
    "\n",
    "plot_voc_comparisons(all_data_mcm_gcvoc, all_data_mcm_bbvoc, '$MCM_{GCVOC}$', '$MCM_{BBVOC}$',\n",
    "                     'XO2', axes[0, 1], \n",
    "                     'Total XO$_{2}$ (ppb)', set_ylabel=False, show_legend=True, set_xlabel=False, annotate_one_to_one=True, flights= flights)\n",
    "plot_voc_comparisons(all_data_mcm_gcvoc, all_data_gc, '$MCM_{GCVOC}$', '$GEOS-Chem$', \n",
    "                     'XO2', axes[1, 1], \n",
    "                     '', set_ylabel=False, show_legend=False, set_xlabel=True, flights= flights)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd51f0e-52ad-4a6f-806f-cdb9acc1676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = ['CH2O: NO2', 'LROx: LNOx', 'OHRnox: OHRvoc']\n",
    "nrows, ncols = len(compounds), 2\n",
    "fig, axes = plt.subplots(ncols, nrows, figsize=(6*nrows, 5*ncols))  # Adjust the figure size to fit the 2x3 layout\n",
    "for idx, compound in enumerate(compounds):\n",
    "    if idx == len(compounds)-1: \n",
    "        if_legend = True\n",
    "        if_annotate_one_to_one = True\n",
    "    else:\n",
    "        if_legend = False\n",
    "        if_annotate_one_to_one = False\n",
    "    if_ylabel = True if idx == 0 else False\n",
    "    plot_voc_comparisons(all_data_mcm_gcvoc, all_data_mcm_bbvoc, '$MCM_{GCVOC}$', '$MCM_{BBVOC}$',\n",
    "                         compound, axes[0, idx], \n",
    "                         text_labels[compound], set_ylabel=if_ylabel, show_legend=False, set_xlabel=False)\n",
    "    plot_voc_comparisons(all_data_mcm_gcvoc, all_data_gc, '$MCM_{GCVOC}$', '$GEOS-Chem$', \n",
    "                         compound, axes[1, idx], \n",
    "                         '', set_ylabel=if_ylabel, show_legend=if_legend, set_xlabel=True, annotate_one_to_one=if_annotate_one_to_one)\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3b1f3-be95-4614-a284-feb01e806acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!! Go to O3_NOx_CH2O_VOCR_v6 for ozone in each flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa153458-c72a-4234-9a3b-22e892a74572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d373218-996c-4cfd-8dda-c2d349616ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19105ca5-f2d3-4d85-8eb3-8fc20827711e",
   "metadata": {},
   "source": [
    "#### Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e757d65-db80-462a-8d1e-a0b822184007",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7.25, 3), sharey='row')\n",
    "# ------------------------------------------------\n",
    "# 1) Plot your two subplots\n",
    "# ------------------------------------------------\n",
    "# Subplot (a)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_PAN'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True)\n",
    "\n",
    "axes[0].set_ylim(0, 0.010)   \n",
    "\n",
    "# Subplot (b)\n",
    "var_x, var_y = 'output_chem_age', 'NEMR_PAN'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False)\n",
    "\n",
    "\n",
    "# Adding text labels to each subplot\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Set up y limitation\n",
    "    ax.set_ylim(0)\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.95, labels[i], transform=ax.transAxes, fontsize=9, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    #'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    #'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend above the figure\n",
    "# ------------------------------------------------\n",
    "legend_flights  = fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    \n",
    "    #bbox_to_anchor=(0.52, 1.03),\n",
    "    #ncol=5,\n",
    "    #fontsize=13.4,\n",
    "    #columnspacing=0.01,     # Decrease horizontal space between columns\n",
    "    bbox_to_anchor=(0.52, 1.0),\n",
    "    ncol=4,\n",
    "    fontsize=7,\n",
    "    columnspacing=1,     # Decrease horizontal space between columns\n",
    "    labelspacing=0.01,      # Decrease vertical space between entries\n",
    "    handletextpad=0,      # Space between handle and text\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', markersize=2, linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes[0].legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',      # or pick another location\n",
    "    fontsize=7.5,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Print out the prodcution rate over time\n",
    "# ---------------------------------------\n",
    "var_x_obs, var_y_obs = 'Plume_Age', 'NEMR_PAN_rate'\n",
    "# The observed OH concentration over time\n",
    "for hour in range(1, 6):\n",
    "    # Calculate it for each flight\n",
    "    for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "        all_data_obs_combined_each        = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "        filtered_data_obs_each            = all_data_obs_combined_each[(all_data_obs_combined_each[var_x_obs] > (hour - 1)) & (all_data_obs_combined_each[var_x_obs] < hour)]\n",
    "        # Check if the DataFrame is empty\n",
    "        if not filtered_data_obs_each.empty:\n",
    "            print(flight_id)\n",
    "            #calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs)\n",
    "        else:\n",
    "            print(f\"Skipping {flight_id} at hour {hour} because the data is empty.\")\n",
    "\n",
    "for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "    all_data_obs_combined_each        = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "    print(flight_id)\n",
    "    print(all_data_obs_combined_each[var_y_obs].mean())\n",
    "\n",
    "'''\n",
    "# ----------------------------------\n",
    "# Print out the first hour PAN NEMR\n",
    "# ----------------------------------\n",
    "for fire_id in all_data_obs_lagrangian['Flight_ID'].unique():\n",
    "    all_data_obs_each = all_data_obs_lagrangian[all_data_obs_lagrangian['Flight_ID'] == fire_id]\n",
    "    print(all_data_obs_each)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Save the full figure in high resolution\n",
    "for fmt in ['pdf', 'jpeg', 'tiff']:  # Choose the formats you need\n",
    "    fig.savefig(f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/maintext_figures/Fig6_PAN_TS.{fmt}', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508217a-b03f-4b49-8732-e34b743c6672",
   "metadata": {},
   "source": [
    "#### Updated figure 6, waiting for Lu's approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431f184-9614-4b0d-8d1a-24e9e9473f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6), sharey='row')\n",
    "# ------------------------------------------------\n",
    "# 1) Plot your two subplots\n",
    "# ------------------------------------------------\n",
    "# Subplot (a)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_PAN'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=True)\n",
    "axes.set_ylim(0, 0.010)   \n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend on the right side\n",
    "# ------------------------------------------------\n",
    "legend_flights  = fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.535, 1.08),\n",
    "    ncol=2,\n",
    "    fontsize=14.8,\n",
    "    labelspacing=0.0,      # Decrease vertical space between entries\n",
    "    handletextpad=0.,      # Space between handle and text\n",
    "    columnspacing=-0.1,     # Decrease horizontal space between columns\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes.legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',      # or pick another location\n",
    "    fontsize=25,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5728d-167d-4817-978d-8b77aea03c79",
   "metadata": {},
   "source": [
    "#### Updated supplement, waiting for Lu's approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b77432-d734-4dd3-9cb6-5daa2b02086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9*2, 7.5*1))\n",
    "# ------------------------------------------------\n",
    "# 1) Plot your two subplots\n",
    "# ------------------------------------------------\n",
    "# Subplot (a)\n",
    "var_x, var_y = 'output_chem_age', 'NEMR_O3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=False)\n",
    "\n",
    "# Subplot (b)\n",
    "var_x, var_y = 'output_chem_age', 'NEMR_PAN'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=True, show_legend=False)\n",
    "\n",
    "# Add subplot labels\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Set up y limitation\n",
    "    ax.set_ylim(0)\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.95, labels[i], transform=ax.transAxes, fontsize=25, fontweight='bold', va='top', ha='left')\n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend above the figure\n",
    "# ------------------------------------------------\n",
    "legend_flights  = fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    \n",
    "    #bbox_to_anchor=(0.52, 1.03),\n",
    "    #ncol=5,\n",
    "    #fontsize=13.4,\n",
    "    #columnspacing=0.01,     # Decrease horizontal space between columns\n",
    "    bbox_to_anchor=(0.51, 1.08),\n",
    "    ncol=3,\n",
    "    fontsize=20,\n",
    "    columnspacing=1,     # Decrease horizontal space between columns\n",
    "\n",
    "    labelspacing=0.01,      # Decrease vertical space between entries\n",
    "    handletextpad=0,      # Space between handle and text\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes[0].legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',      # or pick another location\n",
    "    fontsize=25,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbea12-1168-4f56-9e43-1be7fa889dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6980319-a17d-4fc3-a2a3-1b107ba43439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf799336-f1a0-47b2-8045-de9020762716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f558a9d-d3a8-4ef6-9875-0a44cc8be3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1b071-2c68-4238-a678-bac873ae260f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb23a9b2-2bdb-4ada-88ed-617679cb3c24",
   "metadata": {},
   "source": [
    "#### Figure S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9a892-fe23-41ae-bc39-153c825ca1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9*2, 7.5*1) )\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_O3_rate'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True)\n",
    "axes[1].set_ylim(0, 0.08)   # Set y-axis limits for the first plot\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_PAN_rate'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=True, show_legend=False)\n",
    "axes[1].set_ylim(0, 0.008)  # Set y-axis limits for the second plot\n",
    "\n",
    "\n",
    "# Adding text labels to each subplot\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Set up y limitation\n",
    "    ax.set_xlim(0,6 )\n",
    "    ax.set_ylim(0)\n",
    "    # Add a, b, c, d    \n",
    "    ax.text(0.05, 0.95, labels[i], transform=ax.transAxes, fontsize=30, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Define color mapping (optional but recommended)\n",
    "# ------------------------------------------------\n",
    "# Suppose you have flight IDs or fire names, e.g.:\n",
    "flight_colors = {\n",
    "    'P-3B'                 : '#52b9d8',\n",
    "    'RF03'                 : [0.5, 0.0, 0.0, 1.0],\n",
    "    'RF07'                 : '#ff9200',\n",
    "    'RF09'                 : [0.0, 0.3, 1.0, 1.0],\n",
    "    'FN19'                 : '#868686', \n",
    "    #'Other WE-CAN flights' : '#2e5fa1',\n",
    "}\n",
    "\n",
    "id2fire_name_five = {\n",
    "    'P-3B': 'Managed Understory Fire (DISCOVER-AQ)',\n",
    "    'RF03': 'Taylor Creek Fire (WE-CAN)',\n",
    "    'RF07': 'Donnell Fire (WE-CAN)',\n",
    "    'RF09': 'Bear Trap Fire (WE-CAN)',\n",
    "    'FN19': 'Black Water Fire (FIREX-AQ)',\n",
    "    #'Other WE-CAN flights': 'Other WE-CAN flights'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Create dummy legend handles (no marker/line)\n",
    "# ------------------------------------------------\n",
    "legend_handles = []\n",
    "for flight_id, color in flight_colors.items():\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=color,\n",
    "        marker='',\n",
    "        linewidth=0,\n",
    "        label=id2fire_name_five.get(flight_id, flight_id)\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Place a single legend above the figure\n",
    "# ------------------------------------------------\n",
    "legend_flights  = fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='upper center',\n",
    "    \n",
    "    #bbox_to_anchor=(0.52, 1.03),\n",
    "    #ncol=5,\n",
    "    #fontsize=13.4,\n",
    "    #columnspacing=0.01,     # Decrease horizontal space between columns\n",
    "    bbox_to_anchor=(0.51, 1.08),\n",
    "    ncol=3,\n",
    "    fontsize=20,\n",
    "    columnspacing=1,     # Decrease horizontal space between columns\n",
    "\n",
    "    labelspacing=0.01,      # Decrease vertical space between entries\n",
    "    handletextpad=0,      # Space between handle and text\n",
    "    frameon=False  # <-- This removes the legend box\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Recolor legend text to match each handle\n",
    "# ------------------------------------------------\n",
    "# Bold each legend label (and optionally keep other styling)\n",
    "for text, handle in zip(legend_flights.get_texts(), legend_handles):\n",
    "    text.set_color(handle.get_color())       # keep color matching\n",
    "    text.set_fontweight('bold')             # make the label bold\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (6) Second legend: symbol/linestyle-coded \"setup\"\n",
    "# -------------------------------------------------\n",
    "#  - Dot: Observation\n",
    "#  - Solid line: MCMBBVOC\n",
    "#  - Dashed line: MCMGCVOC\n",
    "#  - Dotted line: GEOS-Chem\n",
    "obs_handle = mlines.Line2D([], [], color='k', marker='o', linewidth=0, label='Observation')\n",
    "mcm_bbvoc_handle = mlines.Line2D([], [], color='k', linestyle='-', label='$MCM_{BBVOC}$')\n",
    "mcm_gcvoc_handle = mlines.Line2D([], [], color='k', linestyle='--', label='$MCM_{GCVOC}$')\n",
    "geoschem_handle  = mlines.Line2D([], [], color='k', linestyle=':', label='GEOS-Chem')\n",
    "\n",
    "model_handles = [obs_handle, mcm_bbvoc_handle, mcm_gcvoc_handle, geoschem_handle]\n",
    "\n",
    "# We add a second legend. Often we attach it to 'ax' so it doesn't clash with the first.\n",
    "legend_models = axes[0].legend(\n",
    "    handles=model_handles,\n",
    "    loc='upper right',      # or pick another location\n",
    "    fontsize=25,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "# Because we manually added ax.legend, we must re-add the figure-level legend:\n",
    "fig.add_artist(legend_flights)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71feb2a-0663-4e74-ad0b-d734d789fcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc4afb5-5bc5-487d-9864-509bb8991d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8955f-7566-4e13-bb42-14b1cba0fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Save out the PAN production rates\n",
    "# --------------------------------------\n",
    "def replace_zeros_with_nan(df, column):\n",
    "    df[column] = df[column].replace(0, np.nan)\n",
    "\n",
    "def define_bins_and_labels(plume_age_max):\n",
    "    hour_max = np.ceil(plume_age_max)\n",
    "    bins = np.arange(0, hour_max + 1)\n",
    "    labels = [f\"{int(b)}-{int(b+1)}\" for b in bins[:-1]]\n",
    "    return bins, labels\n",
    "\n",
    "def calculate_statistics(df, bin_column, group_column):\n",
    "    stats = df.groupby(bin_column)[group_column].agg(['mean', 'std', 'min', 'max', 'count']).reset_index()\n",
    "    stats['Mean ± Standard deviation (% per hour)'] = stats.apply(\n",
    "        lambda row: f\"{row['mean']:.1f} ± {row['std']:.1f}\" if pd.notna(row['std']) else f\"{row['mean']:.1f}\", axis=1)\n",
    "    stats['min'] = stats['min'].map(lambda x: f\"{x:.1f}\")\n",
    "    stats['max'] = stats['max'].map(lambda x: f\"{x:.1f}\")\n",
    "    stats.rename(columns={'count': 'Number of datapoints'}, inplace=True)\n",
    "    stats = stats.drop(['mean', 'std'], axis=1)\n",
    "    return stats[['Plume age (hours)', 'Mean ± Standard deviation (% per hour)', 'min', 'max', 'Number of datapoints']]\n",
    "\n",
    "def create_word_document(stats, path):\n",
    "    doc = Document()\n",
    "    table = doc.add_table(rows=1, cols=len(stats.columns))\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    for i, column_name in enumerate(stats.columns):\n",
    "        hdr_cells[i].text = str(column_name)\n",
    "    for index, row in stats.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for col_index, value in enumerate(row):\n",
    "            row_cells[col_index].text = str(value)\n",
    "    doc.save(path)\n",
    "\n",
    "def print_csv(stats):\n",
    "    stats.to_csv(sys.stdout, index=False)\n",
    "\n",
    "def process_dataset(df, path, var):\n",
    "    replace_zeros_with_nan(df, var)\n",
    "    df[var] *= 100  # Scale the variable by 100 to convert it to percentage\n",
    "    bins, labels = define_bins_and_labels(df['Plume_Age'].max())\n",
    "    df['Plume age (hours)'] = pd.cut(df['Plume_Age'], bins=bins, right=False, labels=labels)\n",
    "    stats = calculate_statistics(df, 'Plume age (hours)', var)\n",
    "    create_word_document(stats, path.replace('.docx', '.docx'))\n",
    "    print_csv(stats)  # Printing the CSV content\n",
    "\n",
    "var = 'NEMR_PAN_rate'\n",
    "# Full dataset\n",
    "df_full = all_data_obs[['Flight_ID', 'Plume_Age', var]].copy()\n",
    "file_path = f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/{var}_full.docx'\n",
    "process_dataset(df_full, file_path, var)\n",
    "\n",
    "# Lagrangian dataset\n",
    "df_lagrangian = all_data_obs_lagrangian[['Flight_ID', 'Plume_Age', var]].copy()\n",
    "file_path = f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/{var}_lagrangian.docx'\n",
    "process_dataset(df_lagrangian, file_path, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d12006-c5ee-465f-b5a2-e2d039fa1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Process the nitrate data from Julieta\n",
    "# --------------------------------------\n",
    "# Load the data to inspect the column names and determine how to split it into two DataFrames\n",
    "file_path  = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/WECAN_flts_full_1sec_R1_all_vars_w_PILS_w_OrgN_w_15sec_bkgd_wo_PANs.csv'\n",
    "df_julieta = pd.read_csv(file_path, sep=',')\n",
    "df_julieta = df_julieta.rename(columns={' org_gen': 'org_gen'})\n",
    "\n",
    "# ----------------------\n",
    "# Process nitrate data\n",
    "# ----------------------\n",
    "wecan_data_init      = {}\n",
    "wecan_data_comp_keyN = {}\n",
    "wecan_data_orgN      = {}\n",
    "\n",
    "\n",
    "#keyN_vars       = ['NEMR_NOx', 'NEMR_pNO3', 'NEMR_PAN', 'NEMR_PPN', 'NEMR_HNO3', 'NEMR_HONO', 'NEMR_orgN']\n",
    "#keyN_vars       = ['NEMR_NOx', 'NEMR_HONO', 'NEMR_PAN', 'NEMR_PPN', 'NEMR_orgN', 'NEMR_HNO3_pNO3']\n",
    "keyN_vars       = ['NEMR_NOx', 'NEMR_HONO', 'NEMR_PAN', 'NEMR_PPN', 'NEMR_orgN', 'NEMR_HNO3', 'NEMR_pNO3']\n",
    "#keyN_vars       = ['NEMR_NOx', 'NEMR_HONO', 'NEMR_PAN', 'NEMR_HNO3', 'NEMR_PPN', 'NEMR_orgN', 'NEMR_pNO3']\n",
    "\n",
    "orgN_vars       = [\n",
    "    'NEMR_C2_OrgN', 'NEMR_C3_OrgN', 'NEMR_C4_OrgN', 'NEMR_C5_OrgN', 'NEMR_C6_OrgN', 'NEMR_C7_OrgN',\n",
    "    'NEMR_C8_OrgN', 'NEMR_C9_OrgN', 'NEMR_C10_OrgN', 'NEMR_C11_OrgN', 'NEMR_C12_OrgN', 'NEMR_C13_OrgN',\n",
    "    'NEMR_C14_OrgN', 'NEMR_C15_OrgN', 'NEMR_C16_OrgN', 'NEMR_C17_OrgN'\n",
    "]   \n",
    "required_vars   = [\n",
    "    'Age_physical_avg_min', 'CO', 'NO', 'NO2', 'NO3_AMS', 'PAN', 'PPN', 'HNO3_UWCIMS', 'HONO_UWCIMS', 'org_gen',\n",
    "    'C2_OrgN', 'C3_OrgN', 'C4_OrgN', 'C5_OrgN', 'C6_OrgN', 'C7_OrgN',\n",
    "    'C8_OrgN', 'C9_OrgN', 'C10_OrgN', 'C11_OrgN', 'C12_OrgN', 'C13_OrgN',\n",
    "    'C14_OrgN', 'C15_OrgN', 'C16_OrgN', 'C17_OrgN'\n",
    "]\n",
    "\n",
    "for flight_id in df_julieta['FLIGHT'].unique():\n",
    "    if flight_id not in ['RF03', 'RF07', 'RF09']: continue\n",
    "    df_each                       = df_julieta[df_julieta['FLIGHT'] == flight_id]\n",
    "    df_each_in_plume              = df_each[df_each['in_plume'] > 0]\n",
    "    df_each_out_plume             = df_each[df_each['in_plume'].isna()]\n",
    "    # Get the 95th percentile value of the CO column\n",
    "    top_percent_threshold         = df_each_in_plume['CO'].quantile(0.75)\n",
    "    bottom_percent_threshold      = df_each_out_plume['CO'].quantile(0.05)\n",
    "    # Filter the DataFrame to get only the rows where CO is above or equal to this threshold\n",
    "    df_each_plume_center          = df_each_in_plume[df_each_in_plume['CO']   >= top_percent_threshold]\n",
    "    df_each_bkg                   = df_each_out_plume[df_each_out_plume['CO'] < bottom_percent_threshold].mean(numeric_only=True)\n",
    "    # Retrieve the data we want to focus\n",
    "    df_each_plume_center_reduced  = df_each_plume_center[required_vars].groupby('Age_physical_avg_min').mean(numeric_only=True).reset_index()\n",
    "    df_each_plume_center_reduced['Age_physical_avg_min'] = df_each_plume_center_reduced['Age_physical_avg_min']/60\n",
    "    df_each_plume_center_reduced.set_index('Age_physical_avg_min', inplace=True)\n",
    "    df_each_bkg_reduced           = df_each_bkg[required_vars]\n",
    "    \n",
    "    # Unit conversion\n",
    "    df_each_plume_center_reduced['NO']          = df_each_plume_center_reduced['NO'] / 1000\n",
    "    df_each_plume_center_reduced['NO2']         = df_each_plume_center_reduced['NO2'] / 1000\n",
    "    df_each_plume_center_reduced['PAN']         = df_each_plume_center_reduced['PAN'] / 1000\n",
    "    df_each_plume_center_reduced['PPN']         = df_each_plume_center_reduced['PPN'] / 1000\n",
    "    df_each_plume_center_reduced['HNO3_UWCIMS'] = df_each_plume_center_reduced['HNO3_UWCIMS'] / 1000\n",
    "    df_each_plume_center_reduced['HONO_UWCIMS'] = df_each_plume_center_reduced['HONO_UWCIMS'] / 1000\n",
    "    df_each_plume_center_reduced['org_gen']     = df_each_plume_center_reduced['org_gen'] / 1000\n",
    "    df_each_plume_center_reduced['C2_OrgN']  = df_each_plume_center_reduced['C2_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C3_OrgN']  = df_each_plume_center_reduced['C3_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C4_OrgN']  = df_each_plume_center_reduced['C4_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C5_OrgN']  = df_each_plume_center_reduced['C5_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C6_OrgN']  = df_each_plume_center_reduced['C6_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C7_OrgN']  = df_each_plume_center_reduced['C7_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C8_OrgN']  = df_each_plume_center_reduced['C8_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C9_OrgN']  = df_each_plume_center_reduced['C9_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C10_OrgN'] = df_each_plume_center_reduced['C10_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C11_OrgN'] = df_each_plume_center_reduced['C11_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C12_OrgN'] = df_each_plume_center_reduced['C12_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C13_OrgN'] = df_each_plume_center_reduced['C13_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C14_OrgN'] = df_each_plume_center_reduced['C14_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C15_OrgN'] = df_each_plume_center_reduced['C15_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C16_OrgN'] = df_each_plume_center_reduced['C16_OrgN'] / 1000\n",
    "    df_each_plume_center_reduced['C17_OrgN'] = df_each_plume_center_reduced['C17_OrgN'] / 1000\n",
    "    \n",
    "    df_each_bkg_reduced['NO']                  = df_each_bkg_reduced['NO'] / 1000\n",
    "    df_each_bkg_reduced['NO2']                 = df_each_bkg_reduced['NO2'] / 1000\n",
    "    df_each_bkg_reduced['PAN']                 = df_each_bkg_reduced['PAN'] / 1000\n",
    "    df_each_bkg_reduced['PPN']                 = df_each_bkg_reduced['PPN'] / 1000\n",
    "    df_each_bkg_reduced['HNO3_UWCIMS']         = df_each_bkg_reduced['HNO3_UWCIMS'] / 1000\n",
    "    df_each_bkg_reduced['HONO_UWCIMS']         = df_each_bkg_reduced['HONO_UWCIMS'] / 1000\n",
    "    df_each_bkg_reduced['org_gen']             = df_each_bkg_reduced['org_gen'] / 1000\n",
    "    df_each_bkg_reduced['C2_OrgN']             = df_each_bkg_reduced['C2_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C3_OrgN']             = df_each_bkg_reduced['C3_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C4_OrgN']             = df_each_bkg_reduced['C4_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C5_OrgN']             = df_each_bkg_reduced['C5_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C6_OrgN']             = df_each_bkg_reduced['C6_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C7_OrgN']             = df_each_bkg_reduced['C7_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C8_OrgN']             = df_each_bkg_reduced['C8_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C9_OrgN']             = df_each_bkg_reduced['C9_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C10_OrgN']            = df_each_bkg_reduced['C10_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C11_OrgN']            = df_each_bkg_reduced['C11_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C12_OrgN']            = df_each_bkg_reduced['C12_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C13_OrgN']            = df_each_bkg_reduced['C13_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C14_OrgN']            = df_each_bkg_reduced['C14_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C15_OrgN']            = df_each_bkg_reduced['C15_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C16_OrgN']            = df_each_bkg_reduced['C16_OrgN'] / 1000\n",
    "    df_each_bkg_reduced['C17_OrgN']            = df_each_bkg_reduced['C17_OrgN'] / 1000\n",
    "    \n",
    "    # Convert ug/m^3 to ppb\n",
    "    MW_NO3 = 62.0049  # NO3- in g/mol\n",
    "    df_each_plume_center_reduced['NO3_AMS']     = (df_each_plume_center_reduced['NO3_AMS'] / MW_NO3) * 24.45\n",
    "    df_each_bkg_reduced['NO3_AMS']              = (df_each_bkg_reduced['NO3_AMS'] / MW_NO3) * 24.45\n",
    "    # Calculate NEMR\n",
    "    delta_CO    = df_each_plume_center_reduced['CO'] - df_each_bkg_reduced['CO']\n",
    "    for species in [var for var in required_vars if var not in ['Age_physical_avg_min', 'CO']]:\n",
    "        delta_spec = df_each_plume_center_reduced[species] - df_each_bkg_reduced[species]\n",
    "        df_each_plume_center_reduced[f'NEMR_{species}'] = (df_each_plume_center_reduced[species] - df_each_bkg_reduced[species]) / delta_CO\n",
    "    # Group the data for every hour \n",
    "    # Create bin edges for every X hour\n",
    "    interval_X                   = 1\n",
    "    bin_edges_obs                = np.arange(0, df_each_plume_center_reduced.index.max() + interval_X, interval_X)\n",
    "    aggregation, aggregation_err = 'mean', 'std'\n",
    "    # Use the `cut` function to bin the data  \n",
    "    df_each_plume_center_reduced['time_bin'] = pd.cut(df_each_plume_center_reduced.index, bins=bin_edges_obs, labels=bin_edges_obs[:-1] + interval_X, right=False)\n",
    "\n",
    "    # Store initial values for each flight\n",
    "    wecan_data_init[flight_id] = {\n",
    "        'Init_NEMR_pNO3': df_each_plume_center_reduced['NEMR_NO3_AMS'].iloc[0],\n",
    "        'Init_NEMR_orgN': df_each_plume_center_reduced['NEMR_org_gen'].iloc[0],\n",
    "    }\n",
    "\n",
    "    # Store values for each flight\n",
    "    # replace column names\n",
    "    col_maps  = {'NEMR_NO3_AMS'    : 'NEMR_pNO3', \n",
    "                 'NEMR_HNO3_UWCIMS': 'NEMR_HNO3', \n",
    "                 'NEMR_HONO_UWCIMS': 'NEMR_HONO', \n",
    "                 'NEMR_org_gen'    : 'NEMR_orgN', \n",
    "                }\n",
    "    df_each_plume_center_reduced                   = df_each_plume_center_reduced.rename(columns=col_maps)\n",
    "    df_each_plume_center_reduced['NEMR_NOx']       = df_each_plume_center_reduced['NEMR_NO'] + df_each_plume_center_reduced['NEMR_NO2']\n",
    "    df_each_plume_center_reduced['NEMR_HNO3_pNO3'] = df_each_plume_center_reduced['NEMR_HNO3'] + df_each_plume_center_reduced['NEMR_pNO3']\n",
    "    wecan_data_comp_keyN[flight_id]                = df_each_plume_center_reduced[keyN_vars + ['time_bin']]\n",
    "    wecan_data_orgN[flight_id]                     = df_each_plume_center_reduced[orgN_vars + ['time_bin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b705ec-8296-461d-bbf3-37a59307d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Plot the NOy partition for observations and models\n",
    "# ------------------------------------------------------\n",
    "# Select flight\n",
    "Select_flight = 'RF03'\n",
    "# Group the data for every hour\n",
    "# Create bin edges for every X minutes\n",
    "interval_X = 1\n",
    "all_data_mcm_bbvoc_noy = all_data_mcm_bbvoc.copy()\n",
    "all_data_mcm_gcvoc_noy = all_data_mcm_gcvoc.copy()\n",
    "all_data_gc_noy        = all_data_gc.copy()\n",
    "bin_edges_mod = np.arange(0, all_data_mcm_bbvoc_noy['Plume_Age'].max() + interval_X, interval_X)\n",
    "aggregation, aggregation_err = 'mean', 'std'\n",
    "# Use the `cut` function to bin the data  \n",
    "all_data_mcm_bbvoc_noy['time_bin']       = pd.cut(all_data_mcm_bbvoc_noy['Plume_Age'], bins=bin_edges_mod, labels=bin_edges_mod[:-1] + interval_X, right=False)\n",
    "all_data_mcm_gcvoc_noy['time_bin']       = pd.cut(all_data_mcm_gcvoc_noy['Plume_Age'], bins=bin_edges_mod, labels=bin_edges_mod[:-1] + interval_X, right=False)\n",
    "all_data_gc_noy['time_bin']              = pd.cut(all_data_gc_noy['Plume_Age'], bins=bin_edges_mod, labels=bin_edges_mod[:-1] + interval_X, right=False)\n",
    "\n",
    "# Process the data\n",
    "all_data_mcm_bbvoc_noy['NEMR_orgN']      = all_data_mcm_bbvoc_noy['NEMR_PNs_excl'] + all_data_mcm_bbvoc_noy['NEMR_ANs']\n",
    "all_data_mcm_gcvoc_noy['NEMR_orgN']      = all_data_mcm_gcvoc_noy['NEMR_PNs_excl'] + all_data_mcm_gcvoc_noy['NEMR_ANs']\n",
    "all_data_gc_noy['NEMR_orgN']             = all_data_gc_noy['NEMR_PNs_excl'] + all_data_gc_noy['NEMR_ANs']\n",
    "\n",
    "\n",
    "all_data_mcm_bbvoc_noy['NEMR_NOx']       = all_data_mcm_bbvoc_noy['NEMR_NO'] + all_data_mcm_bbvoc_noy['NEMR_NO2']\n",
    "all_data_mcm_gcvoc_noy['NEMR_NOx']       = all_data_mcm_gcvoc_noy['NEMR_NO'] + all_data_mcm_gcvoc_noy['NEMR_NO2']\n",
    "all_data_gc_noy['NEMR_NOx']              = all_data_gc_noy['NEMR_NO'] + all_data_gc_noy['NEMR_NO2']\n",
    "#all_data_mcm_bbvoc_noy['NEMR_HNO3_pNO3'] = all_data_mcm_bbvoc_noy['NEMR_HNO3']\n",
    "all_data_mcm_bbvoc_noy.index             = all_data_mcm_bbvoc_noy['Plume_Age']\n",
    "all_data_mcm_gcvoc_noy.index             = all_data_mcm_gcvoc_noy['Plume_Age']\n",
    "all_data_gc_noy.index                    = all_data_gc_noy['Plume_Age']\n",
    "\n",
    "# Aggregate mean concentrations by plume age bin\n",
    "varialbes_noy_mod = [var for var in keyN_vars if var != 'NEMR_pNO3']\n",
    "varialbes_noy_obs = keyN_vars\n",
    "\n",
    "# Select specifci flight and make a copy to ensure the original data is not modified\n",
    "all_data_mcm_bbvoc_select              = all_data_mcm_bbvoc_noy[all_data_mcm_bbvoc_noy['Flight_ID']==Select_flight].copy()[varialbes_noy_mod + ['time_bin']]\n",
    "all_data_mcm_gcvoc_select              = all_data_mcm_gcvoc_noy[all_data_mcm_gcvoc_noy['Flight_ID']==Select_flight].copy()[varialbes_noy_mod + ['time_bin']]\n",
    "all_data_gc_select                     = all_data_gc_noy[all_data_gc_noy['Flight_ID']==Select_flight].copy()[varialbes_noy_mod + ['time_bin']]\n",
    "all_data_mcm_bbvoc_select['NEMR_orgN'] = all_data_mcm_bbvoc_select['NEMR_orgN'] + wecan_data_init[Select_flight]['Init_NEMR_orgN']\n",
    "all_data_mcm_gcvoc_select['NEMR_orgN'] = all_data_mcm_gcvoc_select['NEMR_orgN'] + wecan_data_init[Select_flight]['Init_NEMR_orgN']\n",
    "all_data_gc_select['NEMR_orgN']        = all_data_gc_select['NEMR_orgN'] + wecan_data_init[Select_flight]['Init_NEMR_orgN']\n",
    "\n",
    "# Initialize an empty list to store DataFrame for each flight\n",
    "flight_ids = ['RF03', 'RF07', 'RF09']\n",
    "dfs_all_data_mcm_bbvoc_wecan = []\n",
    "dfs_all_data_mcm_gcvoc_wecan = []\n",
    "dfs_all_data_gc_wecan        = []\n",
    "# Loop through each flight ID\n",
    "for flight_id in flight_ids:\n",
    "    # Select the data for the current flight\n",
    "    all_data_mcm_bbvoc_select_dummy = all_data_mcm_bbvoc_noy[all_data_mcm_bbvoc_noy['Flight_ID'] == flight_id].copy()\n",
    "    all_data_mcm_gcvoc_select_dummy = all_data_mcm_gcvoc_noy[all_data_mcm_gcvoc_noy['Flight_ID'] == flight_id].copy()\n",
    "    all_data_gc_select_dummy        = all_data_gc_noy[all_data_gc_noy['Flight_ID'] == flight_id].copy()\n",
    "    # Adjust the 'NEMR_orgN' based on the initial values\n",
    "    all_data_mcm_bbvoc_select_dummy['NEMR_orgN'] = all_data_mcm_bbvoc_select_dummy['NEMR_orgN'] + wecan_data_init[flight_id]['Init_NEMR_orgN']\n",
    "    all_data_mcm_gcvoc_select_dummy['NEMR_orgN'] = all_data_mcm_gcvoc_select_dummy['NEMR_orgN'] + wecan_data_init[flight_id]['Init_NEMR_orgN']\n",
    "    all_data_gc_select_dummy['NEMR_orgN']        = all_data_gc_select_dummy['NEMR_orgN'] + wecan_data_init[flight_id]['Init_NEMR_orgN']\n",
    "    # Append the modified DataFrame to the list\n",
    "    dfs_all_data_mcm_bbvoc_wecan.append(all_data_mcm_bbvoc_select_dummy[varialbes_noy_mod + ['time_bin']])\n",
    "    dfs_all_data_mcm_gcvoc_wecan.append(all_data_mcm_gcvoc_select_dummy[varialbes_noy_mod + ['time_bin']])\n",
    "    dfs_all_data_gc_wecan.append(all_data_gc_select_dummy[varialbes_noy_mod + ['time_bin']])\n",
    "all_data_mcm_bbvoc_wecan = pd.concat(dfs_all_data_mcm_bbvoc_wecan)\n",
    "all_data_mcm_gcvoc_wecan = pd.concat(dfs_all_data_mcm_gcvoc_wecan)\n",
    "all_data_gc_wecan        = pd.concat(dfs_all_data_gc_wecan)\n",
    "all_data_mcm_bbvoc_wecan.reset_index(drop=True, inplace=True)\n",
    "all_data_mcm_gcvoc_wecan.reset_index(drop=True, inplace=True)\n",
    "all_data_gc_wecan.reset_index(drop=True, inplace=True)\n",
    "# ---------------------------------------------------------------------------\n",
    "# Choose Specific flight or the whole data and calculate mean concentrations\n",
    "# ---------------------------------------------------------------------------\n",
    "processed_mcm_bbvoc = all_data_mcm_bbvoc_select.groupby('time_bin')[varialbes_noy_mod].mean(numeric_only=True).copy()\n",
    "processed_mcm_gcvoc = all_data_mcm_gcvoc_select.groupby('time_bin')[varialbes_noy_mod].mean(numeric_only=True).copy()\n",
    "processed_gc        = all_data_gc_select.groupby('time_bin')[varialbes_noy_mod].mean(numeric_only=True).copy()\n",
    "processed_obs       = wecan_data_comp_keyN[Select_flight].groupby('time_bin')[varialbes_noy_obs].mean(numeric_only=True).copy()\n",
    "\n",
    "# Drop rows where all values are NaN\n",
    "processed_mcm_bbvoc = processed_mcm_bbvoc.dropna(how='all')\n",
    "processed_mcm_gcvoc = processed_mcm_gcvoc.dropna(how='all')\n",
    "processed_gc        = processed_gc.dropna(how='all')\n",
    "\n",
    "# Calculate missing NOy\n",
    "Init_NOy_mcm_bbvoc                  = processed_mcm_bbvoc.iloc[0, :].sum() + wecan_data_init[Select_flight]['Init_NEMR_pNO3']\n",
    "processed_mcm_bbvoc['NEMR_missing'] = np.nan\n",
    "processed_mcm_bbvoc['NEMR_missing'] = processed_mcm_bbvoc.apply(lambda row: Init_NOy_mcm_bbvoc - row.iloc[:-1].sum(), axis=1)\n",
    "processed_mcm_bbvoc.index = processed_mcm_bbvoc.index.astype(float)\n",
    "\n",
    "Init_NOy_mcm_gcvoc                  = processed_mcm_gcvoc.iloc[0, :].sum() + wecan_data_init[Select_flight]['Init_NEMR_pNO3']\n",
    "processed_mcm_gcvoc['NEMR_missing'] = np.nan\n",
    "processed_mcm_gcvoc['NEMR_missing'] = processed_mcm_gcvoc.apply(lambda row: Init_NOy_mcm_gcvoc - row.iloc[:-1].sum(), axis=1)\n",
    "processed_mcm_gcvoc.index = processed_mcm_gcvoc.index.astype(float)\n",
    "\n",
    "Init_NOy_gc                         = processed_gc.iloc[0, :].sum() + wecan_data_init[Select_flight]['Init_NEMR_pNO3']\n",
    "processed_gc['NEMR_missing']        = np.nan\n",
    "processed_gc['NEMR_missing']        = processed_gc.apply(lambda row: Init_NOy_gc - row.iloc[:-1].sum(), axis=1)\n",
    "processed_gc.index                  = processed_gc.index.astype(float)\n",
    "\n",
    "# Add two dummy rows with NaN values to extend the x-axis\n",
    "max_index                                = processed_mcm_bbvoc.index.max()\n",
    "processed_mcm_bbvoc.loc[max_index + 0.5] = np.nan\n",
    "processed_mcm_bbvoc.loc[max_index + 1.0] = np.nan\n",
    "processed_mcm_gcvoc.loc[max_index + 0.5] = np.nan\n",
    "processed_mcm_gcvoc.loc[max_index + 1.0] = np.nan\n",
    "processed_gc.loc[max_index + 0.5]        = np.nan\n",
    "processed_gc.loc[max_index + 1.0]        = np.nan\n",
    "\n",
    "processed_obs.index                      = processed_obs.index.astype('object')\n",
    "processed_obs.loc[max_index + 0.5]       = np.nan\n",
    "processed_obs.loc[max_index + 1.0]       = np.nan\n",
    "\n",
    "# Normalize the data\n",
    "processed_mcm_bbvoc_norm            = processed_mcm_bbvoc.copy()\n",
    "processed_mcm_gcvoc_norm            = processed_mcm_gcvoc.copy()\n",
    "processed_gc_norm                   = processed_gc.copy()\n",
    "processed_obs_norm                  = processed_obs.copy()\n",
    "\n",
    "processed_mcm_bbvoc_norm.iloc[:, :] = processed_mcm_bbvoc.iloc[:, :].div(processed_mcm_bbvoc.iloc[:, :].sum(axis=1), axis=0)*100\n",
    "processed_mcm_gcvoc_norm.iloc[:, :] = processed_mcm_gcvoc.iloc[:, :].div(processed_mcm_gcvoc.iloc[:, :].sum(axis=1), axis=0)*100\n",
    "processed_gc_norm.iloc[:, :]        = processed_gc.iloc[:, :].div(processed_gc.iloc[:, :].sum(axis=1), axis=0)*100\n",
    "processed_obs_norm.iloc[:, :]       = processed_obs.iloc[:, :].div(processed_obs.iloc[:, :].sum(axis=1), axis=0)*100\n",
    "\n",
    "# Pie carts processing\n",
    "def custom_autopct(pct):\n",
    "    return ('%.0f%%' % pct) if pct > 4.5 else ''\n",
    "overall_means_mcm_bbvoc             = processed_mcm_bbvoc_norm.mean()\n",
    "overall_means_mcm_gcvoc             = processed_mcm_gcvoc_norm.mean()\n",
    "overall_means_gc                    = processed_gc_norm.mean()\n",
    "overall_means_obs                   = processed_obs_norm.mean()\n",
    "\n",
    "# Custom legend names\n",
    "legend_names= {\n",
    "    'NEMR_PAN': 'PAN',\n",
    "    'NEMR_PPN': 'PPN',\n",
    "    'NEMR_orgN': 'OrgN$_{excl.}$',\n",
    "    'NEMR_HNO3': 'HNO$_{3}$',\n",
    "    'NEMR_HNO3_pNO3': 'HNO$_{3}$+pNO$_{3}$',\n",
    "    'NEMR_NOx': 'NO$_{x}$ (NO + NO$_{2}$)',\n",
    "    'NEMR_HONO': 'HONO',\n",
    "    'NEMR_missing': 'Unmodelled NO$_{y}$',\n",
    "    'NEMR_pNO3': 'pNO3'\n",
    "}\n",
    "color_map = {\n",
    "    'PAN': 'tab:red',\n",
    "    'PPN': 'salmon',\n",
    "    'OrgN$_{excl.}$': 'tab:orange',\n",
    "    'HNO$_{3}$': 'tab:green',\n",
    "    'HNO$_{3}$+pNO$_{3}$': 'tab:green',\n",
    "    'NO$_{x}$ (NO + NO$_{2}$)': 'tab:purple',\n",
    "    'HONO': 'tab:blue',\n",
    "    'Unmodelled NO$_{y}$': 'darkgrey',  # Set unmodeled NOy to grey\n",
    "    'pNO3': 'tab:pink'  # Set unmodeled NOy to grey\n",
    "\n",
    "}\n",
    "# Ensure that colors are assigned according to the order in processed DataFrame\n",
    "plot_colors_mcm_bbvoc          = [color_map[legend_names[col]] for col in processed_mcm_bbvoc.columns]\n",
    "plot_colors_obs                = [color_map[legend_names[col]] for col in processed_obs.columns]\n",
    "\n",
    "overall_means_mcm_bbvoc_colors = [color_map[legend_names[key]] for key in overall_means_mcm_bbvoc.index]\n",
    "overall_means_obs_colors       = [color_map[legend_names[key]] for key in overall_means_obs.index if key in overall_means_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b5591-6880-473e-8d40-1fa6f19b0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_obs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6d8ac-7b29-4de6-ad69-c7bca02d5acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbedb0dc-9581-4d59-8faf-d892aad3b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Plot barplot and piechart\n",
    "# ==========================\n",
    "# Define figsize for each subplot\n",
    "figsize_per_subplot = (12, 5)\n",
    "\n",
    "# Create three subplots, with the first two sharing the x-axis\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(figsize_per_subplot[0], figsize_per_subplot[1] * 2))\n",
    "# Flatten the axes array\n",
    "ax1, ax2 = axes.flatten()\n",
    "# Second subplot: Normalized stacked bar plot\n",
    "processed_obs_norm.rename(columns=legend_names).plot(kind='bar', stacked=True, color=plot_colors_obs, ax=ax1)\n",
    "ax1.legend(loc='upper right', fontsize=12)\n",
    "# Add numbers to the stacked bars in the second subplot\n",
    "for bars in ax1.containers:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 5:\n",
    "            ax1.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2,\n",
    "                     f'{height:.0f}', ha='center', va='center', fontsize=12, color='black')\n",
    "# Second subplot: Normalized stacked bar plot\n",
    "processed_mcm_bbvoc_norm.rename(columns=legend_names).plot(kind='bar', stacked=True, color=plot_colors_mcm_bbvoc, ax=ax2)\n",
    "ax2.legend(loc='upper right', fontsize=12)\n",
    "# Add numbers to the stacked bars in the second subplot\n",
    "for bars in ax2.containers:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 5:\n",
    "            ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2,\n",
    "                     f'{height:.0f}', ha='center', va='center', fontsize=12, color='black')\n",
    "            \n",
    "ax1.text(0.97, 0.05, f'Observation', transform=ax1.transAxes, fontsize=20, va='bottom', ha='right')\n",
    "ax2.text(0.97, 0.05, 'MCM$_{BBVOC}$', transform=ax2.transAxes, fontsize=20, va='bottom', ha='right')\n",
    "\n",
    "# Hide the last two x-tick labels\n",
    "xticks = processed_obs_norm.index.to_list()\n",
    "xticklabels = [str(tick) for tick in xticks]\n",
    "xticklabels[-2:] = ['', '']\n",
    "# Apply the custom x-ticks\n",
    "ax1.set_xticks(range(len(xticks)))\n",
    "ax1.set_xticklabels(xticklabels)\n",
    "ax2.set_xticks(range(len(xticks)))\n",
    "ax2.set_xticklabels(xticklabels)\n",
    "\n",
    "# -----------------\n",
    "# Plotting setting\n",
    "# -----------------\n",
    "# Adjust spacing\n",
    "plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "for i, ax in enumerate([ax1, ax2], start=1):\n",
    "    # Get the current y-axis limits\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    # Calculate the range (max - min)\n",
    "    yrange = ymax - ymin\n",
    "    # Extend the max value by the defined percentage\n",
    "    ax.set_ylim(0, ymax + yrange * 0.1)\n",
    "\n",
    "    # Set tick parameters and labels for all subplots\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "    # Annotate each subplot with (a), (b), (c)\n",
    "    ax.text(0.05, 0.97, f'({chr(96+i)})', transform=ax.transAxes, fontsize=20, va='top', ha='right')\n",
    "    ax.set_xlabel('')  # Hide x-axis labels for the first subplot\n",
    "\n",
    "# Set global labels for the  figure\n",
    "fig.text(0.05, 0.7, 'Normalized ∆NO$_y$/∆CO', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "fig.text(0.05, 0.35, 'Normalized ∆NO$_y$/∆CO', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "fig.text(0.5, 0.08, 'Physical age (hour)', ha='center', va='center',  fontsize=20)\n",
    "\n",
    "# Create a pie chart on the same axis as the first bar plot\n",
    "ax_pie1 = fig.add_axes([0.9, 0.48, 0.4, 0.4])   # left, bottom, width, height\n",
    "ax_pie2 = fig.add_axes([0.9, 0.10, 0.4, 0.4])   # left, bottom, width, height # \n",
    "wedges1, texts1, autotexts1 = ax_pie1.pie(overall_means_obs, autopct=custom_autopct, startangle=90, colors=overall_means_obs_colors, textprops={'fontsize': 20})\n",
    "wedges2, texts2, autotexts2 = ax_pie2.pie(overall_means_mcm_bbvoc, autopct=custom_autopct, startangle=90, colors=overall_means_mcm_bbvoc_colors, textprops={'fontsize': 20})\n",
    "\n",
    "ax_pie1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax_pie2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# Annotate the pie chart as (c)\n",
    "ax_pie1.text(0.15, 0.98, f'(c)', transform=ax_pie1.transAxes, fontsize=20, va='top', ha='right') \n",
    "ax_pie2.text(0.15, 0.98, f'(d)', transform=ax_pie2.transAxes, fontsize=20, va='top', ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa10eb2-5cc1-4c11-99d4-cb2719f09bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# NOy for RF07 and RF09\n",
    "# =====================\n",
    "flights = ['RF03', 'RF07', 'RF09']\n",
    "processed_data = {}\n",
    "\n",
    "for flight in flights:\n",
    "    # Select specific flight and make a copy to ensure the original data is not modified\n",
    "    all_data_mcm_bbvoc_each = all_data_mcm_bbvoc_noy[all_data_mcm_bbvoc_noy['Flight_ID'] == flight].copy()[varialbes_noy_mod + ['time_bin']]\n",
    "    all_data_mcm_bbvoc_each['NEMR_orgN'] += wecan_data_init[flight]['Init_NEMR_orgN']\n",
    "\n",
    "    # Calculate mean concentrations\n",
    "    processed_mcm_bbvoc_each = all_data_mcm_bbvoc_each.groupby('time_bin')[varialbes_noy_mod].mean(numeric_only=True).copy()\n",
    "    processed_obs_each       = wecan_data_comp_keyN[flight].groupby('time_bin')[varialbes_noy_obs].mean(numeric_only=True).copy()\n",
    "\n",
    "    # Drop rows where all values are NaN\n",
    "    processed_mcm_bbvoc_each = processed_mcm_bbvoc_each.dropna(how='all')\n",
    "\n",
    "    # Calculate missing NOy\n",
    "    Init_NOy                                 = processed_mcm_bbvoc_each.iloc[0, :].sum() + wecan_data_init[flight]['Init_NEMR_pNO3']\n",
    "    processed_mcm_bbvoc_each['NEMR_missing'] = processed_mcm_bbvoc_each.apply(lambda row: Init_NOy - row.iloc[:-1].sum(), axis=1)\n",
    "\n",
    "    # Convert index to float\n",
    "    processed_mcm_bbvoc_each.index = processed_mcm_bbvoc_each.index.astype(float)\n",
    "    processed_obs_each.index       = processed_obs_each.index.astype('object')\n",
    "\n",
    "    # Add two dummy rows with NaN values to extend the x-axis\n",
    "    max_index = processed_mcm_bbvoc_each.index.max()\n",
    "    processed_mcm_bbvoc_each.loc[max_index + 0.5] = np.nan\n",
    "    processed_mcm_bbvoc_each.loc[max_index + 1.0] = np.nan\n",
    "    processed_obs_each.loc[max_index + 0.5] = np.nan\n",
    "    processed_obs_each.loc[max_index + 1.0] = np.nan\n",
    "\n",
    "    # Normalize the data\n",
    "    processed_mcm_bbvoc_norm            = processed_mcm_bbvoc_each.copy()\n",
    "    processed_obs_norm                  = processed_obs_each.copy()\n",
    "    processed_mcm_bbvoc_norm.iloc[:, :] = processed_mcm_bbvoc_each.iloc[:, :].div(processed_mcm_bbvoc_each.iloc[:, :].sum(axis=1), axis=0)*100\n",
    "    processed_obs_norm.iloc[:, :]       = processed_obs_each.iloc[:, :].div(processed_obs_each.iloc[:, :].sum(axis=1), axis=0)*100\n",
    "\n",
    "    # Calcualte mean\n",
    "    overall_means_mcm_bbvoc              = processed_mcm_bbvoc_norm.mean()\n",
    "    overall_means_obs                    = processed_obs_norm.mean()\n",
    "    \n",
    "    # Store the processed data\n",
    "    processed_data[flight] = {\n",
    "        'Observation': overall_means_obs,\n",
    "        'Model'      : overall_means_mcm_bbvoc,\n",
    "    }\n",
    "# Create subplots with observation and model for the same flight in different rows\n",
    "fig, axes = plt.subplots(2, len(flights), figsize=(7*len(flights), 5*2))\n",
    "axes      = axes.flatten()\n",
    "# Plotting pie charts\n",
    "for i, (flight, flight_data) in enumerate(processed_data.items()):\n",
    "    # Ensure the observation subplot is in the first column of each row\n",
    "    obs_composition = flight_data['Observation']\n",
    "    model_composition = flight_data['Model']\n",
    "    # Plot observation and model data\n",
    "    #axes[i].pie(list(obs_composition.values), autopct=custom_autopct, startangle=90, colors=overall_means_obs_colors, textprops={'fontsize': 20})\n",
    "    #axes[i + len(flights)].pie(list(model_composition.values), autopct=custom_autopct, startangle=90, colors=overall_means_mcm_bbvoc_colors, textprops={'fontsize': 20})\n",
    "        \n",
    "    # clip negatives & NaNs to zero\n",
    "    sizes_obs = obs_composition.values.astype(float).copy()\n",
    "    sizes_obs[np.isnan(sizes_obs)] = 0\n",
    "    sizes_obs[sizes_obs < 0]     = 0\n",
    "    \n",
    "    sizes_mod = model_composition.values.astype(float).copy()\n",
    "    sizes_mod[np.isnan(sizes_mod)] = 0\n",
    "    sizes_mod[sizes_mod < 0]       = 0\n",
    "    \n",
    "    # new pie calls, with labels\n",
    "    axes[i].pie(\n",
    "        sizes_obs,\n",
    "        autopct=custom_autopct,\n",
    "        startangle=90,\n",
    "        colors=overall_means_obs_colors,\n",
    "        textprops={'fontsize': 20}\n",
    "    )\n",
    "    axes[i + len(flights)].pie(\n",
    "        sizes_mod,\n",
    "        autopct=custom_autopct,\n",
    "        startangle=90,\n",
    "        colors=overall_means_mcm_bbvoc_colors,\n",
    "        textprops={'fontsize': 20}\n",
    "    )    \n",
    "    \n",
    "    # Add legend for each subplot\n",
    "    if i == 0:\n",
    "        axes[i].legend([legend_names[col] for col in obs_composition.index], bbox_to_anchor=(0.1, 0.9), loc='upper right', fontsize=12)\n",
    "        axes[i+len(flights)].legend([legend_names[col] for col in model_composition.index], bbox_to_anchor=(0.1, 0.9), loc='upper right', fontsize=12)\n",
    "axes[0].text(0.05, 0.38, f'Observation', transform=axes[0].transAxes, fontsize=20, va='bottom', ha='right')\n",
    "axes[len(flights)].text(0.05, 0.38, 'MCM$_{BBVOC}$', transform=axes[len(flights)].transAxes, fontsize=20, va='bottom', ha='right')\n",
    "\n",
    "for num in range(len(flights)):  axes[num].text(0.5, 1, id2fire_name[flights[num]].replace('\\n(WE-CAN)', ''), transform=axes[num].transAxes, fontsize=25, va='top', ha='center')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=-0.15, wspace=-0.45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb1278-d975-48d3-8dff-a4bb13928fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f898e-c543-4224-9990-205f5042307e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a8800-c6a9-490e-890f-05b3b07a71b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914bc6c6-b6b6-4d5b-9835-286ada1a5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# NOy for multiple\n",
    "# =====================\n",
    "flights = ['RF03', 'RF07', 'RF09']\n",
    "processed_data = {}\n",
    "\n",
    "for flight in flights:\n",
    "    # Select specific flight and make a copy to ensure the original data is not modified\n",
    "    all_data_mcm_bbvoc_each = all_data_mcm_bbvoc_noy[all_data_mcm_bbvoc_noy['Flight_ID'] == flight].copy()[varialbes_noy_mod + ['time_bin']]\n",
    "    all_data_mcm_gcvoc_each = all_data_mcm_gcvoc_noy[all_data_mcm_gcvoc_noy['Flight_ID'] == flight].copy()[varialbes_noy_mod + ['time_bin']]\n",
    "    all_data_gc_each        = all_data_gc_noy[all_data_gc_noy['Flight_ID'] == flight].copy()[varialbes_noy_mod + ['time_bin']]\n",
    "\n",
    "    all_data_mcm_bbvoc_each['NEMR_orgN'] += wecan_data_init[flight]['Init_NEMR_orgN']\n",
    "    all_data_mcm_gcvoc_each['NEMR_orgN'] += wecan_data_init[flight]['Init_NEMR_orgN']\n",
    "    all_data_gc_each['NEMR_orgN']        += wecan_data_init[flight]['Init_NEMR_orgN']\n",
    "\n",
    "    # Group the data for every hour \n",
    "    # Create bin edges for every X hour\n",
    "    interval_X                   = 5/60\n",
    "    bin_edges_obs                = np.arange(0, all_data_mcm_bbvoc_each.index.max() + interval_X, interval_X)\n",
    "    aggregation, aggregation_err = 'mean', 'std'\n",
    "    # Use the `cut` function to bin the data  \n",
    "    all_data_mcm_bbvoc_each['time_bin'] = pd.cut(all_data_mcm_bbvoc_each.index, bins=bin_edges_obs, labels=bin_edges_obs[:-1] + interval_X, right=False)\n",
    "    all_data_mcm_gcvoc_each['time_bin'] = pd.cut(all_data_mcm_gcvoc_each.index, bins=bin_edges_obs, labels=bin_edges_obs[:-1] + interval_X, right=False)\n",
    "    all_data_gc_each['time_bin']        = pd.cut(all_data_gc_each.index, bins=bin_edges_obs, labels=bin_edges_obs[:-1] + interval_X, right=False)\n",
    "    \n",
    "    # Calculate mean concentrations\n",
    "    processed_mcm_bbvoc_each = all_data_mcm_bbvoc_each.groupby('time_bin')[varialbes_noy_mod].mean(numeric_only=True).copy()\n",
    "    processed_mcm_gcvoc_each = all_data_mcm_gcvoc_each.groupby('time_bin')[varialbes_noy_mod].mean(numeric_only=True).copy()\n",
    "    processed_gc_each        = all_data_gc_each.groupby('time_bin')[varialbes_noy_mod].mean(numeric_only=True).copy()\n",
    "    processed_obs_each       = wecan_data_comp_keyN[flight].groupby('time_bin')[varialbes_noy_obs].mean(numeric_only=True).copy()\n",
    "\n",
    "    # Drop rows where all values are NaN\n",
    "    processed_mcm_bbvoc_each = processed_mcm_bbvoc_each.dropna(how='all')\n",
    "    processed_mcm_gcvoc_each = processed_mcm_gcvoc_each.dropna(how='all')\n",
    "    processed_gc_each        = processed_gc_each.dropna(how='all')\n",
    "    processed_obs_each       = processed_obs_each.dropna(how='all')\n",
    "    \n",
    "    # Calculate missing NOy\n",
    "    Init_NOy_mcm_bbvoc_each  = processed_mcm_bbvoc_each.iloc[0, :].sum() + wecan_data_init[flight]['Init_NEMR_pNO3']\n",
    "    Init_NOy_mcm_gcvoc_each  = processed_mcm_gcvoc_each.iloc[0, :].sum() + wecan_data_init[flight]['Init_NEMR_pNO3']\n",
    "    Init_NOy_gc_each         = processed_gc_each.iloc[0, :].sum() + wecan_data_init[flight]['Init_NEMR_pNO3']\n",
    "    \n",
    "    processed_mcm_bbvoc_each['NEMR_missing'] = processed_mcm_bbvoc_each.apply(lambda row: Init_NOy_mcm_bbvoc_each - row.iloc[:-1].sum(), axis=1)\n",
    "    processed_mcm_gcvoc_each['NEMR_missing'] = processed_mcm_gcvoc_each.apply(lambda row: Init_NOy_mcm_gcvoc_each - row.iloc[:-1].sum(), axis=1)\n",
    "    processed_gc_each['NEMR_missing']        = processed_gc_each.apply(lambda row: Init_NOy_gc_each - row.iloc[:-1].sum(), axis=1)\n",
    "\n",
    "    # Convert index to float\n",
    "    processed_mcm_bbvoc_each.index = processed_mcm_bbvoc_each.index.astype(float)\n",
    "    processed_mcm_gcvoc_each.index = processed_mcm_gcvoc_each.index.astype(float)\n",
    "    processed_gc_each.index        = processed_gc_each.index.astype(float)\n",
    "    processed_obs_each.index       = processed_obs_each.index.astype('object')\n",
    "\n",
    "    # Calculate NOz time series\n",
    "    processed_mcm_bbvoc_ts = processed_mcm_bbvoc_each.drop(['NEMR_NOx', 'NEMR_missing'], axis=1).sum(axis=1)\n",
    "    processed_mcm_gcvoc_ts = processed_mcm_gcvoc_each.drop(['NEMR_NOx', 'NEMR_missing'], axis=1).sum(axis=1)\n",
    "    processed_gc_ts        = processed_gc_each.drop(['NEMR_NOx', 'NEMR_missing'], axis=1).sum(axis=1)\n",
    "    processed_obs_ts       = processed_obs_each.drop(['NEMR_NOx'], axis=1).sum(axis=1)\n",
    "\n",
    "    # Interpolate based on observations\n",
    "    #tmp_mcm_bbvoc = np.interp(processed_obs_ts.index, processed_mcm_bbvoc_ts.index, processed_mcm_bbvoc_ts.values)\n",
    "    #tmp_mcm_gcvoc = np.interp(processed_obs_ts.index, processed_mcm_gcvoc_ts.index, processed_mcm_gcvoc_ts.values)\n",
    "    #tmp_gc        = np.interp(processed_obs_ts.index, processed_gc_ts.index, processed_gc_ts.values)\n",
    "    tmp_obs        = np.interp(processed_mcm_bbvoc_ts.index, processed_obs_ts.index, processed_obs_ts.values)\n",
    "\n",
    "    # Create a new series with the interpolated values\n",
    "    #processed_mcm_bbvoc_ts = pd.Series(tmp_mcm_bbvoc, index=processed_obs_ts.index)\n",
    "    #processed_mcm_gcvoc_ts = pd.Series(tmp_mcm_gcvoc, index=processed_obs_ts.index)\n",
    "    #processed_gc_ts        = pd.Series(tmp_gc, index=processed_obs_ts.index)\n",
    "    processed_obs_ts        = pd.Series(tmp_obs, index=processed_mcm_bbvoc_ts.index)\n",
    "\n",
    "    # Store the processed data\n",
    "    processed_data[flight] = {\n",
    "        'Observation': processed_obs_ts,\n",
    "        'MCM$_{BBVOC}$': processed_mcm_bbvoc_ts,\n",
    "        'MCM$_{GCVOC}$': processed_mcm_gcvoc_ts,\n",
    "        'GEOS-Chem'           : processed_gc_ts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f90c8-e048-4c90-9f93-698e66e50ed0",
   "metadata": {},
   "source": [
    "#### Figure S6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847908e-bcb9-4f1a-8e03-f175440e0072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define flights\n",
    "flights = ['RF03', 'RF07', 'RF09']\n",
    "# Colors for each flight\n",
    "colors = ['blue', 'green', 'red']\n",
    "flight_colors = dict(zip(flights, colors))\n",
    "\n",
    "# Model datasets\n",
    "model_datasets = {\n",
    "    'MCM$_{BBVOC}$': all_data_mcm_bbvoc_noy,\n",
    "    'MCM$_{GCVOC}$': all_data_mcm_gcvoc_noy,\n",
    "    'GEOS-Chem': all_data_gc_noy\n",
    "}\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(model_datasets), figsize=(6*len(model_datasets), 5), sharey=True)  # Adjust subplot layout\n",
    "\n",
    "# Loop through each model\n",
    "for ax, (model_name, model_data) in zip(axes, model_datasets.items()):\n",
    "    all_obs_data = []\n",
    "    all_mod_data = []\n",
    "\n",
    "    # Loop through each flight\n",
    "    for flight, color in flight_colors.items():\n",
    "        # Data for the observation\n",
    "        obs_data = wecan_data_orgN[flight].drop(['time_bin'], axis=1).sum(axis=1) \n",
    "        \n",
    "        # Data for the model\n",
    "        mod_data = model_data[model_data['Flight_ID'] == flight].copy()\n",
    "        mod_data['NEMR_orgN'] += wecan_data_init[flight]['Init_NEMR_orgN']\n",
    "        mod_data = mod_data['NEMR_orgN'] \n",
    "        \n",
    "        # Interpolate model data to the observational data index\n",
    "        mod_data_interpolated = np.interp(obs_data.index, mod_data.index, mod_data.values)\n",
    "\n",
    "        #if model_name == 'GEOS-Chem':\n",
    "        #    print(obs_data)\n",
    "        #   print(mod_data_interpolated)\n",
    "\n",
    "        # Store data for overall slope calculation\n",
    "        all_obs_data.extend(obs_data.tolist())\n",
    "        all_mod_data.extend(mod_data_interpolated.tolist())\n",
    "\n",
    "        # Scatter plot for observation vs. model\n",
    "        ax.scatter(mod_data_interpolated, obs_data, s=100, color=color, label=id2fire_name[flight].replace('\\n(WE-CAN)', ''), alpha=0.6, edgecolors='k')\n",
    "        # Calculate and annotate the slope\n",
    "        slope, intercept = np.polyfit(obs_data, mod_data_interpolated, 1)\n",
    "        slope_text = f'Slope for {flight}: {slope:.2f}'\n",
    "        #ax.text(0.95, 0.20 - 0.08 * list(flight_colors.keys()).index(flight), slope_text,\n",
    "        #        transform=ax.transAxes, color=color, fontsize=15, horizontalalignment='right')\n",
    "\n",
    "        #if model_name == 'GEOS-Chem': print(all_mod_data)\n",
    "    # Draw a 1:1 line\n",
    "    max_value = __builtins__.max(__builtins__.max(all_obs_data), __builtins__.max(all_mod_data))\n",
    "    min_value = __builtins__.min(__builtins__.min(all_obs_data), __builtins__.min(all_mod_data))\n",
    "    ax.plot([min_value, max_value], [min_value, max_value], 'k--', label='1:1 Line')\n",
    "\n",
    "    # Calculate and annotate overall slope for all flights combined\n",
    "    overall_slope, overall_intercept = np.polyfit(all_mod_data, all_obs_data, 1)\n",
    "    sorted_all_mod_data = np.sort(all_mod_data)\n",
    "    ax.plot(sorted_all_mod_data, np.polyval([overall_slope, overall_intercept], sorted_all_mod_data), 'k-', label='Overall best fit')\n",
    "\n",
    "    # Annotation\n",
    "    overall_slope_text = f'Slope: {overall_slope:.2f}'\n",
    "    ax.text(0.95, 0.05, overall_slope_text, transform=ax.transAxes, fontsize=20, color='black', horizontalalignment='right')\n",
    "\n",
    "    # Set titles and labels\n",
    "    ax.set_xlabel(f'{model_name} (ppbv/ppbv)', fontsize=20)\n",
    "    # Increase tick font size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(0.1/100, 1/100)\n",
    "    ax.set_ylim(0.1/100, 1/100)\n",
    "    \n",
    "# Set up y label\n",
    "axes[0].set_ylabel(f'Observation (ppbv/ppbv)', fontsize=20)\n",
    "\n",
    "# Legend\n",
    "axes[0].legend(loc='upper left', fontsize=15)\n",
    "\n",
    "# Place a centered title across the subplots using `text`\n",
    "fig.text(0.5, 0.99, 'ΔOrgN/ΔCO within 5 hours of plume aging', ha='center', fontsize=30)\n",
    "\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()  # Adjust layout to make room for the main title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113947d-ba37-4e8e-9cad-40ae4bc1b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define flights\n",
    "flights = ['RF03', 'RF07', 'RF09']\n",
    "# Colors for each flight\n",
    "colors = ['blue', 'green', 'red']\n",
    "flight_colors = dict(zip(flights, colors))\n",
    "\n",
    "# Model datasets\n",
    "model_datasets = {\n",
    "    'MCM$_{BBVOC}$': all_data_mcm_bbvoc_noy,\n",
    "    'MCM$_{GCVOC}$': all_data_mcm_gcvoc_noy,\n",
    "    'GEOS-Chem': all_data_gc_noy\n",
    "}\n",
    "\n",
    "# Loop through each flight\n",
    "for flight in flights:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(model_datasets), figsize=(6*len(model_datasets), 5))  # One row per model for each flight\n",
    "    color = flight_colors[flight]\n",
    "    \n",
    "    # Loop through each model\n",
    "    for ax, (model_name, model_data) in zip(axes, model_datasets.items()):\n",
    "        # Data for the model\n",
    "        mod_data = model_data[model_data['Flight_ID'] == flight].copy()\n",
    "        mod_data['NEMR_orgN'] += wecan_data_init[flight]['Init_NEMR_orgN']\n",
    "        mod_data = mod_data['NEMR_orgN']\n",
    "\n",
    "        # Data for the observation\n",
    "        obs_data = wecan_data_orgN[flight].drop(['time_bin'], axis=1).sum(axis=1)\n",
    "        \n",
    "        # Interpolate model data to the observational data index\n",
    "        mod_data_interpolated = np.interp(obs_data.index, mod_data.index, mod_data.values)\n",
    "\n",
    "        # Scatter plot for observation vs. model\n",
    "        ax.scatter(mod_data_interpolated, obs_data, s=100, color=color, label=f'{flight} data', alpha=0.6, edgecolors='k')\n",
    "\n",
    "        # Calculate slope and plot individual best-fit line for each flight\n",
    "        if len(obs_data) > 1 and len(mod_data_interpolated) > 1:\n",
    "            slope, intercept = np.polyfit(mod_data_interpolated, obs_data, 1)\n",
    "            sorted_mod_data = np.sort(mod_data_interpolated)\n",
    "            ax.plot(sorted_mod_data, slope * sorted_mod_data + intercept, color=color, linestyle='-', label=f'Best fit for {flight}')\n",
    "            \n",
    "            # Annotate slope\n",
    "            slope_annotation = f'Slope for {flight}: {slope:.2f}'\n",
    "            ax.annotate(slope_annotation, xy=(0.95, 0.05 + 0.05 * list(flight_colors.keys()).index(flight)), xycoords='axes fraction', color=color, fontsize=14, ha='right')\n",
    "\n",
    "        # Draw a 1:1 line\n",
    "        max_value = __builtins__.max(__builtins__.max(obs_data), __builtins__.max(mod_data))\n",
    "        min_value = __builtins__.min(__builtins__.min(obs_data), __builtins__.min(mod_data))\n",
    "        ax.plot([min_value, max_value], [min_value, max_value], 'k--', label='1:1 Line')\n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f'{model_name} comparison for {flight}', fontsize=16)\n",
    "        ax.set_xlabel(f'{model_name} (ppbv/ppbv)', fontsize=14)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        \n",
    "        ax.set_xlim(min_value, max_value)\n",
    "        ax.set_ylim(min_value, max_value)\n",
    "\n",
    "        # Legend\n",
    "        ax.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "    # Set up y label for the first subplot\n",
    "    axes[0].set_ylabel(f'Observation (ppbv/ppbv)', fontsize=14)\n",
    "    \n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f'/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/output/outputFlight_{flight}_Comparison.pdf')  # Save as PDF\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76499d90-25e3-422c-892e-17179243bcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f2426-3bd3-4878-bff6-1ddcc1f5c564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7bc35-e909-4555-a1d8-08a90a58b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wecan_data_orgN['RF03'].mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758703cf-69e3-4425-bdad-ff301d1b636e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64054bd-b493-41f8-908f-6cd371a5a1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09eb4c-9cf4-4ab2-bbbd-8153b328f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and plot the data for a single flight\n",
    "def process_and_plot(flight_data, ax, if_legend=False):\n",
    "    # Drop the time_bin column and calculate the mean\n",
    "    data_series = flight_data.drop(['time_bin'], axis=1).mean()\n",
    "    # Sum values from C9 to C17\n",
    "    lumped_C9_C17 = data_series[['NEMR_C9_OrgN', 'NEMR_C10_OrgN', 'NEMR_C11_OrgN', 'NEMR_C12_OrgN', 'NEMR_C13_OrgN', 'NEMR_C14_OrgN', 'NEMR_C15_OrgN', 'NEMR_C16_OrgN', 'NEMR_C17_OrgN']].sum()\n",
    "    # Create a new Series excluding C9 to C17 individual components and adding the lumped sum\n",
    "    new_data = data_series.drop(['NEMR_C9_OrgN', 'NEMR_C10_OrgN', 'NEMR_C11_OrgN', 'NEMR_C12_OrgN', 'NEMR_C13_OrgN', 'NEMR_C14_OrgN', 'NEMR_C15_OrgN', 'NEMR_C16_OrgN', 'NEMR_C17_OrgN'])\n",
    "    new_data['NEMR_C9-C17_OrgN'] = lumped_C9_C17\n",
    "    # Normalize the data\n",
    "    data_normalized = new_data / new_data.sum()\n",
    "\n",
    "    # Name map\n",
    "    name_map = {\n",
    "        'NEMR_C2_OrgN': 'C2',\n",
    "        'NEMR_C3_OrgN': 'C3',\n",
    "        'NEMR_C4_OrgN': 'C4',\n",
    "        'NEMR_C5_OrgN': 'C5',\n",
    "        'NEMR_C6_OrgN': 'C6',\n",
    "        'NEMR_C7_OrgN': 'C7',\n",
    "        'NEMR_C8_OrgN': 'C8',\n",
    "        'NEMR_C9-C17_OrgN': 'C9-C17',\n",
    "    }\n",
    "    data_normalized.index = data_normalized.index.map(name_map)\n",
    "\n",
    "    # Plot colors\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:grey']\n",
    "    # Pie charts processing\n",
    "    def custom_autopct(pct):\n",
    "        return ('%.0f%%' % pct) if pct > 5 else ''\n",
    "\n",
    "    # Create the pie chart\n",
    "    wedges, texts, autotexts = ax.pie(data_normalized, autopct=custom_autopct, startangle=90, colors=colors, textprops={'fontsize': 20})\n",
    "\n",
    "    # Improve display of autopct labels\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')  # Set the color of percentages to white\n",
    "    ax.set_ylabel('')  # Remove the y-label\n",
    "    # Legend formatting with increased size\n",
    "    if if_legend:\n",
    "        ax.legend(wedges, data_normalized.index, title=\"\", loc=\"center right\", \n",
    "                  bbox_to_anchor=(-0.4, 0, 0.5, 1), fontsize=20) # (x, y, width, height)\n",
    "# Create subplots for three flights\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "process_and_plot(wecan_data_orgN['RF03'], axs[0], if_legend=True)\n",
    "process_and_plot(wecan_data_orgN['RF07'], axs[1])\n",
    "process_and_plot(wecan_data_orgN['RF09'], axs[2])\n",
    "axs[0].text(0.5, 0.98, 'Taylor Creek Fire', transform=axs[0].transAxes, fontsize=25, va='top', ha='center') \n",
    "axs[1].text(0.5, 0.98, 'Donnel Fire', transform=axs[1].transAxes, fontsize=25, va='top', ha='center') \n",
    "axs[2].text(0.5, 0.98, 'Bear Trap Fire', transform=axs[2].transAxes, fontsize=25, va='top', ha='center') \n",
    "fig.text(0.5, 1, 'Observed partitioning of organic nitrogen species (OrgN$_{(excl.)}$)', va='bottom', ha='center', fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=-0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5731d7-38c3-4990-9938-dd59aed89ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of flight IDs corresponding to different fires\n",
    "flights = ['RF03', 'RF07', 'RF09']\n",
    "\n",
    "# Combine the data from all flights into one DataFrame\n",
    "combined_data = pd.concat([wecan_data_orgN[flight] for flight in flights], ignore_index=True)\n",
    "\n",
    "# Drop the 'time_bin' column and calculate the mean across all data\n",
    "data_series = combined_data.drop(['time_bin'], axis=1).mean()\n",
    "\n",
    "# Sum values from NEMR_C9_OrgN to NEMR_C17_OrgN\n",
    "lumped_C9_C17 = data_series[['NEMR_C9_OrgN', 'NEMR_C10_OrgN', 'NEMR_C11_OrgN', 'NEMR_C12_OrgN',\n",
    "                             'NEMR_C13_OrgN', 'NEMR_C14_OrgN', 'NEMR_C15_OrgN', 'NEMR_C16_OrgN',\n",
    "                             'NEMR_C17_OrgN']].sum()\n",
    "\n",
    "# Create a new Series excluding individual C9 to C17 components and adding the lumped sum\n",
    "new_data = data_series.drop(['NEMR_C9_OrgN', 'NEMR_C10_OrgN', 'NEMR_C11_OrgN', 'NEMR_C12_OrgN',\n",
    "                             'NEMR_C13_OrgN', 'NEMR_C14_OrgN', 'NEMR_C15_OrgN', 'NEMR_C16_OrgN',\n",
    "                             'NEMR_C17_OrgN'])\n",
    "\n",
    "new_data['NEMR_C9-C17_OrgN'] = lumped_C9_C17\n",
    "\n",
    "# Normalize the data to get percentages\n",
    "data_normalized_obs = new_data / new_data.sum()\n",
    "\n",
    "# Map the column names to simpler labels for plotting\n",
    "name_map = {\n",
    "    'NEMR_C2_OrgN': 'C2',\n",
    "    'NEMR_C3_OrgN': 'C3',\n",
    "    'NEMR_C4_OrgN': 'C4',\n",
    "    'NEMR_C5_OrgN': 'C5',\n",
    "    'NEMR_C6_OrgN': 'C6',\n",
    "    'NEMR_C7_OrgN': 'C7',\n",
    "    'NEMR_C8_OrgN': 'C8',\n",
    "    'NEMR_C9-C17_OrgN': 'C9-C17',\n",
    "}\n",
    "data_normalized_obs.index = data_normalized_obs.index.map(name_map)\n",
    "\n",
    "# Define the colors for the pie chart\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:grey']\n",
    "\n",
    "# Define the custom autopct function for displaying percentages\n",
    "def custom_autopct(pct):\n",
    "    return ('%.0f%%' % pct) if pct > 5 else ''\n",
    "\n",
    "# Create the pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "wedges, texts, autotexts = ax.pie(data_normalized_obs, autopct=custom_autopct, startangle=90,\n",
    "                                  colors=colors, textprops={'fontsize': 20})\n",
    "\n",
    "# Set the percentage labels to white color for better visibility\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "\n",
    "# Remove the y-label\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Add the legend\n",
    "ax.legend(wedges, data_normalized_obs.index, title=\"\", loc=\"center right\",\n",
    "          bbox_to_anchor=(1.3, 0.5), fontsize=20)\n",
    "\n",
    "# Add the title\n",
    "fig.text(0.5, 1, 'Average Observed Partitioning of Organic Nitrogen Species (OrgN$_{(excl.)}$)',\n",
    "         va='bottom', ha='center', fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648023f3-80de-4095-9bf6-1537be52ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrames from CSV files\n",
    "file_dir = '/glade/work/lixujin/PYTHON/SciProj/Box_modeling_analysis/VOC_OH_exposure/input'\n",
    "combined_df_mcm_bbvoc_grouped = pd.read_csv(f'{file_dir}/combined_df_mcm_bbvoc_grouped.csv', index_col=0)\n",
    "combined_df_mcm_gcvoc_grouped = pd.read_csv(f'{file_dir}/combined_df_mcm_gcvoc_grouped.csv', index_col=0)\n",
    "combined_df_gc_grouped        = pd.read_csv(f'{file_dir}/combined_df_gc_grouped.csv', index_col=0)\n",
    "# Reconstruct the common index\n",
    "common_index = ['C' + str(item) if isinstance(item, int) else item for item in combined_df_mcm_bbvoc_grouped.index]\n",
    "\n",
    "# Reindex the DataFrames and align indices\n",
    "combined_df_gc_grouped              = combined_df_gc_grouped.reindex(combined_df_mcm_bbvoc_grouped.index)\n",
    "combined_df_gc_grouped.fillna(0, inplace=True)\n",
    "combined_df_mcm_bbvoc_grouped.index = common_index\n",
    "combined_df_mcm_gcvoc_grouped.index = common_index\n",
    "combined_df_gc_grouped.index        = common_index\n",
    "models = [combined_df_mcm_bbvoc_grouped, combined_df_mcm_gcvoc_grouped, combined_df_gc_grouped]\n",
    "titles = ['MCM$_{BBVOC}$', 'MCM$_{GCVOC}$', 'GEOS-Chem']\n",
    "\n",
    "# Create pie plots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # 1x3 plot grid for three models\n",
    "\n",
    "# Define custom autopct function with increased fontsize\n",
    "def custom_autopct(pct):\n",
    "    return ('%1.1f%%' % pct) if pct > 5 else ''\n",
    "\n",
    "# Storing wedges for the legend\n",
    "wedges_list = []\n",
    "for i, model in enumerate(models):\n",
    "    wedges, texts, autotexts = axs[i].pie(model['Mean (freq)'],\n",
    "                                          autopct=lambda pct: custom_autopct(pct),\n",
    "                                          startangle=90,\n",
    "                                          textprops={'fontsize': 20})  # Set the fontsize for percentage labels\n",
    "    axs[i].set_title(titles[i], fontsize=25, y=0.92)\n",
    "    wedges_list.append(wedges)  # Store wedges for later legend use\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.05, wspace=-0.35)\n",
    "\n",
    "# Using a single legend for all pie charts, from wedges of the first model\n",
    "fig.legend(wedges_list[0], common_index,\n",
    "           loc=\"center right\", bbox_to_anchor=(0.85, 0.66), fontsize=16)\n",
    "fig.text(0.5, 1, 'Modeled partitioning of organic nitrogen species (OrgN)', va='bottom', ha='center', fontsize=30)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639662e-23c5-4a5a-b94f-89b2e3c1f7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6ddc9-050f-4246-bdb0-760d9f532790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88517865-b0c9-4c5d-a7ee-45de5a08656a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94317190-87e4-4e5b-b1eb-20cac3875dd8",
   "metadata": {},
   "source": [
    "#### Figure S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c23a97-96ef-4da2-a0a0-e8c7959f28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# Create Figure and Plot Pie Charts\n",
    "# ------------------------------------\n",
    "# Define the labels and colors to be used in the pie charts\n",
    "labels = ['C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9-C17']\n",
    "colors = [\n",
    "    'tab:blue', 'tab:orange', 'tab:green', 'tab:red',\n",
    "    'tab:purple', 'tab:brown', 'tab:pink', 'tab:grey'\n",
    "]\n",
    "\n",
    "# Create a figure with 2 rows and 2 columns to accommodate 4 pie charts\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 12))  # Adjust figsize as needed\n",
    "\n",
    "# Define a custom function to format the percentage labels\n",
    "def custom_autopct(pct):\n",
    "    return ('%1.1f%%' % pct) if pct > 5 else ''  # Show percentages > 5%\n",
    "\n",
    "# Plot the observation pie chart in the first subplot\n",
    "wedges_obs, texts_obs, autotexts_obs = axs[0, 0].pie(\n",
    "    data_normalized_obs,\n",
    "    autopct=lambda pct: custom_autopct(pct),\n",
    "    startangle=90,\n",
    "    colors=colors,\n",
    "    textprops={'fontsize': 20}\n",
    ")\n",
    "axs[0, 0].set_title('Observation', fontsize=25, y=0.92)  # Set subplot title\n",
    "\n",
    "# Optionally set the percentage labels to white for better visibility\n",
    "for autotext in autotexts_obs:\n",
    "    autotext.set_color('white')\n",
    "\n",
    "# ------------------------------------\n",
    "# Prepare Model Data for Plotting\n",
    "# ------------------------------------\n",
    "\n",
    "# List of your model DataFrames\n",
    "models = [combined_df_mcm_bbvoc_grouped, combined_df_mcm_gcvoc_grouped, combined_df_gc_grouped]\n",
    "titles = ['MCM$_{BBVOC}$', 'MCM$_{GCVOC}$', 'GEOS-Chem']\n",
    "axes_positions = [(0, 1), (1, 0), (1, 1)]  # Positions in the 2x2 grid\n",
    "\n",
    "# Iterate over the models to process and plot each one\n",
    "for model_df, title, pos in zip(models, titles, axes_positions):\n",
    "    # Extract the 'Mean (freq)' column\n",
    "    model_data = model_df['Mean (freq)']\n",
    "    \n",
    "    # Normalize the data to get fractions (percentages)\n",
    "    model_data_normalized = model_data / model_data.sum()\n",
    "    \n",
    "    # Ensure the index matches the labels\n",
    "    model_data_normalized = model_data_normalized.reindex(labels)\n",
    "    \n",
    "    # Fill missing values with zero (if any)\n",
    "    model_data_normalized.fillna(0, inplace=True)\n",
    "    \n",
    "    # Plot the pie chart\n",
    "    wedges, texts, autotexts = axs[pos].pie(\n",
    "        model_data_normalized,\n",
    "        autopct=lambda pct: custom_autopct(pct),\n",
    "        startangle=90,\n",
    "        colors=colors,\n",
    "        textprops={'fontsize': 20}\n",
    "    )\n",
    "    axs[pos].set_title(title, fontsize=25, y=0.92)  # Set subplot title\n",
    "\n",
    "    # Optionally set the percentage labels to white for better visibility\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "\n",
    "# ---------------------------\n",
    "# Adjust Layout and Add Legend\n",
    "# ---------------------------\n",
    "\n",
    "# Add a single legend for all pie charts, using the wedges and labels from the observation pie chart\n",
    "fig.legend(wedges_obs, labels, loc=\"center right\",\n",
    "           bbox_to_anchor=(0.65, 0.85),  # Position the legend outside the figure\n",
    "           fontsize=16\n",
    ")\n",
    "\n",
    "# Add the main title for the entire figure\n",
    "fig.text(\n",
    "    0.5, 1,  # Position at the center top\n",
    "    'Partitioning of organic nitrogen species (OrgN)',\n",
    "    va='bottom',\n",
    "    ha='center',\n",
    "    fontsize=35\n",
    ")\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlap and improve spacing\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=-0.1, wspace=-0.55)\n",
    "\n",
    "# Display the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff3b69-b8f0-4b09-a9fc-56eb4c138ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb03ef-ea44-453d-bb1d-bc1b4c2b9c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9c6c4-2025-4f53-a092-a59ba411d1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a13365-c66e-458c-b87b-33535ae584e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flight = 'RF07'\n",
    "# Data for the observation\n",
    "obs_data = wecan_data_orgN[flight].drop(['time_bin'], axis=1).sum(axis=1)*100\n",
    "\n",
    "# Data for the model\n",
    "model_data = all_data_mcm_bbvoc_noy[all_data_mcm_bbvoc_noy['Flight_ID'] == flight].copy()\n",
    "model_data['NEMR_orgN'] += wecan_data_init[flight]['Init_NEMR_orgN']\n",
    "model_data = model_data['NEMR_orgN']*100\n",
    "\n",
    "# Calculate NMB\n",
    "nmb = 100 * (model_data.mean() - obs_data.mean()) / obs_data.mean()\n",
    "\n",
    "# Create a single figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plotting both series\n",
    "obs_data.plot(ax=ax, label='Observation', color='blue')\n",
    "model_data.plot(ax=ax, label='MCM$_{BBVOC}$', color='red')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.legend(fontsize=15)\n",
    "# Increase the tick label sizes\n",
    "ax.tick_params(axis='both', labelsize=14)  # Increase font size of ticks on both x and y axes\n",
    "\n",
    "# Hide x and y labels\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Annotate NMB\n",
    "ax.annotate(f'NMB: {nmb:.0f}%', xy=(0.95, 0.05), xycoords='axes fraction', fontsize=15,\n",
    "            horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "# Set global labels for the  figure\n",
    "fig.text(0.05, 0.5, '∆OrgN$_(excl.)$/∆CO (%)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "fig.text(0.5, 0.05, 'Physical age (hour)', ha='center', va='center',  fontsize=20)\n",
    "\n",
    "ax.text(0.5, 1, 'OrgN$_{excl.}$ NEMR in Taylor Creek', transform=ax.transAxes, fontsize=25, va='bottom', ha='center') \n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b3ab6-10b7-4ab6-b911-f01504e661ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d21709f-86f0-42c6-8598-87a411cb54a7",
   "metadata": {},
   "source": [
    "#### Response to reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b8659-807a-4ac5-95dc-8351e423ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_helper(group_column, var_x, var_y, ax, title, set_ylabel, show_legend, set_xlabel=True, set_annotate=True):\n",
    "    # Select group names and corresponding legend title\n",
    "    if group_column == 'VOCR_NOxR_group': \n",
    "        unique_groups = VOCR_NOxR_group_names\n",
    "        legend_title = 'OHRvoc: OHRnox'\n",
    "    elif group_column == 'NOxR_VOCR_group':\n",
    "        unique_groups = NOxR_VOCR_group_names\n",
    "        legend_title = 'OHRnox: OHRvoc'    \n",
    "    elif group_column == 'VOCR_group':\n",
    "        unique_groups = all_data_obs_combined['VOCR_group'].unique()\n",
    "        unique_groups = np.sort(unique_groups)\n",
    "        legend_title = 'VOC reactivity'    \n",
    "    elif group_column == 'Flight_ID':\n",
    "        unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "        legend_title = 'Flight ID'\n",
    "    elif group_column == 'O3_category':\n",
    "        unique_groups = all_data_obs_combined['O3_cateplot_data_helpergory'].unique()\n",
    "        #unique_groups = np.sort(unique_groups)\n",
    "        legend_title = 'O3 concentration'\n",
    "    elif group_column == 'Ox_category':\n",
    "        unique_groups = all_data_obs_combined['Ox_category'].unique()\n",
    "        #unique_groups = np.sort(unique_groups)\n",
    "        legend_title = 'Ox concentration'\n",
    "    elif group_column == 'CH2O_NO2_group':\n",
    "        unique_groups = all_data_obs_combined['CH2O_NO2_group'].unique()\n",
    "        legend_title = 'CH$_{2}$O: NO$_{2}$'\n",
    "\n",
    "    # The slope of NEMR O3 vs plume age\n",
    "    mean_lagrangian = []\n",
    "    nmb_values_mcm_bbvoc = {}\n",
    "    nmb_values_mcm_gcvoc = {}\n",
    "    nmb_values_gc = {}\n",
    "    color_flight = {}\n",
    "    \n",
    "    # Set up colors\n",
    "    if group_column == 'Flight_ID':\n",
    "        unique_groups = desired_order_flights\n",
    "    if len(unique_groups) == 6:\n",
    "        group_colors = np.array([\n",
    "            [0.80645161, 1.0, 0.16129032, 1.0],\n",
    "            [0.5, 0.0, 0.0, 1.0],\n",
    "            [0.0, 0.0, 0.5, 1.0],\n",
    "            [0.0, 0.3, 1.0, 1.0],\n",
    "            [1.0, 0.40740741, 0.0, 1.0],\n",
    "            [0.16129032, 1.0, 0.80645161, 1.0],\n",
    "        ])\n",
    "\n",
    "        group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "    \n",
    "    else:\n",
    "        group_colors = plt.cm.jet(np.linspace(0, 1, len(unique_groups)))\n",
    "\n",
    "    OH_cal_VOCs = ['Furan', 'Furfural', 'Furanone', 'Furan: CO', 'Furfural: CO', 'Furanone: CO']\n",
    "    for idx, group in enumerate(unique_groups):\n",
    "        skip_P3B_conditions     = ((group == 'P-3B') and ('PAN' in var_y)) or  \\\n",
    "                                    ((group == 'P-3B') and (var_y in OH_cal_VOCs)) or  \\\n",
    "                                    ((group == 'P-3B') and ('NO2' in var_y)) or \\\n",
    "                                    ((group == 'P-3B') and ('NO' in var_y))\n",
    "\n",
    "        skip_FN19_conditions    = (group == 'FN19') and ('HNO3' in var_y)\n",
    "        skip_GCVOC_conditions   =  var_y in OH_cal_VOCs\n",
    "        skip_nonLang_conditions = ('output' in var_x) and ('NEMR_O3' in var_y or 'NEMR_PAN' in var_y) and (group == 'Other WE-CAN flights') \n",
    "        # Skip P-3B for calculated chemical age\n",
    "        if skip_P3B_conditions:\n",
    "            print('skip P-3B for missing data')\n",
    "            continue\n",
    "        if skip_FN19_conditions:\n",
    "            print('skip FN19 for missing data')\n",
    "            continue\n",
    "        if skip_nonLang_conditions:\n",
    "            print('skip non-Lagrangian flights')\n",
    "            continue\n",
    "\n",
    "        # Replace calculated OH/chemical age from actual OH in MCMBBVOC        \n",
    "        group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]            \n",
    "        group_data_obs  = group_data_obs.dropna(subset=[var_x, var_y])\n",
    "        x_obs, y_obs    = (group_data_obs[var_x]).astype(float), (group_data_obs[var_y]).astype(float)\n",
    "        valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "        \n",
    "        if group in Lagrangian_flights: mean_lagrangian.append(y_obs[valid_indices].mean())\n",
    "\n",
    "        # Plot observational data if available\n",
    "        if valid_indices.any():\n",
    "            # Determine if the circle should be solid or open based on the flight\n",
    "            face_color = group_colors[idx]\n",
    "            # 1) Plot dots even they are not in Lagrangian flights\n",
    "            if \"dil\" not in var_y:\n",
    "                if group_column == 'Flight_ID': \n",
    "                    if group not in Lagrangian_flights: continue\n",
    "                    face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "                    #face_color = 'none' # To make Lu happy, VOC plot\n",
    "                    ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "                else:\n",
    "                    ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=group)\n",
    "                    \n",
    "            # 2) Plot dots only when they are in Lagrangian flights and var_y is specific.\n",
    "            # dil for model VOC evalutions, \n",
    "            if 'dil' in var_y and group in Lagrangian_flights:\n",
    "                if np.all(y_obs[valid_indices] == 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    if group_column == 'Flight_ID': \n",
    "                        face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "                        #face_color = 'none' # To make Lu happy, VOC plot\n",
    "                        ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "                    else:\n",
    "                        ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=group)\n",
    "            # Perform linear regression\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "            \n",
    "        # Group model results with flight ID instead.\n",
    "        if (group_column == 'Flight_ID') and (group in Lagrangian_flights):            \n",
    "            group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "            group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "            group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "\n",
    "            # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "            bin_size = 10/60 if var_y == 'LROx: LNOx' else 0.25 # 30/15 minutes in hours\n",
    "            group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "            group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "            group_data_gc_binned             = group_data_gc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "            # Choose what we want to smooth the model results\n",
    "            # Binned model data if we are using actual OH related varialbe\n",
    "            if ('output' in var_y or 'output' in var_x) or (var_x=='Plume_Age' and var_y=='LROx: LNOx'):\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x]).astype(float), (group_data_mcm_bbvoc_binned[var_y]).astype(float)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x]).astype(float), (group_data_mcm_gcvoc_binned[var_y]).astype(float)\n",
    "                x_gc, y_gc               = (group_data_gc_binned[var_x]).astype(float), (group_data_gc_binned[var_y]).astype(float)\n",
    "            else:\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc[var_x]).astype(float), (group_data_mcm_bbvoc[var_y]).astype(float)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc[var_x]).astype(float), (group_data_mcm_gcvoc[var_y]).astype(float)\n",
    "                x_gc, y_gc               = (group_data_gc[var_x]).astype(float), (group_data_gc[var_y]).astype(float)\n",
    "            \n",
    "            valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                                ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                                ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "            \n",
    "            x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "            x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "            x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "\n",
    "            # Smoothen the data, Lixu\n",
    "            if (var_x, var_y) == ('Plume_Age', 'CH2O: NO2') or (var_x, var_y) == ('Plume_Age', 'OHRnox: OHRvoc'):\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=10/60)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=10/60)\n",
    "                x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=10/60)\n",
    "\n",
    "            if (var_x, var_y) == ('Plume_Age', 'LROx: LNOx'):\n",
    "                if group == 'P-3B':\n",
    "                    x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=10/60)\n",
    "                    x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=10/60)\n",
    "                    x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=10/60)\n",
    "                else:\n",
    "                    x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=30/60)\n",
    "                    x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=30/60)\n",
    "                    x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=30/60)\n",
    "\n",
    "            \n",
    "            # Add solid lines for model output\n",
    "            if valid_indices_mod.any():\n",
    "                ax.plot(x_mcm_bbvoc, y_mcm_bbvoc, \n",
    "                        color = group_colors[idx], linestyle='-', linewidth=4, label=id2fire_name.get(group,group))\n",
    "                # Define keys to check in corresponding dictionaries\n",
    "                check_conditions = {\n",
    "                    var_x: ['output'],\n",
    "                    var_y: ['Furanoids excl.', 'Acrolein', 'BIACET', 'Butadiene', 'Butanedione', 'Diacetyl',  'Maleic anhydride']\n",
    "                }\n",
    "                \n",
    "                # Check if all specified keys are missing in their respective dictionaries\n",
    "                if all(key not in dictionary for dictionary, keys in check_conditions.items() for key in keys):\n",
    "                    if not skip_GCVOC_conditions:\n",
    "                        ax.plot(x_mcm_gcvoc, y_mcm_gcvoc, \n",
    "                                color=group_colors[idx], linestyle='--', linewidth=4)\n",
    "                        ax.plot(x_gc, y_gc, \n",
    "                                color=group_colors[idx], linestyle=':', linewidth=4)\n",
    "            \n",
    "            # ------------------------\n",
    "            # Calculate the model error\n",
    "            # -------------------------\n",
    "            # Only when observation exists\n",
    "            if valid_indices.any():\n",
    "                # Define the degree of the polynomial model       \n",
    "                degree = 2 if group!='FN19' else 1\n",
    "                # Create a polynomial regression model\n",
    "                poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "                # Fit the polynomial regression model on observational data\n",
    "                poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "                # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "                x_model       = x_mcm_bbvoc\n",
    "                y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "            # Using mcmbbvoc as the observation\n",
    "            else:\n",
    "                y_predicted = y_mcm_bbvoc\n",
    "            # Calculate Normalized Median Bias (NMB)\n",
    "            #nmb_mcm_bbvoc               = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            #nmb_mcm_gcvoc               = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            #nmb_gc                      = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            nmb_mcm_bbvoc = 100 * np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "            nmb_mcm_gcvoc = 100 * np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "            nmb_gc        = 100 * np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "\n",
    "            # After calculating NMB\n",
    "            nmb_values_mcm_bbvoc[group] = nmb_mcm_bbvoc\n",
    "            nmb_values_mcm_gcvoc[group] = nmb_mcm_gcvoc\n",
    "            nmb_values_gc[group]        = nmb_gc\n",
    "            color_flight[group]         = group_colors[idx]\n",
    "\n",
    "        # Defalt setting for title, ticks, and labels\n",
    "        if set_xlabel: ax.set_xlabel(text_labels.get(var_x, var_x), fontsize=25)\n",
    "        if set_ylabel: ax.set_ylabel(text_labels.get(var_y, var_y), fontsize=25)\n",
    "        ax.set_title(title, fontsize=25)\n",
    "        ax.tick_params(axis='both', labelsize=20)\n",
    "        # Legend        \n",
    "        if show_legend:\n",
    "            if var_y == 'NEMR_PAN' and group_column == 'Flight_ID':\n",
    "                legend_fontsize = 20\n",
    "            elif var_y == 'NEMR_O3' and group_column == 'Flight_ID':\n",
    "                legend_fontsize = 16.5\n",
    "            #elif var_y == 'CH2O: NO2' and group_column == 'Flight_ID':\n",
    "            #    legend_fontsize = 13\n",
    "            elif var_y == 'OHRnox: OHRvoc' and group_column == 'Flight_ID':\n",
    "                legend_fontsize = 15\n",
    "\n",
    "            elif skip_GCVOC_conditions:\n",
    "                legend_fontsize = 15\n",
    "\n",
    "            else:\n",
    "                legend_fontsize = 11.8\n",
    "            if group_column == 'Flight_ID':\n",
    "                desired_order = desired_order_flights\n",
    "                reorder_legend(ax, desired_order, id2fire_name, fontsize=legend_fontsize, title_fontsize = 15, legend_loc='upper right')\n",
    "            elif group_column == 'CH2O_NO2_group':\n",
    "                desired_order = CH2O_NO2_group_names\n",
    "                reorder_legend(ax, desired_order, id2fire_name, legend_title='FNR', fontsize=15, title_fontsize = 15, legend_loc='upper right')\n",
    "            else:\n",
    "                ax.legend(title=legend_title, fontsize=14, title_fontsize = 15, loc='upper right')\n",
    "    # -------------------\n",
    "    # Annotation settings\n",
    "    # -------------------\n",
    "    if var_x=='Plume_Age' or 'cal_chem' in var_x:\n",
    "        # Calculate median and interquartile range (IQR)\n",
    "        nmb_values_mcm_bbvoc_array = np.array(list(nmb_values_mcm_bbvoc.values()), dtype=float)\n",
    "        nmb_values_mcm_gcvoc_array = np.array(list(nmb_values_mcm_gcvoc.values()), dtype=float)\n",
    "        nmb_values_gc_array        = np.array(list(nmb_values_gc.values()), dtype=float)\n",
    "        median_mcm_bbvoc, q1_mcm_bbvoc, q3_mcm_bbvoc = np.nanmedian(nmb_values_mcm_bbvoc_array), np.nanpercentile(nmb_values_mcm_bbvoc_array, 25), np.nanpercentile(nmb_values_mcm_bbvoc_array, 75)\n",
    "        median_mcm_gcvoc, q1_mcm_gcvoc, q3_mcm_gcvoc = np.nanmedian(nmb_values_mcm_gcvoc_array), np.nanpercentile(nmb_values_mcm_gcvoc_array, 25), np.nanpercentile(nmb_values_mcm_gcvoc_array, 75)\n",
    "        median_gc, q1_gc, q3_gc                      = np.nanmedian(nmb_values_gc_array), np.nanpercentile(nmb_values_gc_array, 25), np.nanpercentile(nmb_values_gc_array, 75)\n",
    "        iqr_mcm_bbvoc = q3_mcm_bbvoc - q1_mcm_bbvoc\n",
    "        iqr_mcm_gcvoc = q3_mcm_gcvoc - q1_mcm_gcvoc\n",
    "        iqr_gc        = q3_gc - q1_gc\n",
    "        # Calculate mean and standard deviation\n",
    "        mean_mcm_bbvoc, std_mcm_bbvoc = np.nanmean(nmb_values_mcm_bbvoc_array), np.nanstd(nmb_values_mcm_bbvoc_array)\n",
    "        mean_mcm_gcvoc, std_mcm_gcvoc = np.nanmean(nmb_values_mcm_gcvoc_array), np.nanstd(nmb_values_mcm_gcvoc_array)\n",
    "        mean_gc, std_gc               = np.nanmean(nmb_values_gc_array), np.nanstd(nmb_values_gc_array)\n",
    "\n",
    "        # Annotate mean ± std in each subplot\n",
    "        # Determine if we want to show bias for each individual flights or the average of flights.\n",
    "        annotate_condition1 = ('dil' in var_y) or ('cal' in var_y)  # or ('PAN' in var_y) \n",
    "        annotate_condition2 = ('O3' in var_y)  or ('NEMR_PAN' in var_y and var_x=='Plume_Age') or ('VOCR' in var_y)  or ('NO2' in var_y) or ('NO' in var_y)\n",
    "        if annotate_condition1:\n",
    "            if 'dil' in var_y: xy, ha, va, color =(0.05, 0.0), 'left', 'bottom', 'black'\n",
    "            if 'cal' in var_y: xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "            if 'O3' in var_y:\n",
    "                if var_x=='Plume_Age': xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "                if 'cal' in var_x: xy, ha, va, color =(0.95, 0.55), 'right', 'bottom', 'black'\n",
    "            if ('PAN' in var_y) and var_x=='Plume_Age': xy, ha, va, color =(0.95, 0.55), 'right', 'bottom', 'black'\n",
    "            if 'VOCR' in var_y and var_x=='Plume_Age': xy, ha, va, color =(0.95, 0.05), 'right', 'bottom', 'black'\n",
    "            \n",
    "            \n",
    "            if set_annotate: \n",
    "                ax.annotate(f\"NMB:({median_mcm_bbvoc:.0f}±{iqr_mcm_bbvoc:.0f})%\", \n",
    "                         xy=xy,  # Position of the annotation\n",
    "                         xycoords='axes fraction',\n",
    "                         ha=ha, va=va,  # Alignment of the text\n",
    "                         fontsize=20,  # Font size of the text\n",
    "                         color=color)  # Color of the text\n",
    "        if annotate_condition2:\n",
    "            if 'cal' in var_x or 'PAN' in var_y: \n",
    "                start_x = 0.95\n",
    "                start_y = 0.38\n",
    "                step_y  = 0.05\n",
    "                ha='right'\n",
    "                va='bottom'\n",
    "            elif var_y == 'NEMR_O3' or var_y == 'NEMR_O3_rate' or var_y == 'NEMR_PAN_rate':\n",
    "                start_x = 0.95\n",
    "                start_y = 0.38\n",
    "                step_y  = 0.05\n",
    "                ha='right'\n",
    "                va='bottom'\n",
    "            elif ('VOCR' in var_y):\n",
    "                start_x = 0.7\n",
    "                start_y = 0.87\n",
    "                step_y  = 0.1\n",
    "                ha='right'\n",
    "                va='top'\n",
    "            else:\n",
    "                start_x = 0.95\n",
    "                start_y = 0.45\n",
    "                step_y  = 0.05\n",
    "                ha='right'\n",
    "                va='bottom'\n",
    "            # Desired order of keys\n",
    "            desired_order = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']\n",
    "\n",
    "            # Desired order of keys\n",
    "            nmb_values_mcm_bbvoc_ordered = OrderedDict((key, nmb_values_mcm_bbvoc[key]) for key in desired_order if key in nmb_values_mcm_bbvoc)\n",
    "            nmb_values_mcm_gcvoc_ordered = OrderedDict((key, nmb_values_mcm_gcvoc[key]) for key in desired_order if key in nmb_values_mcm_gcvoc)\n",
    "            nmb_values_gc_ordered        = OrderedDict((key, nmb_values_gc[key]) for key in desired_order if key in nmb_values_gc)\n",
    "\n",
    "            # Annotations            \n",
    "            # Set up for details\n",
    "            if (var_x, var_y) ==  ('Plume_Age', 'VOCR: CO'):\n",
    "                nmb_fontsize = 15\n",
    "            else:\n",
    "                nmb_fontsize = 20\n",
    "\n",
    "            if 'rate' in var_y:\n",
    "                print(x_obs)\n",
    "            if 'rate' not in var_y:\n",
    "                if set_annotate: \n",
    "                    ax.annotate(f'$MCM_{{BBVOC}}$, $MCM_{{GCVOC}}$, GEOS-Chem',\n",
    "                                xy=(start_x, start_y+step_y),  # Position of the annotation\n",
    "                                xycoords='axes fraction',\n",
    "                                ha=ha, va=va,  # Alignment of the text\n",
    "                                fontsize=nmb_fontsize,  # Font size of the text\n",
    "                                color='black')  # Color of the text, + 1 to skip P-3B\n",
    "    \n",
    "                for idx, group in enumerate(nmb_values_mcm_bbvoc_ordered):\n",
    "                    # Extract the name and perform the split operation outside the f-string\n",
    "                    nmb_value_mcm_bbvoc = nmb_values_mcm_bbvoc_ordered[group]\n",
    "                    nmb_value_mcm_gcvoc = nmb_values_mcm_gcvoc_ordered[group]\n",
    "                    nmb_value_gc        = nmb_values_gc_ordered[group]\n",
    "                    color     = color_flight[group]\n",
    "                    # Check if the group requires a box\n",
    "                    if group in ['FN19', 'RF03'] and 'NEMR_O3' in var_y:\n",
    "                        bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"none\", lw=2, ec=color, alpha=0.7)\n",
    "                    else:\n",
    "                        bbox_props = None\n",
    "                    if set_annotate:\n",
    "                        ax.annotate(f'{nmb_value_mcm_bbvoc:.0f}%, {nmb_value_mcm_gcvoc:.0f}%, {nmb_value_gc:.0f}%', \n",
    "                                    xy=(start_x, start_y-idx*step_y),  # Position of the annotation\n",
    "                                    xycoords='axes fraction',\n",
    "                                    ha=ha, va=va,  # Alignment of the text\n",
    "                                    fontsize=nmb_fontsize,  # Font size of the text\n",
    "                                    color=color,   # Color of the text, + 1 to skip P-3B\n",
    "                                    bbox=bbox_props)  # Apply box properties if specified\n",
    "\n",
    "    if (var_x,var_y)==('CH2O: NO2', 'OHRvoc: OHRnox') or (var_x,var_y)==('CH2O: CO', 'VOCR: CO'):\n",
    "        # Calculate and annotate overall slope and R-squared for all observations\n",
    "        all_x_obs, all_y_obs = all_data_obs_combined[var_x], all_data_obs_combined[var_y]\n",
    "        valid_indices_all = ~np.isnan(all_x_obs) & ~np.isnan(all_y_obs)\n",
    "        slope_all, intercept_all, r_value_all, p_value_all, std_err_all = linregress(np.array(all_x_obs)[valid_indices_all], np.array(all_y_obs)[valid_indices_all])\n",
    "        r_squared_all = r_value_all ** 2\n",
    "        if set_annotate:\n",
    "            plt.annotate(f\"Slope={slope_all:.1f}±{std_err_all:.1f}, $R^2$={r_squared_all:.2f}\", \n",
    "                         xy=(0.95, 0.05), xycoords='axes fraction', \n",
    "                         ha='right', va='top', fontsize=15, color='black')\n",
    "\n",
    "    \n",
    "    # Conditional to check if we are analyzing the right variables\n",
    "    #if (var_x, var_y) == ('output_chem_age', 'NEMR_O3') or (var_x, var_y) == ('output_chem_age', 'NEMR_PAN'):\n",
    "    if var_x == 'output_chem_age':\n",
    "        # Compute valid indices (indices where neither x nor y are NaN)\n",
    "        valid_indices_all = ~np.isnan(all_data_obs_lagrangian[var_x]) & ~np.isnan(all_data_obs_lagrangian[var_y])\n",
    "    \n",
    "        # Use valid indices to select data for R^2 calculation\n",
    "        valid_r2_x = all_data_obs_lagrangian[var_x][valid_indices_all]\n",
    "        valid_r2_y = all_data_obs_lagrangian[var_y][valid_indices_all]\n",
    "    \n",
    "        # Compute R^2 value only if there are enough valid data points\n",
    "        if len(valid_r2_x) > 1:\n",
    "            # Calculate correlation coefficient\n",
    "            correlation_matrix = np.corrcoef(valid_r2_x, valid_r2_y)\n",
    "            correlation_xy = correlation_matrix[0, 1]\n",
    "            r2 = correlation_xy**2\n",
    "            print(f'This is r2: {r2}')\n",
    "            \n",
    "            # Annotate R2 value on the plot\n",
    "            #if set_annotate:\n",
    "            ax.annotate(f'R² = {r2:.2f}', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=25, \n",
    "                        horizontalalignment='right', verticalalignment='top', backgroundcolor='white')\n",
    "        else:\n",
    "            print(\"Not enough valid data to calculate R².\")\n",
    "            \n",
    "    # --------------------\n",
    "    # Print out analysis\n",
    "    # --------------------\n",
    "    if var_x == 'Plume_Age' and var_y in ['cal_OH_mean', 'cal_OH_median']:\n",
    "        # ---------------------\n",
    "        # The first timeframe\n",
    "        # The first hour\n",
    "        # ---------------------\n",
    "        filtered_data_obs_first = all_data_obs_combined[all_data_obs_combined[var_x] < 40/60]\n",
    "        filtered_data_obs_first = filtered_data_obs_first.dropna(subset=[var_y])\n",
    "        # Calculate the slope\n",
    "        slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress((filtered_data_obs_first[var_x]).astype(float),  (filtered_data_obs_first[var_y]).astype(float))\n",
    "        # Calculate the mean values and std err within the timeframe\n",
    "        mean_value, std_dev = filtered_data_obs_first[var_y].mean(), filtered_data_obs_first[var_y].std()\n",
    "        median_value, iqr_val = filtered_data_obs_first[var_y].median(), iqr(filtered_data_obs_first[var_y])\n",
    "        # Print the mean and standard deviation\n",
    "        print(f'The mean/std value of first hour (1E6 molec/cm3): {mean_value/1E6:.1f}±{std_dev/1E6:.1f}')\n",
    "        print(f'The median/iqr value of first hour (1E6 molec/cm3): {median_value/1E6:.1f}±{iqr_val/1E6:.1f}')\n",
    "        # --------------------\n",
    "        # The second timeframe\n",
    "        # 1-3 hours\n",
    "        # --------------------\n",
    "        filtered_data_obs_second = all_data_obs_combined[(all_data_obs_combined[var_x] > 1) & (all_data_obs_combined[var_x] < 3)]\n",
    "        filtered_data_obs_second = filtered_data_obs_second.dropna(subset=[var_y])\n",
    "        # Calculate the slope\n",
    "        slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress((filtered_data_obs_second[var_x]).astype(float),  (filtered_data_obs_second[var_y]).astype(float))\n",
    "        # Calculate the mean values and std err within the timeframe\n",
    "        mean_value, std_dev = filtered_data_obs_second[var_y].mean(), filtered_data_obs_second[var_y].std()\n",
    "        median_value, iqr_val = filtered_data_obs_second[var_y].median(), iqr(filtered_data_obs_second[var_y])\n",
    "        # Print the mean and standard deviation\n",
    "        print(f'The mean/std value of second hour (1E6 molec/cm3): {mean_value/1E6:.1f}±{std_dev/1E6:.1f}')\n",
    "        print(f'The median/iqr value of second hour (1E6 molec/cm3): {median_value/1E6:.1f}±{iqr_val/1E6:.1f}')\n",
    "        # --------------------\n",
    "        # Reference datapoints\n",
    "        # --------------------\n",
    "        x_points = [40/60, 40/60, 1.2, 20/60, 21/60, 45/60, 53/60, 56/60, 32/60]\n",
    "        y_points = [1.7E7, 1.14E7, 4.1E6, 4E6, 8.9E6, 4E6, 3E6, 2.8E6, 3.5E6]\n",
    "        labels = ['Hobbs et al. (2003)', 'Yokelson et al. (2009)', 'Yokelson et al. (2009)', 'Palm et al. (2021)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)']\n",
    "        markers = ['*', 's', 's', 'P', '^', '^', '^', '^', '^']\n",
    "        \n",
    "        # Track labels that have been annotated\n",
    "        annotated_labels = set()\n",
    "        \n",
    "        # Plot each point using corresponding marker and size\n",
    "        for xp, yp, label, marker in zip(x_points, y_points, labels, markers):\n",
    "            ax.scatter(xp, yp, marker=marker, color='black', s=100, label='_nolegend_')  # Use corresponding marker\n",
    "        \n",
    "            # Mute the annotation to make Lu happy\n",
    "            # Annotate the first occurrence of each label with text and a longer arrow\n",
    "            #if label not in annotated_labels:\n",
    "            #    ax.annotate(label, \n",
    "            #                xy=(xp, yp), xytext=(xp + 2, yp+8E6), \n",
    "            #                textcoords='data', fontsize=14, \n",
    "            #                arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            #                ha='left')\n",
    "            #    annotated_labels.add(label)  # Mark label as annotated\n",
    "        \n",
    "    if var_x == 'Plume_Age' and var_y == 'NEMR_HONO':\n",
    "        pct_first_data  = []\n",
    "        pct_second_data = []\n",
    "        for idx, group in enumerate(all_data_obs['Flight_ID'].unique()):\n",
    "            group_data_obs       = all_data_obs[all_data_obs[group_column] == group]\n",
    "            group_data_obs       = group_data_obs.dropna(subset=[var_x, var_y])\n",
    "            group_data_obs_first  = group_data_obs[group_data_obs[var_x] < 0.5]\n",
    "            group_data_obs_second = group_data_obs[(group_data_obs[var_x] < 1.5) & (group_data_obs[var_x] > 1)]\n",
    "            group_data_obs_third  = group_data_obs[(group_data_obs[var_x] < 2.5) & (group_data_obs[var_x] > 2)]\n",
    "            try:\n",
    "                pct_first  = 1 - group_data_obs_second[var_y].mean(skipna=True)/group_data_obs_first[var_y].mean(skipna=True)\n",
    "            except:\n",
    "                pct_first = np.nan\n",
    "            try:\n",
    "                pct_second = 1 - group_data_obs_third[var_y].mean(skipna=True)/group_data_obs_first[var_y].mean(skipna=True)\n",
    "            except:\n",
    "                pct_second = np.nan\n",
    "            pct_first_data.append(pct_first*100)\n",
    "            pct_second_data.append(pct_second*100)\n",
    "        print(f'The consumed HONO in the first hour: {np.nanmean(np.array(pct_first_data)):.1f}±{np.nanstd(np.array(pct_first_data)):.1f}%')\n",
    "        print(f'The consumed HONO in the second hour: {np.nanmean(np.array(pct_second_data)):.1f}±{np.nanstd(np.array(pct_second_data)):.1f}%')\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Average NEMR O3 per hour in each plume\n",
    "    # --------------------------------------\n",
    "    if (var_x == 'Plume_Age' or 'output' in var_x) and var_y == 'NEMR_O3':\n",
    "        nemr_o3_rate = {}\n",
    "        # Calculate the slope\n",
    "        for flight_id in all_data_obs['Flight_ID'].unique():\n",
    "            all_data_obs_each = all_data_obs[all_data_obs['Flight_ID'] == flight_id]\n",
    "            x = (all_data_obs_each[var_x]).astype(float)\n",
    "            y = (all_data_obs_each[var_y]).astype(float)\n",
    "            \n",
    "            # Remove NaN values\n",
    "            mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "            x_clean = x[mask]\n",
    "            y_clean = y[mask]\n",
    "            \n",
    "            #if len(x_clean) > 1 and len(y_clean) > 1:  # Ensure there are enough points to perform regression\n",
    "            #    # Use np.linalg.lstsq to force the intercept to zero\n",
    "            #    slope_obs_each, _, _, _ = np.linalg.lstsq(x_clean[:, np.newaxis], y_clean, rcond=None)\n",
    "            #    slope_obs_each = slope_obs_each[0]\n",
    "            #    nemr_o3_rate[flight_id] = slope_obs_each\n",
    "\n",
    "\n",
    "            # convert to numpy arrays (to allow multidimensional indexing)\n",
    "            x_arr = x_clean.to_numpy()\n",
    "            y_arr = y_clean.to_numpy()\n",
    "            mask = ~np.isnan(x_arr) & ~np.isnan(y_arr)\n",
    "        \n",
    "            if np.sum(mask) > 1:  # ensure at least two valid points\n",
    "                x_fit = x_arr[mask][:, None]\n",
    "                y_fit = y_arr[mask]\n",
    "                # least‐squares with zero intercept\n",
    "                slope_obs_each, _, _, _ = np.linalg.lstsq(x_fit, y_fit, rcond=None)\n",
    "                slope_obs_each = slope_obs_each[0]\n",
    "                nemr_o3_rate[flight_id] = slope_obs_each\n",
    "\n",
    "        print(f'This is NEMR O3 rate (ppb/h)')\n",
    "        rounded_nemr_o3_rate = {key: round(value, 2) for key, value in nemr_o3_rate.items()}\n",
    "        print(rounded_nemr_o3_rate)\n",
    "\n",
    "    if (var_x == 'Plume_Age') and (('NEMR_O3' in var_y) or ('NEMR_PAN' in var_y)):\n",
    "        # ---------------------------------\n",
    "        # Average NEMR O3 from observations\n",
    "        # ---------------------------------\n",
    "        if var_y in ['NEMR_O3', 'NEMR_PAN']:\n",
    "            scale = 100\n",
    "            unit  = '%'\n",
    "        elif var_y in ['NEMR_O3_rate', 'NEMR_PAN_rate']:\n",
    "            scale = 100\n",
    "            unit  = '% per hour'\n",
    "        else:\n",
    "            scale = 1\n",
    "            unit = 'undefined'            \n",
    "        nemr_mean          = all_data_obs[var_y].describe()['mean'] *scale\n",
    "        nemr_std           = all_data_obs[var_y].describe()['std'] * scale\n",
    "        nemr_max, nemr_min = all_data_obs[var_y].describe()['max'] * scale, all_data_obs[var_y].describe()['min'] * scale\n",
    "        mean_lagrangian_dummy = np.array(mean_lagrangian) * scale\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'The range of {var_y} for Lagarangian flights: {np.min(mean_lagrangian_dummy):.1f}, {np.max(mean_lagrangian_dummy):.1f}{unit}')\n",
    "        print(f'The stat of {var_y} for Lagarangian flights: {np.mean(mean_lagrangian_dummy):.1f}±{np.std(mean_lagrangian_dummy):.1f}{unit}')\n",
    "        print(f'The range of {var_y} for all flights: {nemr_min:.1f}{unit}, {nemr_max:.1f}{unit}')\n",
    "        print(f'The stat of {var_y} for all flights: {nemr_mean:.1f}±{nemr_std:.1f}{unit}')\n",
    "    # --------------------\n",
    "    # Reference datapoints\n",
    "    # --------------------\n",
    "    if var_y == 'NEMR_O3' and var_x == 'Plume_Age':\n",
    "        # Set up data points and their references\n",
    "        x_points = [0.5, 2, 4.5, 0.5, 2, 1, 1, 2, 1]\n",
    "        y_points = [0.015, 0.08, 0.09, 0.015,0.1, 0.09, 0.15, 0.078, 0.1]\n",
    "        markers = ['*', 's', 'P', 'P', 'P', '^', '^', '^', 'D']\n",
    "        labels = ['Hobbs et al.', 'Goode et al.', 'Akagi et al.', 'Akagi et al.', 'Akagi et al.', 'Yokelson et al.', 'Yokelson et al.', 'Yokelson et al.', 'Liu et al.']\n",
    "        arrow_lengths = [0.4, 0.12, 0.25, 0.25, 0.25, 0.2, 0.2, 0.2, 0.2]  # Example lengths in pixels\n",
    "        x_max, y_max  = ax.get_xlim()[1], ax.get_ylim()[1]\n",
    "        \n",
    "        '''\n",
    "        labels = ['Hobbs et al. (1996)', 'Goode  et al. (2000)', 'Akagi et al. (2011)',  'Akagi et al. (2012)', \n",
    "                  #'Akagi et al. (2013)', \n",
    "                  'Akagi et al. (2013)', 'Yokelson et al. (2003)', 'Yokelson et al. (2003)', 'Yokelson et al. (2009)', 'Liu et al. (2016)']\n",
    "        markers = ['*', 's', 'P', \n",
    "                   #'^', \n",
    "                   '^', 'D', 'D', 'X', 'h']\n",
    "        '''\n",
    "        # Track labels that have been annotated\n",
    "        annotated_labels = set() \n",
    "        # Mute the markers for ozone NEMR\n",
    "        #for xp, yp, label, marker, length in zip(x_points, y_points, labels, markers, arrow_lengths):\n",
    "        #    # Plot the scatters\n",
    "        #    ax.scatter(xp, yp, marker=marker, color='black', s=100, label='_nolegend_')  # Ensure markers are visible\n",
    "        #    # Define a consistent direction (e.g., upward-right)\n",
    "        #    direction = np.array([1, 2])\n",
    "        #    direction_norm = direction / np.linalg.norm(direction)\n",
    "        #    offset = direction_norm * length\n",
    "        #    offset_x, offset_y = offset[0]*x_max, offset[1]*y_max\n",
    "            \n",
    "            #Mute the arorws to make Lu happy\n",
    "    \n",
    "            #if label not in annotated_labels:\n",
    "            #    ax.annotate(label, xy=(xp, yp), \n",
    "            #                xytext=(xp+offset_x, yp + offset_y),  # Adjusting the text position relative to the data point\n",
    "            #                textcoords='data', fontsize=14,\n",
    "            #                arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            #                ha='left')\n",
    "            #    annotated_labels.add(label)  # Mark label as annotated\n",
    "\n",
    "    # ----------------------------\n",
    "    # Calculate e-folding lifetime\n",
    "    # ----------------------------\n",
    "    def calculate_efolding_lifetime(df, var_x, var_y, flight_id):\n",
    "        \"\"\"\n",
    "        Calculates and prints the e-folding lifetime of a given variable (compound concentration) against time.\n",
    "        \"\"\"\n",
    "        # Filtering out non-positive concentrations for log transformation\n",
    "        df_filtered = df[df[var_y] > 0]\n",
    "        \n",
    "        if df_filtered.empty:\n",
    "            print(f\"Skipping {flight_id} for {var_y} because no data is available after filtering.\")\n",
    "            return\n",
    "    \n",
    "        # Calculate natural log of concentration\n",
    "        ln_conc = np.log(df_filtered[var_y])\n",
    "        # Perform linear regression\n",
    "        slope, _, _, _, _ = linregress(df_filtered[var_x], ln_conc)\n",
    "        # Calculate e-folding lifetime (tau)\n",
    "        if slope != 0:\n",
    "            tau = -1 / slope\n",
    "            print(f\"E-folding lifetime ({flight_id}): {tau:.1f} hours ({var_y})\")\n",
    "        else:\n",
    "            print(f\"Skipping calculation for {flight_id} as slope is zero, leading to division by zero.\")\n",
    "\n",
    "    #VOC_list = ['Furanoids (dil)', 'Acrolein (dil)', '1,3-Butadiene (dil)', 'Formaldehyde (dil)', 'Acetaldehyde (dil)', 'Maleic anhydride (dil)']\n",
    "    VOC_list = ['Furanoids excl.', 'BIACET', 'VOCR: CO']\n",
    "\n",
    "    for flight_id in all_data_obs_combined['Flight_ID'].unique():\n",
    "        if var_x == 'Plume_Age' and var_y in VOC_list:\n",
    "            df_each_obs = all_data_obs_lagrangian[all_data_obs_lagrangian['Flight_ID'] == flight_id]\n",
    "            df_each_mod = all_data_mcm_bbvoc[all_data_mcm_bbvoc['Flight_ID'] == flight_id]\n",
    "            print('Observed efolding lifetime')\n",
    "            calculate_efolding_lifetime(df_each_obs, 'Plume_Age', var_y, flight_id)\n",
    "            print('Modeled efolding lifetime')\n",
    "            calculate_efolding_lifetime(df_each_mod, 'Plume_Age', var_y, flight_id)\n",
    "            print()\n",
    "    # ===============================================\n",
    "    # Define the NMB data for three different models\n",
    "    # ===============================================\n",
    "    nmb_data = {\n",
    "        f'$MCM_{{BBVOC}}$':nmb_values_mcm_bbvoc,\n",
    "        f'$MCM_{{GCVOC}}$': nmb_values_mcm_gcvoc,\n",
    "        'GEOS-Chem': nmb_values_gc,\n",
    "    }\n",
    "    # Create a DataFrame from the dictionary\n",
    "    df_nmb = pd.DataFrame(nmb_data)\n",
    "    print()\n",
    "    print(f'{var_y} vs {var_x} (NMB)')\n",
    "    if df_nmb.isna().any().any() or np.isinf(df_nmb).any().any():\n",
    "        print(\"Data contains NaN or Infinite values, handling...\")\n",
    "    \n",
    "        # Step 2: Handle NaNs and Infinite values\n",
    "        df_nmb = df_nmb.fillna(0)  # Replace NaNs with 0 or another appropriate value\n",
    "        df_nmb.replace([np.inf, -np.inf], 0, inplace=True)  # Replace infinities if necessary\n",
    "    # Step 3: Convert to integer safely\n",
    "    df_nmb = df_nmb.astype(int)\n",
    "\n",
    "    print(df_nmb.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793586e6-2962-4c7c-8d0c-f514407340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8*2, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'output_chem_age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Set y-axis label\n",
    "axes[0].set_ylabel(\"Norm. OHR$_{VOC}$ (s$^{-1}$ ppm$_{CO}$$^{-1}$)\", fontsize=22)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7437468-7348-4910-b64f-9c3cb930deac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d2302-d2a4-4e4f-a4e3-3cddc39b5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'output_chem_age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Set y-axis label\n",
    "axes.set_ylabel(\"Norm. OHR$_{VOC}$ (s$^{-1}$ ppm$_{CO}$$^{-1}$)\", fontsize=22)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16c0da-9fdd-40b0-9d26-ccd4f37f1bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c067a88-ebb2-41a4-b8fa-b08bcf11d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8*2, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Maleic anhydride (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'output_chem_age', 'Maleic anhydride (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9533493-e07e-4ca5-b7b2-3563a61bf361",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8*2, 5*2), sharey='row', sharex='col')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Maleic anhydride (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][0], '', set_ylabel=True, set_xlabel=False, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'output_chem_age', 'Maleic anhydride (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][1], '', set_ylabel=False, set_xlabel=False, show_legend=False, set_annotate=False)\n",
    "var_x, var_y = 'Plume_Age', 'Furanoids excl. (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][0], '', set_ylabel=True, show_legend=False, set_annotate=False)\n",
    "var_x, var_y = 'output_chem_age', 'Furanoids excl. (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e28a1-4d89-445f-befc-1d2632cd9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8*2, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Acrolein (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'output_chem_age', 'Acrolein (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01b035-676e-47f1-b366-59ecdd29ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8*2, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Formaldehyde (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'output_chem_age', 'Formaldehyde (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b242034-19db-4967-8c87-b3fe74b95dc4",
   "metadata": {},
   "source": [
    "#### Figure S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b85558-90f4-409d-b405-d2c30796838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Formaldehyde (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=True, set_annotate=True)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab8fcc-d1fc-4090-b704-a5491bc835fb",
   "metadata": {},
   "source": [
    "#### Figure S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9e679-6f29-4e39-aa07-05cba948ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_helper_test(group_column, var_x, var_y, ax, title, set_ylabel, show_legend, set_xlabel=True, set_annotate=True, plot_points=True):\n",
    "    # Select group names and corresponding legend title\n",
    "    if group_column == 'VOCR_NOxR_group': \n",
    "        unique_groups = VOCR_NOxR_group_names\n",
    "        legend_title = 'OHRvoc: OHRnox'   \n",
    "    elif group_column == 'Flight_ID':\n",
    "        unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "        legend_title = 'Flight ID'\n",
    "\n",
    "    # The slope of NEMR O3 vs plume age\n",
    "    mean_lagrangian = []\n",
    "    nmb_values_mcm_bbvoc = {}\n",
    "    nmb_values_mcm_gcvoc = {}\n",
    "    nmb_values_gc = {}\n",
    "    color_flight = {}\n",
    "    \n",
    "    # Set up colors\n",
    "    if group_column == 'Flight_ID':\n",
    "        unique_groups = desired_order_flights\n",
    "    if len(unique_groups) == 6:\n",
    "        group_colors = np.array([\n",
    "            [0.80645161, 1.0, 0.16129032, 1.0],\n",
    "            [0.5, 0.0, 0.0, 1.0],\n",
    "            [0.0, 0.0, 0.5, 1.0],\n",
    "            [0.0, 0.3, 1.0, 1.0],\n",
    "            [1.0, 0.40740741, 0.0, 1.0],\n",
    "            [0.16129032, 1.0, 0.80645161, 1.0],\n",
    "        ])\n",
    "\n",
    "        group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "    \n",
    "    else:\n",
    "        group_colors = plt.cm.jet(np.linspace(0, 1, len(unique_groups)))\n",
    "\n",
    "    dummy_handles = []  # For storing dummy scatter artists for the legend\n",
    "\n",
    "    OH_cal_VOCs = ['Furan', 'Furfural', 'Furanone', 'Furan: CO', 'Furfural: CO', 'Furanone: CO']\n",
    "    for idx, group in enumerate(unique_groups):\n",
    "        if group not in Lagrangian_flights: continue\n",
    "        skip_P3B_conditions     = ((group == 'P-3B') and ('PAN' in var_y)) or  \\\n",
    "                                    ((group == 'P-3B') and (var_y in OH_cal_VOCs)) or  \\\n",
    "                                    ((group == 'P-3B') and ('NO2' in var_y)) or \\\n",
    "                                    ((group == 'P-3B') and ('NO' in var_y)) or \\\n",
    "                                    ((group == 'P-3B') and (var_y == 'NEMR_Benzene'))\n",
    "\n",
    "        skip_GCVOC_conditions   =  (var_y in OH_cal_VOCs) or (var_y == 'NEMR_Benzene')\n",
    "        skip_nonLang_conditions = ('output' in var_x) and ('NEMR_O3' in var_y or 'NEMR_PAN' in var_y) and (group == 'Other WE-CAN flights') \n",
    "        # Skip P-3B for calculated chemical age\n",
    "        if skip_P3B_conditions:\n",
    "            print('skip P-3B for missing PAN data')\n",
    "            continue\n",
    "        if skip_nonLang_conditions:\n",
    "            print('skip non-Lagrangian flights')\n",
    "            continue\n",
    "\n",
    "        # Replace calculated OH/chemical age from actual OH in MCMBBVOC        \n",
    "        group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]            \n",
    "        group_data_obs  = group_data_obs.dropna(subset=[var_x, var_y])\n",
    "        x_obs, y_obs    = (group_data_obs[var_x]).astype(float), (group_data_obs[var_y]).astype(float)\n",
    "        valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "        \n",
    "        if group in Lagrangian_flights: mean_lagrangian.append(y_obs[valid_indices].mean())\n",
    "\n",
    "        # Plot observational data if available\n",
    "        if valid_indices.any():\n",
    "            # Determine if the circle should be solid or open based on the flight\n",
    "            face_color = group_colors[idx]\n",
    "            if plot_points:\n",
    "                # 1) Plot dots even they are not in Lagrangian flights\n",
    "                if \"dil\" not in var_y:\n",
    "                    if group_column == 'Flight_ID': \n",
    "                        if group not in Lagrangian_flights: continue\n",
    "                        face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "                        #face_color = 'none' # To make Lu happy, VOC plot\n",
    "                        sc = ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "                    else:\n",
    "                        sc = ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=group)\n",
    "                        \n",
    "                # 2) Plot dots only when they are in Lagrangian flights and var_y is specific.\n",
    "                # dil for model VOC evalutions, \n",
    "                if 'dil' in var_y and group in Lagrangian_flights:\n",
    "                    if np.all(y_obs[valid_indices] == 0):\n",
    "                        continue\n",
    "                    else:\n",
    "                        if group_column == 'Flight_ID': \n",
    "                            face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "                            #face_color = 'none' # To make Lu happy, VOC plot\n",
    "                            sc = ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "                        else:\n",
    "                            sc= ax.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=group)\n",
    "            else:\n",
    "                # Plot an empty (dummy) scatter so that the legend gets an entry\n",
    "                face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "                sc = ax.scatter([], [], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group, group))\n",
    "                dummy_handles.append(sc)\n",
    "            \n",
    "            # Perform linear regression\n",
    "            if plot_points: slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "        \n",
    "        # Group model results with flight ID instead.\n",
    "        if (group_column == 'Flight_ID') and (group in Lagrangian_flights):            \n",
    "            group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "            group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "            group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "\n",
    "            # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "            bin_size = 10/60 if var_y == 'LROx: LNOx' else 0.25 # 30/15 minutes in hours\n",
    "            group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "            group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "            group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "            group_data_gc_binned             = group_data_gc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "            # Choose what we want to smooth the model results\n",
    "            # Binned model data if we are using actual OH related varialbe\n",
    "            if ('output' in var_y or 'output' in var_x) or (var_x=='Plume_Age' and var_y=='LROx: LNOx'):\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x]).astype(float), (group_data_mcm_bbvoc_binned[var_y]).astype(float)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x]).astype(float), (group_data_mcm_gcvoc_binned[var_y]).astype(float)\n",
    "                x_gc, y_gc               = (group_data_gc_binned[var_x]).astype(float), (group_data_gc_binned[var_y]).astype(float)\n",
    "            else:\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc[var_x]).astype(float), (group_data_mcm_bbvoc[var_y]).astype(float)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc[var_x]).astype(float), (group_data_mcm_gcvoc[var_y]).astype(float)\n",
    "                x_gc, y_gc               = (group_data_gc[var_x]).astype(float), (group_data_gc[var_y]).astype(float)\n",
    "            \n",
    "            valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                                ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                                ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "            \n",
    "            x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "            x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "            x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "\n",
    "            # Smoothen the data, Lixu\n",
    "            if (var_x, var_y) == ('Plume_Age', 'CH2O: NO2') or (var_x, var_y) == ('Plume_Age', 'OHRnox: OHRvoc'):\n",
    "                x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=10/60)\n",
    "                x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=10/60)\n",
    "                x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=10/60)\n",
    "\n",
    "            if (var_x, var_y) == ('Plume_Age', 'LROx: LNOx'):\n",
    "                if group == 'P-3B':\n",
    "                    x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=10/60)\n",
    "                    x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=10/60)\n",
    "                    x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=10/60)\n",
    "                else:\n",
    "                    x_mcm_bbvoc, y_mcm_bbvoc = bin_data(x_mcm_bbvoc, y_mcm_bbvoc, bin_width=30/60)\n",
    "                    x_mcm_gcvoc, y_mcm_gcvoc = bin_data(x_mcm_gcvoc, y_mcm_gcvoc, bin_width=30/60)\n",
    "                    x_gc, y_gc               = bin_data(x_gc, y_gc, bin_width=30/60)\n",
    "\n",
    "            \n",
    "            # Add solid lines for model output\n",
    "            if plot_points: \n",
    "                if valid_indices_mod.any():\n",
    "                    ax.plot(x_mcm_bbvoc, y_mcm_bbvoc, \n",
    "                            color = group_colors[idx], linestyle='-', linewidth=4, label=id2fire_name.get(group,group))\n",
    "                    # Define keys to check in corresponding dictionaries\n",
    "                    check_conditions = {\n",
    "                        var_x: ['output'],\n",
    "                        var_y: ['Furanoids excl.', 'Acrolein', 'BIACET', 'Butadiene', 'Butanedione', 'Diacetyl',  'Maleic anhydride']\n",
    "                    }\n",
    "                    \n",
    "                    # Check if all specified keys are missing in their respective dictionaries\n",
    "                    if all(key not in dictionary for dictionary, keys in check_conditions.items() for key in keys):\n",
    "                        if not skip_GCVOC_conditions:\n",
    "                            ax.plot(x_mcm_gcvoc, y_mcm_gcvoc, \n",
    "                                    color=group_colors[idx], linestyle='--', linewidth=4)\n",
    "                            ax.plot(x_gc, y_gc, \n",
    "                                    color=group_colors[idx], linestyle=':', linewidth=4)\n",
    "            else:\n",
    "                ax.scatter([], [], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group, group))\n",
    "\n",
    "            # ------------------------\n",
    "            # Calculate the model error\n",
    "            # -------------------------\n",
    "            # Only when observation exists\n",
    "            if valid_indices.any():\n",
    "                # Define the degree of the polynomial model       \n",
    "                degree = 2 if group!='FN19' else 1\n",
    "                # Create a polynomial regression model\n",
    "                poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "                # Fit the polynomial regression model on observational data\n",
    "                poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "                # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "                x_model       = x_mcm_bbvoc\n",
    "                y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "            # Using mcmbbvoc as the observation\n",
    "            else:\n",
    "                y_predicted = y_mcm_bbvoc\n",
    "            # Calculate Normalized Median Bias (NMB)\n",
    "            #nmb_mcm_bbvoc               = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            #nmb_mcm_gcvoc               = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            #nmb_gc                      = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "            # Calculate Normalized Mean Bias (NMB)\n",
    "            nmb_mcm_bbvoc = 100 * np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "            nmb_mcm_gcvoc = 100 * np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "            nmb_gc        = 100 * np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "\n",
    "            \n",
    "            # After calculating NMB\n",
    "            nmb_values_mcm_bbvoc[group] = nmb_mcm_bbvoc\n",
    "            nmb_values_mcm_gcvoc[group] = nmb_mcm_gcvoc\n",
    "            nmb_values_gc[group]        = nmb_gc\n",
    "            color_flight[group]         = group_colors[idx]\n",
    "\n",
    "        # Defalt setting for title, ticks, and labels\n",
    "        if set_xlabel: ax.set_xlabel(text_labels.get(var_x, var_x), fontsize=25)\n",
    "        if set_ylabel: ax.set_ylabel(text_labels.get(var_y, var_y), fontsize=25)\n",
    "        ax.set_title(title, fontsize=25)\n",
    "        ax.tick_params(axis='both', labelsize=20)\n",
    "        # Legend        \n",
    "        if show_legend:\n",
    "            desired_order = desired_order_flights\n",
    "            reorder_legend(ax, desired_order, id2fire_name, fontsize=20, title_fontsize = 15, legend_loc='center')\n",
    "    \n",
    "    # Conditional to check if we are analyzing the right variables\n",
    "    #if (var_x, var_y) == ('output_chem_age', 'NEMR_O3') or (var_x, var_y) == ('output_chem_age', 'NEMR_PAN'):\n",
    "    if var_x == 'output_chem_age':\n",
    "        # Compute valid indices (indices where neither x nor y are NaN)\n",
    "        valid_indices_all = ~np.isnan(all_data_obs_lagrangian[var_x]) & ~np.isnan(all_data_obs_lagrangian[var_y])\n",
    "    \n",
    "        # Use valid indices to select data for R^2 calculation\n",
    "        valid_r2_x = all_data_obs_lagrangian[var_x][valid_indices_all]\n",
    "        valid_r2_y = all_data_obs_lagrangian[var_y][valid_indices_all]\n",
    "    \n",
    "        # Compute R^2 value only if there are enough valid data points\n",
    "        if len(valid_r2_x) > 1:\n",
    "            # Calculate correlation coefficient\n",
    "            correlation_matrix = np.corrcoef(valid_r2_x, valid_r2_y)\n",
    "            correlation_xy = correlation_matrix[0, 1]\n",
    "            r2 = correlation_xy**2\n",
    "            print(f'This is r2: {r2}')\n",
    "            \n",
    "            # Annotate R2 value on the plot\n",
    "            if plot_points:\n",
    "                ax.annotate(f'R² = {r2:.2f}', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=25, \n",
    "                            horizontalalignment='right', verticalalignment='top', backgroundcolor='white')\n",
    "        else:\n",
    "            print(\"Not enough valid data to calculate R².\")\n",
    "            \n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7*2, 5*2))\n",
    "# Select variable\n",
    "var_x, var_y = 'output_chem_age', 'VOCR: CO'\n",
    "plot_data_helper_test('Flight_ID', var_x, var_y,  axes[0][0], '', set_ylabel=True, set_xlabel=False, show_legend=False, set_annotate=False, plot_points=True)\n",
    "\n",
    "var_x, var_y = 'output_chem_age', 'Maleic anhydride (dil)'\n",
    "plot_data_helper_test('Flight_ID', var_x, var_y,  axes[0][1], '', set_ylabel=False, set_xlabel=False, show_legend=True, set_annotate=False, plot_points=False)\n",
    "\n",
    "var_x, var_y = 'output_chem_age', 'Maleic anhydride (dil)'\n",
    "plot_data_helper_test('Flight_ID', var_x, var_y,  axes[1][0], '', set_ylabel=True, show_legend=False, set_annotate=False, plot_points=True)\n",
    "\n",
    "var_x, var_y = 'output_chem_age', 'Furanoids excl. (dil)'\n",
    "plot_data_helper_test('Flight_ID', var_x, var_y,  axes[1][1], '', set_ylabel=True, show_legend=False, set_annotate=False, plot_points=True)\n",
    "\n",
    "# Hide x and y ticks\n",
    "axes[0][0].set_xticks([])\n",
    "axes[0][1].set_xticks([])\n",
    "axes[0][1].set_yticks([])\n",
    "# Hide the frame (axes spines)\n",
    "for spine in axes[0][1].spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Change the label name\n",
    "axes[0][0].set_ylabel('Norm. OHR$_{VOC}$ (s$^{-1}$ ppm$_{CO}$$^{-1}$)', fontsize=20)\n",
    "axes[1][0].set_ylabel('Maleic anhydride (ppb)', fontsize=24)\n",
    "axes[1][1].set_ylabel('Furanoid excl. (ppb)', fontsize=24)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.05)  # Lower hspace brings rows closer together.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc67e02-b231-4038-b33c-eba5960c7c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357812f-038e-4a2e-be9b-9610da94f9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced6604-90fb-44dd-a3ae-9dbd7cb32dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb448b-c34e-4767-9b45-f70eb3611e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143209bc-7ea5-4515-ad30-3518f9be4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8*2, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'output_chem_age', 'VOCR: CO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cddc4-5ef2-4304-bfe0-dd9b158d3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_mcm_bbvoc['NEMR_Benzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173dc4e-c59f-4efd-9015-1221c8034ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_mcm_gcvoc['NEMR_Benzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d33b6a-91d1-4cb0-aad2-a2b69365d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_obs_lagrangian[all_data_obs_lagrangian['Flight_ID']=='P-3B']['NEMR_Benzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40daf0-436f-4d6f-8943-51c3f5331112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853982e4-0880-4bfe-b8cb-c76f239df023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of lagrangian flights\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8*1, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_Benzene'\n",
    "plot_data_helper_test('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=False, set_annotate=False)\n",
    "\n",
    "# Set y-axis range (e.g., from 0 to 10)\n",
    "axes.set_ylim(0, 0.003)\n",
    "# Set y-axis label\n",
    "axes.set_ylabel(\"ΔBenzene/ΔCO (ppb/ppb)\")\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e29b9-1568-426e-846b-3d47c0a45df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC decay\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8*3, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Furan'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'Plume_Age', 'Furfural'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "var_x, var_y = 'Plume_Age', 'Furanone'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[2], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "# Set y-axis range (e.g., from 0 to 10)\n",
    "#axes.set_ylim(0, 0.003)\n",
    "# Set y-axis label\n",
    "axes[0].set_ylabel(\"Mixing ratio (ppb)\")\n",
    "\n",
    "# Set up title\n",
    "axes[0].set_title(\"Furan\", fontsize=25)\n",
    "axes[1].set_title(\"Furfural\", fontsize=25)\n",
    "axes[2].set_title(\"Furanone\", fontsize=25)\n",
    "\n",
    "# Adding a line at 50 ppt (0.05 ppb)\n",
    "axes[0].axhline(y=0.1, color='black', linestyle='-', label='50 ppt', linewidth=2)\n",
    "axes[1].axhline(y=0.1, color='black', linestyle='-', linewidth=2)\n",
    "axes[2].axhline(y=0.1, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf6e725-15df-4449-8906-ae93b05e42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC decay\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8*3, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False)\n",
    "var_x, var_y = 'Plume_Age', 'NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "var_x, var_y = 'Plume_Age', 'NOx'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[2], '', set_ylabel=False, show_legend=False, set_annotate=False)\n",
    "# Set y-axis range (e.g., from 0 to 10)\n",
    "axes[0].set_ylim(0, 0.1)\n",
    "axes[1].set_ylim(0, 0.1)\n",
    "axes[2].set_ylim(0, 0.1)\n",
    "\n",
    "# Set y-axis label\n",
    "axes[0].set_ylabel(\"Mixing ratio (ppb)\")\n",
    "\n",
    "# Set up title\n",
    "axes[0].set_title(\"NO\", fontsize=25)\n",
    "axes[1].set_title(\"NO2\", fontsize=25)\n",
    "axes[2].set_title(\"NOx\", fontsize=25)\n",
    "\n",
    "# Adding a line at 50 ppt (0.05 ppb)\n",
    "axes[0].axhline(y=0.1, color='black', linestyle='-', label='50 ppt', linewidth=2)\n",
    "axes[1].axhline(y=0.1, color='black', linestyle='-', linewidth=2)\n",
    "axes[2].axhline(y=0.1, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bec9f-6ccd-4520-9a12-87f522a72df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7d9ac-4b49-4c6e-bff0-844c7449989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Group by Flight_ID\n",
    "grouped = all_data_obs_lagrangian.groupby('Flight_ID', as_index=False)\n",
    "\n",
    "all_diffs        = []  # to store percent changes from all flights\n",
    "all_diffs_before = []  # to store percent changes from all flights\n",
    "all_diffs_after  = []  # to store percent changes from all flights\n",
    "\n",
    "for flight, grp in grouped:\n",
    "    # 2. Sort each group by Plume_Age (ascending)\n",
    "    grp = grp.sort_values(by='Plume_Age').reset_index(drop=True)\n",
    "    \n",
    "    # 3. Compute consecutive percent changes in furan:CO ratio\n",
    "    ratio_values = grp['Furan: CO'].values\n",
    "    \n",
    "    for i in range(len(ratio_values) - 1):\n",
    "        # Avoid division by zero\n",
    "        if ratio_values[i] != 0:\n",
    "            # Percent change = ((next - current) / current) * 100\n",
    "            diff_percent = 100 * (ratio_values[i+1] - ratio_values[i]) / ratio_values[i]\n",
    "            \n",
    "            if diff_percent < 0:\n",
    "                all_diffs.append(diff_percent)\n",
    "                if grp['Plume_Age'][i] < 2.5: all_diffs_before.append(diff_percent)\n",
    "                if grp['Plume_Age'][i] > 2.5: all_diffs_after.append(diff_percent)\n",
    "\n",
    "# 4. Summarize across all flights\n",
    "mean_diff        = np.mean(all_diffs)\n",
    "min_diff         = np.min(all_diffs)\n",
    "max_diff         = np.max(all_diffs)\n",
    "\n",
    "mean_diff_before = np.mean(all_diffs_before)\n",
    "min_diff_before  = np.min(all_diffs_before)\n",
    "max_diff_before  = np.max(all_diffs_before)\n",
    "\n",
    "mean_diff_after = np.mean(all_diffs_after)\n",
    "min_diff_after  = np.min(all_diffs_after)\n",
    "max_diff_after  = np.max(all_diffs_after)\n",
    "\n",
    "# Print the statistics\n",
    "print(f\"Mean percent change in Furan:CO between consecutive transects: {mean_diff:.2f}%\")\n",
    "print(f\"Minimum percent change: {min_diff:.2f}%\")\n",
    "print(f\"Maximum percent change: {max_diff:.2f}%\")\n",
    "print(f\"Before 2.5 hours - Mean: {mean_diff_before:.2f}%, Min: {min_diff_before:.2f}%, Max: {max_diff_before:.2f}%\")\n",
    "print(f\"After 2.5 hours - Mean: {mean_diff_after:.2f}%, Min: {min_diff_after:.2f}%, Max: {max_diff_after:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53230d0a-78d7-45a7-8350-de65cbf78e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO and NO2\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8*3, 6*2), sharex='col')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_NO'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][0], '', set_ylabel=True, show_legend=True)\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][1], '', set_ylabel=True, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'NO: NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0][2], '', set_ylabel=True, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_NOx'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][0], '', set_ylabel=True, show_legend=False)\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_HNO3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1][1], '', set_ylabel=True, show_legend=False)\n",
    "\n",
    "\n",
    "# Set up y label\n",
    "'''\n",
    "axes[0][0].set_ylabel('ΔNO/ΔCO', fontsize=25)\n",
    "axes[0][1].set_ylabel('ΔNO$_{2}$/ΔCO', fontsize=25)\n",
    "axes[1][0].set_ylabel('ΔNO$_{x}$/ΔCO', fontsize=25)\n",
    "axes[1][1].set_ylabel('ΔNO$_{x}$/ΔCO', fontsize=25)\n",
    "'''\n",
    "\n",
    "axes[0][0].set_ylabel('ΔNO/ΔCO', fontsize=25)\n",
    "axes[0][1].set_ylabel('ΔNO$_{2}$/ΔCO', fontsize=25)\n",
    "axes[0][2].set_ylabel('NO: NO$_{2}$', fontsize=25)\n",
    "axes[1][0].set_ylabel('ΔNO$_{X}$/ΔCO', fontsize=25)\n",
    "axes[1][1].set_ylabel('ΔHNO$_{3}$/ΔCO', fontsize=25)\n",
    "\n",
    "# y limit\n",
    "axes[0][0].set_ylim(0)\n",
    "axes[0][1].set_ylim(0)\n",
    "axes[0][2].set_ylim(0)\n",
    "axes[1][0].set_ylim(0)\n",
    "axes[1][1].set_ylim(0)\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436534d0-dfef-4382-818f-26a0dbbf4e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76ecc8-adc3-44ea-a547-fec995dc8051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebd295-47df-42c1-9762-c9e5583470f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d21152-592f-4fa5-99f2-cb64b4ff0807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476036a2-80d5-414c-9b56-e723fdd018d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0970d-5615-4c02-9641-ab763e49e533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48780989-824b-4292-9f45-be7aeb657195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d6ed9-c7f8-4de4-9b5f-0b0e687e1630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb57c75-b1bc-4853-a1e7-400e444d5fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf51cec-5808-4b06-a972-36bf2dd2fd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26ec0a-5e40-405b-a2be-2eb8a2f97ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99870e-c85e-42fb-abc7-89d1cac73a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO and NO2\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8*2, 6*1))\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[0], '', set_ylabel=True, show_legend=True, set_annotate=False )\n",
    "axes[0].set_ylabel('ΔNO$_{2}$/ΔCO', fontsize=25)\n",
    "axes[0].set_ylim(0)\n",
    "\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NEMR_HNO3'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes[1], '', set_ylabel=True, show_legend=True, set_annotate=False )\n",
    "axes[1].set_ylabel('ΔHNO$_{3}$/ΔCO', fontsize=25)\n",
    "axes[1].set_ylim(0)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f0fba-5f3a-427d-b8cd-bcf0145885e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175768b4-8935-4a3f-b517-33edc3fb4da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a5e10-6573-40ec-9d89-de4cb0270543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99b873-a730-461e-8275-ff85b0bbe349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO and NO2\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8*1, 6*1), sharey='row')\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'NO: NO2'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=False )\n",
    "axes.set_ylabel('NO: NO2', fontsize=25)\n",
    "axes.set_ylim(0)\n",
    "\n",
    "# Increase the legend size for the first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa18701-8aba-4e95-b335-60925c956645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4dd8b-3c39-414d-9d66-3fe1c4f8f803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a774b-fb5a-4d30-8bf4-da30f87d97fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66ad0e-3e6b-42a6-9960-bdca870e619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea71ca-9ee5-44f1-b0c2-374a1982f29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e0346-4fe4-4c95-9d66-2203a1912be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43403cbe-d3eb-4033-8688-2c411f0b0e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a143a-9828-42bd-8904-73a505c855a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d589b-4379-4a99-acf9-723ea3b0d78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2a9f58-081a-4907-9228-652ccc8c8376",
   "metadata": {},
   "source": [
    "#### Updated Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62a930-05e8-493d-a814-5925e46923df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# OH calculation method\n",
    "# ---------------------\n",
    "# Plotting\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12*2, 9), sharey=False)\n",
    "# ==================================================\n",
    "# Calculated OH concentration vs direct model output\n",
    "# Analysis in the maintext\n",
    "# ==================================================\n",
    "# Select variable\n",
    "var_x_obs, var_y_obs = 'Plume_Age', 'cal_OH_mean'\n",
    "var_x_mod, var_y_mod = 'Plume_Age', 'output_OH'\n",
    "group_column = 'Flight_ID'\n",
    "set_ylabel=True\n",
    "show_legend=True\n",
    "title = 'Plume-center OH concentrations'\n",
    "# Legend\n",
    "legend_title = 'Flight ID'\n",
    "show_legend  = True\n",
    "# The slope of NEMR O3 vs plume age\n",
    "mean_lagrangian = []\n",
    "nmb_values_mcm_bbvoc = {}\n",
    "nmb_values_mcm_gcvoc = {}\n",
    "nmb_values_gc = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time = {}\n",
    "nmb_values_mcm_gcvoc_less_time = {}\n",
    "nmb_values_gc_less_time        = {}\n",
    "\n",
    "nmb_values_voc_numbers1 = {}\n",
    "nmb_values_voc_numbers2 = {}\n",
    "nmb_values_mechanisms  = {}\n",
    "color_flight = {}\n",
    "# Set up colors\n",
    "unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "unique_groups = np.array(['P-3B', 'RF03', 'RF07', 'RF09', 'FN19', 'Other WE-CAN flights'])\n",
    "\n",
    "if len(unique_groups) == 6:\n",
    "    group_colors = np.array([\n",
    "        [0.80645161, 1.0, 0.16129032, 1.0],\n",
    "        [0.5, 0.0, 0.0, 1.0],\n",
    "        [0.0, 0.0, 0.5, 1.0],\n",
    "        [0.0, 0.3, 1.0, 1.0],\n",
    "        [1.0, 0.40740741, 0.0, 1.0],\n",
    "        [0.16129032, 1.0, 0.80645161, 1.0],\n",
    "    ])\n",
    "\n",
    "    group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "\n",
    "for idx, group in enumerate(unique_groups):\n",
    "    '''\n",
    "    # Skip P-3B for calculated chemical age\n",
    "    if group == 'P-3B' and conditions:\n",
    "        print('skip P-3B for its unresonable chemical age')\n",
    "        continue\n",
    "    '''\n",
    "    group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]\n",
    "    group_data_obs  = group_data_obs.dropna(subset=[var_x_obs, var_y_obs])\n",
    "    x_obs, y_obs    = (group_data_obs[var_x_obs]).astype(float), (group_data_obs[var_y_obs]).astype(float)\n",
    "\n",
    "    \n",
    "    if group == 'RF07': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.541500] # Based on CO and HONO\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    if group == 'RF09': \n",
    "        # Define the target plume ages for which the OH concentration should be set to NaN\n",
    "        target_ages = [3.744000,  4.620500, 4.093667] #4.391833,\n",
    "        # Create a mask where the rounded plume ages match any of the target ages\n",
    "        mask = x_obs.round(6).isin(target_ages)\n",
    "        # Set corresponding OH concentration values in data2 to np.nan\n",
    "        y_obs[mask] = np.nan\n",
    "    \n",
    "    valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "    \n",
    "    # Plot observational data if available\n",
    "    if valid_indices.any():\n",
    "        # Determine if the circle should be solid or open based on the flight\n",
    "        face_color = group_colors[idx]\n",
    "        # Plot dots even they are not in Lagrangian flights\n",
    "        if group_column == 'Flight_ID': \n",
    "            if group not in Lagrangian_flights: continue\n",
    "            \n",
    "            '''\n",
    "            face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "            axes.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "            '''\n",
    "            \n",
    "            # Determine the face color based on the flight\n",
    "            edge_color  = group_colors[idx]  # Color from your color map\n",
    "            marker_size = 100  # Adjust this value as needed\n",
    "            alpha_value = 1\n",
    "            #edge_color = \"none\" # comment it out if we want to remove dots\n",
    "            \n",
    "            if group in ['RF03', 'RF07', 'RF09']:\n",
    "                edge_color  = edge_color\n",
    "                face_color  = edge_color  # Use the edge color to fill markers\n",
    "                #face_color = \"none\"  # comment it out if we want to remove dots\n",
    "                linewidth  = 5\n",
    "            else:\n",
    "                edge_color = \"none\"\n",
    "                face_color = \"none\"  # remove dots\n",
    "                linewidth  = 5\n",
    "\n",
    "            # Plot actual scatter data with hollow markers\n",
    "            axes[0].scatter(x_obs[valid_indices], y_obs[valid_indices]/1E6, edgecolors=edge_color, facecolors=face_color, label='_nolegend_', s=marker_size, alpha=alpha_value)\n",
    "            # Plot dummy scatter just for creating the legend entry\n",
    "            axes[0].scatter([], [], edgecolors=group_colors[idx], facecolors=group_colors[idx], label=id2fire_name.get(group, group), s=100)\n",
    "\n",
    "        \n",
    "        # Perform linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "\n",
    "    # Group model results with flight ID instead.\n",
    "    if (group_column == 'Flight_ID') and (group in Lagrangian_flights):\n",
    "        group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "        group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "        group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "        # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "        # Assuming Plume_Age is in hours, 0.25 hours is equivalent to 15 minutes\n",
    "        bin_size = 0.25  # 15 minutes in hours\n",
    "        group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "        group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "        group_data_gc_binned             = group_data_gc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x_mod]).astype(float), (group_data_mcm_bbvoc_binned[var_y_mod]).astype(float)\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x_mod]).astype(float), (group_data_mcm_gcvoc_binned[var_y_mod]).astype(float)\n",
    "        x_gc, y_gc               = (group_data_gc_binned[var_x_mod]).astype(float), (group_data_gc_binned[var_y_mod]).astype(float)\n",
    "\n",
    "        valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                            ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                            ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "        x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "\n",
    "        # Add solid lines for model output\n",
    "        if valid_indices_mod.any():\n",
    "            axes[0].plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', linewidth = linewidth)\n",
    "            axes[0].plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', linewidth = linewidth) # make Lu happy\n",
    "            axes[0].plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy       \n",
    "        else:\n",
    "            axes[0].plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes[0].plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes[0].plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy\n",
    "\n",
    "        # ------------------------\n",
    "        # Calculate the model error\n",
    "        # -------------------------\n",
    "        # Only when observation exists\n",
    "        if valid_indices.any():\n",
    "            # Define the degree of the polynomial model       \n",
    "            degree = 2 if group!='FN19' else 1\n",
    "            # Create a polynomial regression model\n",
    "            poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "            # Fit the polynomial regression model on observational data\n",
    "            poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "            # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "            x_model       = x_mcm_bbvoc\n",
    "            y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "        # Using mcmbbvoc as the observation\n",
    "        else:\n",
    "            y_predicted = y_mcm_bbvoc\n",
    "\n",
    "        # Calculate Normalized Median Bias (NMB)        \n",
    "        #nmb_mcm_bbvoc   = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_mcm_gcvoc   = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_gc          = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        nmb_mcm_bbvoc = 100 * np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_mcm_gcvoc = 100 * np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_gc        = 100 * np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "                \n",
    "        # Define a new set of valid indices where x_obs is less than 2\n",
    "        indices_less_time       = x_model < 2.5\n",
    "        \n",
    "        #nmb_mcm_bbvoc_less_time = 100 * (np.nanmedian(y_mcm_bbvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_mcm_gcvoc_less_time = 100 * (np.nanmedian(y_mcm_gcvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_gc_less_time        = 100 * (np.nanmedian(y_gc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        nmb_mcm_bbvoc_less_time = 100 * np.nansum(y_mcm_bbvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_mcm_gcvoc_less_time = 100 * np.nansum(y_mcm_gcvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_gc_less_time        = 100 * np.nansum(y_gc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "                \n",
    "        # Calculate differences among models\n",
    "        #nmb_voc_numbers1= 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_voc_numbers2= 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_mechanisms  = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_gcvoc)) / np.nanmedian(y_mcm_gcvoc)\n",
    "        nmb_voc_numbers1 = 100 * np.nansum(y_mcm_gcvoc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_voc_numbers2 = 100 * np.nansum(y_gc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_mechanisms   = 100 * np.nansum(y_gc - y_mcm_gcvoc) / np.nansum(y_mcm_gcvoc)\n",
    "                \n",
    "        # After calculating NMB\n",
    "        nmb_values_mcm_bbvoc[group]   = nmb_mcm_bbvoc\n",
    "        nmb_values_mcm_gcvoc[group]   = nmb_mcm_gcvoc\n",
    "        nmb_values_gc[group]          = nmb_gc\n",
    "\n",
    "        nmb_values_mcm_bbvoc_less_time[group]   = nmb_mcm_bbvoc_less_time\n",
    "        nmb_values_mcm_gcvoc_less_time[group]   = nmb_mcm_gcvoc_less_time\n",
    "        nmb_values_gc_less_time[group]          = nmb_gc_less_time\n",
    "\n",
    "        nmb_values_voc_numbers1[group]= nmb_voc_numbers1\n",
    "        nmb_values_voc_numbers2[group]= nmb_voc_numbers2\n",
    "        nmb_values_mechanisms[group]  = nmb_mechanisms\n",
    "        color_flight[group]           = group_colors[idx]\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Annotation settings\n",
    "# -------------------\n",
    "# Calculate median and interquartile range (IQR)\n",
    "nmb_values_mcm_bbvoc_array    = np.array(list(nmb_values_mcm_bbvoc.values()), dtype=float)\n",
    "nmb_values_mcm_gcvoc_array    = np.array(list(nmb_values_mcm_gcvoc.values()), dtype=float)\n",
    "nmb_values_gc_array           = np.array(list(nmb_values_gc.values()), dtype=float)\n",
    "nmb_values_voc_numbers1_array = np.array(list(nmb_values_voc_numbers1.values()), dtype=float)\n",
    "nmb_values_voc_numbers2_array = np.array(list(nmb_values_voc_numbers2.values()), dtype=float)\n",
    "nmb_values_mechanisms_array   = np.array(list(nmb_values_mechanisms.values()), dtype=float)\n",
    "\n",
    "\n",
    "median_mcm_bbvoc, q1_mcm_bbvoc, q3_mcm_bbvoc          = np.nanmedian(nmb_values_mcm_bbvoc_array), np.nanpercentile(nmb_values_mcm_bbvoc_array, 25), np.nanpercentile(nmb_values_mcm_bbvoc_array, 75)\n",
    "median_mcm_gcvoc, q1_mcm_gcvoc, q3_mcm_gcvoc          = np.nanmedian(nmb_values_mcm_gcvoc_array), np.nanpercentile(nmb_values_mcm_gcvoc_array, 25), np.nanpercentile(nmb_values_mcm_gcvoc_array, 75)\n",
    "median_gc, q1_gc, q3_gc                               = np.nanmedian(nmb_values_gc_array), np.nanpercentile(nmb_values_gc_array, 25), np.nanpercentile(nmb_values_gc_array, 75)\n",
    "median_voc_numbers1, q1_voc_numbers1, q3_voc_numbers1 = np.nanmedian(nmb_values_voc_numbers1_array), np.nanpercentile(nmb_values_voc_numbers1_array, 25), np.nanpercentile(nmb_values_voc_numbers1_array, 75)\n",
    "median_voc_numbers2, q1_voc_numbers2, q3_voc_numbers2 = np.nanmedian(nmb_values_voc_numbers2_array), np.nanpercentile(nmb_values_voc_numbers2_array, 25), np.nanpercentile(nmb_values_voc_numbers2_array, 75)\n",
    "median_mechanisms, q1_mechanisms, q3_mechanisms       = np.nanmedian(nmb_values_mechanisms_array), np.nanpercentile(nmb_values_mechanisms_array, 25), np.nanpercentile(nmb_values_mechanisms_array, 75)\n",
    "\n",
    "iqr_mcm_bbvoc    = q3_mcm_bbvoc - q1_mcm_bbvoc\n",
    "iqr_mcm_gcvoc    = q3_mcm_gcvoc - q1_mcm_gcvoc\n",
    "iqr_gc           = q3_gc - q1_gc\n",
    "iqr_voc_numbers1 = q3_voc_numbers1 - q1_voc_numbers1\n",
    "iqr_voc_numbers2 = q3_voc_numbers2 - q1_voc_numbers2\n",
    "iqr_mechanisms   = q3_mechanisms - q1_mechanisms\n",
    "# Calculate mean and standard deviation\n",
    "mean_mcm_bbvoc, std_mcm_bbvoc       = np.nanmean(nmb_values_mcm_bbvoc_array), np.nanstd(nmb_values_mcm_bbvoc_array)\n",
    "mean_mcm_gcvoc, std_mcm_gcvoc       = np.nanmean(nmb_values_mcm_gcvoc_array), np.nanstd(nmb_values_mcm_gcvoc_array)\n",
    "mean_gc, std_gc                     = np.nanmean(nmb_values_gc_array), np.nanstd(nmb_values_gc_array)\n",
    "mean_voc_numbers1, std_voc_numbers1 = np.nanmean(nmb_values_voc_numbers1_array), np.nanstd(nmb_values_voc_numbers1_array)\n",
    "mean_voc_numbers2, std_voc_numbers2 = np.nanmean(nmb_values_voc_numbers2_array), np.nanstd(nmb_values_voc_numbers2_array)\n",
    "mean_mechanisms, std_mechanisms     = np.nanmean(nmb_values_mechanisms_array), np.nanstd(nmb_values_mechanisms_array)\n",
    "\n",
    "'''\n",
    "# Annotate mean ± std in each subplot\n",
    "# Determine if we want to show bias for each individual flights or the average of flights.\n",
    "xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "axes.annotate(f\"NMB:({median_mcm_bbvoc:.0f}±{iqr_mcm_bbvoc:.0f})%\", \n",
    "             xy=xy,  # Position of the annotation\n",
    "             xycoords='axes fraction',\n",
    "             ha=ha, va=va,  # Alignment of the text\n",
    "             fontsize=20,  # Font size of the text\n",
    "             color=color)  # Color of the text\n",
    "'''\n",
    "\n",
    "\n",
    "# Desired order of keys\n",
    "desired_order = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']\n",
    "# Desired order of keys\n",
    "nmb_values_mcm_bbvoc_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc[key]) for key in desired_order if key in nmb_values_mcm_bbvoc)\n",
    "nmb_values_mcm_gcvoc_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc[key]) for key in desired_order if key in nmb_values_mcm_gcvoc)\n",
    "nmb_values_gc_ordered           = OrderedDict((key, nmb_values_gc[key]) for key in desired_order if key in nmb_values_gc)\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_less_time)\n",
    "nmb_values_mcm_gcvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_less_time)\n",
    "nmb_values_gc_less_time_ordered           = OrderedDict((key, nmb_values_gc_less_time[key]) for key in desired_order if key in nmb_values_gc_less_time)\n",
    "\n",
    "nmb_values_voc_numbers1_ordered = OrderedDict((key, nmb_values_voc_numbers1[key]) for key in desired_order if key in nmb_values_voc_numbers1)\n",
    "nmb_values_voc_numbers2_ordered = OrderedDict((key, nmb_values_voc_numbers2[key]) for key in desired_order if key in nmb_values_voc_numbers2)\n",
    "nmb_values_mechanisms_ordered   = OrderedDict((key, nmb_values_mechanisms[key]) for key in desired_order if key in nmb_values_mechanisms)\n",
    "\n",
    "for idx, group in enumerate(nmb_values_mcm_bbvoc_ordered):\n",
    "    # Extract the name and perform the split operation outside the f-string\n",
    "    nmb_value_mcm_bbvoc    = nmb_values_mcm_bbvoc_ordered[group]\n",
    "    nmb_value_mcm_gcvoc    = nmb_values_mcm_gcvoc_ordered[group]\n",
    "    nmb_value_gc           = nmb_values_gc_ordered[group]\n",
    "    nmb_value_voc_numbers1 = nmb_values_voc_numbers1_ordered[group]\n",
    "    nmb_value_voc_numbers2 = nmb_values_voc_numbers2_ordered[group]\n",
    "    nmb_value_mechanisms   = nmb_values_mechanisms_ordered[group]\n",
    "    color     = color_flight[group]\n",
    "    # Check if the group requires a box\n",
    "    if group in ['FN19', 'RF03']:\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"none\", lw=2, ec=color, alpha=0.7)\n",
    "    else:\n",
    "        bbox_props = None\n",
    "# Assuming you want to align floating-point numbers with up to 1 decimal place\n",
    "max_width = 2  # total digits for integer part\n",
    "decimal_places = 0  # digits after decimal\n",
    "start_y = 0.38\n",
    "\n",
    "\n",
    "# Showing NMB for RF03 with white background for text\n",
    "axes[0].annotate(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.08),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"GEOS-Chem: {nmb_values_gc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.16),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print(\"RF03 (<2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "\n",
    "print(\"RF07 (>2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "print(\"RF09  (<2.5h)\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Reference datapoints\n",
    "# --------------------\n",
    "x_points = [40/60, 40/60, 1.2, 20/60, 21/60, 45/60, 53/60, 56/60, 32/60]\n",
    "y_points = [1.7E7, 1.14E7, 4.1E6, 4E6, 8.9E6, 4E6, 3E6, 2.8E6, 3.5E6]\n",
    "labels = ['Hobbs et al. (2003)', 'Yokelson et al. (2009)', 'Yokelson et al. (2009)', 'Palm et al. (2021)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)']\n",
    "\n",
    "markers = ['*', 's', 's', 'P', '^', '^', '^', '^', '^']\n",
    "# Track labels that have been annotated\n",
    "annotated_labels = set()\n",
    "# Plot each point using corresponding marker and size\n",
    "for xp, yp, label, marker in zip(x_points, y_points, labels, markers):\n",
    "    axes[0].scatter(xp, yp/1E6, marker=marker, color='black', s=300, label='_nolegend_', zorder=888)  # Use corresponding marker\n",
    "    # Mute the annotation to make Lu happy\n",
    "    '''\n",
    "    # Annotate the first occurrence of each label with text and a longer arrow\n",
    "    if label not in annotated_labels:\n",
    "        axes[0].annotate(label, \n",
    "                    #xy=(xp, yp), xytext=(xp + 2, yp+8E6), \n",
    "                    xy=(xp, yp/1E6), xytext=(xp + 1, (yp+8E6)/1E6), \n",
    "                    textcoords='data', fontsize=14, \n",
    "                    arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "                    ha='left')\n",
    "        annotated_labels.add(label)  # Mark label as annotated\n",
    "    '''\n",
    "# --------------------\n",
    "# Print out analysis\n",
    "# Maintext analysis\n",
    "# --------------------\n",
    "# Function to calculate statistics for each hour time frame\n",
    "def calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour):\n",
    "    # Calculate the slope\n",
    "    slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress(filtered_data_obs[var_x_obs].astype(float), filtered_data_obs[var_y_obs].astype(float))\n",
    "    # Calculate the mean values and std err within the timeframe\n",
    "    mean_val, std_dev   = filtered_data_obs[var_y_obs].mean(), filtered_data_obs[var_y_obs].std()\n",
    "    median_val, iqr_val = filtered_data_obs[var_y_obs].median(), iqr(filtered_data_obs[var_y_obs])\n",
    "    min_value, max_value= __builtins__.min(filtered_data_obs[var_y_obs]), __builtins__.max(filtered_data_obs[var_y_obs])\n",
    "    if var_y_obs in ['output_OH', 'cal_OH_mean']: \n",
    "        unit  = '1E6 molec/cm3'\n",
    "        scale =  1/1E6\n",
    "    elif var_y_obs in ['NEMR_PAN', 'NEMR_PAN_rate']:\n",
    "        unit  = '%'\n",
    "        scale =  100\n",
    "    else:\n",
    "        unit  = 'non-defined'\n",
    "        scale =  1\n",
    "    \n",
    "    # Print the mean and standard deviation\n",
    "    print(f'Time Frame: {hour} hour')\n",
    "    print(f'The mean/std value ({unit}): {mean_val*scale:.1f}±{std_dev*scale:.1f}')\n",
    "    print(f'The median/iqr value ({unit}): {median_val*scale:.1f}±{iqr_val*scale:.1f}')\n",
    "    print(f'min and max value ({unit}): {min_value*scale:.1f}, {max_value*scale:.1f}')\n",
    "    print()\n",
    "\n",
    "# The observed OH concentration over the initial 40 minutes\n",
    "initial_minutes = 40 / 60  # Convert 40 minutes into hours for comparison with Plume_Age in hours\n",
    "# Filter data for the initial 40 minutes\n",
    "filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] <= initial_minutes)]\n",
    "filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "# Check if the DataFrame is not empty before proceeding\n",
    "if not filtered_data_obs.empty:\n",
    "    # Calculate statistics for the initial 40 minutes\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "else:\n",
    "    print(\"No data available for the initial 40 minutes.\")\n",
    "# Calculate it for each flight\n",
    "for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "    all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "    filtered_data_obs_each = all_data_obs_combined_each[all_data_obs_combined_each[var_x_obs] <= initial_minutes]\n",
    "    # Check if the DataFrame is empty\n",
    "    if not filtered_data_obs_each.empty:\n",
    "        print(f\"Calculating for Flight ID: {flight_id} for the initial 40 minutes\")\n",
    "        calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "    else:\n",
    "        print(f\"Skipping {flight_id} for the initial 40 minutes because the data is empty.\")\n",
    "\n",
    "# The observed OH concentration over time\n",
    "for hour in range(1, 6):\n",
    "    # Filter data for the current time frame\n",
    "    filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] > (hour - 1)) & (all_data_obs_combined[var_x_obs] < hour)]\n",
    "    filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "    # Calculate statistics for the current time frame\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour)\n",
    "\n",
    "    # Calculate it for each flight\n",
    "    for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "        all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "        filtered_data_obs_each     = all_data_obs_combined_each[(all_data_obs_combined_each[var_x_obs] > (hour - 1)) & (all_data_obs_combined_each[var_x_obs] < hour)]\n",
    "        # Check if the DataFrame is empty\n",
    "        if not filtered_data_obs_each.empty:\n",
    "            print(flight_id)\n",
    "            calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, hour)\n",
    "        else:\n",
    "            print(f\"Skipping {flight_id} at hour {hour} because the data is empty.\")\n",
    "\n",
    "# The model differences among model simulations\n",
    "# Print the mean +/- std\n",
    "print('Model differences among three model simulations')\n",
    "print(f'Mean ± Std (VOC init 1) : {nmb_values_voc_numbers1_array.mean():.0f} ± {nmb_values_voc_numbers1_array.std():.0f}')\n",
    "print(f'Mean ± Std (VOC init 2) : {nmb_values_voc_numbers2_array.mean():.0f} ± {nmb_values_voc_numbers2_array.std():.0f}')\n",
    "print(f'Mean ± Std (mechanism): {nmb_values_mechanisms_array.mean():.0f} ± {nmb_values_mechanisms_array.std():.0f}')\n",
    "\n",
    "# ----------------------------\n",
    "# Chemical age vs Physical age\n",
    "# ----------------------------\n",
    "# Define age segments and corresponding colors\n",
    "# Define age segments and corresponding colors\n",
    "age_segments = [(0, 0.5), (0.5, 1), (1, 1.5), (1.5, 2), (2, 2.5), (2.5, 3), (3, np.inf)]\n",
    "age_segments = [(0,  1), (1, 2), (2, 3), (3, 4), (4, 5), (5, np.inf)]\n",
    "colors       = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange', 'tab:grey']\n",
    "\n",
    "# Set up figure and axes\n",
    "var_x = 'Plume_Age'\n",
    "var_y = 'output_chem_age'\n",
    "clean_data = all_data_mcm_bbvoc.dropna(subset=[var_x, var_y])\n",
    "\n",
    "\n",
    "# Resetting min and max if they were overridden\n",
    "try:\n",
    "    del min  # Only if 'min' was redefined\n",
    "    del max  # Only if 'max' was redefined\n",
    "except NameError as e:\n",
    "    print(\"Error:\", e)\n",
    "# Find the overall range for plotting the 1:1 line\n",
    "min_val = __builtins__.min(__builtins__.min(clean_data[var_x]), __builtins__.min(clean_data[var_y]))\n",
    "max_val = __builtins__.max(__builtins__.max(clean_data[var_x]), __builtins__.max(clean_data[var_y]))\n",
    "\n",
    "# Loop through each age segment\n",
    "for (start, end), color in zip(age_segments, colors):\n",
    "    segment = clean_data[(clean_data[var_x] >= start) & (clean_data[var_x] < end)]\n",
    "    bin_size = 30/60.0/60.0  # 15 minutes in hours, adjust if needed\n",
    "    segment['Time_Bin'] = (segment[var_x] // bin_size) * bin_size\n",
    "    segment_binned = segment.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "    axes[1].scatter(segment_binned[var_x], segment_binned[var_y], color=color, alpha=0.5, s=50)\n",
    "\n",
    "    if not segment.empty:\n",
    "        X = segment_binned[var_x].values.reshape(-1, 1)\n",
    "        y = segment_binned[var_y].values\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(X, y)\n",
    "        slope = model.coef_[0]\n",
    "        label = f'>{start} h: Slope={slope:.1f}' if np.isinf(end) else f'{start}-{end} h: Slope={slope:.1f}'\n",
    "        y_vals = np.linspace(0, segment_binned[var_y].max(), 100)\n",
    "        x_vals = y_vals / slope\n",
    "        axes[1].plot(x_vals, y_vals, color=color, label=label, linewidth=5)\n",
    "\n",
    "\n",
    "# Defalt setting for title, ticks, and labels\n",
    "axes[0].set_xlabel(text_labels.get(var_x_obs, var_x_obs), fontsize=30)\n",
    "axes[0].set_ylabel(text_labels.get(var_y_obs, var_y_obs), fontsize=30)\n",
    "axes[0].tick_params(axis='both', labelsize=30)\n",
    "axes[0].set_ylim(0, 3E7/1E6)  # Set y limits from min y to calculated upper limit\n",
    "# Set the x-axis limit\n",
    "axes[0].set_xlim([0, 5])  # None means no lower limit, 8 is the upper limit\n",
    "\n",
    "# Draw horizontal line and add annotation for the first subplot\n",
    "axes[0].axhline(y=1.5, color='black', linestyle='-', linewidth=3)\n",
    "\n",
    "'''\n",
    "axes[0].annotate('Ambient OH level', fontsize=25,\n",
    "                 xy=(0.75, 1.2), xytext=(0.90, 1.2),\n",
    "                 textcoords='data', ha='center', va='top')\n",
    "'''\n",
    "# Legend\n",
    "show_legend=1\n",
    "if show_legend:\n",
    "    if group_column == 'Flight_ID':\n",
    "        desired_order = desired_order_flights\n",
    "        reorder_legend(axes[0], desired_order, id2fire_name, fontsize=20, legend_loc='upper right')\n",
    "        #reorder_legend(axes[0], desired_order, id2fire_name, fontsize=20, legend_loc='upper left')\n",
    "\n",
    "# Add the 1:1 line\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'k--', label='1:1 Line')\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=30)\n",
    "axes[1].set_xlabel('Physical age (hour)', fontsize=30)\n",
    "axes[1].set_ylabel('Chemical age (hour)', fontsize=30)\n",
    "axes[1].legend(fontsize=25)\n",
    "axes[1].yaxis.set_major_formatter(ScalarFormatter())  # Optional: To format the y-axis ticks into readable numbers\n",
    "axes[1].xaxis.set_major_formatter(ScalarFormatter())\n",
    "# Set x-axis ticks to every 2 hours\n",
    "axes[1].xaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "\n",
    "\n",
    "# Annotation for subplot (a)\n",
    "axes[0].text(0.02, 0.95, '(a)', transform=axes[0].transAxes, fontsize=16, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Set y-axis limits\n",
    "#axes[0].set_ylim(0, 25)  # This sets the minimum to 0 and the maximum to 20\n",
    "axes[0].set_ylim(0, 25)  # This sets the minimum to 0 and the maximum to 20\n",
    "# Annotation for subplot (b)\n",
    "axes[1].text(0.02, 0.95, '(b)', transform=axes[1].transAxes, fontsize=16, fontweight='bold', va='top', ha='left')\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbb89d-0d8a-442a-a815-dceb4ab06290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb30667-69a4-44c1-8865-b4c81c53346c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79f5f9-e18f-4c41-9d3b-5dc4c6f95987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e3945-5119-4b7d-8f4b-e91cb098839b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fe18a-ebb7-4918-a9cd-92d2dd176aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e098ab-6665-48e1-9fb9-ec79d2fca09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_order_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2c560-129f-40c2-bfc1-10f027dbb55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e420ec1-e718-4f2e-8514-51de825caaa3",
   "metadata": {},
   "source": [
    "#### Figure X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45871c5-349e-4b88-b9a5-4ecc5292eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# OH calculation method\n",
    "# ---------------------\n",
    "# Plotting\n",
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12*1, 9), sharey=False)\n",
    "# ==================================================\n",
    "# Calculated OH concentration vs direct model output\n",
    "# Analysis in the maintext\n",
    "# ==================================================\n",
    "# Select variable\n",
    "var_x_obs, var_y_obs = 'Plume_Age', 'cal_OH_wide_mean'\n",
    "var_x_mod, var_y_mod = 'Plume_Age', 'output_OH'\n",
    "group_column = 'Flight_ID'\n",
    "set_ylabel=True\n",
    "show_legend=True\n",
    "title = 'Plume-center OH concentrations'\n",
    "# Legend\n",
    "legend_title = 'Flight ID'\n",
    "show_legend  = True\n",
    "# The slope of NEMR O3 vs plume age\n",
    "mean_lagrangian = []\n",
    "nmb_values_mcm_bbvoc = {}\n",
    "nmb_values_mcm_gcvoc = {}\n",
    "nmb_values_gc = {}\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time = {}\n",
    "nmb_values_mcm_gcvoc_less_time = {}\n",
    "nmb_values_gc_less_time        = {}\n",
    "\n",
    "nmb_values_voc_numbers1 = {}\n",
    "nmb_values_voc_numbers2 = {}\n",
    "nmb_values_mechanisms  = {}\n",
    "color_flight = {}\n",
    "# Set up colors\n",
    "unique_groups = all_data_obs_combined['Flight_ID'].unique()\n",
    "unique_groups = np.array(['P-3B', 'RF03', 'RF07', 'RF09', 'FN19', 'Other WE-CAN flights'])\n",
    "\n",
    "if len(unique_groups) == 6:\n",
    "    group_colors = np.array([\n",
    "        [0.80645161, 1.0, 0.16129032, 1.0],\n",
    "        [0.5, 0.0, 0.0, 1.0],\n",
    "        [0.0, 0.0, 0.5, 1.0],\n",
    "        [0.0, 0.3, 1.0, 1.0],\n",
    "        [1.0, 0.40740741, 0.0, 1.0],\n",
    "        [0.16129032, 1.0, 0.80645161, 1.0],\n",
    "    ])\n",
    "\n",
    "    group_colors = ['#52b9d8', [0.5, 0.0, 0.0, 1.0], '#ff9200', [0.0, 0.3, 1.0, 1.0], '#868686', '#2e5fa1']\n",
    "\n",
    "for idx, group in enumerate(unique_groups):\n",
    "    '''\n",
    "    # Skip P-3B for calculated chemical age\n",
    "    if group == 'P-3B' and conditions:\n",
    "        print('skip P-3B for its unresonable chemical age')\n",
    "        continue\n",
    "    '''\n",
    "    group_data_obs  = all_data_obs_combined[all_data_obs_combined[group_column] == group]\n",
    "    group_data_obs  = group_data_obs.dropna(subset=[var_x_obs, var_y_obs])\n",
    "    x_obs, y_obs    = (group_data_obs[var_x_obs]).astype(float), (group_data_obs[var_y_obs]).astype(float)\n",
    "    valid_indices = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "\n",
    "    # Plot observational data if available\n",
    "    if valid_indices.any():\n",
    "        # Determine if the circle should be solid or open based on the flight\n",
    "        face_color = group_colors[idx]\n",
    "        # Plot dots even they are not in Lagrangian flights\n",
    "        if group_column == 'Flight_ID': \n",
    "            if group not in Lagrangian_flights: continue\n",
    "            \n",
    "            '''\n",
    "            face_color = group_colors[idx] if group in Lagrangian_flights else \"none\" \n",
    "            axes.scatter(x_obs[valid_indices], y_obs[valid_indices], edgecolors=group_colors[idx], facecolors=face_color, label=id2fire_name.get(group,group))\n",
    "            '''\n",
    "            \n",
    "            # Determine the face color based on the flight\n",
    "            edge_color  = group_colors[idx]  # Color from your color map\n",
    "            marker_size = 100  # Adjust this value as needed\n",
    "            alpha_value = 1\n",
    "            #edge_color = \"none\" # comment it out if we want to remove dots\n",
    "            \n",
    "            if group in ['RF03', 'RF07', 'RF09']:\n",
    "                edge_color  = edge_color\n",
    "                face_color  = edge_color  # Use the edge color to fill markers\n",
    "                #face_color = \"none\"  # comment it out if we want to remove dots\n",
    "                linewidth  = 5\n",
    "            else:\n",
    "                edge_color = \"none\"\n",
    "                face_color = \"none\"  # remove dots\n",
    "                linewidth  = 5\n",
    "\n",
    "            # Plot actual scatter data with hollow markers\n",
    "            axes.scatter(x_obs[valid_indices], y_obs[valid_indices]/1E6, edgecolors=edge_color, facecolors=face_color, label='_nolegend_', s=marker_size, alpha=alpha_value)\n",
    "            # Plot dummy scatter just for creating the legend entry\n",
    "            axes.scatter([], [], edgecolors=group_colors[idx], facecolors=group_colors[idx], label=id2fire_name.get(group, group), s=100)\n",
    "\n",
    "        \n",
    "        # Perform linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x_obs[valid_indices], y_obs[valid_indices])\n",
    "\n",
    "    # Group model results with flight ID instead.\n",
    "    if (group_column == 'Flight_ID') and (group in Lagrangian_flights):\n",
    "        group_data_mcm_bbvoc  = all_data_mcm_bbvoc[all_data_mcm_bbvoc[group_column] == group]\n",
    "        group_data_mcm_gcvoc  = all_data_mcm_gcvoc[all_data_mcm_gcvoc[group_column] == group]\n",
    "        group_data_gc         = all_data_gc[all_data_gc[group_column] == group]\n",
    "        # Binning the data based on time for every 15 minutes and averaging each bin\n",
    "        # Assuming Plume_Age is in hours, 0.25 hours is equivalent to 15 minutes\n",
    "        bin_size = 0.25  # 15 minutes in hours\n",
    "        group_data_mcm_bbvoc['Time_Bin'] = (group_data_mcm_bbvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_gcvoc['Time_Bin'] = (group_data_mcm_gcvoc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_gc['Time_Bin']        = (group_data_gc['Plume_Age'] // bin_size) * bin_size\n",
    "        group_data_mcm_bbvoc_binned      = group_data_mcm_bbvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "        group_data_mcm_gcvoc_binned      = group_data_mcm_gcvoc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "        group_data_gc_binned             = group_data_gc.groupby('Time_Bin').mean(numeric_only=True)\n",
    "\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = (group_data_mcm_bbvoc_binned[var_x_mod]).astype(float), (group_data_mcm_bbvoc_binned[var_y_mod]).astype(float)\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = (group_data_mcm_gcvoc_binned[var_x_mod]).astype(float), (group_data_mcm_gcvoc_binned[var_y_mod]).astype(float)\n",
    "        x_gc, y_gc               = (group_data_gc_binned[var_x_mod]).astype(float), (group_data_gc_binned[var_y_mod]).astype(float)\n",
    "\n",
    "        valid_indices_mod = ~np.isnan(x_mcm_bbvoc) & ~np.isnan(y_mcm_bbvoc) & \\\n",
    "                            ~np.isnan(x_mcm_gcvoc) & ~np.isnan(y_mcm_gcvoc) & \\\n",
    "                            ~np.isnan(x_gc) & ~np.isnan(y_gc)\n",
    "\n",
    "        x_mcm_bbvoc, y_mcm_bbvoc = x_mcm_bbvoc[valid_indices_mod], y_mcm_bbvoc[valid_indices_mod]\n",
    "        x_mcm_gcvoc, y_mcm_gcvoc = x_mcm_gcvoc[valid_indices_mod], y_mcm_gcvoc[valid_indices_mod]\n",
    "        x_gc, y_gc               = x_gc[valid_indices_mod],y_gc [valid_indices_mod]\n",
    "        '''\n",
    "        # Add solid lines for model output\n",
    "        if valid_indices_mod.any():\n",
    "            axes.plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', linewidth = linewidth)\n",
    "            axes.plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', linewidth = linewidth) # make Lu happy\n",
    "            axes.plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy       \n",
    "        else:\n",
    "            axes.plot(x_mcm_bbvoc, y_mcm_bbvoc/1E6, color = group_colors[idx], linestyle='-', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes.plot(x_mcm_gcvoc, y_mcm_gcvoc/1E6, color = group_colors[idx], linestyle='--', label=id2fire_name.get(group,group), linewidth = linewidth)\n",
    "            axes.plot(x_gc, y_gc/1E6, color = group_colors[idx], linestyle=':', linewidth = linewidth) # make Lu happy\n",
    "        '''\n",
    "        # ------------------------\n",
    "        # Calculate the model error\n",
    "        # -------------------------\n",
    "        # Only when observation exists\n",
    "        if valid_indices.any():\n",
    "            # Define the degree of the polynomial model       \n",
    "            degree = 2 if group!='FN19' else 1\n",
    "            # Create a polynomial regression model\n",
    "            poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "            # Fit the polynomial regression model on observational data\n",
    "            poly_model.fit(x_obs[valid_indices].values.reshape(-1, 1), y_obs[valid_indices].values)\n",
    "            # Predict VOCR using the regression model at the MCM_BB_VOC time points\n",
    "            x_model       = x_mcm_bbvoc\n",
    "            y_predicted   = poly_model.predict(x_model.values.reshape(-1, 1))\n",
    "        # Using mcmbbvoc as the observation\n",
    "        else:\n",
    "            y_predicted = y_mcm_bbvoc\n",
    "\n",
    "        # Calculate Normalized Median Bias (NMB)        \n",
    "        #nmb_mcm_bbvoc   = 100 * (np.nanmedian(y_mcm_bbvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_mcm_gcvoc   = 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        #nmb_gc          = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_predicted)) / np.nanmedian(y_predicted)\n",
    "        nmb_mcm_bbvoc = 100 * np.nansum(y_mcm_bbvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_mcm_gcvoc = 100 * np.nansum(y_mcm_gcvoc - y_predicted) / np.nansum(y_predicted)\n",
    "        nmb_gc        = 100 * np.nansum(y_gc - y_predicted) / np.nansum(y_predicted)\n",
    "\n",
    "        \n",
    "        # Define a new set of valid indices where x_obs is less than 2\n",
    "        indices_less_time       = x_model < 2\n",
    "        #nmb_mcm_bbvoc_less_time = 100 * (np.nanmedian(y_mcm_bbvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_mcm_gcvoc_less_time = 100 * (np.nanmedian(y_mcm_gcvoc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        #nmb_gc_less_time        = 100 * (np.nanmedian(y_gc[indices_less_time]) - np.nanmedian(y_predicted[indices_less_time])) / np.nanmedian(y_predicted[indices_less_time])\n",
    "        nmb_mcm_bbvoc_less_time = 100 * np.nansum(y_mcm_bbvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_mcm_gcvoc_less_time = 100 * np.nansum(y_mcm_gcvoc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        nmb_gc_less_time        = 100 * np.nansum(y_gc[indices_less_time] - y_predicted[indices_less_time]) / np.nansum(y_predicted[indices_less_time])\n",
    "        \n",
    "                \n",
    "        # Calculate differences among models\n",
    "        #nmb_voc_numbers1= 100 * (np.nanmedian(y_mcm_gcvoc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_voc_numbers2= 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_bbvoc)) / np.nanmedian(y_mcm_bbvoc)\n",
    "        #nmb_mechanisms  = 100 * (np.nanmedian(y_gc) - np.nanmedian(y_mcm_gcvoc)) / np.nanmedian(y_mcm_gcvoc)\n",
    "        nmb_voc_numbers1 = 100 * np.nansum(y_mcm_gcvoc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_voc_numbers2 = 100 * np.nansum(y_gc - y_mcm_bbvoc) / np.nansum(y_mcm_bbvoc)\n",
    "        nmb_mechanisms   = 100 * np.nansum(y_gc - y_mcm_gcvoc) / np.nansum(y_mcm_gcvoc)\n",
    "        \n",
    "        # After calculating NMB\n",
    "        nmb_values_mcm_bbvoc[group]   = nmb_mcm_bbvoc\n",
    "        nmb_values_mcm_gcvoc[group]   = nmb_mcm_gcvoc\n",
    "        nmb_values_gc[group]          = nmb_gc\n",
    "\n",
    "        nmb_values_mcm_bbvoc_less_time[group]   = nmb_mcm_bbvoc_less_time\n",
    "        nmb_values_mcm_gcvoc_less_time[group]   = nmb_mcm_gcvoc_less_time\n",
    "        nmb_values_gc_less_time[group]          = nmb_gc_less_time\n",
    "\n",
    "        nmb_values_voc_numbers1[group]= nmb_voc_numbers1\n",
    "        nmb_values_voc_numbers2[group]= nmb_voc_numbers2\n",
    "        nmb_values_mechanisms[group]  = nmb_mechanisms\n",
    "        color_flight[group]           = group_colors[idx]\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Annotation settings\n",
    "# -------------------\n",
    "# Calculate median and interquartile range (IQR)\n",
    "nmb_values_mcm_bbvoc_array    = np.array(list(nmb_values_mcm_bbvoc.values()), dtype=float)\n",
    "nmb_values_mcm_gcvoc_array    = np.array(list(nmb_values_mcm_gcvoc.values()), dtype=float)\n",
    "nmb_values_gc_array           = np.array(list(nmb_values_gc.values()), dtype=float)\n",
    "nmb_values_voc_numbers1_array = np.array(list(nmb_values_voc_numbers1.values()), dtype=float)\n",
    "nmb_values_voc_numbers2_array = np.array(list(nmb_values_voc_numbers2.values()), dtype=float)\n",
    "nmb_values_mechanisms_array   = np.array(list(nmb_values_mechanisms.values()), dtype=float)\n",
    "\n",
    "\n",
    "median_mcm_bbvoc, q1_mcm_bbvoc, q3_mcm_bbvoc          = np.nanmedian(nmb_values_mcm_bbvoc_array), np.nanpercentile(nmb_values_mcm_bbvoc_array, 25), np.nanpercentile(nmb_values_mcm_bbvoc_array, 75)\n",
    "median_mcm_gcvoc, q1_mcm_gcvoc, q3_mcm_gcvoc          = np.nanmedian(nmb_values_mcm_gcvoc_array), np.nanpercentile(nmb_values_mcm_gcvoc_array, 25), np.nanpercentile(nmb_values_mcm_gcvoc_array, 75)\n",
    "median_gc, q1_gc, q3_gc                               = np.nanmedian(nmb_values_gc_array), np.nanpercentile(nmb_values_gc_array, 25), np.nanpercentile(nmb_values_gc_array, 75)\n",
    "median_voc_numbers1, q1_voc_numbers1, q3_voc_numbers1 = np.nanmedian(nmb_values_voc_numbers1_array), np.nanpercentile(nmb_values_voc_numbers1_array, 25), np.nanpercentile(nmb_values_voc_numbers1_array, 75)\n",
    "median_voc_numbers2, q1_voc_numbers2, q3_voc_numbers2 = np.nanmedian(nmb_values_voc_numbers2_array), np.nanpercentile(nmb_values_voc_numbers2_array, 25), np.nanpercentile(nmb_values_voc_numbers2_array, 75)\n",
    "median_mechanisms, q1_mechanisms, q3_mechanisms       = np.nanmedian(nmb_values_mechanisms_array), np.nanpercentile(nmb_values_mechanisms_array, 25), np.nanpercentile(nmb_values_mechanisms_array, 75)\n",
    "\n",
    "iqr_mcm_bbvoc    = q3_mcm_bbvoc - q1_mcm_bbvoc\n",
    "iqr_mcm_gcvoc    = q3_mcm_gcvoc - q1_mcm_gcvoc\n",
    "iqr_gc           = q3_gc - q1_gc\n",
    "iqr_voc_numbers1 = q3_voc_numbers1 - q1_voc_numbers1\n",
    "iqr_voc_numbers2 = q3_voc_numbers2 - q1_voc_numbers2\n",
    "iqr_mechanisms   = q3_mechanisms - q1_mechanisms\n",
    "# Calculate mean and standard deviation\n",
    "mean_mcm_bbvoc, std_mcm_bbvoc       = np.nanmean(nmb_values_mcm_bbvoc_array), np.nanstd(nmb_values_mcm_bbvoc_array)\n",
    "mean_mcm_gcvoc, std_mcm_gcvoc       = np.nanmean(nmb_values_mcm_gcvoc_array), np.nanstd(nmb_values_mcm_gcvoc_array)\n",
    "mean_gc, std_gc                     = np.nanmean(nmb_values_gc_array), np.nanstd(nmb_values_gc_array)\n",
    "mean_voc_numbers1, std_voc_numbers1 = np.nanmean(nmb_values_voc_numbers1_array), np.nanstd(nmb_values_voc_numbers1_array)\n",
    "mean_voc_numbers2, std_voc_numbers2 = np.nanmean(nmb_values_voc_numbers2_array), np.nanstd(nmb_values_voc_numbers2_array)\n",
    "mean_mechanisms, std_mechanisms     = np.nanmean(nmb_values_mechanisms_array), np.nanstd(nmb_values_mechanisms_array)\n",
    "\n",
    "'''\n",
    "# Annotate mean ± std in each subplot\n",
    "# Determine if we want to show bias for each individual flights or the average of flights.\n",
    "xy, ha, va, color =(0.95, 0.50), 'right', 'bottom', 'black'\n",
    "axes.annotate(f\"NMB:({median_mcm_bbvoc:.0f}±{iqr_mcm_bbvoc:.0f})%\", \n",
    "             xy=xy,  # Position of the annotation\n",
    "             xycoords='axes fraction',\n",
    "             ha=ha, va=va,  # Alignment of the text\n",
    "             fontsize=20,  # Font size of the text\n",
    "             color=color)  # Color of the text\n",
    "'''\n",
    "\n",
    "\n",
    "# Desired order of keys\n",
    "desired_order = ['P-3B', 'RF03', 'RF07', 'RF09', 'FN19']\n",
    "# Desired order of keys\n",
    "nmb_values_mcm_bbvoc_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc[key]) for key in desired_order if key in nmb_values_mcm_bbvoc)\n",
    "nmb_values_mcm_gcvoc_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc[key]) for key in desired_order if key in nmb_values_mcm_gcvoc)\n",
    "nmb_values_gc_ordered           = OrderedDict((key, nmb_values_gc[key]) for key in desired_order if key in nmb_values_gc)\n",
    "\n",
    "nmb_values_mcm_bbvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_bbvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_bbvoc_less_time)\n",
    "nmb_values_mcm_gcvoc_less_time_ordered    = OrderedDict((key, nmb_values_mcm_gcvoc_less_time[key]) for key in desired_order if key in nmb_values_mcm_gcvoc_less_time)\n",
    "nmb_values_gc_less_time_ordered           = OrderedDict((key, nmb_values_gc_less_time[key]) for key in desired_order if key in nmb_values_gc_less_time)\n",
    "\n",
    "nmb_values_voc_numbers1_ordered = OrderedDict((key, nmb_values_voc_numbers1[key]) for key in desired_order if key in nmb_values_voc_numbers1)\n",
    "nmb_values_voc_numbers2_ordered = OrderedDict((key, nmb_values_voc_numbers2[key]) for key in desired_order if key in nmb_values_voc_numbers2)\n",
    "nmb_values_mechanisms_ordered   = OrderedDict((key, nmb_values_mechanisms[key]) for key in desired_order if key in nmb_values_mechanisms)\n",
    "\n",
    "for idx, group in enumerate(nmb_values_mcm_bbvoc_ordered):\n",
    "    # Extract the name and perform the split operation outside the f-string\n",
    "    nmb_value_mcm_bbvoc    = nmb_values_mcm_bbvoc_ordered[group]\n",
    "    nmb_value_mcm_gcvoc    = nmb_values_mcm_gcvoc_ordered[group]\n",
    "    nmb_value_gc           = nmb_values_gc_ordered[group]\n",
    "    nmb_value_voc_numbers1 = nmb_values_voc_numbers1_ordered[group]\n",
    "    nmb_value_voc_numbers2 = nmb_values_voc_numbers2_ordered[group]\n",
    "    nmb_value_mechanisms   = nmb_values_mechanisms_ordered[group]\n",
    "    color     = color_flight[group]\n",
    "    # Check if the group requires a box\n",
    "    if group in ['FN19', 'RF03']:\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.1\", fc=\"none\", lw=2, ec=color, alpha=0.7)\n",
    "    else:\n",
    "        bbox_props = None\n",
    "# Assuming you want to align floating-point numbers with up to 1 decimal place\n",
    "max_width = 2  # total digits for integer part\n",
    "decimal_places = 0  # digits after decimal\n",
    "start_y = 0.38\n",
    "\n",
    "'''\n",
    "# Showing NMB for RF03 with white background for text\n",
    "axes[0].annotate(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='white', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.08),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='white', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "axes[0].annotate(f\"GEOS-Chem: {nmb_values_gc_ordered['RF03']:>{max_width}.{decimal_places}f}%\",\n",
    "              xy=(0.95, start_y-0.16),  # Position of the annotation\n",
    "              xycoords='axes fraction',\n",
    "              ha='right', va='bottom',  # Alignment of the text\n",
    "              fontsize=24,  # Font size of the text\n",
    "              color=color_flight['RF03'],\n",
    "              bbox=dict(facecolor='white', edgecolor='none', boxstyle='round,pad=0.5'))  # White background\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "print(\"RF03\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF03']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "\n",
    "print(\"RF07\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF07']:>{max_width}.{decimal_places}f}%\")\n",
    "\n",
    "print(\"RF09\")\n",
    "print(f\"MCM$_{{BBVOC}}$: {nmb_values_mcm_bbvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"MCM$_{{GCVOC}}$: {nmb_values_mcm_gcvoc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "print(f\"GC: {nmb_values_gc_less_time_ordered['RF09']:>{max_width}.{decimal_places}f}%\")\n",
    "'''\n",
    "\n",
    "'''\n",
    "# --------------------\n",
    "# Reference datapoints\n",
    "# --------------------\n",
    "x_points = [40/60, 40/60, 1.2, 20/60, 21/60, 45/60, 53/60, 56/60, 32/60]\n",
    "y_points = [1.7E7, 1.14E7, 4.1E6, 4E6, 8.9E6, 4E6, 3E6, 2.8E6, 3.5E6]\n",
    "labels = ['Hobbs et al. (2003)', 'Yokelson et al. (2009)', 'Yokelson et al. (2009)', 'Palm et al. (2021)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)', 'Akherati et al. (2022)']\n",
    "\n",
    "markers = ['*', 's', 's', 'P', '^', '^', '^', '^', '^']\n",
    "# Track labels that have been annotated\n",
    "annotated_labels = set()\n",
    "# Plot each point using corresponding marker and size\n",
    "for xp, yp, label, marker in zip(x_points, y_points, labels, markers):\n",
    "    axes.scatter(xp, yp/1E6, marker=marker, color='black', s=300, label='_nolegend_', zorder=888)  # Use corresponding marker\n",
    "    # Mute the annotation to make Lu happy\n",
    "    \n",
    "    # Annotate the first occurrence of each label with text and a longer arrow\n",
    "    #if label not in annotated_labels:\n",
    "    #    axes[0].annotate(label, \n",
    "    #                #xy=(xp, yp), xytext=(xp + 2, yp+8E6), \n",
    "    #                xy=(xp, yp/1E6), xytext=(xp + 1, (yp+8E6)/1E6), \n",
    "    #                textcoords='data', fontsize=14, \n",
    "    #                arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "    #                ha='left')\n",
    "    #    annotated_labels.add(label)  # Mark label as annotated\n",
    "    \n",
    "\n",
    "'''\n",
    "# --------------------\n",
    "# Print out analysis\n",
    "# Maintext analysis\n",
    "# --------------------\n",
    "# Function to calculate statistics for each hour time frame\n",
    "def calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour):\n",
    "    # Calculate the slope\n",
    "    slope_obs, intercept_obs, r_value_obs, p_value_obs, std_err_obs = linregress(filtered_data_obs[var_x_obs].astype(float), filtered_data_obs[var_y_obs].astype(float))\n",
    "    # Calculate the mean values and std err within the timeframe\n",
    "    mean_val, std_dev   = filtered_data_obs[var_y_obs].mean(), filtered_data_obs[var_y_obs].std()\n",
    "    median_val, iqr_val = filtered_data_obs[var_y_obs].median(), iqr(filtered_data_obs[var_y_obs])\n",
    "    min_value, max_value= __builtins__.min(filtered_data_obs[var_y_obs]), __builtins__.max(filtered_data_obs[var_y_obs])\n",
    "    if var_y_obs in ['output_OH', 'cal_OH_mean']: \n",
    "        unit  = '1E6 molec/cm3'\n",
    "        scale =  1/1E6\n",
    "    elif var_y_obs in ['NEMR_PAN', 'NEMR_PAN_rate']:\n",
    "        unit  = '%'\n",
    "        scale =  100\n",
    "    else:\n",
    "        unit  = 'non-defined'\n",
    "        scale =  1\n",
    "    '''\n",
    "    # Print the mean and standard deviation\n",
    "    print(f'Time Frame: {hour} hour')\n",
    "    print(f'The mean/std value ({unit}): {mean_val*scale:.1f}±{std_dev*scale:.1f}')\n",
    "    print(f'The median/iqr value ({unit}): {median_val*scale:.1f}±{iqr_val*scale:.1f}')\n",
    "    print(f'min and max value ({unit}): {min_value*scale:.1f}, {max_value*scale:.1f}')\n",
    "    print()\n",
    "    '''\n",
    "# The observed OH concentration over the initial 40 minutes\n",
    "initial_minutes = 40 / 60  # Convert 40 minutes into hours for comparison with Plume_Age in hours\n",
    "# Filter data for the initial 40 minutes\n",
    "filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] <= initial_minutes)]\n",
    "filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "# Check if the DataFrame is not empty before proceeding\n",
    "if not filtered_data_obs.empty:\n",
    "    # Calculate statistics for the initial 40 minutes\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "else:\n",
    "    print(\"No data available for the initial 40 minutes.\")\n",
    "# Calculate it for each flight\n",
    "for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "    all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "    filtered_data_obs_each = all_data_obs_combined_each[all_data_obs_combined_each[var_x_obs] <= initial_minutes]\n",
    "    # Check if the DataFrame is empty\n",
    "    if not filtered_data_obs_each.empty:\n",
    "        print(f\"Calculating for Flight ID: {flight_id} for the initial 40 minutes\")\n",
    "        calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, \"initial 40 minutes\")\n",
    "    else:\n",
    "        print(f\"Skipping {flight_id} for the initial 40 minutes because the data is empty.\")\n",
    "\n",
    "# The observed OH concentration over time\n",
    "for hour in range(1, 6):\n",
    "    # Filter data for the current time frame\n",
    "    filtered_data_obs = all_data_obs_combined[(all_data_obs_combined[var_x_obs] > (hour - 1)) & (all_data_obs_combined[var_x_obs] < hour)]\n",
    "    filtered_data_obs = filtered_data_obs.dropna(subset=[var_y_obs])\n",
    "    # Calculate statistics for the current time frame\n",
    "    calculate_statistics(filtered_data_obs, var_x_obs, var_y_obs, hour)\n",
    "\n",
    "    # Calculate it for each flight\n",
    "    for flight_id in df_OH_mod_mcm_bbvoc['Flight_ID'].unique():\n",
    "        all_data_obs_combined_each = all_data_obs_combined[all_data_obs_combined['Flight_ID'] == flight_id]\n",
    "        filtered_data_obs_each     = all_data_obs_combined_each[(all_data_obs_combined_each[var_x_obs] > (hour - 1)) & (all_data_obs_combined_each[var_x_obs] < hour)]\n",
    "        # Check if the DataFrame is empty\n",
    "        if not filtered_data_obs_each.empty:\n",
    "            print(flight_id)\n",
    "            calculate_statistics(filtered_data_obs_each, var_x_obs, var_y_obs, hour)\n",
    "        else:\n",
    "            print(f\"Skipping {flight_id} at hour {hour} because the data is empty.\")\n",
    "'''\n",
    "# The model differences among model simulations\n",
    "# Print the mean +/- std\n",
    "print('Model differences among three model simulations')\n",
    "print(f'Mean ± Std (VOC init 1) : {nmb_values_voc_numbers1_array.mean():.0f} ± {nmb_values_voc_numbers1_array.std():.0f}')\n",
    "print(f'Mean ± Std (VOC init 2) : {nmb_values_voc_numbers2_array.mean():.0f} ± {nmb_values_voc_numbers2_array.std():.0f}')\n",
    "print(f'Mean ± Std (mechanism): {nmb_values_mechanisms_array.mean():.0f} ± {nmb_values_mechanisms_array.std():.0f}')\n",
    "'''\n",
    "# ----------------------------\n",
    "# Chemical age vs Physical age\n",
    "# ----------------------------\n",
    "# Define age segments and corresponding colors\n",
    "# Define age segments and corresponding colors\n",
    "age_segments = [(0, 0.5), (0.5, 1), (1, 1.5), (1.5, 2), (2, 2.5), (2.5, 3), (3, np.inf)]\n",
    "age_segments = [(0,  1), (1, 2), (2, 3), (3, 4), (4, 5), (5, np.inf)]\n",
    "colors       = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange', 'tab:grey']\n",
    "\n",
    "# Resetting min and max if they were overridden\n",
    "try:\n",
    "    del min  # Only if 'min' was redefined\n",
    "    del max  # Only if 'max' was redefined\n",
    "except NameError as e:\n",
    "    print(\"Error:\", e)\n",
    "# Find the overall range for plotting the 1:1 line\n",
    "min_val = __builtins__.min(__builtins__.min(clean_data[var_x]), __builtins__.min(clean_data[var_y]))\n",
    "max_val = __builtins__.max(__builtins__.max(clean_data[var_x]), __builtins__.max(clean_data[var_y]))\n",
    "\n",
    "\n",
    "# Defalt setting for title, ticks, and labels\n",
    "axes.set_xlabel(text_labels.get(var_x_obs, var_x_obs), fontsize=30)\n",
    "axes.set_ylabel(\"OH (1×10$^{6}$ molecule cm$^{-3}$)\", fontsize=30)\n",
    "axes.tick_params(axis='both', labelsize=30)\n",
    "axes.set_ylim(0, 3E7/1E6)  # Set y limits from min y to calculated upper limit\n",
    "# Set the x-axis limit\n",
    "axes.set_xlim([0, 5])  # None means no lower limit, 8 is the upper limit\n",
    "\n",
    "\n",
    "# Legend\n",
    "show_legend=1\n",
    "if show_legend:\n",
    "    if group_column == 'Flight_ID':\n",
    "        desired_order = ['RF03', 'RF07', 'RF09']\n",
    "        reorder_legend(axes, desired_order, id2fire_name, fontsize=20, legend_loc='upper right')\n",
    "  \n",
    "\n",
    "# Set y-axis limits\n",
    "axes.set_ylim(0, 20)  # This sets the minimum to 0 and the maximum to 20\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a18c59-6b19-4c5c-b969-f45c7bd46f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_order_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28c394-99f9-4f12-a504-fc310c9949e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063d876-daa7-4755-99d3-a4109d9698b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729bbd1d-0b6d-48e6-8e07-c9b3a602f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# Question: check how much will be changed with furanone being removed\n",
    "# ====================================================================\n",
    "\n",
    "# Setup a figure with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))  # Adjusted width for clarity\n",
    "plot_index = 0\n",
    "\n",
    "for id, df_calOH_raw in calOH_conc_vocs_per_flight_obs.items():\n",
    "    if id in ['RF03', 'RF07', 'RF09']:  # Specific flights for plotting\n",
    "        df_calOH = df_calOH_raw.copy()\n",
    "        df_calOH_nofuranone = df_calOH.drop(columns='Furanone', inplace=False)\n",
    "        df_calOH[\"Avg_OH\"] = df_calOH.mean(axis=1, skipna=True)\n",
    "        df_calOH_nofuranone[\"Avg_OH\"] = df_calOH_nofuranone.mean(axis=1, skipna=True)\n",
    "\n",
    "        # Plotting on specific subplot\n",
    "        ax = axes[plot_index]\n",
    "        ax.plot(df_calOH.index / 60.0, df_calOH[\"Avg_OH\"], marker='o', linestyle='-', label=\"With Furanone\")\n",
    "        ax.plot(df_calOH_nofuranone.index / 60.0, df_calOH_nofuranone[\"Avg_OH\"], marker='s', linestyle='--', label=\"Without Furanone\")\n",
    "        ax.set_xlabel(\"Plume age (hour)\", fontsize=15)\n",
    "        ax.set_title(id2fire_name.get(id, id), fontsize=12)\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Increase font size of tick labels\n",
    "        ax.tick_params(axis='both', which='major', labelsize=15)  # Adjust labelsize as needed\n",
    "\n",
    "        plot_index += 1\n",
    "\n",
    "# Set a common y-label for the entire figure\n",
    "fig.text(-0.01, 0.5, 'OH (molecule cm$^{-3}$)', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738adc6b-77a2-4223-8366-cb8ef002008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### \n",
    "# FNR threshold testing\n",
    "#######################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pwlf  # Piecewise linear fitting library\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1) Piecewise linear fitting: FNR = 5.57\n",
    "# ---------------------------------------\n",
    "NO = all_data_obs_lagrangian['NO']\n",
    "FNR = all_data_obs_lagrangian['CH2O: NO2'] \n",
    "\n",
    "# Assuming you already have the data loaded in NO and FNR arrays\n",
    "pwlf_model = pwlf.PiecewiseLinFit(NO, FNR)\n",
    "breakpoints = pwlf_model.fit(2)  # Restricting to just one breakpoint besides the ends\n",
    "\n",
    "# Determine the FNR values at the breakpoint\n",
    "breakpoint_index = np.argmin(np.abs(NO - breakpoints[1]))  # Find the index of the NO value closest to the breakpoint\n",
    "fnr_at_breakpoint = FNR[breakpoint_index]  # Get the corresponding FNR value\n",
    "\n",
    "# Predict for plotting\n",
    "x_hat = np.linspace(NO.min(), NO.max(), 100)\n",
    "y_hat = pwlf_model.predict(x_hat)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(NO, FNR, color='orange', label='Original Data')\n",
    "#plt.plot(x_hat, y_hat, color='blue', label='Piecewise Linear Fit')\n",
    "#plt.axvline(x=breakpoints[1], color='red', ls='--', label='Breakpoint at NO=' + str(round(breakpoints[1], 2)))\n",
    "plt.axhline(y=fnr_at_breakpoint, color='green', ls='--', label='FNR Threshold=' + str(round(fnr_at_breakpoint, 2)))\n",
    "plt.xlabel('NO (ppb)')\n",
    "plt.ylabel('FNR (CH2O: NO2)')\n",
    "plt.title('FNR at Significant NO Breakpoint')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Significant Breakpoint for NO:\", breakpoints[1])\n",
    "print(\"Corresponding FNR Threshold using piecewise linear regression:\", fnr_at_breakpoint)\n",
    "# ---------------------------------------\n",
    "# 2) Derivative Analysis: FNR = 6.23\n",
    "# ---------------------------------------\n",
    "# Assuming NO and FNR are numpy arrays and sorted by NO\n",
    "# Calculate the derivative of FNR with respect to NO\n",
    "derivatives = np.gradient(FNR, NO)\n",
    "\n",
    "# Plot FNR vs NO with the derivative overlay\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('NO (ppb)')\n",
    "ax1.set_ylabel('FNR', color=color)\n",
    "ax1.plot(NO, FNR, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Derivative (dFNR/dNO)', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(NO, derivatives, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.title('FNR vs NO and Rate of Change')\n",
    "plt.show()\n",
    "\n",
    "# Identifying the point where derivative changes significantly\n",
    "# Assuming the transition is from near zero to a negative value\n",
    "threshold_index = np.where(derivatives > 10)[0][0]  # Example threshold, adjust as necessary\n",
    "threshold_FNR = FNR[threshold_index]\n",
    "threshold_NO = NO[threshold_index]\n",
    "\n",
    "print(\"Threshold FNR:\", threshold_FNR)\n",
    "print(\"Corresponding NO:\", threshold_NO)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3) K-means clustering: FNR threshold = 3.88\n",
    "# --------------------------------------------\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'NO': NO,  # Your NO data\n",
    "    'FNR': FNR  # Your FNR data\n",
    "})\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[['NO', 'FNR']])\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Sorting by NO to analyze transitions\n",
    "data_sorted = data.sort_values(by='NO')\n",
    "cluster_changes = data_sorted['Cluster'].diff().abs()\n",
    "change_indices = cluster_changes[cluster_changes > 0].index\n",
    "\n",
    "# Determining more precise threshold by focusing on the mid-point between changes\n",
    "data_sorted['Midpoint_FNR'] = (data_sorted['FNR'].shift(-1) + data_sorted['FNR']) / 2\n",
    "thresholds = data_sorted.loc[change_indices, 'Midpoint_FNR']\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['blue', 'orange']  # Colors for the clusters\n",
    "for i in range(2):\n",
    "    cluster_data = data[data['Cluster'] == i]\n",
    "    plt.scatter(cluster_data['NO'], cluster_data['FNR'], color=colors[i], label=f'Cluster {i+1}')\n",
    "\n",
    "for threshold in thresholds:\n",
    "    plt.axhline(y=threshold, color='red', linestyle='--', label='FNR Threshold' if 'FNR Threshold' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "plt.title('Refined Cluster Analysis of NO and FNR with Precise Thresholds')\n",
    "plt.xlabel('NO (ppb)')\n",
    "plt.ylabel('FNR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Calculated FNR Thresholds:\")\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01876931-3477-4b6c-bbc4-632385494969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0a55f-f1a8-44e5-91de-0ed946684d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3181551-a690-48d4-8fa3-c4e95fee9b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5d23e-a61e-4dbf-8fa3-d3a341ec1ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c0bd3-fc85-40d5-98cd-5ebea6261c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a404773-d810-440c-8b6d-1ebf87aa0278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "141efa12-2c4a-4990-ad17-d58e9d864b2b",
   "metadata": {},
   "source": [
    "### Furanoids paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc7070-6dbb-4e5b-b1e4-df8cbe496f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 1x1 figure\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 9), sharey=True)\n",
    "# Select variable\n",
    "var_x, var_y = 'Plume_Age', 'Furanoids excl. (dil)'\n",
    "plot_data_helper('Flight_ID', var_x, var_y,  axes, '', set_ylabel=True, show_legend=True)\n",
    "axes.set_ylim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0dea64-c178-4815-99d5-d0b8eae16b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69c2aac7-68af-40c8-a06e-f46e1cb77e90",
   "metadata": {},
   "source": [
    "## Save processed datasets (recommended for re-use)\n",
    "\n",
    "This notebook produces several *analysis-ready* (processed) datasets that are useful\n",
    "to save and reload directly, without re-running all preprocessing steps.\n",
    "\n",
    "### What is saved\n",
    "- **all_data_obs**  \n",
    "  Observation-based data after filtering, merging, and derived-variable calculation.\n",
    "- **all_data_gc**  \n",
    "  GEOS-Chem outputs mapped to the same structure as observations.\n",
    "- **all_data_mcm_gcvoc**  \n",
    "  MCM runs constrained by GC VOCs.\n",
    "- **all_data_mcm_bbvoc**  \n",
    "  MCM runs constrained by BB VOCs.\n",
    "\n",
    "### Recommended workflow\n",
    "If you want to start from processed data in the future:\n",
    "1. Skip raw-data ingestion and preprocessing cells\n",
    "2. Load the processed files from `./processed_data/`\n",
    "3. Proceed directly to plotting or analysis\n",
    "\n",
    "Example:\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_pickle(\"./processed_data/all_data_obs.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e36cc-b670-4dd1-a610-98b90483f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets as CSV only\n",
    "outdir = \"./processed_data\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "processed_vars = [\n",
    "    \"all_data_obs\",\n",
    "    \"all_data_gc\",\n",
    "    \"all_data_mcm_gcvoc\",\n",
    "    \"all_data_mcm_bbvoc\",\n",
    "]\n",
    "\n",
    "for var in processed_vars:\n",
    "    if var in globals():\n",
    "        df = globals()[var]\n",
    "\n",
    "        # Compressed CSV (recommended: much smaller, still easy to read)\n",
    "        csv_path = os.path.join(outdir, f\"{var}.csv.gz\")\n",
    "        df.to_csv(csv_path, index=False, compression=\"gzip\")\n",
    "\n",
    "        print(f\"Saved {var} -> {csv_path} ({df.shape[0]} rows × {df.shape[1]} cols)\")\n",
    "    else:\n",
    "        print(f\"WARNING: {var} not found — run preprocessing cells first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c4960-f3b2-42b7-91d8-b8d7d4a543d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf888b-31ee-4b9e-8003-287f798188e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9151086-8c32-43f9-9a4e-371c61374f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536020c4-5a5d-446c-9547-22f0ef112fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b1863-f750-4f18-8500-30417f8c0e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1106a2-b934-4122-a306-ac6bbbf63cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03769636-833c-4157-a5cb-d57883cb0df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4430f1-ec82-4afb-bce7-dd3a742b2608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5a61f-3fef-4136-b2e4-7eb23fbcb36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2532e-df18-4346-929d-bf5bdb52852c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2279197-131c-4374-969c-05fc5e5b3cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cf950-452e-426f-a3d5-4c5187316da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811692cd-d7f6-4661-aeeb-94f500d73ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
